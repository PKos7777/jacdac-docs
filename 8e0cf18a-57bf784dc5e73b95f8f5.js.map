{"version":3,"file":"8e0cf18a-57bf784dc5e73b95f8f5.js","mappings":";;;;;AAAA,wBAAwB,mBAAO,CAAC,KAAiI;;AAEjK,mBAAO,CAAC,KAAkC;;AAE1C;AACA;AACA,oBAAoB,sBAAsB;AAC1C;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,+EAA+E,gBAAgB;AAC/F;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC,iCAAiC;AACjC;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,4DAA4D,8CAA8C;AAC1G;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,4DAA4D,8CAA8C,6CAA6C;AACvJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,UAAU;AAClC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,wBAAwB,oBAAoB;AAChF;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,iCAAiC;AACjC;;AAEA;AACA,mBAAmB,oBAAoB;AACvC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,wFAAwF,aAAa;AACrG;AACA;;AAEA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,mDAAmD,+BAA+B,qBAAM,QAAQ,qBAAM,CAAC,sDAAsD;AAC7J;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS;AACT;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,0sCAA0sC;AAC1sC,EAAE;;AAEF;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD,WAAW;AACX;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4CAA4C,cAAc;AAC1D;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;;AAEA,WAAW,aAAa;AACxB;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;;AAEA,8DAA8D,4BAA4B;AAC1F;AACA;;AAEA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,SAAS;AAC1B;;AAEA,8GAA8G,0BAA0B;AACxI;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,gBAAgB;AACtC;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0EAA0E;AAC1E;;AAEA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,aAAa;AAC9C;;AAEA,wBAAwB,SAAS;AACjC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB,UAAU;AACjC;;AAEA;AACA;;AAEA;;AAEA,2BAA2B,UAAU;AACrC;;AAEA;AACA;AACA,IAAI,wBAAwB,UAAU;AACtC;;AAEA;AACA;;AAEA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;;AAEA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,4FAA4F,eAAe;AAC3G;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,wEAAwE,eAAe;AACvF;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,oCAAoC,2BAA2B;AAC/D;;AAEA;AACA;;AAEA;AACA,2FAA2F;AAC3F;;AAEA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP,KAAK,SAAS;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA,SAAS;;AAET;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,4CAA4C;AACnE;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB;AAChB;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA;AACA;;AAEA;;AAEA,6BAA6B,iBAAiB;AAC9C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;;AAEA,2BAA2B,4BAA4B;AACvD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,yBAAyB,iBAAiB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qCAAqC;;AAErC;AACA;AACA;;AAEA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sCAAsC,WAAW;AACjD;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0EAA0E,eAAe;AACzF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,SAAS,2CAA2C;AACpD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,kBAAkB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,WAAW;;AAEX;AACA;AACA;AACA,SAAS;;AAET;AACA,QAAQ;;AAER;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,aAAa,mBAAmB;AAChC;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA,uBAAuB,aAAa;AACpC;AACA;;AAEA,0BAA0B,aAAa;AACvC;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;;AAEA,uBAAuB,WAAW;AAClC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA,GAAG;AACH;AACA;;AAEA,uBAAuB,WAAW;AAClC;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX,UAAU;AACV;AACA;;AAEA;;AAEA;AACA;AACA;AACA,WAAW;;AAEX;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa;;AAEb;AACA;AACA,aAAa;AACb;;AAEA;;AAEA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,gDAAgD,aAAa;AAC7D;AACA;;AAEA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,2BAA2B,iBAAiB;AAC5C;AACA;;AAEA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,gBAAgB;AAChB;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA;AACA,IAAI;AACJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,mBAAO,CAAC,KAAM;AAC9B;;AAEA;AACA,oFAAoF,mBAAO,CAAC,KAAY;AACxG;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA,0DAA0D;AAC1D;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,oGAAoG;AACpG;AACA;AACA;AACA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,mBAAmB;AACxC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,4BAA4B,iBAAiB;AAC7C;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI,wBAAwB,UAAU;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,0CAA0C;AAC1C;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,gEAAgE;AAChE;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,KAAK,iEAAiE;AACtE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,aAAa,uBAAuB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,kCAAkC,WAAW;AAC7C,2CAA2C;AAC3C;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;AACA,gEAAgE,qCAAqC;AACrG;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA,gCAAgC;AAChC;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,yBAAyB,UAAU;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,eAAe;AACtC;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA,8GAA8G,qBAAM,GAAG,qBAAM;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,cAAc;AACtC;AACA;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,oCAAoC,6BAA6B,cAAc;AAC/E;AACA;;AAEA,eAAe,aAAa;AAC5B;AACA;;AAEA,oBAAoB,qBAAqB;AACzC;AACA;;AAEA,+DAA+D,OAAO;AACtE;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gHAAgH,OAAO;AACvH;AACA;;AAEA,iFAAiF,OAAO;AACxF;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ,SAAS;AACjB;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,2CAA2C,MAAM;AACjD;AACA;;AAEA,eAAe,OAAO;AACtB;AACA;;AAEA;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA,wBAAwB;AACxB,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,6BAA6B,MAAM;AACnC;AACA;;AAEA,kBAAkB,OAAO;AACzB;AACA;;AAEA;AACA,sDAAsD,IAAI;AAC1D;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA,qCAAqC,aAAa;AAClD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA,GAAG;AACH,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,WAAW,GAAG;AACd;AACA;AACA;;AAEA;AACA;AACA,QAAQ;;AAER;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iLAAiL;AACjL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,OAAO;AACrF;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,uBAAuB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW,gBAAgB;AAC3B;AACA;;AAEA,kBAAkB,WAAW;AAC7B;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa,MAAM;AACnB;;AAEA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,SAAS,6BAA6B;AACtC;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;;AAEA;;AAEA,kCAAkC,cAAc;AAChD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,2BAA2B,iBAAiB;AAC5C;AACA;AACA,OAAO;AACP,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;AACA;AACA,yCAAyC,aAAa;AACtD;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,mDAAmD;AACnD;;AAEA;AACA;;AAEA;AACA;;AAEA,mDAAmD;AACnD;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC,eAAe;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA,UAAU;AACV;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,8EAA8E;AAC9E;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,UAAU;AACrC;AACA;AACA,IAAI;AACJ;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,yBAAyB;AAC9C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,UAAU;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;;AAEA,qBAAqB,iBAAiB;AACtC;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,iJAAiJ;AACjJ;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uEAAuE,GAAG;AAC1E;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,yBAAyB,UAAU;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,kCAAkC,WAAW;AAC7C,2CAA2C;AAC3C;;AAEA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,yBAAyB,2BAA2B;AACpD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,uBAAuB,uBAAu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uBAAuB,eAAe;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA,UAAU,0CAA0C,aAAa;AACjE,6BAA6B,aAAa;AAC1C;AACA;AACA,UAAU,0CAA0C,aAAa;AACjE,6BAA6B,aAAa;AAC1C,+BAA+B,aAAa;AAC5C;AACA;AACA;AACA,UAAU;AACV;;AAEA,6BAA6B,aAAa;AAC1C,+BAA+B,aAAa;AAC5C,iCAAiC,aAAa;AAC9C,mCAAmC,aAAa;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2BAA2B,UAAU;AACrC;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,qFAAqF;AACrF;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,kCAAkC,qCAAqC;AACvE;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,iCAAiC;;AAEjC;AACA;AACA;;AAEA;;AAEA;;AAEA,kCAAkC;AAClC;;AAEA;AACA,iCAAiC;;AAEjC;AACA;AACA;;AAEA;;AAEA,kCAAkC;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,kGAAkG;;AAElG;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA,UAAU;AACV;;AAEA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,sEAAsE;AACtE;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;AACA,4CAA4C;AAC5C;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,iDAAiD,0BAA0B;AAC3E;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,eAAe;AACf;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,SAAS;AACT;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,iTAAiT;AACjT;;AAEA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,mCAAmC;AAC5D;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA,KAAK;AACL,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC,eAAe;;AAEhB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;AAC1B;AACA;;AAEA;AACA;AACA,6JAA6J;AAC7J;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;;AAEA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA,6BAA6B;AAC7B;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,qBAAqB;AACrB;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;;AAEA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;;AAEA;AACA,qFAAqF,oCAAoC;AACzH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,yEAAyE;AACzE;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0BAA0B,mBAAmB,mBAAmB;AAChE;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA,mBAAmB;AACnB;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB;;AAExB;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,oBAAoB;AAC5C;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,aAAa;AAC/B;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,wGAAwG;AACxG;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,wEAAwE;AACxE;;AAEA,wBAAwB,2CAA2C;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB;AAChB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,cAAc;AACd,cAAc;AACd,cAAc;AACd,cAAc;AACd,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB,mCAAmC;AAC5D;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sDAAsD;AACtD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,4BAA4B,oCAAoC;AAChE;AACA;;AAEA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kCAAkC;AAC1D;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,2BAA2B;AAClD;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;;AAEZ;;AAEA,8BAA8B,qBAAqB;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,yBAAyB,kCAAkC;AAC3D;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,2BAA2B,kCAAkC;AAC7D;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB,kCAAkC;AAC3D;AACA;;AAEA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;;AAEA,+BAA+B,kCAAkC;AACjE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kCAAkC;AAC1D;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,cAAc;AACd;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,WAAW,OAAO;AAClB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,yIAAyI,mBAAmB;AAC5J;AACA;AACA;AACA;;AAEA;AACA,qIAAqI;AACrI;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA,uIAAuI;AACvI;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,oCAAoC,wDAAwD;AAC5F;AACA;AACA;AACA,2DAA2D;AAC3D;AACA,GAAG,EAAE;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,gDAAgD,kBAAkB;AAClE;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,qCAAqC,kBAAkB;AACvD;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,0CAA0C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA,SAAS;AACT;AACA,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,6BAA6B;AACrD;AACA;AACA;;AAEA;AACA;AACA,0BAA0B,6BAA6B;AACvD;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;;AAEA,0BAA0B,6BAA6B;AACvD;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,0DAA0D,kBAAkB;AAC5E;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,sCAAsC,kBAAkB;AACxD;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA,aAAa;AACb;AACA;AACA;AACA;;AAEA,iBAAiB,oBAAoB;AACrC;;AAEA;AACA;;AAEA,8BAA8B,kBAAkB;AAChD;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oDAAoD,kBAAkB;AACtE;AACA;AACA;AACA,aAAa;AACb,YAAY;AACZ;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,sCAAsC;AAC9D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,sBAAsB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;;AAEA,+CAA+C,oBAAoB;AACnE;AACA;;AAEA,8BAA8B,oBAAoB;AAClD;AACA;AACA;;AAEA,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,4BAA4B;AACxD;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA,4BAA4B,mCAAmC;AAC/D;;AAEA;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oCAAoC;AAChE;;AAEA,uFAAuF;AACvF;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA,0BAA0B,mCAAmC;AAC7D;;AAEA;AACA;;AAEA,0BAA0B,oCAAoC;AAC9D;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,0RAA0R;AAC1R;;AAEA;AACA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;AACA,cAAc;;AAEd;;AAEA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8CAA8C,kBAAkB;AAChE;AACA;AACA;;AAEA;AACA;;AAEA,gDAAgD,kBAAkB;AAClE;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;;AAEA,yCAAyC,iBAAiB;AAC1D;;AAEA;AACA;;AAEA;AACA,qBAAqB;AACrB;AACA;AACA;;AAEA,mCAAmC,UAAU;AAC7C;;AAEA;AACA;;AAEA;AACA,eAAe;;AAEf;AACA;AACA;AACA,aAAa;AACb,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,uUAAuU;AACvU;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;;AAEf;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,aAAa;;AAEb;;AAEA;AACA;;AAEA,mBAAmB,eAAe;AAClC;AACA;AACA;AACA;;AAEA,oDAAoD,+BAA+B;AACnF;;AAEA;AACA,4KAA4K;AAC5K;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;;AAEA;AACA;;AAEA,wCAAwC,sBAAsB;AAC9D;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,sCAAsC,qBAAqB;AAC3D;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;;AAErB,wCAAwC,+BAA+B;AACvE;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,2DAA2D;AAC7G;;AAEA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,cAAc;AACnB;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA,SAAS;;AAET;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,wHAAwH;AACxH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,iDAAiD;AACjD;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,yBAAyB;AACzB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,mDAAmD;AAC5E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,6BAA6B,oEAAoE,2PAA2P,qEAAqE;AACja;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,kBAAkB;AACvE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,6BAA6B,kDAAkD;AAC/E;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,kDAAkD;AAC3E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,iDAAiD;AAC1E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,2GAA2G;AAC3G,MAAM,kJAAkJ;AACxJ;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,4IAA4I;AAC5I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS,iGAAiG,2HAA2H;AACrO;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,mBAAmB;AAC3C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;;AAEP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,eAAe;AACzC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,2MAA2M;AAC3M,MAAM;AACN;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8JAA8J,4PAA4P;AAC1Z;AACA;;AAEA,4BAA4B,6BAA6B;AACzD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,mBAAmB;AACxB;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,SAAS;AACT,QAAQ;;AAER;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,2BAA2B;AAC3B;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,0BAA0B,8BAA8B;AACxD;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uIAAuI,iOAAiO;AACxW;AACA;;AAEA,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,0BAA0B;AAC1B;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAS;AACT,QAAQ;;AAER;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,kDAAkD,cAAc;AAChE;AACA;AACA;;AAEA;AACA,KAAK;;AAEL,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,gCAAgC;AACxD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,qBAAqB;AACrB;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,gBAAgB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB;AACzB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA,6EAA6E,kCAAkC,kCAAkC;AACjJ;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,gCAAgC,uBAAuB;AACvD;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA,cAAc;AACd;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA,0DAA0D;AAC1D;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA,UAAU;AACV;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA,UAAU;;AAEV;AACA;;AAEA;AACA;;AAEA,kCAAkC,mBAAmB;AACrD;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,6CAA6C,gDAAgD;AAC7F;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,wBAAwB;AACxB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4BAA4B;AAC5B;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,0BAA0B;AAClD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4BAA4B,wIAAwI,uGAAuG;AAC3Q;;AAEA;;AAEA,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA,sHAAsH;AACtH;AACA;AACA;AACA,uFAAuF,kEAAkE;AACzJ;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,kMAAkM;AAClM;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,iNAAiN;AACjN;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,yFAAyF;AACzF;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,CAAC,eAAe;AAChB;AACA,mEAAmE;AACnE,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,yYAAyY;AACzY;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,kBAAkB;AACzE;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,kBAAkB;AACzE;AACA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B,uBAAuB,UAAU;AACjC;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA;;AAEA,0BAA0B,oBAAoB;AAC9C;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA;AACA;;AAEA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,4BAA4B,WAAW;AACvC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,YAAY;AACxC;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,YAAY;AACxC;AACA;AACA;;AAEA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,+BAA+B,WAAW;AAC1C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,0BAA0B,eAAe;AACzC;AACA;;AAEA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA,QAAQ;AACR,4BAA4B,eAAe;AAC3C;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,UAAU;AACnC;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,0BAA0B,YAAY;AACtC;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA,wBAAwB,YAAY;AACpC;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,WAAW,YAAY;AACvB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;;AAEA,sBAAsB,yBAAyB;AAC/C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uDAAuD,YAAY;AACnE,6CAA6C,sBAAsB;AACnE;AACA;;AAEA,aAAa,sBAAsB;AACnC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA,YAAY;AACZ;AACA;AACA;AACA;;AAEA,sBAAsB,cAAc;AACpC;;AAEA,uCAAuC;AACvC;;AAEA,0BAA0B,cAAc;AACxC,4BAA4B,cAAc;AAC1C;AACA;AACA;;AAEA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC,0BAA0B,cAAc;AACxC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,iCAAiC,aAAa;AAC9C,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,aAAa;AAClD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,aAAa;AAC7C;;AAEA,mCAAmC,cAAc;AACjD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C,wBAAwB,sBAAsB;AAC9C,0BAA0B,qBAAqB;AAC/C;;AAEA;;AAEA,eAAe,QAAQ;AACvB;AACA;;AAEA;;AAEA,2BAA2B,mBAAmB;AAC9C;;AAEA;;AAEA,iBAAiB,QAAQ;AACzB;AACA;;AAEA;;AAEA;AACA;;AAEA,gCAAgC,cAAc;AAC9C;;AAEA,iCAAiC,YAAY;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,eAAe,QAAQ;AACvB;AACA;;AAEA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;;AAEA;;AAEA,iBAAiB,SAAS;AAC1B;AACA;;AAEA;AACA;;AAEA,8BAA8B,oBAAoB;AAClD;;AAEA;;AAEA,mBAAmB,SAAS;AAC5B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,kCAAkC,YAAY;AAC9C;;AAEA,qCAAqC,cAAc;AACnD;;AAEA,uCAAuC,cAAc;AACrD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK,EAAE;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,mBAAmB;AAC/C,8BAA8B,oBAAoB;AAClD,gCAAgC,mBAAmB;AACnD;AACA;AACA;;AAEA;;AAEA,kCAAkC,WAAW;AAC7C;;AAEA,4GAA4G,WAAW;AACvH;;AAEA,+GAA+G,WAAW;AAC1H;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,oBAAoB;AAChD,8BAA8B,mBAAmB;AACjD;AACA;;AAEA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,2GAA2G,WAAW;AACtH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;;AAEA,gCAAgC,sBAAsB;AACtD;;AAEA,kCAAkC,uBAAuB;AACzD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,2BAA2B,qBAAqB;AAChD,6BAA6B,sBAAsB;AACnD;;AAEA,+BAA+B,oBAAoB;AACnD,qCAAqC,cAAc;AACnD;;AAEA,wCAAwC,cAAc;AACtD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;;AAEA,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,cAAc;AACnD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,oBAAoB;AAC9C;AACA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;AACA;;AAEA,8BAA8B,qBAAqB;AACnD;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;;AAEA;AACA;;AAEA,kCAAkC,oBAAoB;AACtD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;;AAEA;;AAEA;;AAEA;;AAEA,sCAAsC,sBAAsB;AAC5D;;AAEA,wCAAwC,uBAAuB;AAC/D;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,qBAAqB;AAClD;;AAEA,+BAA+B,sBAAsB;AACrD;;AAEA,iCAAiC,oBAAoB;AACrD;AACA;;AAEA,uCAAuC,cAAc;AACrD;AACA;;AAEA,yCAAyC,cAAc;AACvD;AACA;;AAEA,2CAA2C,cAAc;AACzD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA,+BAA+B,UAAU;AACzC;AACA;AACA;;AAEA;;AAEA,sCAAsC,cAAc;AACpD;;AAEA,uCAAuC,cAAc;AACrD;;AAEA,wCAAwC,YAAY;AACpD;AACA;;AAEA,wCAAwC,WAAW;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,0DAA0D,WAAW;AACrE,8BAA8B,WAAW;AACzC;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;;AAEA;AACA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,UAAU,yBAAyB,WAAW;AAC9C;;AAEA;AACA,gCAAgC,WAAW;AAC3C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C,0BAA0B,WAAW;AACrC;;AAEA,qDAAqD;AACrD;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;AACA;;AAEA,gCAAgC,sBAAsB;AACtD;;AAEA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,2BAA2B,sBAAsB;AACjD;AACA;;AAEA;;AAEA,6BAA6B,oBAAoB;AACjD,mCAAmC,cAAc;AACjD;;AAEA,sCAAsC,cAAc;AACpD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;;AAEA,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,cAAc;AACnD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,2BAA2B,UAAU;AACrC;;AAEA,6BAA6B,UAAU;AACvC;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA,UAAU;;AAEV;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;;AAET;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,MAAM;AACN;;AAEA,wBAAwB,WAAW;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,aAAa,QAAQ;AACrB;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,8BAA8B,eAAe;AAC7C;AACA;;AAEA;;AAEA,8BAA8B,eAAe;AAC7C;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK,EAAE;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,oBAAoB;AAC7C,2BAA2B,qBAAqB;AAChD,6BAA6B,mBAAmB;AAChD;;AAEA;;AAEA,mBAAmB,QAAQ;AAC3B;AACA;;AAEA;;AAEA,gCAAgC,qBAAqB;AACrD;;AAEA;;AAEA,qBAAqB,SAAS;AAC9B;AACA;;AAEA;;AAEA,kCAAkC,oBAAoB;AACtD;;AAEA;;AAEA,uBAAuB,QAAQ;AAC/B;AACA;;AAEA;;AAEA;AACA;;AAEA,sCAAsC,aAAa;AACnD;;AAEA,yCAAyC,aAAa;AACtD;;AAEA,0CAA0C,aAAa;AACvD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,mBAAmB;AAC/C,8BAA8B,oBAAoB;AAClD,gCAAgC,mBAAmB;AACnD;AACA;AACA;;AAEA;;AAEA,kCAAkC,WAAW;AAC7C;;AAEA,4GAA4G,WAAW;AACvH;;AAEA,8GAA8G,UAAU;AACxH;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,oBAAoB;AAChD,8BAA8B,mBAAmB;AACjD;AACA;;AAEA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,2GAA2G,WAAW;AACtH;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;;AAEA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;;AAEA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;;AAEA;AACA;;AAEA,0GAA0G,WAAW;AACrH;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,gBAAgB;AACxC;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,mCAAmC,wBAAwB;AAC3D;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,oEAAoE;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;;AAEA;AACA;AACA,UAAU,sCAAsC;AAChD;;AAEA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA,OAAO;AACP,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA,mKAAmK,8CAA8C,+DAA+D,SAAS,wCAAwC,sHAAsH,SAAS,uJAAuJ,yCAAyC,SAAS,sCAAsC,iDAAiD,SAAS,2MAA2M,oEAAoE,SAAS,sCAAsC,+EAA+E,SAAS,6CAA6C,iCAAiC,sCAAsC,SAAS,+BAA+B,iDAAiD,SAAS,8CAA8C,yCAAyC,SAAS,mCAAmC,iDAAiD,SAAS;AAClhD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kFAAkF,4JAA4J;AAC9O;;AAEA;AACA;AACA;AACA,mGAAmG,sMAAsM;AACzS;;AAEA;AACA;AACA,8CAA8C,mFAAmF,KAAK;AACtI;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD,oDAAoD,2CAA2C,6CAA6C,qBAAqB,wCAAwC,OAAO,gCAAgC,4BAA4B,wCAAwC,QAAQ,wBAAwB,oDAAoD,QAAQ,yBAAyB,qDAAqD,OAAO,qCAAqC,wCAAwC,kDAAkD,gCAAgC,wBAAwB,gCAAgC,0BAA0B,kCAAkC,sCAAsC,gCAAgC,0BAA0B,mCAAmC,sCAAsC,yBAAyB,KAAK;;AAE/7B;AACA;AACA;AACA;AACA;AACA,4FAA4F,4EAA4E,SAAS,uBAAuB,sGAAsG,wEAAwE,mCAAmC,0BAA0B,KAAK,MAAM,sCAAsC,yDAAyD,+CAA+C,WAAW,2CAA2C,SAAS;AAC3oB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,4FAA4F,4EAA4E,SAAS,uBAAuB,sGAAsG,wEAAwE,mCAAmC,0BAA0B,KAAK,MAAM,sCAAsC,yDAAyD,6EAA6E,WAAW,2CAA2C,SAAS;AACzqB;;AAEA;;AAEA;AACA;AACA;AACA;AACA,wFAAwF,sCAAsC,kDAAkD,SAAS;AACzL;;AAEA;;AAEA;AACA;AACA;AACA;AACA,wFAAwF,2CAA2C,4EAA4E,kDAAkD,SAAS;AAC1Q;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8GAA8G,2CAA2C,iDAAiD,0CAA0C,+CAA+C,+CAA+C,kDAAkD,qFAAqF,wDAAwD,yBAAyB,6BAA6B,+BAA+B,YAAY,sBAAsB,+BAA+B,YAAY,sBAAsB,+BAA+B,YAAY,MAAM,+BAA+B,WAAW,qEAAqE,SAAS;AACl3B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,YAAY;AACpC,0BAA0B,YAAY;AACtC;;AAEA,+CAA+C,wEAAwE,mDAAmD,2EAA2E,qDAAqD,wDAAwD,4CAA4C,qDAAqD,iDAAiD,oDAAoD,sFAAsF,yDAAyD,mCAAmC,wDAAwD,kBAAkB,sBAAsB,wDAAwD,kBAAkB,sBAAsB,wDAAwD,kBAAkB,MAAM,wDAAwD,iBAAiB,eAAe,aAAa;AAC/kC;AACA;;AAEA,qEAAqE,2CAA2C,mCAAmC,sCAAsC,4BAA4B,kBAAkB,sBAAsB,6EAA6E,SAAS;AACnV;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,iJAAiJ;AACjJ,wIAAwI;AACxI,MAAM,gHAAgH;AACtH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP,MAAM;;AAEN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,kBAAkB;AAC9C;AACA;;AAEA;AACA;AACA;AACA,+HAA+H,0BAA0B;AACzJ,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,sDAAsD,iDAAiD,uCAAuC,6CAA6C,qBAAqB,4CAA4C,sBAAsB,OAAO;AAChS,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,aAAa,wBAAwB;AACrC;AACA;;AAEA;AACA,KAAK;;AAEL,wBAAwB,YAAY;AACpC;AACA;AACA,QAAQ;;AAER;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,EAAE;;AAEF;AACA;;AAEA;AACA;;AAEA,iHAAiH,oDAAoD,kDAAkD;AACvN;AACA;AACA,QAAQ;;AAER;AACA;AACA,sDAAsD;AACtD;;AAEA;AACA,wDAAwD;AACxD;;AAEA;AACA,wDAAwD;AACxD;;AAEA;AACA,wDAAwD;AACxD;;AAEA,uDAAuD;AACvD;AACA,GAAG;AACH;AACA;AACA,qCAAqC;AACrC;;AAEA;AACA,uCAAuC,wCAAwC;AAC/E;;AAEA;AACA,uCAAuC,0CAA0C;AACjF;;AAEA;AACA,uCAAuC,0CAA0C;AACjF;;AAEA,sCAAsC;AACtC;;AAEA;AACA,qHAAqH;AACrH,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,gDAAgD;AAC9G;AACA;AACA,kCAAkC;AAClC;AACA;;AAEA;AACA,gGAAgG,kDAAkD,UAAU;AAC5J;AACA;;AAEA,2FAA2F,yGAAyG,+EAA+E;AACnR;AACA,QAAQ,8DAA8D;;AAEtE,0CAA0C,kDAAkD,mFAAmF,6BAA6B;AAC5M,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,6JAA6J,yDAAyD,SAAS;AAC/N;AACA;AACA;AACA;AACA;AACA,8DAA8D,gDAAgD;AAC9G;AACA,0JAA0J,kDAAkD,uEAAuE,OAAO;AAC1R,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA,0EAA0E,6DAA6D,OAAO;AAC9I,GAAG;;AAEH;AACA;AACA;AACA,6DAA6D,0BAA0B,gCAAgC,6CAA6C,0EAA0E,2BAA2B,cAAc,cAAc,cAAc,cAAc,cAAc,QAAQ,2BAA2B,cAAc,cAAc,cAAc,cAAc,cAAc,cAAc,QAAQ,0BAA0B,0IAA0I,+BAA+B,OAAO,4CAA4C,wBAAwB,6BAA6B,oCAAoC,mBAAmB,SAAS,mBAAmB,OAAO,wJAAwJ,iCAAiC,mDAAmD,sCAAsC,2CAA2C,OAAO;AACvpC,GAAG;;AAEH;AACA;AACA;AACA,6CAA6C,iBAAiB,OAAO;;AAErE;AACA;AACA;AACA,kEAAkE,yEAAyE,SAAS,0CAA0C,0DAA0D,SAAS,4DAA4D,yEAAyE,SAAS,0CAA0C,0DAA0D,SAAS,6CAA6C,2GAA2G,uHAAuH,iEAAiE,OAAO,sCAAsC,sHAAsH,iEAAiE,OAAO;AACvjC,SAAS;;AAET;AACA;AACA;AACA,oEAAoE,6GAA6G,qFAAqF,SAAS,4CAA4C,oFAAoF,SAAS;AACxZ;AACA,qDAAqD,2GAA2G,qEAAqE,uHAAuH,kEAAkE,iDAAiD,oDAAoD,6BAA6B,OAAO,wCAAwC,sHAAsH,kEAAkE,6CAA6C,gDAAgD,6BAA6B,OAAO;AACx4B,SAAS;;AAET;AACA;AACA,wDAAwD,2GAA2G,qEAAqE,qFAAqF,uHAAuH,gEAAgE,wCAAwC,mCAAmC,mDAAmD,oDAAoD,gCAAgC,OAAO;AAC7sB;AACA;AACA;AACA,iDAAiD,sHAAsH,gEAAgE,yCAAyC,oCAAoC,+CAA+C,gDAAgD,gCAAgC,OAAO;AAC1b,SAAS;;AAET;AACA;AACA,wDAAwD,2GAA2G,uHAAuH,gEAAgE,uEAAuE,qFAAqF,yDAAyD,0CAA0C,qCAAqC,wCAAwC,mCAAmC,mDAAmD,oDAAoD,oCAAoC,OAAO;AAC31B;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,sBAAsB;AACpD,uGAAuG,sDAAsD;AAC7J;;AAEA,oEAAoE,uHAAuH,gEAAgE,iEAAiE,oCAAoC,+CAA+C,gDAAgD,2DAA2D,OAAO;AACjgB,SAAS;AACT;AACA,GAAG;AACH,4CAA4C,mCAAmC,OAAO;AACtF,GAAG;AACH;AACA;AACA,6CAA6C,iBAAiB,OAAO;;AAErE;AACA;AACA,kEAAkE,yDAAyD,SAAS,0CAA0C,sDAAsD,SAAS,4DAA4D,yDAAyD,SAAS,0CAA0C,sDAAsD,SAAS,6CAA6C,iHAAiH,wDAAwD,OAAO,sCAAsC,sHAAsH,2DAA2D,OAAO;AAC/4B,SAAS;;AAET;AACA;AACA,iEAAiE,2EAA2E,SAAS,4CAA4C,gFAAgF,SAAS,8DAA8D,qHAAqH,+DAA+D,iCAAiC,SAAS,4CAA4C,0HAA0H,kEAAkE,iCAAiC,SAAS,8DAA8D,qHAAqH,+DAA+D,iCAAiC,SAAS,4CAA4C,0HAA0H,kEAAkE,iCAAiC,SAAS,+CAA+C,iHAAiH,6DAA6D,oCAAoC,wCAAwC,2BAA2B,OAAO,wCAAwC,sHAAsH,gEAAgE,0CAA0C,8CAA8C,2BAA2B,OAAO;AACzhE,SAAS;;AAET;AACA;AACA,sDAAsD,6GAA6G,2DAA2D,oEAAoE,KAAK;AACvS;AACA,iDAAiD,sHAAsH,gEAAgE,oDAAoD,OAAO;AAClS,SAAS;;AAET;AACA;AACA,wDAAwD,4FAA4F,6DAA6D,kFAAkF,OAAO;AAC1S;AACA,iDAAiD,iGAAiG,gEAAgE,wDAAwD,OAAO;AACjR,SAAS;;AAET;AACA;AACA;AACA,iDAAiD,sHAAsH,kEAAkE,0EAA0E,wBAAwB,OAAO;AAClV,SAAS;;AAET;AACA;AACA;AACA,iDAAiD,iGAAiG,gEAAgE,4EAA4E,sBAAsB,OAAO;AAC3T,SAAS;;AAET;AACA;AACA;AACA,GAAG;AACH,6CAA6C,kDAAkD,OAAO;AACtG,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,kEAAkE,uBAAuB;AACzF;AACA,uEAAuE,uDAAuD,SAAS;;AAEvI;;AAEA,oDAAoD,mGAAmG,iDAAiD,OAAO;AAC/M;AACA,6CAA6C,6EAA6E,iDAAiD,OAAO;AAClL,OAAO;;AAEP;AACA;AACA;AACA;AACA,mFAAmF,qCAAqC;AACxH;AACA;AACA;AACA,gFAAgF,uDAAuD,SAAS;;AAEhJ;;AAEA,sEAAsE,wGAAwG,mDAAmD,SAAS,oDAAoD,wFAAwF,mDAAmD,SAAS,kEAAkE,wGAAwG,mDAAmD,SAAS,oDAAoD,wFAAwF,mDAAmD,SAAS,sDAAsD,2GAA2G,iDAAiD,OAAO,gDAAgD,qFAAqF,iDAAiD,OAAO;AACtvC,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,2GAA2G,mDAAmD,SAAS,yDAAyD,6FAA6F,iDAAiD,OAAO;AACld;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,qGAAqG,2DAA2D,SAAS;AACzK;;AAEA,0FAA0F,6EAA6E,qCAAqC;;AAE5M;AACA;AACA;;AAEA,6EAA6E,gGAAgG,gFAAgF,mDAAmD,SAAS,yDAAyD,yFAAyF,8DAA8D,iDAAiD,OAAO,uEAAuE,gGAAgG,gFAAgF,mDAAmD,SAAS,yDAAyD,yFAAyF,8DAA8D,iDAAiD,OAAO,6DAA6D,uJAAuJ,4FAA4F,mDAAmD,SAAS,uDAAuD,0IAA0I,kEAAkE,+CAA+C,KAAK;AAC/xD,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,oHAAoH,6DAA6D,WAAW;AAC5L;;AAEA,qGAAqG,4HAA4H,qCAAqC;AACtQ;AACA;AACA;AACA;AACA,wGAAwG,+CAA+C,kCAAkC,+DAA+D,iIAAiI,mDAAmD,SAAS,wEAAwE,oCAAoC,wEAAwE,mHAAmH,qDAAqD,WAAW;AAC5xB,wGAAwG,4EAA4E,oCAAoC,6GAA6G,mDAAmD,SAAS,oEAAoE,qEAAqE,kCAAkC,yFAAyF,iDAAiD,OAAO;;AAE7rB;;AAEA,4EAA4E,iJAAiJ,6CAA6C,yFAAyF,0FAA0F,iDAAiD,OAAO,sEAAsE,wKAAwK,sEAAsE,mDAAmD,SAAS;AACr2B,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,4HAA4H,2DAA2D,SAAS;AAChM;;AAEA,iHAAiH,oJAAoJ,qCAAqC;AAC1S;AACA;AACA;AACA;AACA,qDAAqD;AACrD,+DAA+D;AAC/D,+DAA+D;AAC/D,oHAAoH,kFAAkF,8GAA8G,iIAAiI,mDAAmD,SAAS,kFAAkF,kCAAkC,4HAA4H,+GAA+G,mDAAmD,SAAS;AAC54B,oHAAoH,8JAA8J,qCAAqC,gIAAgI,mDAAmD,SAAS,kFAAkF,kIAAkI,qCAAqC,8GAA8G,mDAAmD,SAAS;;AAEt5B;;AAEA,wFAAwF,qOAAqO,2GAA2G,iDAAiD,OAAO,8EAA8E,wLAAwL,qFAAqF,iDAAiD,OAAO;AACn3B,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,qIAAqI,2DAA2D,SAAS;AACzM;;AAEA,6HAA6H,4KAA4K,qCAAqC;AAC9U;AACA;AACA;AACA;AACA,yHAAyH,yBAAyB,gJAAgJ,+GAA+G,mDAAmD,SAAS,qHAAqH,wLAAwL,4BAA4B,8GAA8G,mDAAmD,SAAS,4FAA4F,uOAAuO,oEAAoE,iDAAiD,OAAO;AAC/3C,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,sKAAsK,2DAA2D,SAAS;AAC1O;;AAEA;AACA;AACA;AACA;AACA;AACA,4JAA4J,wPAAwP,qCAAqC;AACzb;AACA;AACA;AACA;AACA,0JAA0J,yBAAyB,8KAA8K,+GAA+G,mDAAmD,SAAS,sJAAsJ,iQAAiQ,4BAA4B,8GAA8G,mDAAmD,SAAS,2HAA2H,iQAAiQ,oEAAoE,iDAAiD,OAAO;AACjmD,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yFAAyF,mEAAmE,OAAO;AACnK,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,iIAAiI,wFAAwF,4DAA4D,OAAO;AACxV;AACA,qDAAqD,wFAAwF,4DAA4D,OAAO;AAChN,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,2GAA2G,gEAAgE,SAAS,0DAA0D,yFAAyF,gEAAgE,SAAS;AAC5e,mEAAmE,iIAAiI,0EAA0E,+FAA+F,4DAA4D,OAAO;AAChb;AACA,4DAA4D,mHAAmH,4DAA4D,OAAO;AAClP,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wHAAwH,iEAAiE,WAAW;AACpM;;AAEA;AACA,0EAA0E,iIAAiI,0EAA0E,0FAA0F,2HAA2H,4DAA4D,OAAO;AAC7iB;AACA;AACA;AACA,mEAAmE,8IAA8I,4DAA4D,OAAO;AACpR,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA,kFAAkF,0EAA0E,0FAA0F,6EAA6E,gDAAgD,2CAA2C,iIAAiI,6CAA6C,oDAAoD,4FAA4F,oDAAoD,OAAO;AACvxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,eAAe;AAC3C;AACA;;AAEA,0DAA0D,mCAAmC,0CAA0C,iDAAiD,qFAAqF,4DAA4D,OAAO;AAChV,OAAO;AACP;AACA;;AAEA,kEAAkE,+BAA+B,sCAAsC,gEAAgE,GAAG,4DAA4D,+BAA+B,oCAAoC,2CAA2C,gEAAgE,GAAG;AACvb,wGAAwG,gEAAgE,oCAAoC,2CAA2C,gEAAgE,GAAG;AAC1T,yIAAyI,+EAA+E,+BAA+B,sCAAsC,gEAAgE,GAAG;AAChW,2DAA2D,yCAAyC,0HAA0H,KAAK,0CAA0C,2CAA2C,8CAA8C,KAAK;;AAE3W;AACA;AACA;;AAEA;AACA;AACA;AACA,uCAAuC,4BAA4B,mBAAmB,MAAM,yBAAyB,mCAAmC,SAAS,OAAO;AACxK;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;;AAEF;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,yDAAyD,gDAAgD,WAAW,UAAU;AAC9H;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA,+CAA+C,gCAAgC,sBAAsB,sBAAsB,2CAA2C,yCAAyC;AAC/M,OAAO;AACP;AACA;AACA;AACA;;AAEA,8BAA8B,YAAY;AAC1C,gCAAgC,YAAY;AAC5C;;AAEA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA,OAAO;;AAEP,8CAA8C,qDAAqD,sCAAsC,iCAAiC,cAAc,MAAM,mFAAmF,aAAa,WAAW;AACzS;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,+BAA+B;AAC/B,iDAAiD,0CAA0C,6GAA6G,0DAA0D,0EAA0E,4EAA4E,4HAA4H,kCAAkC;AACtjB;;AAEA;AACA,wGAAwG,wEAAwE,OAAO,2DAA2D,uCAAuC,mCAAmC,yBAAyB,uCAAuC,uCAAuC,wDAAwD,SAAS;AACpe;;AAEA;;AAEA;AACA;AACA,mJAAmJ;AACnJ;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,sKAAsK,gCAAgC,uBAAuB,sCAAsC,sCAAsC,yBAAyB,SAAS;AAC3U;;AAEA;;AAEA,mBAAmB;;AAEnB;AACA;AACA,oNAAoN,gCAAgC,uBAAuB,qCAAqC,qCAAqC,yBAAyB,SAAS;AACvX;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA,0CAA0C,+CAA+C,kDAAkD,+DAA+D,SAAS;AACnN;;AAEA;;AAEA;AACA,WAAW;AACX;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,mFAAmF;AACnF,MAAM,0CAA0C;;AAEhD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;;AAER;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,QAAQ,wDAAwD;AAChE;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,uCAAuC,kBAAkB;AACzD;;AAEA;AACA,6OAA6O;AAC7O;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8BAA8B,kBAAkB;AAChD;AACA;;AAEA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,gGAAgG;AAChG,2CAA2C;AAC3C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iJAAiJ;AACzJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;AACA;AACA;;AAEA;AACA,UAAU;AACV,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB,gBAAgB;AAChB;;AAEA,0BAA0B,gCAAgC;AAC1D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,oEAAoE;AACpE;AACA;AACA;AACA,UAAU;AACV,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sDAAsD,kDAAkD,kDAAkD,kDAAkD,iDAAiD,mDAAmD,mDAAmD;AACnW;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4LAA4L,gCAAgC,uBAAuB,sCAAsC,sCAAsC,2CAA2C,SAAS;AACnX;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,0BAA0B,0BAA0B,YAAY,uEAAuE,0HAA0H,4BAA4B,4BAA4B,0GAA0G,4BAA4B,4BAA4B,eAAe;AAC9jB;;AAEA,6JAA6J,uHAAuH,4DAA4D,4DAA4D,kFAAkF,gJAAgJ,+HAA+H,4DAA4D,4DAA4D,kFAAkF;AACv7B;AACA,mEAAmE,gCAAgC,uBAAuB,qCAAqC,qCAAqC,gDAAgD,sDAAsD,SAAS;AACnT;;AAEA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD,sCAAsC;AACtC,+DAA+D,yEAAyE;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,sCAAsC;AACtC,+DAA+D,yEAAyE;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,uCAAuC;AACvC,2FAA2F,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB,8BAA8B,+BAA+B;AACzW,+CAA+C,uDAAuD,qDAAqD,qDAAqD,qDAAqD,oBAAoB,8CAA8C;AACvU,2GAA2G,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB,8BAA8B,yCAAyC;AACnY;AACA;AACA,kEAAkE;AAClE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,4DAA4D,oCAAoC,mCAAmC,oDAAoD,oCAAoC,+BAA+B,oCAAoC,qCAAqC;AAC/W,gDAAgD;AAChD;AACA;AACA;AACA,6OAA6O,yCAAyC,gCAAgC,0BAA0B,oBAAoB,MAAM,wCAAwC,wCAAwC,wDAAwD,wDAAwD,qMAAqM,8DAA8D,WAAW,wBAAwB,SAAS,uBAAuB,uCAAuC,2CAA2C,kFAAkF,SAAS;AAC7hC;;AAEA;;AAEA;AACA;AACA,4MAA4M,gCAAgC,uBAAuB,8CAA8C,8CAA8C,8CAA8C,8CAA8C,iEAAiE,SAAS;AACrgB;;AAEA;;AAEA,uBAAuB;;AAEvB;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA,6DAA6D;AAC7D,4DAA4D;AAC5D;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,2CAA2C;;AAE3C;AACA;;AAEA,+FAA+F;AAC/F;;AAEA;AACA,2EAA2E,uBAAuB,WAAW,iFAAiF,gDAAgD,2DAA2D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,iDAAiD,iCAAiC,4BAA4B,oBAAoB,SAAS,qCAAqC,4MAA4M,uCAAuC,kDAAkD,qCAAqC,sEAAsE,wCAAwC,gCAAgC,wHAAwH,wCAAwC,gCAAgC,4JAA4J,uCAAuC,8BAA8B,SAAS;AACv+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,wCAAwC,UAAU,qCAAqC,6EAA6E,uCAAuC,UAAU,MAAM,4DAA4D,qEAAqE,8DAA8D,wCAAwC,2DAA2D,sCAAsC,aAAa,WAAW,SAAS;AACvnB;AACA,gFAAgF,gEAAgE,6EAA6E,uGAAuG,gEAAgE,6EAA6E;AACjd;AACA,2EAA2E,uCAAuC,WAAW,sFAAsF,mDAAmD,gDAAgD,4DAA4D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,iDAAiD,oDAAoD,gCAAgC,+BAA+B,+BAA+B,+BAA+B,4BAA4B,oBAAoB,SAAS,qCAAqC,gOAAgO,uCAAuC,kDAAkD,qCAAqC,2MAA2M,wCAAwC,gCAAgC,kNAAkN,wCAAwC,gCAAgC,yNAAyN,uCAAuC,oCAAoC,SAAS;AACt/D;;AAEA;;AAEA;AACA;AACA;;AAEA,WAAW,gDAAgD;AAC3D;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;;AAEH;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,wCAAwC,gDAAgD,wCAAwC,OAAO;AACvI;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,wCAAwC,6CAA6C,+BAA+B,mCAAmC,4BAA4B,qCAAqC,SAAS,wCAAwC,6EAA6E,qCAAqC,8BAA8B,uCAAuC,WAAW,SAAS,0BAA0B,OAAO;AACrf;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB,iBAAiB,KAAK,mBAAmB;AACtG,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,4BAA4B,oCAAoC;AACvG,GAAG;AACH,CAAC;AACD,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,oEAAoE;AACpE,KAAK;AACL;AACA,0CAA0C,oFAAoF,4BAA4B,SAAS;AACnK;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE,KAAK;AACL;AACA,0CAA0C,mFAAmF,4BAA4B,SAAS;AAClK;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,mHAAmH,2CAA2C,gCAAgC,iCAAiC,gDAAgD,qCAAqC,mDAAmD,4BAA4B,oBAAoB,MAAM,oDAAoD,iDAAiD,KAAK,iDAAiD,2EAA2E,oCAAoC,gCAAgC,aAAa,WAAW,sCAAsC,SAAS;AAC9wB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,iGAAiG,kCAAkC,uFAAuF,kCAAkC,uFAAuF,kCAAkC,uFAAuF,kCAAkC;AAC9e,MAAM,6DAA6D,kCAAkC,6CAA6C,kCAAkC,6CAA6C,kCAAkC,6CAA6C,kCAAkC;;AAElV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2UAA2U;AAC3U;AACA,kFAAkF,sJAAsJ,SAAS;AACjP,sEAAsE,gIAAgI,SAAS,2CAA2C,oDAAoD,8EAA8E,8EAA8E,2LAA2L,+BAA+B,uCAAuC,0CAA0C,4BAA4B,oBAAoB,MAAM,2BAA2B,sEAAsE,yCAAyC,sHAAsH,mRAAmR,mEAAmE,qBAAqB,WAAW,+BAA+B,SAAS;AACz8C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB,iBAAiB,KAAK,mBAAmB;AACtG,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kCAAkC;AACzE,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,mBAAmB;AAC1D,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,wBAAwB;AAC9F,mDAAmD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AAChU,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,4CAA4C,6CAA6C;AAChI,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yIAAyI,mEAAmE,yBAAyB,6CAA6C,kCAAkC,8BAA8B,2DAA2D,uCAAuC,uCAAuC,+HAA+H,yCAAyC,mCAAmC,iCAAiC,+BAA+B,oBAAoB,uCAAuC,qCAAqC,8DAA8D,yBAAyB,eAAe,iCAAiC,oBAAoB,yCAAyC,uCAAuC,+DAA+D,2BAA2B,iBAAiB,uDAAuD,gOAAgO,+CAA+C,sCAAsC,yCAAyC,sQAAsQ,iBAAiB,eAAe,aAAa,6CAA6C,WAAW;AAC55D;AACA;AACA;AACA;AACA,yCAAyC,wCAAwC,UAAU,MAAM,iDAAiD,SAAS;AAC3J,wFAAwF,iEAAiE,yDAAyD,mDAAmD,4BAA4B,4DAA4D,uDAAuD,uCAAuC,WAAW,uBAAuB,wCAAwC,SAAS,uBAAuB,2CAA2C,gCAAgC,4BAA4B,yDAAyD,qCAAqC,qCAAqC,yIAAyI,+BAA+B,sBAAsB,6BAA6B,oBAAoB,qCAAqC,mCAAmC,4DAA4D,uBAAuB,aAAa,+BAA+B,qBAAqB,UAAU,sDAAsD,yRAAyR,2CAA2C,iDAAiD,uCAAuC,uMAAuM,4CAA4C,gCAAgC,+NAA+N,4CAA4C,gCAAgC,2PAA2P,2CAA2C,WAAW,oCAAoC,SAAS;AACllF;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sKAAsK,mFAAmF,yBAAyB,6CAA6C,iCAAiC,8BAA8B,mFAAmF,qCAAqC,qCAAqC,qCAAqC,wIAAwI,yCAAyC,mCAAmC,+BAA+B,oBAAoB,uCAAuC,qCAAqC,6DAA6D,yBAAyB,eAAe,iCAAiC,oBAAoB,yCAAyC,uCAAuC,gEAAgE,2BAA2B,iBAAiB,mCAAmC,oBAAoB,2CAA2C,yCAAyC,iEAAiE,6BAA6B,mBAAmB,8DAA8D,wOAAwO,iDAAiD,wCAAwC,2CAA2C,wYAAwY,mBAAmB,iBAAiB,eAAe,aAAa,6CAA6C,WAAW;AAC/4E;AACA;AACA;AACA;AACA,yCAAyC,wCAAwC,UAAU,MAAM,iDAAiD,SAAS;AAC3J,iHAAiH,iFAAiF,yDAAyD,mDAAmD,4BAA4B,qEAAqE,uDAAuD,uCAAuC,WAAW,uBAAuB,6CAA6C,SAAS,uBAAuB,2CAA2C,+BAA+B,4BAA4B,iFAAiF,mCAAmC,mCAAmC,mCAAmC,iJAAiJ,+BAA+B,sBAAsB,6BAA6B,oBAAoB,qCAAqC,mCAAmC,2DAA2D,uBAAuB,aAAa,+BAA+B,oBAAoB,qCAAqC,qCAAqC,8DAA8D,yBAAyB,eAAe,iCAAiC,qBAAqB,UAAU,wDAAwD,yTAAyT,+CAA+C,mDAAmD,yCAAyC,wNAAwN,gDAAgD,gCAAgC,qPAAqP,gDAAgD,gCAAgC,sRAAsR,+CAA+C,aAAa,sCAAsC,WAAW,SAAS;AACljG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8HAA8H,6FAA6F,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gDAAgD,uCAAuC,uCAAuC,oLAAoL,2BAA2B,oBAAoB,oDAAoD,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,kDAAkD,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,wDAAwD,mDAAmD,aAAa,WAAW,6BAA6B,SAAS;AACn+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,6GAA6G,uBAAuB,2CAA2C,+BAA+B,4BAA4B,wEAAwE,qCAAqC,qCAAqC,qCAAqC,4MAA4M,6BAA6B,oBAAoB,mDAAmD,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,sDAAsD,gFAAgF,0GAA0G,yBAAyB,eAAe,kCAAkC,iCAAiC,oBAAoB,uDAAuD,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,qEAAqE,qDAAqD,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAC1gE;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wJAAwJ,sCAAsC,4CAA4C,oDAAoD,uCAAuC,uCAAuC,4EAA4E,oEAAoE,SAAS;AACrgB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wJAAwJ,sCAAsC,sCAAsC,uCAAuC,2CAA2C,mDAAmD,4EAA4E,iDAAiD,SAAS;AAC/e;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,2CAA2C,oDAAoD,qHAAqH,mEAAmE,sEAAsE,SAAS;AACtW;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,8CAA8C,8EAA8E,0CAA0C,oCAAoC,0CAA0C,SAAS;AAC7P,2EAA2E,8EAA8E,0CAA0C,oCAAoC,gFAAgF,4CAA4C,sCAAsC,WAAW,SAAS;AAC7Z,4IAA4I,mFAAmF;AAC/N,0CAA0C,mDAAmD,mCAAmC,yDAAyD,4EAA4E,SAAS;AAC9Q;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,mCAAmC;AACnC;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,iEAAiE,0CAA0C,6BAA6B,6BAA6B,mBAAmB,WAAW,oDAAoD,SAAS;AACrQ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,+DAA+D,yCAAyC,oCAAoC,6BAA6B,mBAAmB,WAAW,gEAAgE,SAAS;AACrR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA,uGAAuG,+CAA+C,+CAA+C,iCAAiC,+RAA+R,SAAS;AAC9gB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA,kEAAkE;;AAElE,wBAAwB,kBAAkB;AAC1C,sHAAsH;AACtH;;AAEA,0FAA0F,2CAA2C,2CAA2C,4BAA4B,4BAA4B,qDAAqD;AAC7R;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,qDAAqD,8FAA8F,WAAW;;AAE9J,wBAAwB,kBAAkB;AAC1C;AACA,kHAAkH,mJAAmJ,WAAW;AAChR;;AAEA;AACA,iJAAiJ,iFAAiF,iCAAiC,uBAAuB,oDAAoD,mEAAmE,8DAA8D,8DAA8D,gDAAgD,WAAW,8DAA8D,8DAA8D,gDAAgD,WAAW,8DAA8D,4HAA4H,gDAAgD,WAAW,4BAA4B,SAAS;AACzhC;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6DAA6D,oCAAoC,qCAAqC,qDAAqD,oCAAoC,6CAA6C,wCAAwC,+CAA+C;AACjZ,gDAAgD;AAChD,8PAA8P,iEAAiE,uBAAuB,2CAA2C,gCAAgC,0CAA0C,kHAAkH,qCAAqC,qCAAqC,kLAAkL,2BAA2B,qBAAqB,OAAO,oDAAoD,4DAA4D,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,sDAAsD,6DAA6D,yBAAyB,eAAe,iCAAiC,qBAAqB,UAAU,6NAA6N,uCAAuC,qPAAqP,mDAAmD,kBAAkB,MAAM,qPAAqP,mDAAmD,iBAAiB,eAAe,2CAA2C,uCAAuC,8IAA8I,kBAAkB,MAAM,8IAA8I,iBAAiB,kBAAkB,gCAAgC,+JAA+J,uCAAuC,6KAA6K,mDAAmD,kBAAkB,MAAM,6KAA6K,mDAAmD,iBAAiB,kBAAkB,gCAAgC,sNAAsN,uCAAuC,yOAAyO,mDAAmD,kBAAkB,MAAM,yOAAyO,mDAAmD,iBAAiB,iBAAiB,aAAa,WAAW,mCAAmC,4EAA4E,SAAS;AAC/0I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wGAAwG,iFAAiF,uBAAuB,2CAA2C,+BAA+B,4BAA4B,oFAAoF,sCAAsC,sCAAsC,sCAAsC,wMAAwM,2BAA2B,qBAAqB,OAAO,oDAAoD,2DAA2D,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,sDAAsD,8DAA8D,yBAAyB,eAAe,iCAAiC,qBAAqB,OAAO,wDAAwD,+DAA+D,2BAA2B,iBAAiB,mCAAmC,qBAAqB,UAAU,qQAAqQ,yPAAyP,qDAAqD,iBAAiB,6CAA6C,kJAAkJ,kBAAkB,gCAAgC,qLAAqL,+KAA+K,mDAAmD,kBAAkB,gCAAgC,qPAAqP,4OAA4O,mDAAmD,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACvvG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,YAAY;AACpC,0BAA0B,YAAY;AACtC,gEAAgE,4CAA4C,6EAA6E,6FAA6F,qEAAqE,uDAAuD,6GAA6G,0GAA0G,yDAAyD,+DAA+D,yCAAyC,6CAA6C,4KAA4K,oBAAoB,MAAM,6CAA6C,4KAA4K,mBAAmB,iBAAiB,eAAe,aAAa;AACtxC;AACA;;AAEA,0CAA0C,uCAAuC,kCAAkC,8DAA8D,yBAAyB,oEAAoE,SAAS;AACvR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,EAAE;AACT;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oLAAoL,4BAA4B,6BAA6B,MAAM,6BAA6B,+BAA+B,OAAO,0FAA0F,8DAA8D,yBAAyB,eAAe,iCAAiC,8BAA8B,OAAO,4FAA4F,+DAA+D,2BAA2B,iBAAiB,qEAAqE,uDAAuD,qDAAqD,gDAAgD,kBAAkB,MAAM,uDAAuD,qDAAqD,gDAAgD,iBAAiB,iBAAiB,aAAa,WAAW,6BAA6B,SAAS;AACjgD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,gCAAgC,kDAAkD,0GAA0G,qCAAqC,qCAAqC,wLAAwL,2BAA2B,qBAAqB,OAAO,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,qDAAqD,iCAAiC,iCAAiC,OAAO,uCAAuC,8DAA8D,8DAA8D,6CAA6C,kBAAkB,MAAM,8DAA8D,8DAA8D,6CAA6C,iBAAiB,iBAAiB,aAAa,WAAW,6BAA6B,SAAS;AAC73D;;AAEA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,4BAA4B,gCAAgC,4BAA4B,6BAA6B,MAAM,6BAA6B,8BAA8B,OAAO,2FAA2F,6DAA6D,yBAAyB,eAAe,iCAAiC,+BAA+B,OAAO,4FAA4F,gEAAgE,2BAA2B,iBAAiB,mCAAmC,8BAA8B,OAAO,8FAA8F,iEAAiE,6BAA6B,mBAAmB,6DAA6D,yDAAyD,gDAAgD,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACh7C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,uBAAuB,2CAA2C,+BAA+B,4BAA4B,0EAA0E,qCAAqC,qCAAqC,qCAAqC,gCAAgC,2BAA2B,qBAAqB,OAAO,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,gFAAgF,wGAAwG,yBAAyB,eAAe,kCAAkC,qDAAqD,iCAAiC,qBAAqB,OAAO,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,uDAAuD,mCAAmC,iCAAiC,OAAO,oEAAoE,sEAAsE,6CAA6C,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAC/5D;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kBAAkB;AACzD,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,wCAAwC,mCAAmC;AAC3E,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,wDAAwD,qBAAqB,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,8DAA8D,mCAAmC,mCAAmC,mCAAmC,gFAAgF,kDAAkD,mBAAmB,WAAW,gDAAgD,6CAA6C,wCAAwC,qDAAqD,6CAA6C,mBAAmB,WAAW,sCAAsC,qDAAqD,6CAA6C,mBAAmB,WAAW,qDAAqD,mCAAmC,2GAA2G,gEAAgE,+EAA+E,+EAA+E,6EAA6E,+EAA+E,oEAAoE,oEAAoE,8EAA8E,6DAA6D,gCAAgC,YAAY,MAAM,oKAAoK,kFAAkF,gCAAgC,WAAW,SAAS;AACntE;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,oNAAoN,uDAAuD,iDAAiD,qCAAqC,0CAA0C,+BAA+B,qCAAqC,+CAA+C,sDAAsD,WAAW,yBAAyB,SAAS;AACjmB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL,wBAAwB,sCAAsC;AAC9D;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0JAA0J,yCAAyC,0BAA0B,wDAAwD,wDAAwD,wDAAwD,wCAAwC,+CAA+C,sCAAsC,+CAA+C,gHAAgH,gCAAgC,oEAAoE,0BAA0B,OAAO;AACtyB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6DAA6D,oCAAoC,qCAAqC,qDAAqD,oCAAoC,6CAA6C,wCAAwC,+CAA+C;AACjZ,gDAAgD;AAChD,8PAA8P,iEAAiE,uBAAuB,2CAA2C,+BAA+B,uDAAuD,4BAA4B,uCAAuC,2CAA2C,uCAAuC,qCAAqC,iLAAiL,2GAA2G,qBAAqB,OAAO,oDAAoD,mDAAmD,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,sDAAsD,qDAAqD,yBAAyB,eAAe,qDAAqD,+CAA+C,qCAAqC,aAAa,WAAW,mCAAmC,4EAA4E,SAAS;AAC3jD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ,aAAa,qBAAqB,eAAe,WAAW;;AAEjG,wBAAwB,WAAW;AACnC,0DAA0D,mDAAmD,mDAAmD,uDAAuD,sCAAsC;AAC7P;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,mEAAmE,mDAAmD,0DAA0D,uDAAuD,6CAA6C;AACpR;;AAEA,4DAA4D,8CAA8C;;AAE1G,0BAA0B,qBAAqB;AAC/C;AACA;;AAEA,gEAAgE;AAChE,oFAAoF,yGAAyG,8EAA8E,2LAA2L,+DAA+D,qBAAqB,uDAAuD,mBAAmB,8JAA8J,kEAAkE,sEAAsE,+DAA+D,iMAAiM,gDAAgD,uBAAuB,+FAA+F,sBAAsB,MAAM,0FAA0F,qBAAqB,6HAA6H,wEAAwE,mDAAmD,+DAA+D,qBAAqB,uDAAuD,mBAAmB,qEAAqE;AACt5D;;AAEA,qJAAqJ,kHAAkH,oFAAoF,iMAAiM,qEAAqE,uBAAuB,6DAA6D,qBAAqB,4EAA4E,6GAA6G,kFAAkF,2DAA2D,uBAAuB,oJAAoJ,wHAAwH,oFAAoF,oHAAoH,sFAAsF,6DAA6D,uEAAuE,yBAAyB,+DAA+D,uBAAuB,iFAAiF;AACr5D;AACA,UAAU,2FAA2F,yGAAyG,8EAA8E,yLAAyL,+DAA+D,qBAAqB,uDAAuD,mBAAmB,2GAA2G,gFAAgF,mLAAmL,mEAAmE,qBAAqB,2DAA2D,mBAAmB,gHAAgH,kFAAkF,sDAAsD,oEAAoE,4DAA4D,qBAAqB,gGAAgG,4HAA4H,wEAAwE,mDAAmD,+DAA+D,qBAAqB,uDAAuD,mBAAmB,mDAAmD,6GAA6G,kFAAkF,yDAAyD,kEAAkE,qBAAqB,2DAA2D,mBAAmB,oIAAoI,+JAA+J;;AAE5vF,sGAAsG,2EAA2E,wHAAwH,iFAAiF;AAC1X;;AAEA,uBAAuB;AACvB;;AAEA;AACA;AACA,4CAA4C,4DAA4D,oCAAoC,mCAAmC,oDAAoD,oCAAoC,+BAA+B,oCAAoC,qCAAqC;AAC/W,gDAAgD;AAChD,8PAA8P,iEAAiE,uBAAuB,6CAA6C,+BAA+B,uDAAuD,4BAA4B,uCAAuC,2CAA2C,qCAAqC,qCAAqC,wIAAwI,sFAAsF,4EAA4E,SAAS;AACp8B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,sEAAsE,gCAAgC,wEAAwE,8BAA8B,MAAM,6BAA6B,+BAA+B,OAAO,0FAA0F,8DAA8D,yBAAyB,eAAe,iCAAiC,8BAA8B,OAAO,4FAA4F,+DAA+D,2BAA2B,iBAAiB,uDAAuD,mDAAmD,8CAA8C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAChtC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,gCAAgC,6BAA6B,4CAA4C,qCAAqC,qCAAqC,gCAAgC,6BAA6B,qBAAqB,OAAO,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,qDAAqD,iFAAiF,qBAAqB,OAAO,kDAAkD,4DAA4D,4DAA4D,2CAA2C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACz+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iGAAiG,6CAA6C,uEAAuE,2BAA2B,SAAS;AACzP;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN,wFAAwF,iEAAiE,2CAA2C,uBAAuB,2CAA2C,+BAA+B,4BAA4B,2EAA2E,wCAAwC,wCAAwC,wCAAwC,0BAA0B,oBAAoB,MAAM,gDAAgD,qDAAqD,8BAA8B,oBAAoB,MAAM,oDAAoD,yDAAyD,yDAAyD,8CAA8C,4CAA4C,qCAAqC,iCAAiC,mBAAmB,iBAAiB,eAAe,aAAa,WAAW,kCAAkC,4BAA4B,SAAS;AAC7qC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA,UAAU;;AAEV;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;;AAET;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uDAAuD;AACvD,sCAAsC,uDAAuD,qDAAqD,qDAAqD,qDAAqD,oBAAoB;AAChR,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN,0HAA0H,6EAA6E,uEAAuE;AAC9Q;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,mDAAmD;AACnD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,+OAA+O,2BAA2B,4BAA4B,2BAA2B,4BAA4B,2BAA2B,2BAA2B,eAAe,kCAAkC,+EAA+E;AACnhB,GAAG;AACH,CAAC;AACD,wBAAwB;AACxB;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,EAAE;AAC9D;AACA,4CAA4C;AAC5C;AACA,4EAA4E,gFAAgF,iCAAiC,iDAAiD,kEAAkE,iGAAiG,+BAA+B,4BAA4B,oBAAoB,MAAM,+CAA+C,mEAAmE,gCAAgC,gCAAgC,2CAA2C,2CAA2C,+FAA+F,WAAW,0BAA0B,SAAS,uBAAuB,2CAA2C,qDAAqD,SAAS;AAC3/B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,2FAA2F,iFAAiF,SAAS;AAC1L;;AAEA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,kEAAkE,6CAA6C,8BAA8B,iDAAiD,8BAA8B,wDAAwD,8EAA8E,cAAc,MAAM,iFAAiF,aAAa,mCAAmC,WAAW;AAClgB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,gDAAgD,sBAAsB,sBAAsB,kBAAkB,kHAAkH,MAAM,MAAM,iBAAiB,KAAK;AAClQ,8CAA8C,wBAAwB,wCAAwC,4BAA4B,+BAA+B,gGAAgG,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,wBAAwB;AACvhB;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,gEAAgE,2CAA2C,+BAA+B,+BAA+B,gCAAgC,0FAA0F,0DAA0D,sBAAsB,2BAA2B,6BAA6B,YAAY,sBAAsB,6BAA6B,YAAY,sBAAsB,6BAA6B,YAAY,sBAAsB,6BAA6B,WAAW,kDAAkD,SAAS;AAC9qB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,gEAAgE,2CAA2C,+BAA+B,+BAA+B,gCAAgC,mCAAmC,2BAA2B,QAAQ,QAAQ,2BAA2B,QAAQ,QAAQ,qCAAqC,sCAAsC,wHAAwH,4DAA4D,0BAA0B,+BAA+B,iCAAiC,gBAAgB,sBAAsB,iCAAiC,gBAAgB,sBAAsB,iCAAiC,gBAAgB,sBAAsB,iCAAiC,eAAe,mEAAmE,aAAa,WAAW,2CAA2C,SAAS;AAC9gC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,EAAE;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iGAAiG,wBAAwB,sDAAsD,iCAAiC,4BAA4B,gCAAgC,MAAM,0DAA0D,gGAAgG,aAAa,qDAAqD,WAAW;AACzf;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,0CAA0C,kDAAkD,0CAA0C,SAAS;AAC/I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,yDAAyD;AACzD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,8DAA8D;AAC9D;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,qDAAqD;AACrD;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,sDAAsD;AACtD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,2DAA2D;AAC3D;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,wCAAwC,kBAAkB;AAC1D,+CAA+C,8CAA8C,+CAA+C,+CAA+C,+CAA+C,+CAA+C,oBAAoB;AAC7S;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD;AACnD,8HAA8H;AAC9H;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,0CAA0C;AAC1C,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD;AACnD,6IAA6I;AAC7I;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,qCAAqC,0BAA0B,uCAAuC,qBAAqB,MAAM,4BAA4B,qDAAqD,2CAA2C,2BAA2B,aAAa,WAAW,yCAAyC,yBAAyB,SAAS;AACxsB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,0CAA0C,2CAA2C,2BAA2B,2BAA2B,2BAA2B,2BAA2B,kEAAkE,iEAAiE,gCAAgC,sDAAsD,oZAAoZ,kDAAkD,gCAAgC,gCAAgC,gEAAgE,0EAA0E,6BAA6B,kFAAkF,eAAe,WAAW,0CAA0C,yCAAyC,qBAAqB,MAAM,kCAAkC,oEAAoE,8EAA8E,yEAAyE,8EAA8E,sDAAsD,gCAAgC,uCAAuC,8BAA8B,oDAAoD,+GAA+G,sEAAsE,+BAA+B,4EAA4E,iBAAiB,eAAe,8BAA8B,2BAA2B,aAAa,WAAW,yDAAyD,4BAA4B,SAAS;AACl7E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA,wOAAwO,2CAA2C,4BAA4B,4BAA4B,4BAA4B,+BAA+B,0BAA0B,4BAA4B,MAAM,sEAAsE,kHAAkH,4CAA4C,8DAA8D,+BAA+B,0CAA0C,mBAAmB,MAAM,kCAAkC,yBAAyB,eAAe,yDAAyD,8EAA8E,eAAe,oBAAoB,sBAAsB,eAAe,aAAa,0EAA0E,2CAA2C,mBAAmB,KAAK,kCAAkC,yBAAyB,eAAe,wDAAwD,oMAAoM,6BAA6B,0DAA0D,iBAAiB,qCAAqC,2CAA2C,gCAAgC,iBAAiB,eAAe,oBAAoB,sBAAsB,eAAe,aAAa,SAAS,0BAA0B,SAAS;AACz6D;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;;AAEA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,uBAAuB;AAC7F,wDAAwD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACrU;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gDAAgD,uCAAuC,uCAAuC,oLAAoL,2BAA2B,oBAAoB,kDAAkD,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,wDAAwD,0FAA0F,uKAAuK,yEAAyE,0CAA0C,aAAa,WAAW,6BAA6B,SAAS;AAC3pD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,uBAAuB,2CAA2C,+BAA+B,4BAA4B,wEAAwE,qCAAqC,qCAAqC,qCAAqC,4MAA4M,6BAA6B,oBAAoB,kDAAkD,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,sDAAsD,gFAAgF,0GAA0G,yBAAyB,eAAe,kCAAkC,iCAAiC,oBAAoB,uDAAuD,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,qEAAqE,8HAA8H,0PAA0P,2EAA2E,4CAA4C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACt1E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;;AAEA;AACA,QAAQ;;AAER;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,uBAAuB;AAC7F,wDAAwD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACrU;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,4DAA4D,uBAAuB,kDAAkD,0BAA0B,oBAAoB,MAAM,qCAAqC,gEAAgE,cAAc,4BAA4B,oEAAoE,aAAa,WAAW,+CAA+C,0CAA0C,SAAS,gDAAgD,mCAAmC,yBAAyB,yCAAyC,+BAA+B,uDAAuD,cAAc,sBAAsB,2DAA2D,aAAa,0CAA0C,WAAW;AAC9+B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,uDAAuD,+BAA+B,yDAAyD,YAAY,yBAAyB,6DAA6D,WAAW,0BAA0B;;AAEtR,kDAAkD,0GAA0G,qCAAqC,8BAA8B,8GAA8G,WAAW;AACxV,MAAM;AACN,uDAAuD,sEAAsE,6EAA6E,+CAA+C,kKAAkK,0BAA0B;;AAErb,kDAAkD,0GAA0G,qCAAqC,8BAA8B,8GAA8G,WAAW,yBAAyB,qCAAqC,4EAA4E,8GAA8G,uCAAuC,gCAAgC,kHAAkH,aAAa,WAAW;AACjyB;;AAEA,wFAAwF,kEAAkE,uBAAuB,uDAAuD,iCAAiC,oDAAoD,SAAS;AACtU;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,yCAAyC,qBAAqB;AAC9D,kDAAkD,2CAA2C,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACzS,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,oEAAoE,2CAA2C,gCAAgC,mCAAmC,0BAA0B,4BAA4B,uBAAuB,MAAM,sCAAsC,4BAA4B,kCAAkC,qBAAqB,aAAa,WAAW,8GAA8G,SAAS;AAClhB;;AAEA;;AAEA;AACA,6BAA6B,eAAe,IAAI,eAAe;AAC/D,wDAAwD,8CAA8C,wBAAwB,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB;AACtU;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,CAAC;AACD,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA,uGAAuG,2CAA2C,kDAAkD,uHAAuH,SAAS;AACpU;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,4FAA4F,4DAA4D,uBAAuB,kDAAkD,+EAA+E,6BAA6B,YAAY,MAAM,iDAAiD,4CAA4C,WAAW,SAAS,gDAAgD,mCAAmC,yBAAyB,yCAAyC,8CAA8C,+BAA+B,cAAc,MAAM,4CAA4C,aAAa,WAAW;AAC1wB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,+BAA+B,6BAA6B,6BAA6B,wBAAwB,mCAAmC,2EAA2E,gDAAgD,+BAA+B;AACzV;AACA;;AAEA,iDAAiD,eAAe;AAChE,yEAAyE,sDAAsD,YAAY,MAAM,+CAA+C,iGAAiG,WAAW;AAC5S;;AAEA,sBAAsB,OAAO,uFAAuF,kEAAkE,uBAAuB,uDAAuD,iCAAiC,oDAAoD,SAAS;AAClW;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,gDAAgD,iBAAiB,KAAK,mBAAmB,iBAAiB,KAAK,wFAAwF;AACvM,yKAAyK,wEAAwE,8CAA8C,yHAAyH,4CAA4C,4CAA4C,4CAA4C,4CAA4C,8EAA8E,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACl2B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,+BAA+B;AACtE,iFAAiF,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB;AAClS,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,yCAAyC;AAChF,gGAAgG,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB;AACjT,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0RAA0R,2EAA2E,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gCAAgC,yFAAyF,yHAAyH,mGAAmG,yEAAyE,yEAAyE,uEAAuE,yEAAyE,kEAAkE,kEAAkE,4EAA4E,2DAA2D,gCAAgC,SAAS;AAC14C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+TAA+T,mIAAmI,uDAAuD,0DAA0D,SAAS,uBAAuB,2CAA2C,4BAA4B,4BAA4B,yGAAyG,yFAAyF,yHAAyH,mGAAmG,sIAAsI,0DAA0D,2gBAA2gB,kaAAka,gaAAga,+ZAA+Z,kEAAkE,2DAA2D,kEAAkE,qDAAqD,gCAAgC,SAAS;AAC7xG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oCAAoC,2DAA2D,yDAAyD,+DAA+D,4DAA4D,sDAAsD,mDAAmD,wHAAwH,gEAAgE,+DAA+D,+DAA+D,6DAA6D,uBAAuB,cAAc,2CAA2C,uHAAuH,uBAAuB,aAAa,sCAAsC,sBAAsB,cAAc,6CAA6C,2HAA2H,yBAAyB,eAAe,qDAAqD,gDAAgD,6EAA6E,uDAAuD,mDAAmD,oDAAoD,iDAAiD,4EAA4E,wDAAwD,mDAAmD,4DAA4D,kIAAkI,eAAe,6DAA6D,2GAA2G,eAAe,+DAA+D,6GAA6G,eAAe,gEAAgE,uGAAuG,eAAe,aAAa,WAAW,gEAAgE,SAAS;AACv0F;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8RAA8R,2EAA2E,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gCAAgC,yFAAyF,0MAA0M,4EAA4E,gCAAgC,SAAS;AAC35B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mUAAmU,mIAAmI,uDAAuD,0DAA0D,SAAS,uBAAuB,2CAA2C,4BAA4B,4BAA4B,yGAAyG,yFAAyF,0MAA0M,sIAAsI,0DAA0D,obAAob,gCAAgC,SAAS;AACnuD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oCAAoC,2DAA2D,yDAAyD,+DAA+D,4DAA4D,sDAAsD,mDAAmD,wHAAwH,uEAAuE,+DAA+D,sEAAsE,6DAA6D,uBAAuB,cAAc,2CAA2C,uHAAuH,uBAAuB,aAAa,sCAAsC,sBAAsB,cAAc,6CAA6C,2HAA2H,yBAAyB,eAAe,yIAAyI,6IAA6I,kOAAkO,kOAAkO,qEAAqE,qDAAqD,eAAe,aAAa,WAAW,gEAAgE,SAAS;AAC34E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4FAA4F,0CAA0C,0DAA0D,WAAW;AAC3M;AACA;AACA,0CAA0C,mDAAmD,0CAA0C,SAAS;AAChJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA,qDAAqD,uCAAuC,mCAAmC,4GAA4G,+BAA+B,mIAAmI,aAAa,8BAA8B,WAAW,qCAAqC,iDAAiD,mCAAmC;AAC5jB;AACA,KAAK,eAAe,+BAA+B;AACnD;AACA,KAAK,eAAe,aAAa,gCAAgC;AACjE;AACA,KAAK,eAAe,kCAAkC;AACtD;AACA,KAAK,eAAe,eAAe,aAAa,8BAA8B,WAAW;AACzF;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,6EAA6E,0DAA0D,8CAA8C,4CAA4C,6CAA6C,8BAA8B,8BAA8B,qHAAqH,qHAAqH,6DAA6D,6DAA6D,2HAA2H,2EAA2E,aAAa,mCAAmC,WAAW;AAC/6B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,8IAA8I,2BAA2B,sBAAsB,MAAM,4BAA4B,qBAAqB,MAAM,MAAM,kCAAkC,oBAAoB,QAAQ,MAAM,0BAA0B,OAAO,KAAK;AAC5W,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2IAA2I,yBAAyB,sDAAsD,4BAA4B,+BAA+B,4BAA4B,oBAAoB,MAAM,qCAAqC,8BAA8B,oBAAoB,MAAM,8DAA8D,wFAAwF,eAAe,gDAAgD,kDAAkD,6BAA6B,eAAe,aAAa,iEAAiE,WAAW;AACpzB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA;AACA;AACA,0CAA0C,kDAAkD,4CAA4C,4BAA4B,4CAA4C,YAAY,MAAM,4CAA4C,WAAW,SAAS;AAClS;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,6KAA6K,qCAAqC,gEAAgE;AAClR,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD;AACnD,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC,aAAa,mBAAmB;AACpE,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kBAAkB;AACzD,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,mCAAmC;AAC1E,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,0DAA0D,yCAAyC,sCAAsC,mCAAmC,mBAAmB,yBAAyB,qBAAqB,iBAAiB,KAAK,wBAAwB,qBAAqB,KAAK,SAAS,gCAAgC,KAAK,kBAAkB;AACrX,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,mCAAmC,wBAAwB;AAC3D;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,yCAAyC;AACzC,+CAA+C;AAC/C,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN,oDAAoD,wDAAwD;AAC5G;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA,kFAAkF,gEAAgE,uBAAuB,oDAAoD,0CAA0C,SAAS;AAChR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,oEAAoE;AAC1E;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD,+CAA+C;AAClG,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,0CAA0C,kDAAkD,0CAA0C,SAAS;AAC/I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,gEAAgE,4CAA4C,iCAAiC,mCAAmC,o0BAAo0B,2DAA2D,qEAAqE,+EAA+E,6DAA6D,6DAA6D,yIAAyI,6DAA6D,uCAAuC,sEAAsE,qBAAqB,wBAAwB,YAAY,+BAA+B,mCAAmC,aAAa,MAAM,mCAAmC,YAAY,UAAU;AAC5zD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,6DAA6D,iHAAiH,iCAAiC,mCAAmC,2wCAA2wC,mEAAmE,2EAA2E,wCAAwC,oDAAoD,yDAAyD,UAAU;AAC/yD;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,8BAA8B,YAAY;AAC1C;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,8BAA8B,YAAY;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,8EAA8E,yCAAyC,wCAAwC,sCAAsC,qCAAqC,oCAAoC,sBAAsB,MAAM,4CAA4C,0CAA0C,2GAA2G,uBAAuB,gFAAgF,qBAAqB,oBAAoB,+BAA+B,qCAAqC,oCAAoC,sBAAsB,MAAM,4CAA4C,wEAAwE,2CAA2C,sDAAsD,uBAAuB,qBAAqB,mBAAmB,wDAAwD,kBAAkB,+BAA+B,sCAAsC,qCAAqC,oCAAoC,sBAAsB,MAAM,2CAA2C,gFAAgF,qBAAqB,oBAAoB,+BAA+B,qCAAqC,oCAAoC,sBAAsB,MAAM,2CAA2C,uEAAuE,qBAAqB,mBAAmB,wDAAwD,kBAAkB,+BAA+B,yDAAyD,kBAAkB,MAAM,kCAAkC,iBAAiB,eAAe,wGAAwG,kCAAkC,uGAAuG,2EAA2E,kBAAkB,MAAM,sDAAsD,iBAAiB,mCAAmC,eAAe,6BAA6B,iDAAiD,kCAAkC,sCAAsC,kCAAkC,kCAAkC,wCAAwC,oCAAoC,oCAAoC,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,2DAA2D,wCAAwC,sDAAsD,kBAAkB,MAAM,oEAAoE,oEAAoE,oEAAoE,oEAAoE,8CAA8C,kDAAkD,kDAAkD,yGAAyG,oBAAoB,MAAM,+CAA+C,+CAA+C,+CAA+C,+CAA+C,6PAA6P,0PAA0P,iHAAiH,mBAAmB,iBAAiB,uCAAuC,eAAe;AACxsJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA,2EAA2E,uCAAuC,WAAW;AAC7H;AACA,2EAA2E,wBAAwB,WAAW,4EAA4E,gDAAgD,2DAA2D,SAAS,gDAAgD,8DAA8D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,+GAA+G,0EAA0E,iCAAiC,4BAA4B,oBAAoB,SAAS,qCAAqC,4MAA4M,6UAA6U,uCAAuC,kDAAkD,qCAAqC,uLAAuL,6DAA6D,qKAAqK,wCAAwC,gCAAgC,8LAA8L,iOAAiO,wCAAwC,gCAAgC,qMAAqM,qRAAqR,uCAAuC,8BAA8B,SAAS;AACv+F;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;AACA;AACA,OAAO,sBAAsB;AAC7B;AACA,kCAAkC;AAClC;;AAEA,yDAAyD;AACzD;AACA;;AAEA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,gDAAgD,qBAAqB;AACrE;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA,8CAA8C,qBAAqB;AACnE;AACA;AACA;AACA;AACA,wBAAwB;AACxB;;AAEA;;AAEA,4CAA4C,eAAe;AAC3D;AACA;;AAEA;;AAEA;AACA;AACA,wBAAwB;AACxB;AACA;;AAEA,gFAAgF,yDAAyD,wDAAwD;AACjM;AACA;AACA;;AAEA;AACA;;AAEA,gDAAgD,sBAAsB;AACtE;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,mBAAmB;AACnB,4BAA4B;AAC5B;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,mBAAmB;AACnB;AACA;AACA;AACA,iBAAiB;;AAEjB;AACA;;AAEA;AACA,aAAa;;AAEb;AACA;AACA;AACA,WAAW;AACX,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,gBAAgB;AAChB;;AAEA,kBAAkB,cAAc;AAChC;AACA;;AAEA;AACA,KAAK;;AAEL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,GAAG;;AAEH;AACA;AACA;AACA,CAAC","sources":["webpack://jacdac-docs/./src/workers/tf/dist/node_modules/tf-worker.js"],"sourcesContent":["var _asyncToGenerator = require(\"/home/runner/work/jacdac-docs/jacdac-docs/node_modules/babel-preset-gatsby/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nrequire(\"core-js/modules/es.math.hypot.js\");\n\nfunction e() {\n  return (e = Object.assign || function (e) {\n    for (var t = 1; t < arguments.length; t++) {\n      var n = arguments[t];\n\n      for (var s in n) {\n        Object.prototype.hasOwnProperty.call(n, s) && (e[s] = n[s]);\n      }\n    }\n\n    return e;\n  }).apply(this, arguments);\n}\n\nclass t {\n  constructor(e, t) {\n    this.backend = e, this.dataMover = t, this.data = new WeakMap(), this.dataIdsCount = 0;\n  }\n\n  get(e) {\n    return this.data.has(e) || this.dataMover.moveData(this.backend, e), this.data.get(e);\n  }\n\n  set(e, t) {\n    this.dataIdsCount++, this.data.set(e, t);\n  }\n\n  has(e) {\n    return this.data.has(e);\n  }\n\n  delete(e) {\n    return this.dataIdsCount--, this.data.delete(e);\n  }\n\n  numDataIds() {\n    return this.dataIdsCount;\n  }\n\n}\n\nclass n {\n  refCount(e) {\n    return s(\"refCount\");\n  }\n\n  incRef(e) {\n    return s(\"incRef\");\n  }\n\n  timerAvailable() {\n    return !0;\n  }\n\n  time(e) {\n    return s(\"time\");\n  }\n\n  read(e) {\n    return s(\"read\");\n  }\n\n  readSync(e) {\n    return s(\"readSync\");\n  }\n\n  numDataIds() {\n    return s(\"numDataIds\");\n  }\n\n  disposeData(e, t) {\n    return s(\"disposeData\");\n  }\n\n  write(e, t, n) {\n    return s(\"write\");\n  }\n\n  move(e, t, n, r, a) {\n    return s(\"move\");\n  }\n\n  memory() {\n    return s(\"memory\");\n  }\n\n  floatPrecision() {\n    return s(\"floatPrecision\");\n  }\n\n  epsilon() {\n    return 32 === this.floatPrecision() ? 1e-7 : 1e-4;\n  }\n\n  dispose() {\n    return s(\"dispose\");\n  }\n\n}\n\nfunction s(e) {\n  throw new Error(\"'\".concat(e, \"' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen\"));\n}\n\nfunction r(e) {\n  var t = e.length,\n      n = 0;\n\n  for (; t > 0;) {\n    n = Math.random() * t | 0, t--, o(e, t, n);\n  }\n}\n\nfunction a(e, t, n) {\n  return Math.max(e, Math.min(t, n));\n}\n\nfunction i(e) {\n  return e % 2 == 0 ? e : e + 1;\n}\n\nfunction o(e, t, n) {\n  var s = e[t];\n  e[t] = e[n], e[n] = s;\n}\n\nfunction l(e, t) {\n  if (!e) throw new Error(\"string\" == typeof t ? t : t());\n}\n\nfunction u(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"\";\n  l(p(e, t), () => n + \" Shapes \".concat(e, \" and \").concat(t, \" must match\"));\n}\n\nfunction c(e) {\n  l(null != e, () => \"The input to the tensor constructor must be a non-null value.\");\n}\n\nfunction h(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (null == t && (t = []), Array.isArray(e) || $(e) && !n) for (var _s2 = 0; _s2 < e.length; ++_s2) {\n    h(e[_s2], t, n);\n  } else t.push(e);\n  return t;\n}\n\nfunction d(e) {\n  if (0 === e.length) return 1;\n  var t = e[0];\n\n  for (var _n2 = 1; _n2 < e.length; _n2++) {\n    t *= e[_n2];\n  }\n\n  return t;\n}\n\nfunction p(e, t) {\n  if (e === t) return !0;\n  if (null == e || null == t) return !1;\n  if (e.length !== t.length) return !1;\n\n  for (var _n3 = 0; _n3 < e.length; _n3++) {\n    if (e[_n3] !== t[_n3]) return !1;\n  }\n\n  return !0;\n}\n\nfunction f(e) {\n  return e % 1 == 0;\n}\n\nfunction g(e) {\n  var t = Math.ceil(Math.sqrt(e));\n  return [t, Math.ceil(e / t)];\n}\n\nfunction m(e, t) {\n  return t <= e.length ? e : e + \" \".repeat(t - e.length);\n}\n\nfunction b(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e => 0;\n  var n = arguments.length > 2 ? arguments[2] : undefined;\n  return new Promise((s, r) => {\n    var a = 0;\n\n    var i = () => {\n      if (e()) return void s();\n      a++;\n      var o = t(a);\n      null != n && a >= n ? r() : setTimeout(i, o);\n    };\n\n    i();\n  });\n}\n\nfunction x(e, t) {\n  var n = 1,\n      s = -1;\n\n  for (var _t2 = 0; _t2 < e.length; ++_t2) {\n    if (e[_t2] >= 0) n *= e[_t2];else if (-1 === e[_t2]) {\n      if (-1 !== s) throw Error(\"Shapes can only have 1 implicit size. Found -1 at dim \".concat(s, \" and dim \").concat(_t2));\n      s = _t2;\n    } else if (e[_t2] < 0) throw Error(\"Shapes can not be < 0. Found \".concat(e[_t2], \" at dim \").concat(_t2));\n  }\n\n  if (-1 === s) {\n    if (t > 0 && t !== n) throw Error(\"Size(\".concat(t, \") must match the product of shape \").concat(e));\n    return e;\n  }\n\n  if (0 === n) throw Error(\"Cannot infer the missing size in [\".concat(e, \"] when there are 0 elements\"));\n  if (t % n != 0) throw Error(\"The implicit shape can't be a fractional number. Got \".concat(t, \" / \").concat(n));\n  var r = e.slice();\n  return r[s] = t / n, r;\n}\n\nfunction y(e, t) {\n  var n = t.length;\n  return l((e = null == e ? t.map((e, t) => t) : [].concat(e)).every(e => e >= -n && e < n), () => \"All values in axis param must be in range [-\".concat(n, \", \").concat(n, \") but got axis \").concat(e)), l(e.every(e => f(e)), () => \"All values in axis param must be integers but got axis \".concat(e)), e.map(e => e < 0 ? n + e : e);\n}\n\nfunction k(e, t) {\n  var n = [],\n      s = [],\n      r = null != t && Array.isArray(t) && 0 === t.length,\n      a = null == t || r ? null : y(t, e).sort();\n  var i = 0;\n\n  for (var _t3 = 0; _t3 < e.length; ++_t3) {\n    if (null != a) {\n      if (a[i] === _t3 && 1 !== e[_t3]) throw new Error(\"Can't squeeze axis \".concat(_t3, \" since its dim '\").concat(e[_t3], \"' is not 1\"));\n      (null == a[i] || a[i] > _t3) && 1 === e[_t3] && (n.push(e[_t3]), s.push(_t3)), a[i] <= _t3 && i++;\n    }\n\n    1 !== e[_t3] && (n.push(e[_t3]), s.push(_t3));\n  }\n\n  return {\n    newShape: n,\n    keptDims: s\n  };\n}\n\nfunction w(e, t) {\n  var n = null;\n  if (null == e || \"float32\" === e) n = new Float32Array(t);else if (\"int32\" === e) n = new Int32Array(t);else {\n    if (\"bool\" !== e) throw new Error(\"Unknown data type \".concat(e));\n    n = new Uint8Array(t);\n  }\n  return n;\n}\n\nfunction v(e, t) {\n  var n = null;\n  if (null == e || \"float32\" === e) n = new Float32Array(t);else if (\"int32\" === e) n = new Int32Array(t);else if (\"bool\" === e) n = new Uint8Array(t);else {\n    if (\"string\" !== e) throw new Error(\"Unknown data type \".concat(e));\n    n = new Array(t);\n  }\n  return n;\n}\n\nfunction I(e, t) {\n  return !(\"complex64\" === t || \"float32\" === t && \"complex64\" !== e || \"int32\" === t && \"float32\" !== e && \"complex64\" !== e || \"bool\" === t && \"bool\" === e);\n}\n\nfunction $(e) {\n  return e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array;\n}\n\nfunction N(e) {\n  if (\"float32\" === e || \"int32\" === e) return 4;\n  if (\"complex64\" === e) return 8;\n  if (\"bool\" === e) return 1;\n  throw new Error(\"Unknown dtype \".concat(e));\n}\n\nfunction C(e) {\n  return \"string\" == typeof e || e instanceof String;\n}\n\nfunction S(e) {\n  return \"number\" == typeof e;\n}\n\nfunction T(e) {\n  return Array.isArray(e) ? T(e[0]) : e instanceof Float32Array ? \"float32\" : e instanceof Int32Array || e instanceof Uint8Array ? \"int32\" : S(e) ? \"float32\" : C(e) ? \"string\" : \"boolean\" == typeof e ? \"bool\" : \"float32\";\n}\n\nfunction E(e) {\n  return !!(e && e.constructor && e.call && e.apply);\n}\n\nfunction R(e, t) {\n  for (var _n4 = t; _n4 < e; ++_n4) {\n    if (e % _n4 == 0) return _n4;\n  }\n\n  return e;\n}\n\nfunction A(e) {\n  var t = e.length;\n  if (t < 2) return [];\n  var n = new Array(t - 1);\n  n[t - 2] = e[t - 1];\n\n  for (var _s3 = t - 3; _s3 >= 0; --_s3) {\n    n[_s3] = n[_s3 + 1] * e[_s3 + 1];\n  }\n\n  return n;\n}\n\nfunction F(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = new Array();\n\n  if (1 === t.length) {\n    var _a2 = t[0] * (s ? 2 : 1);\n\n    for (var _t4 = 0; _t4 < _a2; _t4++) {\n      r[_t4] = n[e + _t4];\n    }\n  } else {\n    var _a3 = t[0],\n        _i2 = t.slice(1),\n        _o2 = _i2.reduce((e, t) => e * t) * (s ? 2 : 1);\n\n    for (var _t5 = 0; _t5 < _a3; _t5++) {\n      r[_t5] = F(e + _t5 * _o2, _i2, n, s);\n    }\n  }\n\n  return r;\n}\n\nfunction D(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (0 === e.length) return t[0];\n  var s = e.reduce((e, t) => e * t) * (n ? 2 : 1);\n  if (0 === s) return [];\n  if (s !== t.length) throw new Error(\"[\".concat(e, \"] does not match the input size \").concat(t.length).concat(n ? \" for a complex tensor\" : \"\", \".\"));\n  return F(0, e, t, n);\n}\n\nfunction _(e, t) {\n  var n = O(e, t);\n\n  for (var _e2 = 0; _e2 < n.length; _e2++) {\n    n[_e2] = 1;\n  }\n\n  return n;\n}\n\nfunction O(e, t) {\n  if (null == t || \"float32\" === t || \"complex64\" === t) return new Float32Array(e);\n  if (\"int32\" === t) return new Int32Array(e);\n  if (\"bool\" === t) return new Uint8Array(e);\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction M(e, t) {\n  var n = e.reduce((e, t) => e * t, 1);\n  if (null == t || \"float32\" === t) return D(e, new Float32Array(n));\n  if (\"int32\" === t) return D(e, new Int32Array(n));\n  if (\"bool\" === t) return D(e, new Uint8Array(n));\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction L(e) {\n  e.forEach(t => {\n    l(Number.isInteger(t) && t >= 0, () => \"Tensor must have a shape comprised of positive integers but got shape [\".concat(e, \"].\"));\n  });\n}\n\nfunction z(e, t, n) {\n  if (0 === t) return 0;\n  if (1 === t) return e[0];\n  var s = e[e.length - 1];\n\n  for (var _t6 = 0; _t6 < e.length - 1; ++_t6) {\n    s += n[_t6] * e[_t6];\n  }\n\n  return s;\n}\n\nfunction B(e, t, n) {\n  if (0 === t) return [];\n  if (1 === t) return [e];\n  var s = new Array(t);\n\n  for (var _t7 = 0; _t7 < s.length - 1; ++_t7) {\n    s[_t7] = Math.floor(e / n[_t7]), e -= s[_t7] * n[_t7];\n  }\n\n  return s[s.length - 1] = e, s;\n}\n\nfunction P(e) {\n  return e && e.then && \"function\" == typeof e.then;\n}\n\nclass W {\n  constructor(e) {\n    this.global = e, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = U, this.populateURLFlags();\n  }\n\n  setPlatform(e, t) {\n    null != this.platform && console.warn(\"Platform \".concat(this.platformName, \" has already been set. Overwriting the platform with \").concat(t, \".\")), this.platformName = e, this.platform = t;\n  }\n\n  registerFlag(e, t, n) {\n    if (this.flagRegistry[e] = {\n      evaluationFn: t,\n      setHook: n\n    }, null != this.urlFlags[e]) {\n      var _t8 = this.urlFlags[e];\n      console.warn(\"Setting feature override from URL \".concat(e, \": \").concat(_t8, \".\")), this.set(e, _t8);\n    }\n  }\n\n  getAsync(e) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return e in _this.flags || (_this.flags[e] = yield _this.evaluateFlag(e)), _this.flags[e];\n    })();\n  }\n\n  get(e) {\n    if (e in this.flags) return this.flags[e];\n    var t = this.evaluateFlag(e);\n    if (P(t)) throw new Error(\"Flag \".concat(e, \" cannot be synchronously evaluated. Please use getAsync() instead.\"));\n    return this.flags[e] = t, this.flags[e];\n  }\n\n  getNumber(e) {\n    return this.get(e);\n  }\n\n  getBool(e) {\n    return this.get(e);\n  }\n\n  getFlags() {\n    return this.flags;\n  }\n\n  get features() {\n    return this.flags;\n  }\n\n  set(e, t) {\n    if (null == this.flagRegistry[e]) throw new Error(\"Cannot set flag \".concat(e, \" as it has not been registered.\"));\n    this.flags[e] = t, null != this.flagRegistry[e].setHook && this.flagRegistry[e].setHook(t);\n  }\n\n  evaluateFlag(e) {\n    if (null == this.flagRegistry[e]) throw new Error(\"Cannot evaluate flag '\".concat(e, \"': no evaluation function found.\"));\n    return this.flagRegistry[e].evaluationFn();\n  }\n\n  setFlags(e) {\n    this.flags = Object.assign({}, e);\n  }\n\n  reset() {\n    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();\n  }\n\n  populateURLFlags() {\n    if (void 0 === this.global || void 0 === this.global.location || void 0 === this.global.location.search) return;\n    var e = this.getQueryParams(this.global.location.search);\n    \"tfjsflags\" in e && e.tfjsflags.split(\",\").forEach(e => {\n      var [t, n] = e.split(\":\");\n\n      this.urlFlags[t] = function (e, t) {\n        if (\"true\" === (t = t.toLowerCase()) || \"false\" === t) return \"true\" === t;\n        if (\"\" + +t === t) return +t;\n        throw new Error(\"Could not parse value flag value \".concat(t, \" for flag \").concat(e, \".\"));\n      }(t, n);\n    });\n  }\n\n}\n\nfunction U(e) {\n  var t = {};\n  return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (e) {\n    for (var _len = arguments.length, n = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      n[_key - 1] = arguments[_key];\n    }\n\n    return function (e, t, n) {\n      e[decodeURIComponent(t)] = decodeURIComponent(n || \"\");\n    }(t, n[0], n[1]), n.join(\"=\");\n  }), t;\n}\n\nfunction V() {\n  return H;\n}\n\nvar G,\n    H = null;\n\nfunction j() {\n  if (null == G) {\n    var _e3;\n\n    if (\"undefined\" != typeof window) _e3 = window;else if (\"undefined\" != typeof global) _e3 = global;else if (\"undefined\" != typeof process) _e3 = process;else {\n      if (\"undefined\" == typeof self) throw new Error(\"Could not find a global object\");\n      _e3 = self;\n    }\n    G = _e3;\n  }\n\n  return G;\n}\n\nfunction q(e, t) {\n  var n = function () {\n    var e = j();\n    return null == e._tfGlobals && (e._tfGlobals = new Map()), e._tfGlobals;\n  }();\n\n  if (n.has(e)) return n.get(e);\n  {\n    var _s4 = t();\n\n    return n.set(e, _s4), n.get(e);\n  }\n}\n\nvar K = q(\"kernelRegistry\", () => new Map()),\n    X = q(\"gradRegistry\", () => new Map());\n\nfunction Y(e, t) {\n  var n = te(e, t);\n  return K.get(n);\n}\n\nfunction J(e) {\n  return X.get(e);\n}\n\nfunction Z(e) {\n  var t = K.entries(),\n      n = [];\n\n  for (;;) {\n    var {\n      done: _s5,\n      value: _r2\n    } = t.next();\n    if (_s5) break;\n\n    var [_a4, _i3] = _r2,\n        [_o3] = _a4.split(\"_\");\n\n    _o3 === e && n.push(_i3);\n  }\n\n  return n;\n}\n\nfunction Q(e) {\n  var {\n    kernelName: t,\n    backendName: n\n  } = e,\n      s = te(t, n);\n  K.has(s) && console.warn(\"The kernel '\".concat(t, \"' for backend '\").concat(n, \"' is already registered\")), K.set(s, e);\n}\n\nfunction ee(e) {\n  var {\n    kernelName: t\n  } = e;\n  X.has(t) && V().getBool(\"DEBUG\") && console.warn(\"Overriding the gradient for '\".concat(t, \"'\")), X.set(t, e);\n}\n\nfunction te(e, t) {\n  return \"\".concat(t, \"_\").concat(e);\n}\n\nvar ne = re,\n    se = null;\n\ntry {\n  se = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n} catch (e) {}\n\nfunction re(e, t, n) {\n  this.low = 0 | e, this.high = 0 | t, this.unsigned = !!n;\n}\n\nfunction ae(e) {\n  return !0 === (e && e.__isLong__);\n}\n\nObject.defineProperty(re.prototype, \"__isLong__\", {\n  value: !0\n}), re.isLong = ae;\nvar ie = {},\n    oe = {};\n\nfunction le(e, t) {\n  var n, s, r;\n  return t ? (r = 0 <= (e >>>= 0) && e < 256) && (s = oe[e]) ? s : (n = ce(e, (0 | e) < 0 ? -1 : 0, !0), r && (oe[e] = n), n) : (r = -128 <= (e |= 0) && e < 128) && (s = ie[e]) ? s : (n = ce(e, e < 0 ? -1 : 0, !1), r && (ie[e] = n), n);\n}\n\nfunction ue(e, t) {\n  if (isNaN(e)) return t ? ye : xe;\n\n  if (t) {\n    if (e < 0) return ye;\n    if (e >= ge) return $e;\n  } else {\n    if (e <= -me) return Ne;\n    if (e + 1 >= me) return Ie;\n  }\n\n  return e < 0 ? ue(-e, t).neg() : ce(e % fe | 0, e / fe | 0, t);\n}\n\nfunction ce(e, t, n) {\n  return new re(e, t, n);\n}\n\nre.fromInt = le, re.fromNumber = ue, re.fromBits = ce;\nvar he = Math.pow;\n\nfunction de(e, t, n) {\n  if (0 === e.length) throw Error(\"empty string\");\n  if (\"NaN\" === e || \"Infinity\" === e || \"+Infinity\" === e || \"-Infinity\" === e) return xe;\n  if (\"number\" == typeof t ? (n = t, t = !1) : t = !!t, (n = n || 10) < 2 || 36 < n) throw RangeError(\"radix\");\n  var s;\n  if ((s = e.indexOf(\"-\")) > 0) throw Error(\"interior hyphen\");\n  if (0 === s) return de(e.substring(1), t, n).neg();\n\n  for (var r = ue(he(n, 8)), a = xe, i = 0; i < e.length; i += 8) {\n    var o = Math.min(8, e.length - i),\n        l = parseInt(e.substring(i, i + o), n);\n\n    if (o < 8) {\n      var u = ue(he(n, o));\n      a = a.mul(u).add(ue(l));\n    } else a = (a = a.mul(r)).add(ue(l));\n  }\n\n  return a.unsigned = t, a;\n}\n\nfunction pe(e, t) {\n  return \"number\" == typeof e ? ue(e, t) : \"string\" == typeof e ? de(e, t) : ce(e.low, e.high, \"boolean\" == typeof t ? t : e.unsigned);\n}\n\nre.fromString = de, re.fromValue = pe;\nvar fe = 4294967296,\n    ge = fe * fe,\n    me = ge / 2,\n    be = le(1 << 24),\n    xe = le(0);\nre.ZERO = xe;\nvar ye = le(0, !0);\nre.UZERO = ye;\nvar ke = le(1);\nre.ONE = ke;\nvar we = le(1, !0);\nre.UONE = we;\nvar ve = le(-1);\nre.NEG_ONE = ve;\nvar Ie = ce(-1, 2147483647, !1);\nre.MAX_VALUE = Ie;\nvar $e = ce(-1, -1, !0);\nre.MAX_UNSIGNED_VALUE = $e;\nvar Ne = ce(0, -2147483648, !1);\nre.MIN_VALUE = Ne;\nvar Ce = re.prototype;\nCe.toInt = function () {\n  return this.unsigned ? this.low >>> 0 : this.low;\n}, Ce.toNumber = function () {\n  return this.unsigned ? (this.high >>> 0) * fe + (this.low >>> 0) : this.high * fe + (this.low >>> 0);\n}, Ce.toString = function (e) {\n  if ((e = e || 10) < 2 || 36 < e) throw RangeError(\"radix\");\n  if (this.isZero()) return \"0\";\n\n  if (this.isNegative()) {\n    if (this.eq(Ne)) {\n      var t = ue(e),\n          n = this.div(t),\n          s = n.mul(t).sub(this);\n      return n.toString(e) + s.toInt().toString(e);\n    }\n\n    return \"-\" + this.neg().toString(e);\n  }\n\n  for (var r = ue(he(e, 6), this.unsigned), a = this, i = \"\";;) {\n    var o = a.div(r),\n        l = (a.sub(o.mul(r)).toInt() >>> 0).toString(e);\n    if ((a = o).isZero()) return l + i;\n\n    for (; l.length < 6;) {\n      l = \"0\" + l;\n    }\n\n    i = \"\" + l + i;\n  }\n}, Ce.getHighBits = function () {\n  return this.high;\n}, Ce.getHighBitsUnsigned = function () {\n  return this.high >>> 0;\n}, Ce.getLowBits = function () {\n  return this.low;\n}, Ce.getLowBitsUnsigned = function () {\n  return this.low >>> 0;\n}, Ce.getNumBitsAbs = function () {\n  if (this.isNegative()) return this.eq(Ne) ? 64 : this.neg().getNumBitsAbs();\n\n  for (var e = 0 != this.high ? this.high : this.low, t = 31; t > 0 && 0 == (e & 1 << t); t--) {\n    ;\n  }\n\n  return 0 != this.high ? t + 33 : t + 1;\n}, Ce.isZero = function () {\n  return 0 === this.high && 0 === this.low;\n}, Ce.eqz = Ce.isZero, Ce.isNegative = function () {\n  return !this.unsigned && this.high < 0;\n}, Ce.isPositive = function () {\n  return this.unsigned || this.high >= 0;\n}, Ce.isOdd = function () {\n  return 1 == (1 & this.low);\n}, Ce.isEven = function () {\n  return 0 == (1 & this.low);\n}, Ce.equals = function (e) {\n  return ae(e) || (e = pe(e)), (this.unsigned === e.unsigned || this.high >>> 31 != 1 || e.high >>> 31 != 1) && this.high === e.high && this.low === e.low;\n}, Ce.eq = Ce.equals, Ce.notEquals = function (e) {\n  return !this.eq(e);\n}, Ce.neq = Ce.notEquals, Ce.ne = Ce.notEquals, Ce.lessThan = function (e) {\n  return this.comp(e) < 0;\n}, Ce.lt = Ce.lessThan, Ce.lessThanOrEqual = function (e) {\n  return this.comp(e) <= 0;\n}, Ce.lte = Ce.lessThanOrEqual, Ce.le = Ce.lessThanOrEqual, Ce.greaterThan = function (e) {\n  return this.comp(e) > 0;\n}, Ce.gt = Ce.greaterThan, Ce.greaterThanOrEqual = function (e) {\n  return this.comp(e) >= 0;\n}, Ce.gte = Ce.greaterThanOrEqual, Ce.ge = Ce.greaterThanOrEqual, Ce.compare = function (e) {\n  if (ae(e) || (e = pe(e)), this.eq(e)) return 0;\n  var t = this.isNegative(),\n      n = e.isNegative();\n  return t && !n ? -1 : !t && n ? 1 : this.unsigned ? e.high >>> 0 > this.high >>> 0 || e.high === this.high && e.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(e).isNegative() ? -1 : 1;\n}, Ce.comp = Ce.compare, Ce.negate = function () {\n  return !this.unsigned && this.eq(Ne) ? Ne : this.not().add(ke);\n}, Ce.neg = Ce.negate, Ce.add = function (e) {\n  ae(e) || (e = pe(e));\n  var t = 0,\n      n = 0,\n      s = 0,\n      r = 0;\n  return s += (r += (65535 & this.low) + (65535 & e.low)) >>> 16, n += (s += (this.low >>> 16) + (e.low >>> 16)) >>> 16, t += (n += (65535 & this.high) + (65535 & e.high)) >>> 16, t += (this.high >>> 16) + (e.high >>> 16), ce((s &= 65535) << 16 | (r &= 65535), (t &= 65535) << 16 | (n &= 65535), this.unsigned);\n}, Ce.subtract = function (e) {\n  return ae(e) || (e = pe(e)), this.add(e.neg());\n}, Ce.sub = Ce.subtract, Ce.multiply = function (e) {\n  if (this.isZero()) return xe;\n  if (ae(e) || (e = pe(e)), se) return ce(se.mul(this.low, this.high, e.low, e.high), se.get_high(), this.unsigned);\n  if (e.isZero()) return xe;\n  if (this.eq(Ne)) return e.isOdd() ? Ne : xe;\n  if (e.eq(Ne)) return this.isOdd() ? Ne : xe;\n  if (this.isNegative()) return e.isNegative() ? this.neg().mul(e.neg()) : this.neg().mul(e).neg();\n  if (e.isNegative()) return this.mul(e.neg()).neg();\n  if (this.lt(be) && e.lt(be)) return ue(this.toNumber() * e.toNumber(), this.unsigned);\n  var t = 65535 & this.high,\n      n = this.low >>> 16,\n      s = 65535 & this.low,\n      r = 65535 & e.high,\n      a = e.low >>> 16,\n      i = 65535 & e.low,\n      o = 0,\n      l = 0,\n      u = 0,\n      c = 0;\n  return u += (c += s * i) >>> 16, l += (u += n * i) >>> 16, u &= 65535, l += (u += s * a) >>> 16, o += (l += t * i) >>> 16, l &= 65535, o += (l += n * a) >>> 16, l &= 65535, o += (l += s * r) >>> 16, o += (this.high >>> 16) * i + t * a + n * r + s * (e.high >>> 16), ce((u &= 65535) << 16 | (c &= 65535), (o &= 65535) << 16 | (l &= 65535), this.unsigned);\n}, Ce.mul = Ce.multiply, Ce.divide = function (e) {\n  if (ae(e) || (e = pe(e)), e.isZero()) throw Error(\"division by zero\");\n  var t, n, s;\n  if (se) return this.unsigned || -2147483648 !== this.high || -1 !== e.low || -1 !== e.high ? ce((this.unsigned ? se.div_u : se.div_s)(this.low, this.high, e.low, e.high), se.get_high(), this.unsigned) : this;\n  if (this.isZero()) return this.unsigned ? ye : xe;\n\n  if (this.unsigned) {\n    if (e.unsigned || (e = e.toUnsigned()), e.gt(this)) return ye;\n    if (e.gt(this.shru(1))) return we;\n    s = ye;\n  } else {\n    if (this.eq(Ne)) return e.eq(ke) || e.eq(ve) ? Ne : e.eq(Ne) ? ke : (t = this.shr(1).div(e).shl(1)).eq(xe) ? e.isNegative() ? ke : ve : (n = this.sub(e.mul(t)), s = t.add(n.div(e)));\n    if (e.eq(Ne)) return this.unsigned ? ye : xe;\n    if (this.isNegative()) return e.isNegative() ? this.neg().div(e.neg()) : this.neg().div(e).neg();\n    if (e.isNegative()) return this.div(e.neg()).neg();\n    s = xe;\n  }\n\n  for (n = this; n.gte(e);) {\n    t = Math.max(1, Math.floor(n.toNumber() / e.toNumber()));\n\n    for (var r = Math.ceil(Math.log(t) / Math.LN2), a = r <= 48 ? 1 : he(2, r - 48), i = ue(t), o = i.mul(e); o.isNegative() || o.gt(n);) {\n      o = (i = ue(t -= a, this.unsigned)).mul(e);\n    }\n\n    i.isZero() && (i = ke), s = s.add(i), n = n.sub(o);\n  }\n\n  return s;\n}, Ce.div = Ce.divide, Ce.modulo = function (e) {\n  return ae(e) || (e = pe(e)), se ? ce((this.unsigned ? se.rem_u : se.rem_s)(this.low, this.high, e.low, e.high), se.get_high(), this.unsigned) : this.sub(this.div(e).mul(e));\n}, Ce.mod = Ce.modulo, Ce.rem = Ce.modulo, Ce.not = function () {\n  return ce(~this.low, ~this.high, this.unsigned);\n}, Ce.and = function (e) {\n  return ae(e) || (e = pe(e)), ce(this.low & e.low, this.high & e.high, this.unsigned);\n}, Ce.or = function (e) {\n  return ae(e) || (e = pe(e)), ce(this.low | e.low, this.high | e.high, this.unsigned);\n}, Ce.xor = function (e) {\n  return ae(e) || (e = pe(e)), ce(this.low ^ e.low, this.high ^ e.high, this.unsigned);\n}, Ce.shiftLeft = function (e) {\n  return ae(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? ce(this.low << e, this.high << e | this.low >>> 32 - e, this.unsigned) : ce(0, this.low << e - 32, this.unsigned);\n}, Ce.shl = Ce.shiftLeft, Ce.shiftRight = function (e) {\n  return ae(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? ce(this.low >>> e | this.high << 32 - e, this.high >> e, this.unsigned) : ce(this.high >> e - 32, this.high >= 0 ? 0 : -1, this.unsigned);\n}, Ce.shr = Ce.shiftRight, Ce.shiftRightUnsigned = function (e) {\n  if (ae(e) && (e = e.toInt()), 0 == (e &= 63)) return this;\n  var t = this.high;\n  return e < 32 ? ce(this.low >>> e | t << 32 - e, t >>> e, this.unsigned) : ce(32 === e ? t : t >>> e - 32, 0, this.unsigned);\n}, Ce.shru = Ce.shiftRightUnsigned, Ce.shr_u = Ce.shiftRightUnsigned, Ce.toSigned = function () {\n  return this.unsigned ? ce(this.low, this.high, !1) : this;\n}, Ce.toUnsigned = function () {\n  return this.unsigned ? this : ce(this.low, this.high, !0);\n}, Ce.toBytes = function (e) {\n  return e ? this.toBytesLE() : this.toBytesBE();\n}, Ce.toBytesLE = function () {\n  var e = this.high,\n      t = this.low;\n  return [255 & t, t >>> 8 & 255, t >>> 16 & 255, t >>> 24, 255 & e, e >>> 8 & 255, e >>> 16 & 255, e >>> 24];\n}, Ce.toBytesBE = function () {\n  var e = this.high,\n      t = this.low;\n  return [e >>> 24, e >>> 16 & 255, e >>> 8 & 255, 255 & e, t >>> 24, t >>> 16 & 255, t >>> 8 & 255, 255 & t];\n}, re.fromBytes = function (e, t, n) {\n  return n ? re.fromBytesLE(e, t) : re.fromBytesBE(e, t);\n}, re.fromBytesLE = function (e, t) {\n  return new re(e[0] | e[1] << 8 | e[2] << 16 | e[3] << 24, e[4] | e[5] << 8 | e[6] << 16 | e[7] << 24, t);\n}, re.fromBytesBE = function (e, t) {\n  return new re(e[4] << 24 | e[5] << 16 | e[6] << 8 | e[7], e[0] << 24 | e[1] << 16 | e[2] << 8 | e[3], t);\n};\nvar Se = ne;\nvar Te = Se || Object.assign(Object.create(null), ne, {\n  default: Se\n});\n\nfunction Ee(e) {\n  return Te.fromString(e, !0, 16);\n}\n\nvar Re = Ee(\"c3a5c85c97cb3127\"),\n    Ae = Ee(\"b492b66fbe98f273\"),\n    Fe = Ee(\"9ae16a3b2f90404f\");\n\nfunction De(e) {\n  return e.xor(e.shru(47));\n}\n\nfunction _e(e, t, n) {\n  var s = e.slice(t, t + n);\n  return Te.fromBytes(Array.from(s), !0, !0);\n}\n\nfunction Oe(e, t) {\n  return _e(e, t, 8);\n}\n\nfunction Me(e, t) {\n  return _e(e, t, 4);\n}\n\nfunction Le(e, t) {\n  return 0 === t ? e : e.shru(t).or(e.shl(64 - t));\n}\n\nfunction ze(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : Ee(\"9ddfea08eb382d69\");\n  var s = e.xor(t).mul(n);\n  s = s.xor(s.shru(47));\n  var r = t.xor(s).mul(n);\n  return r = r.xor(r.shru(47)), r = r.mul(n), r;\n}\n\nfunction Be(e, t, n, s) {\n  return function (e, t, n, s, r, a) {\n    r = r.add(e), a = Le(a.add(r).add(s), 21);\n    var i = r;\n    return r = (r = r.add(t)).add(n), a = a.add(Le(r, 44)), [r.add(s), a.add(i)];\n  }(Oe(e, t), Oe(e, t + 8), Oe(e, t + 16), Oe(e, t + 24), n, s);\n}\n\nfunction Pe(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n  var n = Te.fromNumber(81, !0);\n  if (t <= 32) return t <= 16 ? function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n\n    if (t >= 8) {\n      var _n5 = Fe.add(2 * t),\n          _s6 = Oe(e, 0).add(Fe),\n          _r3 = Oe(e, t - 8);\n\n      return ze(Le(_r3, 37).mul(_n5).add(_s6), Le(_s6, 25).add(_r3).mul(_n5), _n5);\n    }\n\n    if (t >= 4) {\n      var _n6 = Fe.add(2 * t);\n\n      return ze(Me(e, 0).shl(3).add(t), Me(e, t - 4), _n6);\n    }\n\n    if (t > 0) {\n      var _n7 = t + (e[t - 1] << 2);\n\n      return De(Fe.mul(e[0] + (e[t >> 1] << 8)).xor(Re.mul(_n7))).mul(Fe);\n    }\n\n    return Fe;\n  }(e, t) : function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n    var n = Fe.add(2 * t),\n        s = Oe(e, 0).mul(Ae),\n        r = Oe(e, 8),\n        a = Oe(e, t - 8).mul(n),\n        i = Oe(e, t - 16).mul(Fe);\n    return ze(Le(s.add(r), 43).add(Le(a, 30)).add(i), s.add(Le(r.add(Fe), 18)).add(a), n);\n  }(e, t);\n  if (t <= 64) return function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n    var n = Fe.add(2 * t),\n        s = Oe(e, 0).mul(Fe),\n        r = Oe(e, 8),\n        a = Oe(e, t - 8).mul(n),\n        i = Oe(e, t - 16).mul(Fe),\n        o = Le(s.add(r), 43).add(Le(a, 30)).add(i),\n        l = ze(o, s.add(Le(r.add(Fe), 18)).add(a), n),\n        u = Oe(e, 16).mul(n),\n        c = Oe(e, 24),\n        h = o.add(Oe(e, t - 32)).mul(n),\n        d = l.add(Oe(e, t - 24)).mul(n);\n    return ze(Le(u.add(c), 43).add(Le(h, 30)).add(d), u.add(Le(c.add(s), 18)).add(h), n);\n  }(e, t);\n  var s = n,\n      r = n.mul(Ae).add(113),\n      a = De(r.mul(Fe).add(113)).mul(Fe),\n      i = [Te.UZERO, Te.UZERO],\n      o = [Te.UZERO, Te.UZERO];\n  s = s.mul(Fe).add(Oe(e, 0));\n  var l = 0;\n  var u = 64 * (t - 1 >> 6),\n      c = u + (t - 1 & 63) - 63;\n\n  do {\n    s = Le(s.add(r).add(i[0]).add(Oe(e, l + 8)), 37).mul(Ae), r = Le(r.add(i[1]).add(Oe(e, l + 48)), 42).mul(Ae), s = s.xor(o[1]), r = r.add(i[0]).add(Oe(e, l + 40)), a = Le(a.add(o[0]), 33).mul(Ae), i = Be(e, l, i[1].mul(Ae), s.add(o[0])), o = Be(e, l + 32, a.add(o[1]), r.add(Oe(e, l + 16))), [a, s] = [s, a], l += 64;\n  } while (l !== u);\n\n  var h = Ae.add(a.and(255).shl(1));\n  return l = c, o[0] = o[0].add(t - 1 & 63), i[0] = i[0].add(o[0]), o[0] = o[0].add(i[0]), s = Le(s.add(r).add(i[0]).add(Oe(e, l + 8)), 37).mul(h), r = Le(r.add(i[1]).add(Oe(e, l + 48)), 42).mul(h), s = s.xor(o[1].mul(9)), r = r.add(i[0].mul(9).add(Oe(e, l + 40))), a = Le(a.add(o[0]), 33).mul(h), i = Be(e, l, i[1].mul(h), s.add(o[0])), o = Be(e, l + 32, a.add(o[1]), r.add(Oe(e, l + 16))), [a, s] = [s, a], ze(ze(i[0], o[0], h).add(De(r).mul(Re)).add(a), ze(i[1], o[1], h).add(s), h);\n}\n\nfunction We(e, t) {\n  return \"string\" === t ? Ge(e) : Ue([e], t);\n}\n\nfunction Ue(e, t) {\n  if (\"string\" === t) throw new Error(\"Cannot convert a string[] to a TypedArray\");\n  if (Array.isArray(e) && (e = h(e)), V().getBool(\"DEBUG\") && function (e, t) {\n    for (var _n8 = 0; _n8 < e.length; _n8++) {\n      var _s7 = e[_n8];\n      if (isNaN(_s7) || !isFinite(_s7)) throw Error(\"A tensor of type \".concat(t, \" being uploaded contains \").concat(_s7, \".\"));\n    }\n  }(e, t), function (e, t) {\n    return e instanceof Float32Array && \"float32\" === t || e instanceof Int32Array && \"int32\" === t || e instanceof Uint8Array && \"bool\" === t;\n  }(e, t)) return e;\n  if (null == t || \"float32\" === t || \"complex64\" === t) return new Float32Array(e);\n  if (\"int32\" === t) return new Int32Array(e);\n\n  if (\"bool\" === t) {\n    var _t9 = new Uint8Array(e.length);\n\n    for (var _n9 = 0; _n9 < _t9.length; ++_n9) {\n      0 !== Math.round(e[_n9]) && (_t9[_n9] = 1);\n    }\n\n    return _t9;\n  }\n\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction Ve() {\n  return V().platform.now();\n}\n\nfunction Ge(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"utf-8\";\n  return t = t || \"utf-8\", V().platform.encode(e, t);\n}\n\nfunction He(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"utf-8\";\n  return t = t || \"utf-8\", V().platform.decode(e, t);\n}\n\nclass je {\n  constructor(e, t) {\n    this.backendTimer = e, this.logger = t, null == t && (this.logger = new Ke());\n  }\n\n  profileKernel(e, t, n) {\n    var s;\n\n    var r = () => {\n      s = n();\n    };\n\n    var a;\n    var i = Ve();\n    if (this.backendTimer.timerAvailable()) a = this.backendTimer.time(r);else {\n      r();\n\n      for (var _e4 of s) {\n        _e4.dataSync();\n      }\n\n      a = Promise.resolve({\n        kernelMs: Ve() - i\n      });\n    }\n\n    if (V().getBool(\"CHECK_COMPUTATION_FOR_ERRORS\")) {\n      var _loop = function _loop(_t10) {\n        var n = s[_t10];\n        n.data().then(t => {\n          qe(t, n.dtype, e);\n        });\n      };\n\n      for (var _t10 = 0; _t10 < s.length; _t10++) {\n        _loop(_t10);\n      }\n    }\n\n    return {\n      kernelName: e,\n      outputs: s,\n      inputs: t,\n      timeMs: a.then(e => e.kernelMs),\n      extraInfo: a.then(e => null != e.getExtraProfileInfo ? e.getExtraProfileInfo() : \"\")\n    };\n  }\n\n  logKernelProfile(e) {\n    var {\n      kernelName: t,\n      outputs: n,\n      timeMs: s,\n      inputs: r,\n      extraInfo: a\n    } = e;\n    n.forEach(e => {\n      Promise.all([e.data(), s, a]).then(n => {\n        this.logger.logKernelProfile(t, e, n[0], n[1], r, n[2]);\n      });\n    });\n  }\n\n}\n\nfunction qe(e, t, n) {\n  if (\"float32\" !== t) return !1;\n\n  for (var _t11 = 0; _t11 < e.length; _t11++) {\n    var _s8 = e[_t11];\n    if (isNaN(_s8) || !isFinite(_s8)) return console.warn(\"Found \".concat(_s8, \" in the result of '\").concat(n, \"'\")), !0;\n  }\n\n  return !1;\n}\n\nclass Ke {\n  logKernelProfile(e, t, n, s, r, a) {\n    var i = \"number\" == typeof s ? m(\"\".concat(s, \"ms\"), 9) : s.error,\n        o = m(e, 25),\n        l = t.rank,\n        u = t.size,\n        c = m(t.shape.toString(), 14);\n    var h = \"\";\n\n    for (var _e5 in r) {\n      var _n10 = r[_e5];\n\n      if (null != _n10) {\n        var _s9 = _n10.shape || t.shape,\n            _r4 = _s9.length;\n\n        h += \"\".concat(_e5, \": \").concat(_r4, \"D \").concat(_r4 > 0 ? _s9 : \"\", \" \");\n      }\n    }\n\n    console.log(\"%c\".concat(o, \"\\t%c\").concat(i, \"\\t%c\").concat(l, \"D \").concat(c, \"\\t%c\").concat(u, \"\\t%c\").concat(h, \"\\t%c\").concat(a), \"font-weight:bold\", \"color:red\", \"color:blue\", \"color: orange\", \"color: green\", \"color: steelblue\");\n  }\n\n}\n\nfunction Xe(e, t, n, s) {\n  var r = A(t),\n      a = function (e, t, n, s) {\n    var r = d(t),\n        a = s[s.length - 1],\n        i = new Array(a).fill(0),\n        o = t.length,\n        l = \"complex64\" === n ? Qe(e) : e;\n    if (o > 1) for (var _e6 = 0; _e6 < r / a; _e6++) {\n      var _t12 = _e6 * a;\n\n      for (var _e7 = 0; _e7 < a; _e7++) {\n        i[_e7] = Math.max(i[_e7], Ye(l[_t12 + _e7], 0, n).length);\n      }\n    }\n    return i;\n  }(e, t, n, r),\n      i = t.length,\n      o = Ze(e, t, n, r, a),\n      l = [\"Tensor\"];\n\n  return s && (l.push(\"  dtype: \".concat(n)), l.push(\"  rank: \".concat(i)), l.push(\"  shape: [\".concat(t, \"]\")), l.push(\"  values:\")), l.push(o.map(e => \"    \" + e).join(\"\\n\")), l.join(\"\\n\");\n}\n\nfunction Ye(e, t, n) {\n  var s;\n  return s = Array.isArray(e) ? \"\".concat(parseFloat(e[0].toFixed(7)), \" + \").concat(parseFloat(e[1].toFixed(7)), \"j\") : C(e) ? \"'\".concat(e, \"'\") : \"bool\" === n ? Je(e) : parseFloat(e.toFixed(7)).toString(), m(s, t);\n}\n\nfunction Je(e) {\n  return 0 === e ? \"false\" : \"true\";\n}\n\nfunction Ze(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !0;\n  var i = \"complex64\" === n ? 2 : 1,\n      o = t[0],\n      l = t.length;\n  if (0 === l) return \"complex64\" === n ? [Ye(Qe(e)[0], 0, n)] : \"bool\" === n ? [Je(e[0])] : [e[0].toString()];\n\n  if (1 === l) {\n    if (o > 20) {\n      var _t13 = Array.from(e.slice(0, 3 * i)),\n          _s10 = Array.from(e.slice((o - 3) * i, o * i));\n\n      return \"complex64\" === n && (_t13 = Qe(_t13), _s10 = Qe(_s10)), [\"[\" + _t13.map((e, t) => Ye(e, r[t], n)).join(\", \") + \", ..., \" + _s10.map((e, t) => Ye(e, r[o - 3 + t], n)).join(\", \") + \"]\"];\n    }\n\n    return [\"[\" + (\"complex64\" === n ? Qe(e) : Array.from(e)).map((e, t) => Ye(e, r[t], n)).join(\", \") + \"]\"];\n  }\n\n  var u = t.slice(1),\n      c = s.slice(1),\n      h = s[0] * i,\n      d = [];\n\n  if (o > 20) {\n    for (var _t14 = 0; _t14 < 3; _t14++) {\n      var _s11 = _t14 * h;\n\n      d.push(...Ze(e.slice(_s11, _s11 + h), u, n, c, r, !1));\n    }\n\n    d.push(\"...\");\n\n    for (var _t15 = o - 3; _t15 < o; _t15++) {\n      var _s12 = _t15 * h;\n\n      d.push(...Ze(e.slice(_s12, _s12 + h), u, n, c, r, _t15 === o - 1));\n    }\n  } else for (var _t16 = 0; _t16 < o; _t16++) {\n    var _s13 = _t16 * h;\n\n    d.push(...Ze(e.slice(_s13, _s13 + h), u, n, c, r, _t16 === o - 1));\n  }\n\n  var p = 2 === l ? \",\" : \"\";\n  d[0] = \"[\" + d[0] + p;\n\n  for (var _e8 = 1; _e8 < d.length - 1; _e8++) {\n    d[_e8] = \" \" + d[_e8] + p;\n  }\n\n  var f = \",\\n\";\n\n  for (var _e9 = 2; _e9 < l; _e9++) {\n    f += \"\\n\";\n  }\n\n  return d[d.length - 1] = \" \" + d[d.length - 1] + \"]\" + (a ? \"\" : f), d;\n}\n\nfunction Qe(e) {\n  var t = [];\n\n  for (var _n11 = 0; _n11 < e.length; _n11 += 2) {\n    t.push([e[_n11], e[_n11 + 1]]);\n  }\n\n  return t;\n}\n\nclass et {\n  constructor(e, t, n) {\n    if (this.dtype = t, this.shape = e.slice(), this.size = d(e), null != n) {\n      var _e10 = n.length;\n      l(_e10 === this.size, () => \"Length of values '\".concat(_e10, \"' does not match the size inferred by the shape '\").concat(this.size, \"'.\"));\n    }\n\n    if (\"complex64\" === t) throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).\");\n    this.values = n || v(t, this.size), this.strides = A(e);\n  }\n\n  set(e) {\n    for (var _len2 = arguments.length, t = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n      t[_key2 - 1] = arguments[_key2];\n    }\n\n    0 === t.length && (t = [0]), l(t.length === this.rank, () => \"The number of provided coordinates (\".concat(t.length, \") must match the rank (\").concat(this.rank, \")\"));\n    var n = this.locToIndex(t);\n    this.values[n] = e;\n  }\n\n  get() {\n    for (var _len3 = arguments.length, e = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n      e[_key3] = arguments[_key3];\n    }\n\n    0 === e.length && (e = [0]);\n    var t = 0;\n\n    for (var _n12 of e) {\n      if (_n12 < 0 || _n12 >= this.shape[t]) throw new Error(\"Requested out of range element at \".concat(e, \".   Buffer shape=\").concat(this.shape));\n      t++;\n    }\n\n    var n = e[e.length - 1];\n\n    for (var _t17 = 0; _t17 < e.length - 1; ++_t17) {\n      n += this.strides[_t17] * e[_t17];\n    }\n\n    return this.values[n];\n  }\n\n  locToIndex(e) {\n    if (0 === this.rank) return 0;\n    if (1 === this.rank) return e[0];\n    var t = e[e.length - 1];\n\n    for (var _n13 = 0; _n13 < e.length - 1; ++_n13) {\n      t += this.strides[_n13] * e[_n13];\n    }\n\n    return t;\n  }\n\n  indexToLoc(e) {\n    if (0 === this.rank) return [];\n    if (1 === this.rank) return [e];\n    var t = new Array(this.shape.length);\n\n    for (var _n14 = 0; _n14 < t.length - 1; ++_n14) {\n      t[_n14] = Math.floor(e / this.strides[_n14]), e -= t[_n14] * this.strides[_n14];\n    }\n\n    return t[t.length - 1] = e, t;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  toTensor() {\n    return tt().makeTensor(this.values, this.shape, this.dtype);\n  }\n\n}\n\nvar tt = null,\n    nt = null;\n\nclass st {\n  constructor(e, t, n, s) {\n    this.kept = !1, this.isDisposedInternal = !1, this.shape = e.slice(), this.dtype = t || \"float32\", this.size = d(e), this.strides = A(e), this.dataId = n, this.id = s, this.rankType = this.rank < 5 ? this.rank.toString() : \"higher\";\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  buffer() {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this2.data();\n      return nt.buffer(_this2.shape, _this2.dtype, e);\n    })();\n  }\n\n  bufferSync() {\n    return nt.buffer(this.shape, this.dtype, this.dataSync());\n  }\n\n  array() {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this3.data();\n      return D(_this3.shape, e, \"complex64\" === _this3.dtype);\n    })();\n  }\n\n  arraySync() {\n    return D(this.shape, this.dataSync(), \"complex64\" === this.dtype);\n  }\n\n  data() {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      _this4.throwIfDisposed();\n\n      var e = tt().read(_this4.dataId);\n\n      if (\"string\" === _this4.dtype) {\n        var _t18 = yield e;\n\n        try {\n          return _t18.map(e => He(e));\n        } catch (e) {\n          throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\");\n        }\n      }\n\n      return e;\n    })();\n  }\n\n  dataSync() {\n    this.throwIfDisposed();\n    var e = tt().readSync(this.dataId);\n    if (\"string\" === this.dtype) try {\n      return e.map(e => He(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\");\n    }\n    return e;\n  }\n\n  bytes() {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      _this5.throwIfDisposed();\n\n      var e = yield tt().read(_this5.dataId);\n      return \"string\" === _this5.dtype ? e : new Uint8Array(e.buffer);\n    })();\n  }\n\n  dispose() {\n    this.isDisposed || (tt().disposeTensor(this), this.isDisposedInternal = !0);\n  }\n\n  get isDisposed() {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) throw new Error(\"Tensor is disposed.\");\n  }\n\n  print() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return nt.print(this, e);\n  }\n\n  clone() {\n    return this.throwIfDisposed(), nt.clone(this);\n  }\n\n  toString() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return Xe(this.dataSync(), this.shape, this.dtype, e);\n  }\n\n  cast(e) {\n    return this.throwIfDisposed(), nt.cast(this, e);\n  }\n\n  variable() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !0;\n    var t = arguments.length > 1 ? arguments[1] : undefined;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    return this.throwIfDisposed(), tt().makeVariable(this, e, t, n);\n  }\n\n}\n\nfunction rt() {\n  return q(\"Tensor\", () => st);\n}\n\nObject.defineProperty(st, Symbol.hasInstance, {\n  value: e => !!e && null != e.data && null != e.dataSync && null != e.throwIfDisposed\n}), rt();\n\nclass at extends st {\n  constructor(e, t, n, s) {\n    super(e.shape, e.dtype, e.dataId, s), this.trainable = t, this.name = n;\n  }\n\n  assign(e) {\n    if (e.dtype !== this.dtype) throw new Error(\"dtype of the new value (\".concat(e.dtype, \") and previous value (\").concat(this.dtype, \") must match\"));\n    if (!p(e.shape, this.shape)) throw new Error(\"shape of the new value (\".concat(e.shape, \") and previous value (\").concat(this.shape, \") must match\"));\n    tt().disposeTensor(this), this.dataId = e.dataId, tt().incRef(this, null);\n  }\n\n  dispose() {\n    tt().disposeVariable(this), this.isDisposedInternal = !0;\n  }\n\n}\n\nvar it, ot, lt, ut, ct;\nObject.defineProperty(at, Symbol.hasInstance, {\n  value: e => e instanceof st && null != e.assign && e.assign instanceof Function\n}), function (e) {\n  e.R0 = \"R0\", e.R1 = \"R1\", e.R2 = \"R2\", e.R3 = \"R3\", e.R4 = \"R4\", e.R5 = \"R5\", e.R6 = \"R6\";\n}(it || (it = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"int32\", e.bool = \"int32\", e.complex64 = \"complex64\";\n}(ot || (ot = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"int32\", e.bool = \"bool\", e.complex64 = \"complex64\";\n}(lt || (lt = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"float32\", e.bool = \"float32\", e.complex64 = \"complex64\";\n}(ut || (ut = {})), function (e) {\n  e.float32 = \"complex64\", e.int32 = \"complex64\", e.bool = \"complex64\", e.complex64 = \"complex64\";\n}(ct || (ct = {}));\nvar ht = {\n  float32: ut,\n  int32: ot,\n  bool: lt,\n  complex64: ct\n};\n\nfunction dt(e, t) {\n  if (\"string\" === e || \"string\" === t) {\n    if (\"string\" === e && \"string\" === t) return \"string\";\n    throw new Error(\"Can not upcast \".concat(e, \" with \").concat(t));\n  }\n\n  return ht[e][t];\n}\n\nfunction pt(e) {\n  return dt(e, \"int32\");\n}\n\nfunction ft(e, t) {\n  if (e.dtype === t.dtype) return [e, t];\n  var n = dt(e.dtype, t.dtype);\n  return [e.cast(n), t.cast(n)];\n}\n\nfunction gt(e) {\n  var t = [];\n  return mt(e, t, new Set()), t;\n}\n\nfunction mt(e, t, n) {\n  if (null == e) return;\n  if (e instanceof st) return void t.push(e);\n  if (s = e, !Array.isArray(s) && \"object\" != typeof s) return;\n  var s;\n  var r = e;\n\n  for (var _e11 in r) {\n    var _s14 = r[_e11];\n    n.has(_s14) || (n.add(_s14), mt(_s14, t, n));\n  }\n}\n\nfunction bt(e) {\n  return null != e.kernelName;\n}\n\nclass xt {\n  constructor() {\n    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = new WeakMap(), this.profiling = !1, this.activeProfile = {\n      newBytes: 0,\n      newTensors: 0,\n      peakBytes: 0,\n      kernels: [],\n      result: null,\n\n      get kernelNames() {\n        return Array.from(new Set(this.kernels.map(e => e.name)));\n      }\n\n    };\n  }\n\n  dispose() {\n    for (var _e12 in this.registeredVariables) {\n      this.registeredVariables[_e12].dispose();\n    }\n  }\n\n}\n\nclass yt {\n  constructor(e) {\n    this.ENV = e, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new xt();\n  }\n\n  ready() {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null != _this6.pendingBackendInit) return _this6.pendingBackendInit.then(() => {});\n      if (null != _this6.backendInstance) return;\n\n      var e = _this6.getSortedBackends();\n\n      for (var _t19 = 0; _t19 < e.length; _t19++) {\n        var _n15 = e[_t19];\n        if (yield _this6.initializeBackend(_n15).success) return void (yield _this6.setBackend(_n15));\n      }\n\n      throw new Error(\"Could not initialize any backends, all backend initializations failed.\");\n    })();\n  }\n\n  get backend() {\n    if (null != this.pendingBackendInit) throw new Error(\"Backend '\".concat(this.backendName, \"' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods\"));\n\n    if (null == this.backendInstance) {\n      var {\n        name: _e13,\n        asyncInit: _t20\n      } = this.initializeBackendsAndReturnBest();\n      if (_t20) throw new Error(\"The highest priority backend '\".concat(_e13, \"' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods\"));\n      this.setBackend(_e13);\n    }\n\n    return this.backendInstance;\n  }\n\n  backendNames() {\n    return Object.keys(this.registryFactory);\n  }\n\n  findBackend(e) {\n    if (!(e in this.registry)) {\n      if (!(e in this.registryFactory)) return null;\n      {\n        var {\n          asyncInit: _t21\n        } = this.initializeBackend(e);\n        if (_t21) return null;\n      }\n    }\n\n    return this.registry[e];\n  }\n\n  findBackendFactory(e) {\n    return e in this.registryFactory ? this.registryFactory[e].factory : null;\n  }\n\n  registerBackend(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    return e in this.registryFactory ? (console.warn(\"\".concat(e, \" backend was already registered. Reusing existing backend factory.\")), !1) : (this.registryFactory[e] = {\n      factory: t,\n      priority: n\n    }, !0);\n  }\n\n  setBackend(e) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null == _this7.registryFactory[e]) throw new Error(\"Backend name '\".concat(e, \"' not found in registry\"));\n\n      if (_this7.backendName = e, null == _this7.registry[e]) {\n        _this7.backendInstance = null;\n\n        var {\n          success: _t22,\n          asyncInit: _n16\n        } = _this7.initializeBackend(e);\n\n        if (!(_n16 ? yield _t22 : _t22)) return !1;\n      }\n\n      return _this7.backendInstance = _this7.registry[e], _this7.setupRegisteredKernels(), _this7.profiler = new je(_this7.backendInstance), !0;\n    })();\n  }\n\n  setupRegisteredKernels() {\n    Z(this.backendName).forEach(e => {\n      null != e.setupFunc && e.setupFunc(this.backendInstance);\n    });\n  }\n\n  disposeRegisteredKernels(e) {\n    Z(e).forEach(t => {\n      null != t.disposeFunc && t.disposeFunc(this.registry[e]);\n    });\n  }\n\n  initializeBackend(e) {\n    var t = this.registryFactory[e];\n    if (null == t) throw new Error(\"Cannot initialize backend \".concat(e, \", no registration found.\"));\n\n    try {\n      var _s15 = t.factory();\n\n      if (!_s15 || _s15 instanceof n || \"function\" != typeof _s15.then) return this.registry[e] = _s15, {\n        success: !0,\n        asyncInit: !1\n      };\n      {\n        var _t23 = ++this.pendingBackendInitId,\n            _n17 = _s15.then(n => !(_t23 < this.pendingBackendInitId || (this.registry[e] = n, this.pendingBackendInit = null, 0))).catch(n => (_t23 < this.pendingBackendInitId || (this.pendingBackendInit = null, console.warn(\"Initialization of backend \".concat(e, \" failed\")), console.warn(n.stack || n.message)), !1));\n\n        return this.pendingBackendInit = _n17, {\n          success: _n17,\n          asyncInit: !0\n        };\n      }\n    } catch (t) {\n      return console.warn(\"Initialization of backend \".concat(e, \" failed\")), console.warn(t.stack || t.message), {\n        success: !1,\n        asyncInit: !1\n      };\n    }\n  }\n\n  removeBackend(e) {\n    if (!(e in this.registryFactory)) throw new Error(\"\".concat(e, \" backend not found in registry\"));\n    this.backendName === e && null != this.pendingBackendInit && this.pendingBackendInitId++, e in this.registry && (this.disposeRegisteredKernels(e), this.registry[e].dispose(), delete this.registry[e]), delete this.registryFactory[e], this.backendName === e && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);\n  }\n\n  getSortedBackends() {\n    if (0 === Object.keys(this.registryFactory).length) throw new Error(\"No backend found in registry.\");\n    return Object.keys(this.registryFactory).sort((e, t) => this.registryFactory[t].priority - this.registryFactory[e].priority);\n  }\n\n  initializeBackendsAndReturnBest() {\n    var e = this.getSortedBackends();\n\n    for (var _t24 = 0; _t24 < e.length; _t24++) {\n      var _n18 = e[_t24],\n          {\n        success: _s16,\n        asyncInit: _r5\n      } = this.initializeBackend(_n18);\n      if (_r5 || _s16) return {\n        name: _n18,\n        asyncInit: _r5\n      };\n    }\n\n    throw new Error(\"Could not initialize any backends, all backend initializations failed.\");\n  }\n\n  moveData(e, t) {\n    var n = this.state.tensorInfo.get(t),\n        s = n.backend,\n        r = this.readSync(t),\n        a = s.refCount(t);\n    s.disposeData(t, !0), n.backend = e, e.move(t, r, n.shape, n.dtype, a), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n  }\n\n  tidy(e, t) {\n    var n,\n        s = null;\n\n    if (null == t) {\n      if (\"function\" != typeof e) throw new Error(\"Please provide a function to tidy()\");\n      t = e;\n    } else {\n      if (\"string\" != typeof e && !(e instanceof String)) throw new Error(\"When calling with two arguments, the first argument to tidy() must be a string\");\n      if (\"function\" != typeof t) throw new Error(\"When calling with two arguments, the 2nd argument to tidy() must be a function\");\n      s = e;\n    }\n\n    return this.scopedRun(() => this.startScope(s), () => this.endScope(n), () => (n = t(), n instanceof Promise && console.error(\"Cannot return a Promise inside of tidy.\"), n));\n  }\n\n  scopedRun(e, t, n) {\n    e();\n\n    try {\n      var _e14 = n();\n\n      return t(), _e14;\n    } catch (e) {\n      throw t(), e;\n    }\n  }\n\n  nextTensorId() {\n    return yt.nextTensorId++;\n  }\n\n  nextVariableId() {\n    return yt.nextVariableId++;\n  }\n\n  clone(e) {\n    var t = wt.runKernel(\"Identity\", {\n      x: e\n    });\n    return this.addTapeNode(this.state.activeScope.name, {\n      x: e\n    }, [t], e => ({\n      x: () => wt.runKernel(\"Cast\", {\n        x: e\n      }, {\n        dtype: \"float32\"\n      })\n    }), [], {}), t;\n  }\n\n  runKernel(e, t, n) {\n    if (null == Y(e, this.backendName)) throw new Error(\"Kernel '\".concat(e, \"' not registered for backend '\").concat(this.backendName, \"'\"));\n    return this.runKernelFunc({\n      kernelName: e,\n      inputs: t,\n      attrs: n\n    });\n  }\n\n  shouldCheckForMemLeaks() {\n    return this.ENV.getBool(\"IS_TEST\");\n  }\n\n  checkKernelForMemLeak(e, t, n) {\n    var s = this.backend.numDataIds();\n    var r = 0;\n    n.forEach(e => {\n      r += \"complex64\" === e.dtype ? 3 : 1;\n    });\n    var a = s - t - r - this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n    if (a > 0) throw new Error(\"Backend '\".concat(this.backendName, \"' has an internal memory leak (\").concat(a, \" data ids) after running '\").concat(e, \"'\"));\n  }\n\n  runKernelFunc(e) {\n    var t,\n        n = [];\n    var s = this.isTapeOn(),\n        r = this.state.numBytes,\n        a = this.state.numTensors;\n    var i, o;\n    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);\n    var u = bt(e) ? e.kernelName : null != this.state.activeScope ? this.state.activeScope.name : \"\";\n\n    if (bt(e)) {\n      var {\n        kernelName: _t25,\n        inputs: _r6,\n        attrs: _a5\n      } = e,\n          _u2 = Y(_t25, this.backendName);\n\n      l(null != _u2, () => \"Cannot find registered kernel '\".concat(_t25, \"' for backend '\").concat(this.backendName, \"'\")), i = () => {\n        var e = this.backend.numDataIds();\n        o = _u2.kernelFunc({\n          inputs: _r6,\n          attrs: _a5,\n          backend: this.backend\n        });\n        var i = Array.isArray(o) ? o : [o];\n        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(_t25, e, i);\n        var l = i.map(e => {\n          if (null != e.rank) return e;\n          var {\n            dataId: t,\n            shape: n,\n            dtype: s\n          } = e;\n          return this.makeTensorFromDataId(t, n, s);\n        });\n\n        if (s) {\n          var _e15 = this.getTensorsForGradient(_t25, _r6, l);\n\n          n = this.saveTensorsForBackwardMode(_e15);\n        }\n\n        return l;\n      };\n    } else {\n      var {\n        forwardFunc: _t26\n      } = e,\n          _r7 = e => {\n        s && (n = e.map(e => this.keep(this.clone(e))));\n      };\n\n      i = () => {\n        var e = this.backend.numDataIds();\n        o = this.tidy(() => _t26(this.backend, _r7));\n        var n = Array.isArray(o) ? o : [o];\n        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(u, e, n), n;\n      };\n    }\n\n    var {\n      inputs: c,\n      attrs: h\n    } = e,\n        d = bt(e) ? null : e.backwardsFunc;\n    var p;\n    return this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n      this.ENV.getBool(\"DEBUG\") || this.state.profiling ? (p = this.profiler.profileKernel(u, c, () => i()), this.ENV.getBool(\"DEBUG\") && this.profiler.logKernelProfile(p), t = p.outputs) : t = i();\n    }), s && this.addTapeNode(u, c, t, d, n, h), this.state.profiling && this.state.activeProfile.kernels.push({\n      name: u,\n      bytesAdded: this.state.numBytes - r,\n      totalBytesSnapshot: this.state.numBytes,\n      tensorsAdded: this.state.numTensors - a,\n      totalTensorsSnapshot: this.state.numTensors,\n      inputShapes: Object.keys(c).map(e => null != c[e] ? c[e].shape : null),\n      outputShapes: t.map(e => e.shape),\n      kernelTimeMs: p.timeMs,\n      extraInfo: p.extraInfo\n    }), Array.isArray(o) ? t : t[0];\n  }\n\n  saveTensorsForBackwardMode(e) {\n    return e.map(e => this.keep(this.clone(e)));\n  }\n\n  getTensorsForGradient(e, t, n) {\n    var s = J(e);\n\n    if (null != s) {\n      var _e16 = s.inputsToSave || [],\n          _r8 = s.outputsToSave || [];\n\n      var _a6;\n\n      s.saveAllInputs ? (l(Array.isArray(t), () => \"saveAllInputs is true, expected inputs to be an array.\"), _a6 = Object.keys(t).map(e => t[e])) : _a6 = _e16.map(e => t[e]);\n\n      var _i4 = n.filter((e, t) => _r8[t]);\n\n      return _a6.concat(_i4);\n    }\n\n    return [];\n  }\n\n  makeTensor(e, t, n, s) {\n    if (null == e) throw new Error(\"Values passed to engine.makeTensor() are null\");\n    s = s || this.backend;\n    var r = e;\n    \"string\" === (n = n || \"float32\") && C(e[0]) && (r = e.map(e => Ge(e)));\n    var a = s.write(r, t, n),\n        i = new st(t, n, a, this.nextTensorId());\n\n    if (this.trackTensor(i, s), \"string\" === n) {\n      var _e17 = this.state.tensorInfo.get(a),\n          _t27 = function (e) {\n        if (null == e) return 0;\n        var t = 0;\n        return e.forEach(e => t += e.length), t;\n      }(r);\n\n      this.state.numBytes += _t27 - _e17.bytes, _e17.bytes = _t27;\n    }\n\n    return i;\n  }\n\n  makeTensorFromDataId(e, t, n, s) {\n    var r = new st(t, n = n || \"float32\", e, this.nextTensorId());\n    return this.trackTensor(r, s), r;\n  }\n\n  makeVariable(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    n = n || this.nextVariableId().toString(), null != s && s !== e.dtype && (e = e.cast(s));\n    var r = new at(e, t, n, this.nextTensorId());\n    if (null != this.state.registeredVariables[r.name]) throw new Error(\"Variable with name \".concat(r.name, \" was already registered\"));\n    return this.state.registeredVariables[r.name] = r, this.incRef(r, this.backend), r;\n  }\n\n  trackTensor(e, t) {\n    this.state.numTensors++, \"string\" === e.dtype && this.state.numStringTensors++;\n    var n = 0;\n    \"complex64\" !== e.dtype && \"string\" !== e.dtype && (n = e.size * N(e.dtype)), this.state.numBytes += n, this.state.tensorInfo.has(e.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(e.dataId, {\n      backend: t || this.backend,\n      dtype: e.dtype,\n      shape: e.shape,\n      bytes: n\n    })), e instanceof at || this.track(e);\n  }\n\n  incRef(e, t) {\n    this.trackTensor(e, t), this.backend.incRef(e.dataId);\n  }\n\n  removeDataId(e, t) {\n    this.state.tensorInfo.has(e) && this.state.tensorInfo.get(e).backend === t && (this.state.tensorInfo.delete(e), this.state.numDataBuffers--);\n  }\n\n  disposeTensor(e) {\n    if (!this.state.tensorInfo.has(e.dataId)) return;\n    var t = this.state.tensorInfo.get(e.dataId);\n\n    if (this.state.numTensors--, \"string\" === e.dtype && (this.state.numStringTensors--, this.state.numBytes -= t.bytes), \"complex64\" !== e.dtype && \"string\" !== e.dtype) {\n      var _t28 = e.size * N(e.dtype);\n\n      this.state.numBytes -= _t28;\n    }\n\n    t.backend.disposeData(e.dataId) && this.removeDataId(e.dataId, t.backend);\n  }\n\n  disposeVariables() {\n    for (var _e18 in this.state.registeredVariables) {\n      this.disposeVariable(this.state.registeredVariables[_e18]);\n    }\n  }\n\n  disposeVariable(e) {\n    this.disposeTensor(e), null != this.state.registeredVariables[e.name] && delete this.state.registeredVariables[e.name];\n  }\n\n  memory() {\n    var e = this.backend.memory();\n    return e.numTensors = this.state.numTensors, e.numDataBuffers = this.state.numDataBuffers, e.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (e.unreliable = !0, null == e.reasons && (e.reasons = []), e.reasons.push(\"Memory usage by string tensors is approximate (2 bytes per character)\")), e;\n  }\n\n  profile(e) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      _this8.state.profiling = !0;\n      var t = _this8.state.numBytes,\n          n = _this8.state.numTensors;\n      _this8.state.activeProfile.kernels = [], _this8.state.activeProfile.result = yield e(), _this8.state.profiling = !1, _this8.state.activeProfile.peakBytes = Math.max(..._this8.state.activeProfile.kernels.map(e => e.totalBytesSnapshot)), _this8.state.activeProfile.newBytes = _this8.state.numBytes - t, _this8.state.activeProfile.newTensors = _this8.state.numTensors - n;\n\n      for (var _e19 of _this8.state.activeProfile.kernels) {\n        _e19.kernelTimeMs = yield _e19.kernelTimeMs, _e19.extraInfo = yield _e19.extraInfo;\n      }\n\n      return _this8.state.activeProfile;\n    })();\n  }\n\n  isTapeOn() {\n    return this.state.gradientDepth > 0 && 0 === this.state.kernelDepth;\n  }\n\n  addTapeNode(e, t, n, s, r, a) {\n    var i = {\n      id: this.state.nextTapeNodeId++,\n      kernelName: e,\n      inputs: t,\n      outputs: n,\n      saved: r\n    },\n        o = J(e);\n    null != o && (s = o.gradFunc), null != s && (i.gradient = e => (e = e.map((e, t) => {\n      if (null == e) {\n        var _e20 = n[t],\n            _s17 = O(_e20.size, _e20.dtype);\n\n        return this.makeTensor(_s17, _e20.shape, _e20.dtype);\n      }\n\n      return e;\n    }), s(e.length > 1 ? e : e[0], r, a))), this.state.activeTape.push(i);\n  }\n\n  keep(e) {\n    return e.kept = !0, e;\n  }\n\n  startTape() {\n    0 === this.state.gradientDepth && (this.state.activeTape = []), this.state.gradientDepth++;\n  }\n\n  endTape() {\n    this.state.gradientDepth--;\n  }\n\n  startScope(e) {\n    var t = {\n      track: [],\n      name: \"unnamed scope\",\n      id: this.state.nextScopeId++\n    };\n    e && (t.name = e), this.state.scopeStack.push(t), this.state.activeScope = t;\n  }\n\n  endScope(e) {\n    var t = gt(e),\n        n = new Set(t.map(e => e.id));\n\n    for (var _e21 = 0; _e21 < this.state.activeScope.track.length; _e21++) {\n      var _t29 = this.state.activeScope.track[_e21];\n      _t29.kept || n.has(_t29.id) || _t29.dispose();\n    }\n\n    var s = this.state.scopeStack.pop();\n    this.state.activeScope = 0 === this.state.scopeStack.length ? null : this.state.scopeStack[this.state.scopeStack.length - 1], t.forEach(e => {\n      e.kept || e.scopeId !== s.id || this.track(e);\n    });\n  }\n\n  gradients(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    if (l(t.length > 0, () => \"gradients() received an empty list of xs.\"), null != n && \"float32\" !== n.dtype) throw new Error(\"dy must have 'float32' dtype, but has '\".concat(n.dtype, \"'\"));\n    var r = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy(\"forward\", e));\n    l(r instanceof st, () => \"The result y returned by f() must be a tensor.\");\n\n    var a = function (e, t, n) {\n      var s = {},\n          r = {};\n\n      for (var _e22 = 0; _e22 < t.length; _e22++) {\n        s[t[_e22].id] = !0;\n      }\n\n      for (var _n19 = 0; _n19 < e.length; _n19++) {\n        var _a7 = e[_n19],\n            _i5 = _a7.inputs;\n\n        for (var _e23 in _i5) {\n          var _n20 = _i5[_e23];\n\n          var _o4 = !1;\n\n          for (var _e24 = 0; _e24 < t.length; _e24++) {\n            if (s[_n20.id]) {\n              _a7.outputs.forEach(e => s[e.id] = !0), _o4 = !0, r[_a7.id] = !0;\n              break;\n            }\n          }\n\n          if (_o4) break;\n        }\n      }\n\n      var a = {};\n      a[n.id] = !0;\n      var i = {};\n\n      for (var _t30 = e.length - 1; _t30 >= 0; _t30--) {\n        var _n21 = e[_t30],\n            _s18 = _n21.inputs;\n\n        for (var _e25 = 0; _e25 < _n21.outputs.length; _e25++) {\n          if (a[_n21.outputs[_e25].id]) {\n            for (var _e26 in _s18) {\n              a[_s18[_e26].id] = !0, i[_n21.id] = !0;\n            }\n\n            break;\n          }\n        }\n      }\n\n      var o = [];\n\n      for (var _t31 = 0; _t31 < e.length; _t31++) {\n        var _n22 = e[_t31];\n\n        if (r[_n22.id] && i[_n22.id]) {\n          var _e27 = {};\n\n          for (var _t33 in _n22.inputs) {\n            var _r9 = _n22.inputs[_t33];\n            s[_r9.id] && (_e27[_t33] = _r9);\n          }\n\n          var _t32 = Object.assign({}, _n22);\n\n          _t32.inputs = _e27, _t32.outputs = _n22.outputs, o.push(_t32);\n        }\n      }\n\n      return o;\n    }(this.state.activeTape, t, r);\n\n    if (!s && 0 === a.length && t.length > 0) throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.\");\n    return this.tidy(\"backward\", () => {\n      var e = {};\n      e[r.id] = null == n ? function (e) {\n        var t = _(d(e), \"float32\");\n\n        return wt.makeTensor(t, e, \"float32\");\n      }(r.shape) : n, function (e, t, n, s) {\n        var _loop2 = function _loop2(_r10) {\n          var a = t[_r10],\n              i = [];\n          if (a.outputs.forEach(t => {\n            var n = e[t.id];\n            i.push(null != n ? n : null);\n          }), null == a.gradient) throw new Error(\"Cannot compute gradient: gradient function not found for \".concat(a.kernelName, \".\"));\n          var o = a.gradient(i);\n\n          var _loop3 = function _loop3(_t34) {\n            if (!(_t34 in o)) throw new Error(\"Cannot backprop through input \".concat(_t34, \". Available gradients found: \").concat(Object.keys(o), \".\"));\n            var r = n(() => o[_t34]());\n            if (\"float32\" !== r.dtype) throw new Error(\"Error in gradient for op \".concat(a.kernelName, \". The gradient of input \").concat(_t34, \" must have 'float32' dtype, but has '\").concat(r.dtype, \"'\"));\n            var i = a.inputs[_t34];\n            if (!p(r.shape, i.shape)) throw new Error(\"Error in gradient for op \".concat(a.kernelName, \". The gradient of input '\").concat(_t34, \"' has shape '\").concat(r.shape, \"', which does not match the shape of the input '\").concat(i.shape, \"'\"));\n            if (null == e[i.id]) e[i.id] = r;else {\n              var _t35 = e[i.id];\n              e[i.id] = s(_t35, r), _t35.dispose();\n            }\n          };\n\n          for (var _t34 in a.inputs) {\n            _loop3(_t34);\n          }\n        };\n\n        for (var _r10 = t.length - 1; _r10 >= 0; _r10--) {\n          _loop2(_r10);\n        }\n      }(e, a, e => this.tidy(e), vt);\n      var s = t.map(t => e[t.id]);\n      return 0 === this.state.gradientDepth && (this.state.activeTape.forEach(e => {\n        for (var _t36 of e.saved) {\n          _t36.dispose();\n        }\n      }), this.state.activeTape = null), {\n        value: r,\n        grads: s\n      };\n    });\n  }\n\n  customGrad(e) {\n    var _this9 = this;\n\n    return l(E(e), () => \"The f passed in customGrad(f) must be a function.\"), function () {\n      for (var _len4 = arguments.length, t = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n        t[_key4] = arguments[_key4];\n      }\n\n      var n;\n      l(t.every(e => e instanceof st), () => \"The args passed in customGrad(f)(x1, x2,...) must all be tensors\");\n      var s = {};\n      return t.forEach((e, t) => {\n        s[t] = e;\n      }), _this9.runKernelFunc({\n        forwardFunc: (s, r) => (n = e(...t, r), l(n.value instanceof st, () => \"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor\"), l(E(n.gradFunc), () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.\"), n.value),\n        backwardsFunc: (e, s) => {\n          var r = n.gradFunc(e, s),\n              a = Array.isArray(r) ? r : [r];\n          l(a.length === t.length, () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).\"), l(a.every(e => e instanceof st), () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.\");\n          var i = {};\n          return a.forEach((e, t) => {\n            i[t] = () => e;\n          }), i;\n        },\n        inputs: s\n      });\n    };\n  }\n\n  readSync(e) {\n    return this.state.tensorInfo.get(e).backend.readSync(e);\n  }\n\n  read(e) {\n    return this.state.tensorInfo.get(e).backend.read(e);\n  }\n\n  time(e) {\n    var _this10 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = Ve(),\n          n = yield _this10.backend.time(e);\n      return n.wallMs = Ve() - t, n;\n    })();\n  }\n\n  track(e) {\n    return null != this.state.activeScope && (e.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(e)), e;\n  }\n\n  get registeredVariables() {\n    return this.state.registeredVariables;\n  }\n\n  reset() {\n    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new xt();\n\n    for (var _e28 in this.registry) {\n      this.disposeRegisteredKernels(_e28), this.registry[_e28].dispose(), delete this.registry[_e28];\n    }\n\n    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;\n  }\n\n}\n\nfunction kt() {\n  var e = j();\n\n  if (null == e._tfengine) {\n    var _t37 = new W(e);\n\n    e._tfengine = new yt(_t37);\n  }\n\n  return H = e._tfengine.ENV, tt = () => e._tfengine, e._tfengine;\n}\n\nyt.nextTensorId = 0, yt.nextVariableId = 0;\nvar wt = kt();\n\nfunction vt(e, t) {\n  return wt.runKernel(\"Add\", {\n    a: e,\n    b: t\n  });\n}\n\nfunction It(e) {\n  if (e || \"undefined\" != typeof navigator && null != navigator) {\n    if (e || (e = navigator), \"ReactNative\" === e.product) return !0;\n\n    var _t38 = e.userAgent || e.vendor || window.opera;\n\n    return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(_t38) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(_t38.substr(0, 4));\n  }\n\n  return !1;\n}\n\nfunction $t() {\n  return \"undefined\" != typeof window && null != window.document || \"undefined\" != typeof WorkerGlobalScope;\n}\n\nvar Nt = V();\n\nfunction Ct(e, t) {\n  var n = e;\n  if ($(e)) return \"string\" === t ? [] : [e.length];\n  if (!Array.isArray(e)) return [];\n  var s = [];\n\n  for (; Array.isArray(n) || $(n) && \"string\" !== t;) {\n    s.push(n.length), n = n[0];\n  }\n\n  return Array.isArray(e) && V().getBool(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\") && St(e, s, []), s;\n}\n\nfunction St(e, t, n) {\n  if (n = n || [], !Array.isArray(e) && !$(e)) return void l(0 === t.length, () => \"Element arr[\".concat(n.join(\"][\"), \"] is a primitive, but should be an array/TypedArray of \").concat(t[0], \" elements\"));\n  l(t.length > 0, () => \"Element arr[\".concat(n.join(\"][\"), \"] should be a primitive, but is an array of \").concat(e.length, \" elements\")), l(e.length === t[0], () => \"Element arr[\".concat(n.join(\"][\"), \"] should have \").concat(t[0], \" elements, but has \").concat(e.length, \" elements\"));\n  var s = t.slice(1);\n\n  for (var _t39 = 0; _t39 < e.length; ++_t39) {\n    St(e[_t39], s, n.concat(_t39));\n  }\n}\n\nfunction Tt(e, t, n, s) {\n  if (\"string_or_numeric\" !== e) {\n    if (null == e) throw new Error(\"Expected dtype cannot be null.\");\n    if (\"numeric\" !== e && e !== t || \"numeric\" === e && \"string\" === t) throw new Error(\"Argument '\".concat(n, \"' passed to '\").concat(s, \"' must be \").concat(e, \" tensor, but got \").concat(t, \" tensor\"));\n  }\n}\n\nfunction Et(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"numeric\";\n  if (e instanceof st) return Tt(s, e.dtype, t, n), e;\n  var r = T(e);\n  if (\"string\" !== r && [\"bool\", \"int32\", \"float32\"].indexOf(s) >= 0 && (r = s), Tt(s, r, t, n), null == e || !$(e) && !Array.isArray(e) && \"number\" != typeof e && \"boolean\" != typeof e && \"string\" != typeof e) throw new Error(\"Argument '\".concat(t, \"' passed to '\").concat(n, \"' must be a Tensor or TensorLike, but got '\").concat(null == e ? \"null\" : e.constructor.name, \"'\"));\n  var a = Ct(e, r);\n  $(e) || Array.isArray(e) || (e = [e]);\n  var i = \"string\" !== r ? Ue(e, r) : h(e, [], !0);\n  return wt.makeTensor(i, a, r);\n}\n\nfunction Rt(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"numeric\";\n  if (!Array.isArray(e)) throw new Error(\"Argument \".concat(t, \" passed to \").concat(n, \" must be a `Tensor[]` or `TensorLike[]`\"));\n  return e.map((e, r) => Et(e, \"\".concat(t, \"[\").concat(r, \"]\"), n, s));\n}\n\nfunction At(e) {\n  var t = Object.keys(e);\n  if (1 !== t.length) throw new Error(\"Please provide an object with a single key (operation name) mapping to a function. Got an object with \".concat(t.length, \" keys.\"));\n  var n = t[0];\n  var s = e[n];\n  n.endsWith(\"_\") && (n = n.substring(0, n.length - 1)), n += \"__op\";\n\n  var r = function r() {\n    wt.startScope(n);\n\n    try {\n      var _t40 = s(...arguments);\n\n      return P(_t40) && console.error(\"Cannot return a Promise inside of tidy.\"), wt.endScope(_t40), _t40;\n    } catch (e) {\n      throw wt.endScope(null), e;\n    }\n  };\n\n  return Object.defineProperty(r, \"name\", {\n    value: n,\n    configurable: !0\n  }), r;\n}\n\nNt.registerFlag(\"DEBUG\", () => !1, e => {\n  e && console.warn(\"Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.\");\n}), Nt.registerFlag(\"IS_BROWSER\", () => $t()), Nt.registerFlag(\"IS_NODE\", () => \"undefined\" != typeof process && void 0 !== process.versions && void 0 !== process.versions.node), Nt.registerFlag(\"IS_CHROME\", () => \"undefined\" != typeof navigator && null != navigator && null != navigator.userAgent && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor)), Nt.registerFlag(\"PROD\", () => !1), Nt.registerFlag(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\", () => Nt.getBool(\"DEBUG\")), Nt.registerFlag(\"DEPRECATION_WARNINGS_ENABLED\", () => !0), Nt.registerFlag(\"IS_TEST\", () => !1), Nt.registerFlag(\"CHECK_COMPUTATION_FOR_ERRORS\", () => !0), Nt.registerFlag(\"WRAP_TO_IMAGEBITMAP\", () => !1);\nvar Ft = At({\n  complex_: function complex_(e, t) {\n    var n = Et(e, \"real\", \"complex\"),\n        s = Et(t, \"imag\", \"complex\");\n    return u(n.shape, s.shape, \"real and imag shapes, \".concat(n.shape, \" and \").concat(s.shape, \", must match in call to tf.complex().\")), wt.runKernel(\"Complex\", {\n      real: n,\n      imag: s\n    });\n  }\n});\n\nfunction Dt(e, t, n, s) {\n  if (null == s && (s = T(e)), \"complex64\" === s) throw new Error(\"Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).\");\n  if (!$(e) && !Array.isArray(e) && \"number\" != typeof e && \"boolean\" != typeof e && \"string\" != typeof e) throw new Error(\"values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray\");\n\n  if (null != t) {\n    L(t);\n\n    var _e29 = d(t),\n        _s19 = d(n);\n\n    l(_e29 === _s19, () => \"Based on the provided shape, [\".concat(t, \"], the tensor should have \").concat(_e29, \" values but has \").concat(_s19));\n\n    for (var _e30 = 0; _e30 < n.length; ++_e30) {\n      var _s20 = n[_e30],\n          _r11 = _e30 !== n.length - 1 || _s20 !== d(t.slice(_e30));\n\n      l(n[_e30] === t[_e30] || !_r11, () => \"Error creating a new Tensor. Inferred shape (\".concat(n, \") does not match the provided shape (\").concat(t, \"). \"));\n    }\n  }\n\n  return $(e) || Array.isArray(e) || (e = [e]), t = t || n, e = \"string\" !== s ? Ue(e, s) : h(e, [], !0), wt.makeTensor(e, t, s);\n}\n\nfunction _t(e, t, n) {\n  return Dt(e, t, Ct(e, n), n);\n}\n\nvar Ot = {\n  float32: 4,\n  float16: 2,\n  int32: 4,\n  uint16: 2,\n  uint8: 1,\n  bool: 1,\n  complex64: 8\n};\n\nfunction Mt(_x2, _x3) {\n  return _Mt.apply(this, arguments);\n}\n\nfunction _Mt() {\n  _Mt = _asyncToGenerator(function* (e, t) {\n    var n = [],\n        s = [],\n        r = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n\n    var _loop32 = function _loop32(_a145) {\n      var i = r[_a145],\n          o = Array.isArray(e) ? e[_a145].tensor : e[i];\n      if (\"float32\" !== o.dtype && \"int32\" !== o.dtype && \"bool\" !== o.dtype && \"string\" !== o.dtype && \"complex64\" !== o.dtype) throw new Error(\"Unsupported dtype in weight '\".concat(i, \"': \").concat(o.dtype));\n      var l = {\n        name: i,\n        shape: o.shape,\n        dtype: o.dtype\n      };\n\n      if (\"string\" === o.dtype) {\n        var _e525 = new Promise( /*#__PURE__*/function () {\n          var _ref38 = _asyncToGenerator(function* (e) {\n            var t = yield o.bytes(),\n                n = t.reduce((e, t) => e + t.length, 0) + 4 * t.length,\n                s = new Uint8Array(n);\n            var r = 0;\n\n            for (var _e526 = 0; _e526 < t.length; _e526++) {\n              var _n299 = t[_e526],\n                  _a146 = new Uint8Array(new Uint32Array([_n299.length]).buffer);\n\n              s.set(_a146, r), r += 4, s.set(_n299, r), r += _n299.length;\n            }\n\n            e(s);\n          });\n\n          return function (_x65) {\n            return _ref38.apply(this, arguments);\n          };\n        }());\n\n        s.push(_e525);\n      } else s.push(o.data());\n\n      null != t && (l.group = t), n.push(l);\n    };\n\n    for (var _a145 = 0; _a145 < r.length; ++_a145) {\n      _loop32(_a145);\n    }\n\n    return {\n      data: Lt(yield Promise.all(s)),\n      specs: n\n    };\n  });\n  return _Mt.apply(this, arguments);\n}\n\nfunction Lt(e) {\n  if (null === e) throw new Error(\"Invalid input value: \".concat(JSON.stringify(e)));\n  var t = 0;\n  var n = [];\n  e.forEach(e => {\n    if (t += e.byteLength, n.push(e.byteLength === e.buffer.byteLength ? e : new e.constructor(e)), !(e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array)) throw new Error(\"Unsupported TypedArray subtype: \".concat(e.constructor.name));\n  });\n  var s = new Uint8Array(t);\n  var r = 0;\n  return n.forEach(e => {\n    s.set(new Uint8Array(e.buffer), r), r += e.byteLength;\n  }), s.buffer;\n}\n\nvar zt = \"undefined\" != typeof Buffer && (\"undefined\" == typeof Blob || \"undefined\" == typeof atob || \"undefined\" == typeof btoa);\n\nfunction Bt(e) {\n  return zt ? Buffer.byteLength(e) : new Blob([e]).size;\n}\n\nfunction Pt(e) {\n  if (1 === e.length) return e[0];\n  var t = 0;\n  e.forEach(e => {\n    t += e.byteLength;\n  });\n  var n = new Uint8Array(t);\n  var s = 0;\n  return e.forEach(e => {\n    n.set(new Uint8Array(e), s), s += e.byteLength;\n  }), n.buffer;\n}\n\nfunction Wt(e, t) {\n  var n = {\n    modelTopology: e.modelTopology,\n    format: e.format,\n    generatedBy: e.generatedBy,\n    convertedBy: e.convertedBy,\n    weightsManifest: t\n  };\n  return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), n;\n}\n\nfunction Ut(e) {\n  if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"Expected JSON model topology, received ArrayBuffer.\");\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: \"JSON\",\n    modelTopologyBytes: null == e.modelTopology ? 0 : Bt(JSON.stringify(e.modelTopology)),\n    weightSpecsBytes: null == e.weightSpecs ? 0 : Bt(JSON.stringify(e.weightSpecs)),\n    weightDataBytes: null == e.weightData ? 0 : e.weightData.byteLength\n  };\n}\n\nfunction Vt() {\n  var e = function () {\n    var e = e => {\n      var t = e << 13,\n          n = 0;\n\n      for (; 0 == (8388608 & t);) {\n        n -= 8388608, t <<= 1;\n      }\n\n      return t &= -8388609, n += 947912704, t | n;\n    },\n        t = new Uint32Array(2048);\n\n    t[0] = 0;\n\n    for (var _n23 = 1; _n23 < 1024; _n23++) {\n      t[_n23] = e(_n23);\n    }\n\n    for (var _e31 = 1024; _e31 < 2048; _e31++) {\n      t[_e31] = 939524096 + (_e31 - 1024 << 13);\n    }\n\n    return t;\n  }(),\n      t = function () {\n    var e = new Uint32Array(64);\n    e[0] = 0, e[31] = 1199570944, e[32] = 2147483648, e[63] = 3347054592;\n\n    for (var _t41 = 1; _t41 < 31; _t41++) {\n      e[_t41] = _t41 << 23;\n    }\n\n    for (var _t42 = 33; _t42 < 63; _t42++) {\n      e[_t42] = 2147483648 + (_t42 - 32 << 23);\n    }\n\n    return e;\n  }(),\n      n = function () {\n    var e = new Uint32Array(64);\n\n    for (var _t43 = 0; _t43 < 64; _t43++) {\n      e[_t43] = 1024;\n    }\n\n    return e[0] = e[32] = 0, e;\n  }();\n\n  return s => {\n    var r = new ArrayBuffer(4 * s.length),\n        a = new Uint32Array(r);\n\n    for (var _r12 = 0; _r12 < s.length; _r12++) {\n      var _i6 = s[_r12];\n      a[_r12] = e[n[_i6 >> 10] + (1023 & _i6)] + t[_i6 >> 10];\n    }\n\n    return new Float32Array(r);\n  };\n}\n\nclass Gt {\n  constructor() {\n    this.saveRouters = [], this.loadRouters = [];\n  }\n\n  static getInstance() {\n    return null == Gt.instance && (Gt.instance = new Gt()), Gt.instance;\n  }\n\n  static registerSaveRouter(e) {\n    Gt.getInstance().saveRouters.push(e);\n  }\n\n  static registerLoadRouter(e) {\n    Gt.getInstance().loadRouters.push(e);\n  }\n\n  static getSaveHandlers(e) {\n    return Gt.getHandlers(e, \"save\");\n  }\n\n  static getLoadHandlers(e, t) {\n    return Gt.getHandlers(e, \"load\", t);\n  }\n\n  static getHandlers(e, t, n) {\n    var s = [];\n    return (\"load\" === t ? Gt.getInstance().loadRouters : Gt.getInstance().saveRouters).forEach(t => {\n      var r = t(e, n);\n      null !== r && s.push(r);\n    }), s;\n  }\n\n}\n\nfunction Ht() {\n  if (!V().getBool(\"IS_BROWSER\")) throw new Error(\"Failed to obtain IndexedDB factory because the current environmentis not a web browser.\");\n  var e = \"undefined\" == typeof window ? self : window,\n      t = e.indexedDB || e.mozIndexedDB || e.webkitIndexedDB || e.msIndexedDB || e.shimIndexedDB;\n  if (null == t) throw new Error(\"The current browser does not appear to support IndexedDB.\");\n  return t;\n}\n\nfunction jt(e) {\n  var t = e.result;\n  t.createObjectStore(\"models_store\", {\n    keyPath: \"modelPath\"\n  }), t.createObjectStore(\"model_info_store\", {\n    keyPath: \"modelPath\"\n  });\n}\n\nclass qt {\n  constructor(e) {\n    if (this.indexedDB = Ht(), null == e || !e) throw new Error(\"For IndexedDB, modelPath must not be null, undefined or empty.\");\n    this.modelPath = e;\n  }\n\n  save(e) {\n    var _this11 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");\n      return _this11.databaseAction(_this11.modelPath, e);\n    })();\n  }\n\n  load() {\n    var _this12 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this12.databaseAction(_this12.modelPath);\n    })();\n  }\n\n  databaseAction(e, t) {\n    return new Promise((e, n) => {\n      var s = this.indexedDB.open(\"tensorflowjs\", 1);\n      s.onupgradeneeded = () => jt(s), s.onsuccess = () => {\n        var r = s.result;\n\n        if (null == t) {\n          var _t44 = r.transaction(\"models_store\", \"readonly\"),\n              _s21 = _t44.objectStore(\"models_store\").get(this.modelPath);\n\n          _s21.onsuccess = () => {\n            if (null == _s21.result) return r.close(), n(new Error(\"Cannot find model with path '\".concat(this.modelPath, \"' in IndexedDB.\")));\n            e(_s21.result.modelArtifacts);\n          }, _s21.onerror = e => (r.close(), n(_s21.error)), _t44.oncomplete = () => r.close();\n        } else {\n          var _s22 = Ut(t),\n              _a8 = r.transaction(\"model_info_store\", \"readwrite\");\n\n          var _i7 = _a8.objectStore(\"model_info_store\");\n\n          var _o5 = _i7.put({\n            modelPath: this.modelPath,\n            modelArtifactsInfo: _s22\n          });\n\n          var _l2;\n\n          _o5.onsuccess = () => {\n            _l2 = r.transaction(\"models_store\", \"readwrite\");\n\n            var o = _l2.objectStore(\"models_store\").put({\n              modelPath: this.modelPath,\n              modelArtifacts: t,\n              modelArtifactsInfo: _s22\n            });\n\n            o.onsuccess = () => e({\n              modelArtifactsInfo: _s22\n            }), o.onerror = e => {\n              _i7 = _a8.objectStore(\"model_info_store\");\n\n              var t = _i7.delete(this.modelPath);\n\n              t.onsuccess = () => (r.close(), n(o.error)), t.onerror = e => (r.close(), n(o.error));\n            };\n          }, _o5.onerror = e => (r.close(), n(_o5.error)), _a8.oncomplete = () => {\n            null == _l2 ? r.close() : _l2.oncomplete = () => r.close();\n          };\n        }\n      }, s.onerror = e => n(s.error);\n    });\n  }\n\n}\n\nqt.URL_SCHEME = \"indexeddb://\";\n\nvar Kt = e => {\n  return V().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(qt.URL_SCHEME) ? (t = e.slice(qt.URL_SCHEME.length), new qt(t)) : null;\n  var t;\n};\n\nGt.registerSaveRouter(Kt), Gt.registerLoadRouter(Kt);\n\nclass Xt {\n  constructor() {\n    this.indexedDB = Ht();\n  }\n\n  listModels() {\n    var _this13 = this;\n\n    return _asyncToGenerator(function* () {\n      return new Promise((e, t) => {\n        var n = _this13.indexedDB.open(\"tensorflowjs\", 1);\n\n        n.onupgradeneeded = () => jt(n), n.onsuccess = () => {\n          var s = n.result,\n              r = s.transaction(\"model_info_store\", \"readonly\"),\n              a = r.objectStore(\"model_info_store\").getAll();\n          a.onsuccess = () => {\n            var t = {};\n\n            for (var _e32 of a.result) {\n              t[_e32.modelPath] = _e32.modelArtifactsInfo;\n            }\n\n            e(t);\n          }, a.onerror = e => (s.close(), t(a.error)), r.oncomplete = () => s.close();\n        }, n.onerror = e => t(n.error);\n      });\n    })();\n  }\n\n  removeModel(e) {\n    var _this14 = this;\n\n    return _asyncToGenerator(function* () {\n      var t;\n      return e = (t = e).startsWith(qt.URL_SCHEME) ? t.slice(qt.URL_SCHEME.length) : t, new Promise((t, n) => {\n        var s = _this14.indexedDB.open(\"tensorflowjs\", 1);\n\n        s.onupgradeneeded = () => jt(s), s.onsuccess = () => {\n          var r = s.result,\n              a = r.transaction(\"model_info_store\", \"readwrite\"),\n              i = a.objectStore(\"model_info_store\"),\n              o = i.get(e);\n          var l;\n          o.onsuccess = () => {\n            if (null == o.result) return r.close(), n(new Error(\"Cannot find model with path '\".concat(e, \"' in IndexedDB.\")));\n            {\n              var _s23 = i.delete(e),\n                  _a9 = () => {\n                l = r.transaction(\"models_store\", \"readwrite\");\n                var s = l.objectStore(\"models_store\").delete(e);\n                s.onsuccess = () => t(o.result.modelArtifactsInfo), s.onerror = e => n(o.error);\n              };\n\n              _s23.onsuccess = _a9, _s23.onerror = e => (_a9(), r.close(), n(o.error));\n            }\n          }, o.onerror = e => (r.close(), n(o.error)), a.oncomplete = () => {\n            null == l ? r.close() : l.oncomplete = () => r.close();\n          };\n        }, s.onerror = e => n(s.error);\n      });\n    })();\n  }\n\n}\n\nvar Yt = \"tensorflowjs_models\",\n    Jt = \"info\",\n    Zt = \"model_topology\",\n    Qt = \"weight_specs\",\n    en = \"weight_data\",\n    tn = \"model_metadata\";\n\nfunction nn(e) {\n  return {\n    info: [Yt, e, Jt].join(\"/\"),\n    topology: [Yt, e, Zt].join(\"/\"),\n    weightSpecs: [Yt, e, Qt].join(\"/\"),\n    weightData: [Yt, e, en].join(\"/\"),\n    modelMetadata: [Yt, e, tn].join(\"/\")\n  };\n}\n\nfunction sn(e) {\n  for (var _t45 of Object.values(e)) {\n    window.localStorage.removeItem(_t45);\n  }\n}\n\nfunction rn(e) {\n  var t = e.split(\"/\");\n  if (t.length < 3) throw new Error(\"Invalid key format: \".concat(e));\n  return t.slice(1, t.length - 1).join(\"/\");\n}\n\nclass an {\n  constructor(e) {\n    if (!V().getBool(\"IS_BROWSER\") || \"undefined\" == typeof window || void 0 === window.localStorage) throw new Error(\"The current environment does not support local storage.\");\n    if (this.LS = window.localStorage, null == e || !e) throw new Error(\"For local storage, modelPath must not be null, undefined or empty.\");\n    this.modelPath = e, this.keys = nn(this.modelPath);\n  }\n\n  save(e) {\n    var _this15 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");\n      {\n        var _t46 = JSON.stringify(e.modelTopology),\n            _n24 = JSON.stringify(e.weightSpecs),\n            _s24 = Ut(e);\n\n        try {\n          return _this15.LS.setItem(_this15.keys.info, JSON.stringify(_s24)), _this15.LS.setItem(_this15.keys.topology, _t46), _this15.LS.setItem(_this15.keys.weightSpecs, _n24), _this15.LS.setItem(_this15.keys.weightData, function (e) {\n            if (zt) return Buffer.from(e).toString(\"base64\");\n            var t = new Uint8Array(e);\n            var n = \"\";\n\n            for (var _e33 = 0, _s25 = t.length; _e33 < _s25; _e33++) {\n              n += String.fromCharCode(t[_e33]);\n            }\n\n            return btoa(n);\n          }(e.weightData)), _this15.LS.setItem(_this15.keys.modelMetadata, JSON.stringify({\n            format: e.format,\n            generatedBy: e.generatedBy,\n            convertedBy: e.convertedBy,\n            signature: null != e.signature ? e.signature : void 0,\n            userDefinedMetadata: null != e.userDefinedMetadata ? e.userDefinedMetadata : void 0,\n            modelInitializer: null != e.modelInitializer ? e.modelInitializer : void 0,\n            trainingConfig: null != e.trainingConfig ? e.trainingConfig : void 0\n          })), {\n            modelArtifactsInfo: _s24\n          };\n        } catch (e) {\n          throw sn(_this15.keys), new Error(\"Failed to save model '\".concat(_this15.modelPath, \"' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=\").concat(_s24.modelTopologyBytes, \", weightSpecsBytes=\").concat(_s24.weightSpecsBytes, \", weightDataBytes=\").concat(_s24.weightDataBytes, \".\"));\n        }\n      }\n    })();\n  }\n\n  load() {\n    var _this16 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = JSON.parse(_this16.LS.getItem(_this16.keys.info));\n      if (null == e) throw new Error(\"In local storage, there is no model with name '\".concat(_this16.modelPath, \"'\"));\n      if (\"JSON\" !== e.modelTopologyType) throw new Error(\"BrowserLocalStorage does not support loading non-JSON model topology yet.\");\n      var t = {},\n          n = JSON.parse(_this16.LS.getItem(_this16.keys.topology));\n      if (null == n) throw new Error(\"In local storage, the topology of model '\".concat(_this16.modelPath, \"' is missing.\"));\n      t.modelTopology = n;\n      var s = JSON.parse(_this16.LS.getItem(_this16.keys.weightSpecs));\n      if (null == s) throw new Error(\"In local storage, the weight specs of model '\".concat(_this16.modelPath, \"' are missing.\"));\n      t.weightSpecs = s;\n\n      var r = _this16.LS.getItem(_this16.keys.modelMetadata);\n\n      if (null != r) {\n        var _e34 = JSON.parse(r);\n\n        t.format = _e34.format, t.generatedBy = _e34.generatedBy, t.convertedBy = _e34.convertedBy, null != _e34.signature && (t.signature = _e34.signature), null != _e34.userDefinedMetadata && (t.userDefinedMetadata = _e34.userDefinedMetadata), null != _e34.modelInitializer && (t.modelInitializer = _e34.modelInitializer), null != _e34.trainingConfig && (t.trainingConfig = _e34.trainingConfig);\n      }\n\n      var a = _this16.LS.getItem(_this16.keys.weightData);\n\n      if (null == a) throw new Error(\"In local storage, the binary weight values of model '\".concat(_this16.modelPath, \"' are missing.\"));\n      return t.weightData = function (e) {\n        if (zt) {\n          var _t47 = Buffer.from(e, \"base64\");\n\n          return _t47.buffer.slice(_t47.byteOffset, _t47.byteOffset + _t47.byteLength);\n        }\n\n        var t = atob(e),\n            n = new Uint8Array(t.length);\n\n        for (var _e35 = 0; _e35 < t.length; ++_e35) {\n          n.set([t.charCodeAt(_e35)], _e35);\n        }\n\n        return n.buffer;\n      }(a), t;\n    })();\n  }\n\n}\n\nan.URL_SCHEME = \"localstorage://\";\n\nvar on = e => {\n  return V().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(an.URL_SCHEME) ? (t = e.slice(an.URL_SCHEME.length), new an(t)) : null;\n  var t;\n};\n\nGt.registerSaveRouter(on), Gt.registerLoadRouter(on);\n\nclass ln {\n  constructor() {\n    l(V().getBool(\"IS_BROWSER\"), () => \"Current environment is not a web browser\"), l(\"undefined\" == typeof window || void 0 !== window.localStorage, () => \"Current browser does not appear to support localStorage\"), this.LS = window.localStorage;\n  }\n\n  listModels() {\n    var _this17 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = {},\n          t = Yt + \"/\",\n          n = \"/\" + Jt;\n\n      for (var _s26 = 0; _s26 < _this17.LS.length; ++_s26) {\n        var _r13 = _this17.LS.key(_s26);\n\n        _r13.startsWith(t) && _r13.endsWith(n) && (e[rn(_r13)] = JSON.parse(_this17.LS.getItem(_r13)));\n      }\n\n      return e;\n    })();\n  }\n\n  removeModel(e) {\n    var _this18 = this;\n\n    return _asyncToGenerator(function* () {\n      var t;\n      var n = nn(e = (t = e).startsWith(an.URL_SCHEME) ? t.slice(an.URL_SCHEME.length) : t);\n      if (null == _this18.LS.getItem(n.info)) throw new Error(\"Cannot find model at path '\".concat(e, \"'\"));\n      var s = JSON.parse(_this18.LS.getItem(n.info));\n      return sn(n), s;\n    })();\n  }\n\n}\n\nclass un {\n  constructor() {\n    this.managers = {};\n  }\n\n  static getInstance() {\n    return null == un.instance && (un.instance = new un()), un.instance;\n  }\n\n  static registerManager(e, t) {\n    l(null != e, () => \"scheme must not be undefined or null.\"), e.endsWith(\"://\") && (e = e.slice(0, e.indexOf(\"://\"))), l(e.length > 0, () => \"scheme must not be an empty string.\");\n    var n = un.getInstance();\n    l(null == n.managers[e], () => \"A model store manager is already registered for scheme '\".concat(e, \"'.\")), n.managers[e] = t;\n  }\n\n  static getManager(e) {\n    var t = this.getInstance().managers[e];\n    if (null == t) throw new Error(\"Cannot find model manager for scheme '\".concat(e, \"'\"));\n    return t;\n  }\n\n  static getSchemes() {\n    return Object.keys(this.getInstance().managers);\n  }\n\n}\n\nclass cn {\n  fetch(e, t) {\n    return fetch(e, t);\n  }\n\n  now() {\n    return performance.now();\n  }\n\n  encode(e, t) {\n    if (\"utf-8\" !== t && \"utf8\" !== t) throw new Error(\"Browser's encoder only supports utf-8, but got \".concat(t));\n    return null == this.textEncoder && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(e);\n  }\n\n  decode(e, t) {\n    return new TextDecoder(t).decode(e);\n  }\n\n}\n\nif (V().get(\"IS_BROWSER\")) {\n  V().setPlatform(\"browser\", new cn());\n\n  try {\n    un.registerManager(an.URL_SCHEME, new ln());\n  } catch (e) {}\n\n  try {\n    un.registerManager(qt.URL_SCHEME, new Xt());\n  } catch (e) {}\n}\n\nvar hn;\n\nfunction dn(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n  var n = arguments.length > 2 ? arguments[2] : undefined;\n  return t = t || \"float32\", L(e), new et(e, t, n);\n}\n\nV().get(\"IS_NODE\") && V().setPlatform(\"node\", new class {\n  constructor() {\n    this.util = require(\"util\"), this.textEncoder = new this.util.TextEncoder();\n  }\n\n  fetch(e, t) {\n    return null != V().global.fetch ? V().global.fetch(e, t) : (null == hn && (hn = require(\"node-fetch\")), hn(e, t));\n  }\n\n  now() {\n    var e = process.hrtime();\n    return 1e3 * e[0] + e[1] / 1e6;\n  }\n\n  encode(e, t) {\n    if (\"utf-8\" !== t && \"utf8\" !== t) throw new Error(\"Node built-in encoder only supports utf-8, but got \".concat(t));\n    return this.textEncoder.encode(e);\n  }\n\n  decode(e, t) {\n    return 0 === e.length ? \"\" : new this.util.TextDecoder(t).decode(e);\n  }\n\n}());\nvar pn = At({\n  cast_: function cast_(e, t) {\n    var n = Et(e, \"x\", \"cast\");\n    if (!function (e) {\n      return \"bool\" === e || \"complex64\" === e || \"float32\" === e || \"int32\" === e || \"string\" === e;\n    }(t)) throw new Error(\"Failed to cast to unknown dtype \".concat(t));\n    if (\"string\" === t && \"string\" !== n.dtype || \"string\" !== t && \"string\" === n.dtype) throw new Error(\"Only strings can be casted to strings\");\n    return wt.runKernel(\"Cast\", {\n      x: n\n    }, {\n      dtype: t\n    });\n  }\n}),\n    fn = At({\n  clone_: function clone_(e) {\n    var t = Et(e, \"x\", \"clone\", \"string_or_numeric\");\n    return wt.runKernel(\"Identity\", {\n      x: t\n    });\n  }\n});\n\nfunction gn(e) {\n  return new Promise(e => setTimeout(e)).then(e);\n}\n\nkt(), nt = {\n  buffer: dn,\n  cast: pn,\n  clone: fn,\n  print: function print(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    console.log(e.toString(t));\n  }\n};\n\nclass mn {\n  constructor(e) {\n    if (!V().getBool(\"IS_BROWSER\")) throw new Error(\"browserDownloads() cannot proceed because the current environment is not a browser.\");\n    e.startsWith(mn.URL_SCHEME) && (e = e.slice(mn.URL_SCHEME.length)), null != e && 0 !== e.length || (e = \"model\"), this.modelJsonFileName = e + \".json\", this.weightDataFileName = e + \".weights.bin\";\n  }\n\n  save(e) {\n    var _this19 = this;\n\n    return _asyncToGenerator(function* () {\n      if (\"undefined\" == typeof document) throw new Error(\"Browser downloads are not supported in this environment since `document` is not present\");\n      var t = window.URL.createObjectURL(new Blob([e.weightData], {\n        type: \"application/octet-stream\"\n      }));\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserDownloads.save() does not support saving model topology in binary formats yet.\");\n      {\n        var _n25 = Wt(e, [{\n          paths: [\"./\" + _this19.weightDataFileName],\n          weights: e.weightSpecs\n        }]),\n            _s27 = window.URL.createObjectURL(new Blob([JSON.stringify(_n25)], {\n          type: \"application/json\"\n        })),\n            _r14 = null == _this19.modelJsonAnchor ? document.createElement(\"a\") : _this19.modelJsonAnchor;\n\n        if (_r14.download = _this19.modelJsonFileName, _r14.href = _s27, yield gn(() => _r14.dispatchEvent(new MouseEvent(\"click\"))), null != e.weightData) {\n          var _e36 = null == _this19.weightDataAnchor ? document.createElement(\"a\") : _this19.weightDataAnchor;\n\n          _e36.download = _this19.weightDataFileName, _e36.href = t, yield gn(() => _e36.dispatchEvent(new MouseEvent(\"click\")));\n        }\n\n        return {\n          modelArtifactsInfo: Ut(e)\n        };\n      }\n    })();\n  }\n\n}\n\nfunction bn(e, t, n, s) {\n  !function (e) {\n    l(null != e && Array.isArray(e) && e.length > 0, () => \"promises must be a none empty array\");\n  }(e), function (e, t) {\n    l(e >= 0 && e <= 1, () => \"Progress fraction must be in range [0, 1], but got startFraction \".concat(e)), l(t >= 0 && t <= 1, () => \"Progress fraction must be in range [0, 1], but got endFraction \".concat(t)), l(t >= e, () => \"startFraction must be no more than endFraction, but got startFraction \".concat(e, \" and endFraction \").concat(t));\n  }(n = null == n ? 0 : n, s = null == s ? 1 : s);\n  var r = 0;\n  return Promise.all(e.map(a => (a.then(a => {\n    var i = n + ++r / e.length * (s - n);\n    return t(i), a;\n  }), a)));\n}\n\nmn.URL_SCHEME = \"downloads://\", Gt.registerSaveRouter(e => V().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(mn.URL_SCHEME) ? function () {\n  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"model\";\n  return new mn(e);\n}(e.slice(mn.URL_SCHEME.length)) : null);\n\nclass xn {\n  constructor(e, t) {\n    if (this.DEFAULT_METHOD = \"POST\", null == t && (t = {}), this.weightPathPrefix = t.weightPathPrefix, this.onProgress = t.onProgress, this.weightUrlConverter = t.weightUrlConverter, null != t.fetchFunc ? (l(\"function\" == typeof t.fetchFunc, () => \"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)\"), this.fetch = t.fetchFunc) : this.fetch = V().platform.fetch, l(null != e && e.length > 0, () => \"URL path for http must not be null, undefined or empty.\"), Array.isArray(e) && l(2 === e.length, () => \"URL paths for http must have a length of 2, (actual length is \".concat(e.length, \").\")), this.path = e, null != t.requestInit && null != t.requestInit.body) throw new Error(\"requestInit is expected to have no pre-existing body, but has one.\");\n    this.requestInit = t.requestInit || {};\n  }\n\n  save(e) {\n    var _this20 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.\");\n      var t = Object.assign({\n        method: _this20.DEFAULT_METHOD\n      }, _this20.requestInit);\n      t.body = new FormData();\n      var n = Wt(e, [{\n        paths: [\"./model.weights.bin\"],\n        weights: e.weightSpecs\n      }]);\n      t.body.append(\"model.json\", new Blob([JSON.stringify(n)], {\n        type: \"application/json\"\n      }), \"model.json\"), null != e.weightData && t.body.append(\"model.weights.bin\", new Blob([e.weightData], {\n        type: \"application/octet-stream\"\n      }), \"model.weights.bin\");\n      var s = yield _this20.fetch(_this20.path, t);\n      if (s.ok) return {\n        modelArtifactsInfo: Ut(e),\n        responses: [s]\n      };\n      throw new Error(\"BrowserHTTPRequest.save() failed due to HTTP response status \".concat(s.status, \".\"));\n    })();\n  }\n\n  load() {\n    var _this21 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this21.fetch(_this21.path, _this21.requestInit);\n      if (!e.ok) throw new Error(\"Request to \".concat(_this21.path, \" failed with status code \").concat(e.status, \". Please verify this URL points to the model JSON of the model to load.\"));\n      var t;\n\n      try {\n        t = yield e.json();\n      } catch (e) {\n        var _t48 = \"Failed to parse model JSON of response from \".concat(_this21.path, \".\");\n\n        throw _this21.path.endsWith(\".pb\") ? _t48 += \" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.\" : _t48 += \" Please make sure the server is serving valid JSON for this request.\", new Error(_t48);\n      }\n\n      if (null == t.modelTopology && null == t.weightsManifest) throw new Error(\"The JSON from HTTP path \".concat(_this21.path, \" contains neither model topology or manifest for weights.\"));\n      return function () {\n        var _ref = _asyncToGenerator(function* (e, t) {\n          var n = {\n            modelTopology: e.modelTopology,\n            format: e.format,\n            generatedBy: e.generatedBy,\n            convertedBy: e.convertedBy\n          };\n\n          if (null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), null != e.weightsManifest) {\n            var [_s28, _r15] = yield t(e.weightsManifest);\n            n.weightSpecs = _s28, n.weightData = _r15;\n          }\n\n          return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), n;\n        });\n\n        return function (_x4, _x5) {\n          return _ref.apply(this, arguments);\n        };\n      }()(t, e => _this21.loadWeights(e));\n    })();\n  }\n\n  loadWeights(e) {\n    var _this22 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = Array.isArray(_this22.path) ? _this22.path[1] : _this22.path,\n          [n, s] = function (e) {\n        var t = e.lastIndexOf(\"/\"),\n            n = e.lastIndexOf(\"?\");\n        return [e.substring(0, t) + \"/\", n > t ? e.substring(n) : \"\"];\n      }(t),\n          r = _this22.weightPathPrefix || n,\n          a = [];\n\n      for (var _t49 of e) {\n        a.push(..._t49.weights);\n      }\n\n      var i = [],\n          o = [];\n\n      for (var _t50 of e) {\n        for (var _e37 of _t50.paths) {\n          null != _this22.weightUrlConverter ? o.push(_this22.weightUrlConverter(_e37)) : i.push(r + _e37 + s);\n        }\n      }\n\n      return _this22.weightUrlConverter && i.push(...(yield Promise.all(o))), [a, Pt(yield function () {\n        var _ref2 = _asyncToGenerator(function* (e, t) {\n          null == t && (t = {});\n          var n = null == t.fetchFunc ? V().platform.fetch : t.fetchFunc,\n              s = e.map(e => n(e, t.requestInit, {\n            isBinary: !0\n          })),\n              r = (null == t.onProgress ? yield Promise.all(s) : yield bn(s, t.onProgress, 0, .5)).map(e => e.arrayBuffer());\n          return null == t.onProgress ? yield Promise.all(r) : yield bn(r, t.onProgress, .5, 1);\n        });\n\n        return function (_x6, _x7) {\n          return _ref2.apply(this, arguments);\n        };\n      }()(i, {\n        requestInit: _this22.requestInit,\n        fetchFunc: _this22.fetch,\n        onProgress: _this22.onProgress\n      }))];\n    })();\n  }\n\n}\n\nfunction yn(e) {\n  return null != e.match(xn.URL_SCHEME_REGEX);\n}\n\nxn.URL_SCHEME_REGEX = /^https?:\\/\\//;\n\nvar kn = (e, t) => {\n  if (\"undefined\" == typeof fetch && (null == t || null == t.fetchFunc)) return null;\n  {\n    var _n26 = !0;\n\n    if (_n26 = Array.isArray(e) ? e.every(e => yn(e)) : yn(e), _n26) return wn(e, t);\n  }\n  return null;\n};\n\nfunction wn(e, t) {\n  return new xn(e, t);\n}\n\nGt.registerSaveRouter(kn), Gt.registerLoadRouter(kn);\nvar vn = At({\n  matMul_: function matMul_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Et(e, \"a\", \"matMul\"),\n        a = Et(t, \"b\", \"matMul\");\n    return [r, a] = ft(r, a), wt.runKernel(\"BatchMatMul\", {\n      a: r,\n      b: a\n    }, {\n      transposeA: n,\n      transposeB: s\n    });\n  }\n}),\n    In = At({\n  oneHot_: function oneHot_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    if (t < 2) throw new Error(\"Error in oneHot: depth must be >=2, but it is \".concat(t));\n    var r = Et(e, \"indices\", \"oneHot\", \"int32\");\n    return wt.runKernel(\"OneHot\", {\n      indices: r\n    }, {\n      depth: t,\n      onValue: n,\n      offValue: s\n    });\n  }\n}),\n    $n = At({\n  transpose_: function transpose_(e, t) {\n    var n = Et(e, \"x\", \"transpose\");\n    return null == t && (t = n.shape.map((e, t) => t).reverse()), l(n.rank === t.length, () => \"Error in transpose: rank of input \".concat(n.rank, \" must match length of perm \").concat(t, \".\")), t.forEach(e => {\n      l(e >= 0 && e < n.rank, () => \"All entries in 'perm' must be between 0 and \" + (n.rank - 1) + \" but got \".concat(t));\n    }), n.rank <= 1 ? n.clone() : wt.runKernel(\"Transpose\", {\n      x: n\n    }, {\n      perm: t\n    });\n  }\n});\n\nfunction Nn(e, t) {\n  var n = e.shape.length,\n      s = t.shape.length;\n  if (n < 1) throw new Error(\"tf.gatherND() expects the input to be rank 1 or higher, but the rank was \".concat(n, \".\"));\n  if (s < 1) throw new Error(\"tf.gatherND() expects the indices to be rank 1 or higher, but the rank was \".concat(s, \".\"));\n  if (\"int32\" !== t.dtype) throw new Error(\"tf.gatherND() expects the indices to be int32 type, but the dtype was \".concat(t.dtype, \".\"));\n  if (t.shape[s - 1] > n) throw new Error(\"index innermost dimension length must be <= tensor rank; saw: \".concat(t.shape[s - 1], \" vs. \").concat(n));\n  if (0 === d(e.shape)) throw new Error(\"Requested more than 0 entries, but input is empty. Input shape: \".concat(e.shape, \".\"));\n  var r = t.shape,\n      a = r[r.length - 1];\n  var i = 1;\n\n  for (var _e38 = 0; _e38 < r.length - 1; ++_e38) {\n    i *= r[_e38];\n  }\n\n  var o = e.shape,\n      l = r.slice();\n  l.pop();\n  var u = 1;\n\n  for (var _e39 = a; _e39 < n; ++_e39) {\n    u *= o[_e39], l.push(o[_e39]);\n  }\n\n  var c = [...A(e.shape).map(e => e / u), 1].slice(0, a);\n  return [l, i, u, c];\n}\n\nfunction Cn(e, t, n) {\n  var s = t.rank > 1 ? t.shape[t.rank - 1] : 1,\n      r = t.rank > 1 ? t.rank - 1 : 1,\n      a = \"Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: \".concat(n.shape, \", indices.shape: \").concat(t.shape, \", shape: \").concat(e, \", sliceDim: \").concat(s, \", and batchDim: \").concat(r, \".\");\n  if (n.rank < r) throw new Error(a + \" update.rank < \".concat(r, \". \"));\n  if (e.length < s + (n.rank - r)) throw new Error(a + \" Output shape length < \".concat(s + (n.rank - r)));\n  if (n.rank !== r + e.length - s) throw new Error(a + \" update.rank != \" + (r + e.length - s));\n\n  for (var _e40 = 0; _e40 < r; ++_e40) {\n    if (n.shape[_e40] !== t.shape[_e40]) throw new Error(a + \" updates.shape[\".concat(_e40, \"] (\").concat(n.shape[_e40], \") != indices.shape[\").concat(_e40, \"] (\").concat(t.shape[_e40], \").\"));\n  }\n\n  for (var _t51 = 0; _t51 < n.rank - r; ++_t51) {\n    if (n.shape[_t51 + r] !== e[_t51 + s]) throw new Error(a + \" updates.shape[\".concat(_t51 + r, \"] (\").concat(n.shape[_t51 + r], \") != shape[\").concat(_t51 + r, \"] (\").concat(e[_t51 + r], \")\"));\n  }\n}\n\nfunction Sn(e, t, n) {\n  var s = t.shape.length,\n      r = s > 1 ? t.shape[s - 1] : 1,\n      a = n.length;\n  var i = 1;\n\n  for (var _e41 = r; _e41 < a; ++_e41) {\n    i *= n[_e41];\n  }\n\n  var o = r < 1 ? 1 : r;\n  return {\n    sliceRank: r,\n    numUpdates: d(t.shape) / o,\n    sliceSize: i,\n    strides: [...A(n.slice(0, r)), 1],\n    outputSize: d(n)\n  };\n}\n\nfunction Tn(e, t, n) {\n  var s = e.shape.length;\n  l(s === t.length, () => \"Error in slice\".concat(s, \"D: Length of begin \").concat(t, \" must match the rank of the array (\").concat(s, \").\")), l(s === n.length, () => \"Error in slice\".concat(s, \"D: Length of size \").concat(n, \" must match the rank of the array (\").concat(s, \").\"));\n\n  var _loop4 = function _loop4(_r16) {\n    l(t[_r16] + n[_r16] <= e.shape[_r16], () => \"Error in slice\".concat(s, \"D: begin[\").concat(_r16, \"] + size[\").concat(_r16, \"] (\").concat(t[_r16] + n[_r16], \") would overflow input.shape[\").concat(_r16, \"] (\").concat(e.shape[_r16], \")\"));\n  };\n\n  for (var _r16 = 0; _r16 < s; ++_r16) {\n    _loop4(_r16);\n  }\n}\n\nfunction En(e) {\n  var t = [];\n  var n = 0;\n\n  for (; e > 0;) {\n    1 & e && t.push(n), e /= 2, n++;\n  }\n\n  return t;\n}\n\nfunction Rn(e, t, n) {\n  var s = [];\n\n  for (var _r17 = 0; _r17 < e.length; _r17++) {\n    s[_r17] = Math.ceil((t[_r17] - e[_r17]) / n[_r17]);\n  }\n\n  return s;\n}\n\nfunction An(e, t, n, s) {\n  var r = [...e];\n\n  for (var _e42 = r.length; _e42 < s.length; _e42++) {\n    r.push(1);\n  }\n\n  for (var _e43 = 0; _e43 < n; _e43++) {\n    0 === _e43 ? r[t] = 1 : (r.splice(t, 0, 1), r.pop());\n  }\n\n  return r;\n}\n\nfunction Fn(e, t, n) {\n  return n <= e ? n : n - (t - 1);\n}\n\nfunction Dn(e, t) {\n  var n = [];\n\n  for (var _s29 = 0; _s29 < e; _s29++) {\n    n.push(t + _s29);\n  }\n\n  return n;\n}\n\nfunction _n(e, t, n, s, r, a, i, o, l) {\n  var u = e.length;\n  var c = new Array(u),\n      h = new Array(u),\n      d = new Array(u);\n\n  if (t.length && n > 0) {\n    var _l3 = t[0],\n        _u3 = n + 1;\n\n    c = On(i, _l3, _u3, s, e), h = Mn(o, _l3, _u3, r, e), d = An(a, _l3, _u3, e);\n  } else for (var _t52 = 0; _t52 < u; _t52++) {\n    c[_t52] = zn(i, s, a, e, _t52, l), h[_t52] = Bn(o, r, a, e, _t52, l), d[_t52] = Ln(a, _t52, l);\n  }\n\n  return {\n    begin: c,\n    end: h,\n    strides: d\n  };\n}\n\nfunction On(e, t, n, s, r) {\n  var a = [...r],\n      i = Dn(n, t);\n\n  for (var _r18 = 0; _r18 < a.length; _r18++) {\n    if (i.indexOf(_r18) > -1) a[_r18] = 0;else {\n      var _i8 = Fn(t, n, _r18);\n\n      var _o6 = s[_i8];\n      e & 1 << _i8 && (_o6 = 0), a[_r18] = _o6;\n    }\n  }\n\n  return a;\n}\n\nfunction Mn(e, t, n, s, r) {\n  var i = [...r],\n      o = Dn(n, t);\n\n  for (var _r19 = 0; _r19 < i.length; _r19++) {\n    if (o.indexOf(_r19) > -1) i[_r19] = Number.MAX_SAFE_INTEGER;else {\n      var _a10 = Fn(t, n, _r19);\n\n      var _o7 = s[_a10];\n      e & 1 << _a10 && (_o7 = Number.MAX_SAFE_INTEGER), i[_r19] = _o7;\n    }\n  }\n\n  for (var _e44 = 0; _e44 < i.length; _e44++) {\n    var _t53 = r[_e44];\n    i[_e44] < 0 && (i[_e44] += _t53), i[_e44] = a(0, i[_e44], r[_e44]);\n  }\n\n  return i;\n}\n\nfunction Ln(e, t, n) {\n  var s = e[t];\n  return (n & 1 << t || null == s) && (s = 1), s;\n}\n\nfunction zn(e, t, n, s, r, i) {\n  var o = t[r];\n  (e & 1 << r || i & 1 << r || null == o) && (o = (n[r] || 1) > 0 ? Number.MIN_SAFE_INTEGER : Number.MAX_SAFE_INTEGER);\n  var l = s[r];\n  return o < 0 && (o += l), o = a(0, o, l - 1), o;\n}\n\nfunction Bn(e, t, n, s, r, i) {\n  var o = t[r];\n  var l = n[r] || 1;\n  (e & 1 << r || i & 1 << r || null == o) && (o = l > 0 ? Number.MAX_SAFE_INTEGER : Number.MIN_SAFE_INTEGER);\n  var u = s[r];\n  return o < 0 && (o += u), o = l > 0 ? a(0, o, u) : a(-1, o, u - 1), o;\n}\n\nfunction Pn(e, t, n) {\n  var s = n.length;\n\n  for (var _e45 = 0; _e45 < n.length; _e45++) {\n    if (n[_e45] > 1) {\n      s = _e45;\n      break;\n    }\n  }\n\n  for (var _r20 = s + 1; _r20 < n.length; _r20++) {\n    if (t[_r20] > 0 || n[_r20] !== e[_r20]) return !1;\n  }\n\n  return !0;\n}\n\nfunction Wn(e, t) {\n  var n = e.length > 0 ? e[e.length - 1] : 1;\n\n  for (var _s30 = 0; _s30 < e.length - 1; _s30++) {\n    n += e[_s30] * t[_s30];\n  }\n\n  return n;\n}\n\nfunction Un(e, t, n) {\n  var s;\n  var r = e.shape.length;\n  var a;\n  return s = \"number\" == typeof t ? [t, ...new Array(r - 1).fill(0)] : t.length < r ? t.concat(new Array(r - t.length).fill(0)) : t.slice(), s.forEach(e => {\n    l(-1 !== e, () => \"slice() does not support negative begin indexing.\");\n  }), a = null == n ? new Array(r).fill(-1) : \"number\" == typeof n ? [n, ...new Array(r - 1).fill(-1)] : n.length < r ? n.concat(new Array(r - n.length).fill(-1)) : n, a = a.map((t, n) => t >= 0 ? t : (l(-1 === t, () => \"Negative size values should be exactly -1 but got \".concat(t, \" for the slice() size at index \").concat(n, \".\")), e.shape[n] - s[n])), [s, a];\n}\n\nfunction Vn(e, t, n, s, r, a, i, o, l) {\n  var u = t.slice(),\n      c = n.slice(),\n      h = s;\n  null == s && (h = new Array(u.length));\n  var d = En(i);\n  if (d.length > 1) throw new Error(\"Multiple ellipses in slice is not allowed.\");\n  if (0 !== i && 0 !== o) throw new Error(\"Using both ellipsisMask and newAxisMask is not yet supported.\");\n  if (0 !== i && 0 !== l) throw new Error(\"Using both ellipsisMask and shrinkAxisMask is not yet supported.\");\n  var p = e.length - u.length,\n      f = En(o),\n      g = e.slice();\n  f.forEach(e => {\n    u[e] = 0, c[e] = 1, g.splice(e, 0, 1);\n  });\n\n  var {\n    begin: m,\n    end: b,\n    strides: x\n  } = _n(g, d, p, u, c, h, r, a, i);\n\n  u = m, c = b, h = x;\n  var y = En(l);\n  y.forEach(e => {\n    c[e] = u[e] + 1, h[e] = 1;\n  });\n  var k = Rn(u, c, h),\n      w = k.filter((e, t) => -1 === y.indexOf(t));\n  return {\n    nonStrided: h.every(e => 1 === e),\n    $begin: u,\n    $end: c,\n    $strides: h,\n    size: k,\n    newShape: g,\n    outShape: w\n  };\n}\n\nvar Gn = {\n  __proto__: null,\n  assertParamsValid: Tn,\n  maskToAxes: En,\n  computeOutShape: Rn,\n  stridesWithElidedDims: An,\n  getNormalizedAxes: _n,\n  startIndicesWithElidedDims: On,\n  stopIndicesWithElidedDims: Mn,\n  stridesForAxis: Ln,\n  startForAxis: zn,\n  stopForAxis: Bn,\n  isSliceContinous: Pn,\n  computeFlatOffset: Wn,\n  parseSliceParams: Un,\n  sliceInfo: Vn\n};\n\nclass Hn {\n  getClassName() {\n    return this.constructor.className;\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nclass jn {\n  constructor() {\n    this.classNameMap = {};\n  }\n\n  static getMap() {\n    return null == jn.instance && (jn.instance = new jn()), jn.instance;\n  }\n\n  static register(e) {\n    jn.getMap().classNameMap[e.className] = [e, e.fromConfig];\n  }\n\n}\n\nfunction qn(e) {\n  l(null != e.className, () => \"Class being registered does not have the static className property defined.\"), l(\"string\" == typeof e.className, () => \"className is required to be a string, but got type \" + typeof e.className), l(e.className.length > 0, () => \"Class being registered has an empty-string as its className, which is disallowed.\"), jn.register(e);\n}\n\nfunction Kn() {\n  return wt;\n}\n\nfunction Xn() {\n  return wt.memory();\n}\n\nfunction Yn(e, t) {\n  return wt.tidy(e, t);\n}\n\nfunction Jn(e) {\n  gt(e).forEach(e => e.dispose());\n}\n\nfunction Zn(e) {\n  return wt.keep(e);\n}\n\nfunction Qn(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  return wt.registerBackend(e, t, n);\n}\n\nvar es = At({\n  add_: function add_(e, t) {\n    var n = Et(e, \"a\", \"add\"),\n        s = Et(t, \"b\", \"add\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Add\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ts = At({\n  floorDiv_: function floorDiv_(e, t) {\n    var n = Et(e, \"a\", \"floorDiv\"),\n        s = Et(t, \"b\", \"floorDiv\");\n    return [n, s] = ft(n, s), wt.runKernel(\"FloorDiv\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ns = At({\n  div_: function div_(e, t) {\n    var n = Et(e, \"a\", \"div\"),\n        s = Et(t, \"b\", \"div\");\n    return [n, s] = ft(n, s), \"int32\" === n.dtype && \"int32\" === s.dtype ? ts(n, s) : wt.runKernel(\"RealDiv\", {\n      a: n,\n      b: s\n    }, {});\n  }\n}),\n    ss = At({\n  mul_: function mul_(e, t) {\n    var n = Et(e, \"a\", \"mul\"),\n        s = Et(t, \"b\", \"mul\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Multiply\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    rs = At({\n  abs_: function abs_(e) {\n    var t = Et(e, \"x\", \"abs\");\n    return wt.runKernel(\"complex64\" === t.dtype ? \"ComplexAbs\" : \"Abs\", {\n      x: t\n    });\n  }\n}),\n    as = At({\n  acos_: function acos_(e) {\n    var t = Et(e, \"x\", \"acos\");\n    return wt.runKernel(\"Acos\", {\n      x: t\n    });\n  }\n}),\n    is = At({\n  acosh_: function acosh_(e) {\n    var t = Et(e, \"x\", \"acosh\");\n    return wt.runKernel(\"Acosh\", {\n      x: t\n    });\n  }\n}),\n    os = At({\n  all_: function all_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"all\", \"bool\");\n    return wt.runKernel(\"All\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    ls = At({\n  any_: function any_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"any\", \"bool\");\n    return wt.runKernel(\"Any\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    us = At({\n  argMax_: function argMax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"argMax\");\n    return wt.runKernel(\"ArgMax\", {\n      x: n\n    }, {\n      axis: t\n    });\n  }\n}),\n    cs = At({\n  argMin_: function argMin_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"argMin\");\n    return wt.runKernel(\"ArgMin\", {\n      x: n\n    }, {\n      axis: t\n    });\n  }\n}),\n    hs = At({\n  asin_: function asin_(e) {\n    var t = Et(e, \"x\", \"asin\");\n    return wt.runKernel(\"Asin\", {\n      x: t\n    });\n  }\n}),\n    ds = At({\n  asinh_: function asinh_(e) {\n    var t = Et(e, \"x\", \"asinh\");\n    return wt.runKernel(\"Asinh\", {\n      x: t\n    });\n  }\n}),\n    ps = At({\n  atan_: function atan_(e) {\n    var t = Et(e, \"x\", \"atan\");\n    return wt.runKernel(\"Atan\", {\n      x: t\n    });\n  }\n}),\n    fs = At({\n  atan2_: function atan2_(e, t) {\n    var n = Et(e, \"a\", \"atan2\"),\n        s = Et(t, \"b\", \"atan2\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Atan2\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    gs = At({\n  atanh_: function atanh_(e) {\n    var t = Et(e, \"x\", \"atanh\");\n    return wt.runKernel(\"Atanh\", {\n      x: t\n    });\n  }\n});\n\nfunction ms(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  return ys(e, [...t, e[3]], n, a, s, null, null, Ts(r));\n}\n\nfunction bs(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"channelsLast\";\n  var [o, l] = vs(t);\n  var u;\n  if (\"channelsLast\" === i) u = [o, l, e[3], e[3]];else {\n    if (\"channelsFirst\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    u = [o, l, e[1], e[1]];\n  }\n  return ys(e, u, n, s, r, a, !1, i);\n}\n\nfunction xs(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"NDHWC\";\n  var [o, l, u] = Is(t);\n  var c, h;\n  if (\"NDHWC\" === i) h = \"channelsLast\", c = [o, l, u, e[4], e[4]];else {\n    if (\"NCDHW\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    h = \"channelsFirst\", c = [o, l, u, e[1], e[1]];\n  }\n  return ks(e, c, n, s, r, !1, h, a);\n}\n\nfunction ys(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : \"channelsLast\";\n  var [l, u, c, h] = [-1, -1, -1, -1];\n  if (\"channelsLast\" === o) [l, u, c, h] = e;else {\n    if (\"channelsFirst\" !== o) throw new Error(\"Unknown dataFormat \".concat(o));\n    [l, h, u, c] = e;\n  }\n\n  var [d, p,, f] = t,\n      [g, m] = vs(n),\n      [b, x] = vs(s),\n      y = $s(d, b),\n      k = $s(p, x),\n      {\n    padInfo: w,\n    outHeight: v,\n    outWidth: I\n  } = function (e, t, n, s, r, a, i, o, l) {\n    var u, c, h;\n\n    if (\"number\" == typeof e) {\n      u = {\n        top: e,\n        bottom: e,\n        left: e,\n        right: e,\n        type: 0 === e ? \"VALID\" : \"NUMBER\"\n      };\n\n      var _r21 = function (e, t, n, s, r) {\n        null == s && (s = ws(e, t, n));\n        var a = e[1];\n        return [Ns((e[0] - t + 2 * s) / n + 1, r), Ns((a - t + 2 * s) / n + 1, r)];\n      }([t, n], a, s, e, o);\n\n      c = _r21[0], h = _r21[1];\n    } else if (\"same\" === e) {\n      c = Math.ceil(t / s), h = Math.ceil(n / r);\n\n      var _e46 = Math.max(0, (c - 1) * s + a - t),\n          _o8 = Math.max(0, (h - 1) * r + i - n),\n          _l4 = Math.floor(_e46 / 2),\n          _d2 = _e46 - _l4,\n          _p2 = Math.floor(_o8 / 2);\n\n      u = {\n        top: _l4,\n        bottom: _d2,\n        left: _p2,\n        right: _o8 - _p2,\n        type: \"SAME\"\n      };\n    } else if (\"valid\" === e) u = {\n      top: 0,\n      bottom: 0,\n      left: 0,\n      right: 0,\n      type: \"VALID\"\n    }, c = Math.ceil((t - a + 1) / s), h = Math.ceil((n - i + 1) / r);else {\n      if (\"object\" != typeof e) throw Error(\"Unknown padding parameter: \".concat(e));\n      {\n        var _d3 = \"channelsLast\" === l ? e[1][0] : e[2][0],\n            _p3 = \"channelsLast\" === l ? e[1][1] : e[2][1],\n            _f2 = \"channelsLast\" === l ? e[2][0] : e[3][0],\n            _g2 = \"channelsLast\" === l ? e[2][1] : e[3][1];\n\n        u = {\n          top: _d3,\n          bottom: _p3,\n          left: _f2,\n          right: _g2,\n          type: 0 === _d3 && 0 === _p3 && 0 === _f2 && 0 === _g2 ? \"VALID\" : \"EXPLICIT\"\n        }, c = Ns((t - a + _d3 + _p3) / s + 1, o), h = Ns((n - i + _f2 + _g2) / r + 1, o);\n      }\n    }\n\n    return {\n      padInfo: u,\n      outHeight: c,\n      outWidth: h\n    };\n  }(r, u, c, g, m, y, k, a, o),\n      $ = i ? f * h : f;\n\n  var N;\n  return \"channelsFirst\" === o ? N = [l, $, v, I] : \"channelsLast\" === o && (N = [l, v, I, $]), {\n    batchSize: l,\n    dataFormat: o,\n    inHeight: u,\n    inWidth: c,\n    inChannels: h,\n    outHeight: v,\n    outWidth: I,\n    outChannels: $,\n    padInfo: w,\n    strideHeight: g,\n    strideWidth: m,\n    filterHeight: d,\n    filterWidth: p,\n    effectiveFilterHeight: y,\n    effectiveFilterWidth: k,\n    dilationHeight: b,\n    dilationWidth: x,\n    inShape: e,\n    outShape: N,\n    filterShape: t\n  };\n}\n\nfunction ks(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"channelsLast\";\n  var o = arguments.length > 7 ? arguments[7] : undefined;\n  var [l, u, c, h, d] = [-1, -1, -1, -1, -1];\n  if (\"channelsLast\" === i) [l, u, c, h, d] = e;else {\n    if (\"channelsFirst\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    [l, d, u, c, h] = e;\n  }\n\n  var [p, f, g,, m] = t,\n      [b, x, y] = Is(n),\n      [k, w, v] = Is(s),\n      I = $s(p, k),\n      $ = $s(f, w),\n      N = $s(g, v),\n      {\n    padInfo: C,\n    outDepth: S,\n    outHeight: T,\n    outWidth: E\n  } = function (e, t, n, s, r, a, i, o, l, u, c) {\n    var h, d, p, f;\n\n    if (\"number\" == typeof e) {\n      h = {\n        top: e,\n        bottom: e,\n        left: e,\n        right: e,\n        front: e,\n        back: e,\n        type: 0 === e ? \"VALID\" : \"NUMBER\"\n      };\n\n      var _a11 = function (e, t, n, s, r, a) {\n        null == r && (r = ws(e, t, s));\n        var i = e[1],\n            o = e[2];\n        return [Ns((e[0] - t + 2 * r) / s + 1, a), Ns((i - t + 2 * r) / s + 1, a), Ns((o - t + 2 * r) / s + 1, a), 1];\n      }([t, n, s, 1], o, 0, r, e, c);\n\n      d = _a11[0], p = _a11[1], f = _a11[2];\n    } else if (\"same\" === e) {\n      d = Math.ceil(t / r), p = Math.ceil(n / a), f = Math.ceil(s / i);\n\n      var _e47 = (d - 1) * r + o - t,\n          _c2 = (p - 1) * a + l - n,\n          _g3 = (f - 1) * i + u - s,\n          _m2 = Math.floor(_e47 / 2),\n          _b2 = _e47 - _m2,\n          _x8 = Math.floor(_c2 / 2),\n          _y2 = _c2 - _x8,\n          _k2 = Math.floor(_g3 / 2);\n\n      h = {\n        top: _x8,\n        bottom: _y2,\n        left: _k2,\n        right: _g3 - _k2,\n        front: _m2,\n        back: _b2,\n        type: \"SAME\"\n      };\n    } else {\n      if (\"valid\" !== e) throw Error(\"Unknown padding parameter: \".concat(e));\n      h = {\n        top: 0,\n        bottom: 0,\n        left: 0,\n        right: 0,\n        front: 0,\n        back: 0,\n        type: \"VALID\"\n      }, d = Math.ceil((t - o + 1) / r), p = Math.ceil((n - l + 1) / a), f = Math.ceil((s - u + 1) / i);\n    }\n\n    return {\n      padInfo: h,\n      outDepth: d,\n      outHeight: p,\n      outWidth: f\n    };\n  }(r, u, c, h, b, x, y, I, $, N, o),\n      R = a ? m * d : m;\n\n  var A;\n  return \"channelsFirst\" === i ? A = [l, R, S, T, E] : \"channelsLast\" === i && (A = [l, S, T, E, R]), {\n    batchSize: l,\n    dataFormat: i,\n    inDepth: u,\n    inHeight: c,\n    inWidth: h,\n    inChannels: d,\n    outDepth: S,\n    outHeight: T,\n    outWidth: E,\n    outChannels: R,\n    padInfo: C,\n    strideDepth: b,\n    strideHeight: x,\n    strideWidth: y,\n    filterDepth: p,\n    filterHeight: f,\n    filterWidth: g,\n    effectiveFilterDepth: I,\n    effectiveFilterHeight: $,\n    effectiveFilterWidth: N,\n    dilationDepth: k,\n    dilationHeight: w,\n    dilationWidth: v,\n    inShape: e,\n    outShape: A,\n    filterShape: t\n  };\n}\n\nfunction ws(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n  var r = $s(t, s);\n  return Math.floor((e[0] * (n - 1) - n + r) / 2);\n}\n\nfunction vs(e) {\n  return \"number\" == typeof e ? [e, e, e] : 2 === e.length ? [e[0], e[1], 1] : e;\n}\n\nfunction Is(e) {\n  return \"number\" == typeof e ? [e, e, e] : e;\n}\n\nfunction $s(e, t) {\n  return t <= 1 ? e : e + (e - 1) * (t - 1);\n}\n\nfunction Ns(e, t) {\n  if (!t) return Math.trunc(e);\n\n  switch (t) {\n    case \"round\":\n      return Math.round(e);\n\n    case \"ceil\":\n      return Math.ceil(e);\n\n    case \"floor\":\n      return Math.floor(e);\n\n    default:\n      throw new Error(\"Unknown roundingMode \".concat(t));\n  }\n}\n\nfunction Cs(e) {\n  var [t, n, s] = vs(e);\n  return 1 === t && 1 === n && 1 === s;\n}\n\nfunction Ss(e, t) {\n  return Cs(e) || Cs(t);\n}\n\nfunction Ts(e) {\n  if (\"NHWC\" === e) return \"channelsLast\";\n  if (\"NCHW\" === e) return \"channelsFirst\";\n  throw new Error(\"Unknown dataFormat \".concat(e));\n}\n\nvar Es = At({\n  reshape_: function reshape_(e, t) {\n    var n = Et(e, \"x\", \"reshape\", \"string_or_numeric\");\n    return wt.runKernel(\"Reshape\", {\n      x: n\n    }, {\n      shape: t\n    });\n  }\n}),\n    Rs = At({\n  avgPool_: function avgPool_(e, t, n, s, r) {\n    var a = Et(e, \"x\", \"avgPool\", \"float32\");\n    l(Ss(n, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '1'\"));\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Es(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === i.rank, () => \"Error in avgPool: x must be rank 4 but got rank \".concat(i.rank, \".\")), null != r && l(f(s), () => \"Error in avgPool: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var u = wt.runKernel(\"AvgPool\", {\n      x: i\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r\n    });\n    return u = pn(u, a.dtype), o ? Es(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    As = At({\n  avgPool3d_: function avgPool3d_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NDHWC\";\n    var i = Et(e, \"x\", \"avgPool3d\", \"float32\");\n    var o = i,\n        u = !1;\n    4 === i.rank && (u = !0, o = Es(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === o.rank, () => \"Error in avgPool3d: x must be rank 5 but got rank \".concat(o.rank, \".\")), l(\"NDHWC\" === a, () => \"Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of \".concat(a)), null != r && l(f(s), () => \"Error in avgPool3d: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var c = wt.runKernel(\"AvgPool3D\", {\n      x: o\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r,\n      dataFormat: a\n    });\n    return c = pn(c, o.dtype), u ? Es(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;\n  }\n}),\n    Fs = At({\n  concat_: function concat_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    l(e.length >= 1, () => \"Pass at least one tensor to concat\");\n    var n = Rt(e, \"tensors\", \"concat\", \"string_or_numeric\");\n    return \"complex64\" === n[0].dtype && n.forEach(e => {\n      if (\"complex64\" !== e.dtype) throw new Error(\"Cannot concatenate complex64 tensors with a tensor\\n          with dtype \".concat(e.dtype, \". \"));\n    }), 1 === n.length ? fn(n[0]) : wt.runKernel(\"Concat\", n, {\n      axis: t\n    });\n  }\n}),\n    Ds = At({\n  sigmoid_: function sigmoid_(e) {\n    var t = Et(e, \"x\", \"sigmoid\");\n    return wt.runKernel(\"Sigmoid\", {\n      x: t\n    });\n  }\n}),\n    _s = At({\n  slice_: function slice_(e, t, n) {\n    var s = Et(e, \"x\", \"slice\", \"string_or_numeric\");\n    if (0 === s.rank) throw new Error(\"Slicing scalar is not possible\");\n    return wt.runKernel(\"Slice\", {\n      x: s\n    }, {\n      begin: t,\n      size: n\n    });\n  }\n}),\n    Os = At({\n  tanh_: function tanh_(e) {\n    var t = Et(e, \"x\", \"tanh\");\n    return wt.runKernel(\"Tanh\", {\n      x: t\n    });\n  }\n}),\n    Ms = At({\n  batchToSpaceND_: function batchToSpaceND_(e, t, n) {\n    var s = Et(e, \"x\", \"batchToSpaceND\"),\n        r = t.reduce((e, t) => e * t);\n    return l(s.rank >= 1 + t.length, () => \"input rank is \".concat(s.rank, \" but should be > than blockShape.length \").concat(t.length)), l(n.length === t.length, () => \"crops.length is \".concat(n.length, \" but should be equal to blockShape.length  \").concat(t.length)), l(s.shape[0] % r == 0, () => \"input tensor batch is \".concat(s.shape[0], \" but is not divisible by the product of the elements of blockShape \").concat(t.join(\" * \"), \" === \").concat(r)), wt.runKernel(\"BatchToSpaceND\", {\n      x: s\n    }, {\n      blockShape: t,\n      crops: n\n    });\n  }\n}),\n    Ls = At({\n  batchNorm_: function batchNorm_(e, t, n, s, r, a) {\n    null == a && (a = .001);\n    var i = Et(e, \"x\", \"batchNorm\"),\n        o = Et(t, \"mean\", \"batchNorm\"),\n        u = Et(n, \"variance\", \"batchNorm\");\n    var c, h;\n    null != r && (c = Et(r, \"scale\", \"batchNorm\")), null != s && (h = Et(s, \"offset\", \"batchNorm\")), l(o.rank === u.rank, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == h || o.rank === h.rank, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == c || o.rank === c.rank, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\");\n\n    var d = function (e) {\n      var t;\n      return t = 0 === e.rank || 1 === e.rank ? Es(e, [1, 1, 1, e.size]) : 2 === e.rank ? Es(e, [1, 1, e.shape[0], e.shape[1]]) : 3 === e.rank ? Es(e, [1, e.shape[0], e.shape[1], e.shape[2]]) : e, t;\n    }(i),\n        p = wt.runKernel(\"FusedBatchNorm\", {\n      x: d,\n      scale: c,\n      offset: h,\n      mean: o,\n      variance: u\n    }, {\n      varianceEpsilon: a\n    });\n\n    return Es(p, i.shape);\n  }\n}),\n    zs = At({\n  batchNorm2d_: function batchNorm2d_(e, t, n, s, r, a) {\n    var i = Et(e, \"x\", \"batchNorm\"),\n        o = Et(t, \"mean\", \"batchNorm\"),\n        u = Et(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Et(r, \"scale\", \"batchNorm\")), null != s && (h = Et(s, \"offset\", \"batchNorm\")), l(2 === i.rank, () => \"Error in batchNorm2D: x must be rank 2 but got rank \".concat(i.rank, \".\")), l(2 === o.rank || 1 === o.rank, () => \"Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank \".concat(o.rank, \".\")), l(2 === u.rank || 1 === u.rank, () => \"Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(2 === c.rank || 1 === c.rank, () => \"Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(2 === h.rank || 1 === h.rank, () => \"Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank \".concat(h.rank, \".\")), Ls(i, o, u, h, c, a);\n  }\n}),\n    Bs = At({\n  batchNorm3d_: function batchNorm3d_(e, t, n, s, r, a) {\n    var i = Et(e, \"x\", \"batchNorm\"),\n        o = Et(t, \"mean\", \"batchNorm\"),\n        u = Et(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Et(r, \"scale\", \"batchNorm\")), null != s && (h = Et(s, \"offset\", \"batchNorm\")), l(3 === i.rank, () => \"Error in batchNorm3D: x must be rank 3 but got rank \".concat(i.rank, \".\")), l(3 === o.rank || 1 === o.rank, () => \"Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank \".concat(o.rank, \".\")), l(3 === u.rank || 1 === u.rank, () => \"Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(3 === c.rank || 1 === c.rank, () => \"Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(3 === h.rank || 1 === h.rank, () => \"Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank \".concat(h.rank, \".\")), Ls(i, o, u, h, c, a);\n  }\n}),\n    Ps = At({\n  batchNorm4d_: function batchNorm4d_(e, t, n, s, r, a) {\n    var i = Et(e, \"x\", \"batchNorm\"),\n        o = Et(t, \"mean\", \"batchNorm\"),\n        u = Et(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Et(r, \"scale\", \"batchNorm\")), null != s && (h = Et(s, \"offset\", \"batchNorm\")), l(4 === i.rank, () => \"Error in batchNorm4D: x must be rank 4 but got rank \".concat(i.rank, \".\")), l(4 === o.rank || 1 === o.rank, () => \"Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank \".concat(o.rank, \".\")), l(4 === u.rank || 1 === u.rank, () => \"Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(4 === c.rank || 1 === c.rank, () => \"Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(4 === h.rank || 1 === h.rank, () => \"Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank \".concat(h.rank, \".\")), Ls(i, o, u, h, c, a);\n  }\n}),\n    Ws = At({\n  bincount_: function bincount_(e, t, n) {\n    var s = Et(e, \"x\", \"bincount\"),\n        r = Et(t, \"weights\", \"bincount\");\n    return l(\"int32\" === s.dtype, () => \"Error in bincount: input dtype must be int32, but got \".concat(s.dtype)), l(n >= 0, () => \"size must be non-negative, but got \".concat(n, \".\")), l(r.size === s.size || 0 === r.size, () => \"Error in bincount: weights must have the same size as input or0-length, but got input shape: \".concat(s.shape, \", weights shape: \").concat(r.shape, \".\")), wt.runKernel(\"Bincount\", {\n      x: s,\n      weights: r\n    }, {\n      size: n\n    });\n  }\n}),\n    Us = At({\n  broadcastTo_: function broadcastTo_(e, t) {\n    var n = Et(e, \"broadcastTo\", \"x\");\n    var s = n.shape;\n    if (t.some(e => !(e > 0) || e % 1 != 0)) throw new Error(\"broadcastTo(): Invalid broadcast shape [\".concat(t, \"].\"));\n    if (t.length < n.rank) throw new Error(\"broadcastTo(): shape.length=\".concat(t.length, \" < input.rank=\").concat(n.rank, \".\"));\n\n    if (t.length > n.rank) {\n      var _e48 = n.shape.slice();\n\n      for (; _e48.length < t.length;) {\n        _e48.unshift(1);\n      }\n\n      n = Es(n, _e48);\n    }\n\n    var r = n.shape,\n        a = Array.from(t);\n\n    for (var _e49 = t.length - 1; _e49 >= 0; _e49--) {\n      if (r[_e49] === t[_e49]) a[_e49] = 1;else if (1 !== n.shape[_e49]) throw new Error(\"broadcastTo(): [\".concat(s, \"] cannot be broadcast to [\").concat(t, \"].\"));\n    }\n\n    return 0 === a.map((e, t) => e > 1 ? t : -1).filter(e => e >= 0).length ? fn(n) : wt.runKernel(\"Tile\", {\n      x: n\n    }, {\n      reps: a\n    });\n  }\n}),\n    Vs = At({\n  ceil_: function ceil_(e) {\n    var t = Et(e, \"x\", \"ceil\");\n    return wt.runKernel(\"Ceil\", {\n      x: t\n    });\n  }\n}),\n    Gs = At({\n  clipByValue_: function clipByValue_(e, t, n) {\n    var s = Et(e, \"x\", \"clipByValue\");\n    return l(t <= n, () => \"Error in clip: min (\".concat(t, \") must be less than or equal to max (\").concat(n, \").\")), wt.runKernel(\"ClipByValue\", {\n      x: s\n    }, {\n      clipValueMin: t,\n      clipValueMax: n\n    });\n  }\n}),\n    Hs = At({\n  concat1d_: function concat1d_(e) {\n    return Fs(e, 0);\n  }\n}),\n    js = At({\n  concat2d_: function concat2d_(e, t) {\n    return Fs(e, t);\n  }\n}),\n    qs = At({\n  concat3d_: function concat3d_(e, t) {\n    return Fs(e, t);\n  }\n}),\n    Ks = At({\n  concat4d_: function concat4d_(e, t) {\n    return Fs(e, t);\n  }\n}),\n    Xs = At({\n  conv2d_: function conv2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Et(e, \"x\", \"conv2d\"),\n        u = Et(t, \"filter\", \"conv2d\");\n    var c = o,\n        h = !1;\n    3 === o.rank && (h = !0, c = Es(o, [1, o.shape[0], o.shape[1], o.shape[2]])), l(4 === c.rank, () => \"Error in conv2d: input must be rank 4, but got rank \".concat(c.rank, \".\")), l(4 === u.rank, () => \"Error in conv2d: filter must be rank 4, but got rank \".concat(u.rank, \".\")), null != i && l(f(s), () => \"Error in conv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\"));\n    var d = \"NHWC\" === r ? c.shape[3] : c.shape[1];\n    l(d === u.shape[2], () => \"Error in conv2d: depth of input (\".concat(d, \") must match input depth for filter \").concat(u.shape[2], \".\")), l(Ss(n, a), () => \"Error in conv2D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\"));\n    var p = wt.runKernel(\"Conv2D\", {\n      x: c,\n      filter: u\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i\n    });\n    return h ? Es(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;\n  }\n}),\n    Ys = At({\n  conv1d_: function conv1d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Et(e, \"x\", \"conv1d\"),\n        u = Et(t, \"filter\", \"conv1d\");\n    var c = o,\n        h = !1;\n    2 === o.rank && (h = !0, c = Es(o, [1, o.shape[0], o.shape[1]])), l(3 === c.rank, () => \"Error in conv1d: input must be rank 3, but got rank \".concat(c.rank, \".\")), l(3 === u.rank, () => \"Error in conv1d: filter must be rank 3, but got rank \".concat(u.rank, \".\")), null != i && l(f(s), () => \"Error in conv1d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\")), l(c.shape[2] === u.shape[1], () => \"Error in conv1d: depth of input (\".concat(c.shape[2], \") must match input depth for filter \").concat(u.shape[1], \".\")), l(Ss(n, a), () => \"Error in conv1D: Either stride or dilation must be 1. Got stride \".concat(n, \" and dilation '\").concat(a, \"'\")), l(\"NWC\" === r, () => \"Error in conv1d: got dataFormat of \".concat(r, \" but only NWC is currently supported.\"));\n    var d = Es(u, [1, u.shape[0], u.shape[1], u.shape[2]]),\n        p = Es(c, [c.shape[0], 1, c.shape[1], c.shape[2]]),\n        g = Xs(p, d, [1, n], s, \"NHWC\", [1, a], i);\n    return Es(g, h ? [g.shape[2], g.shape[3]] : [g.shape[0], g.shape[2], g.shape[3]]);\n  }\n}),\n    Js = At({\n  conv2DBackpropInput_: function conv2DBackpropInput_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    l(e.length === t.rank, () => \"Length of inShape (\".concat(e.length, \") and rank of dy (\").concat(t.rank, \") must match\"));\n    var o = e,\n        u = t,\n        c = !1;\n    3 === t.rank && (c = !0, u = Es(t, [1, t.shape[0], t.shape[1], t.shape[2]]), o = [1, e[0], e[1], e[2]]), l(4 === o.length, () => \"Error in conv2dDerInput: inShape must be length 4, but got length \".concat(o.length, \".\")), l(4 === u.rank, () => \"Error in conv2dDerInput: dy must be rank 4, but got rank \".concat(u.rank)), l(4 === n.rank, () => \"Error in conv2dDerInput: filter must be rank 4, but got rank \".concat(n.rank));\n    var h = \"NHWC\" === a ? o[3] : o[1],\n        d = \"NHWC\" === a ? u.shape[3] : u.shape[1];\n    l(h === n.shape[2], () => \"Error in conv2dDerInput: depth of input (\".concat(h, \") must match input depth for filter \").concat(n.shape[2], \".\")), l(d === n.shape[3], () => \"Error in conv2dDerInput: depth of output (\".concat(d, \") must match output depth for filter \").concat(n.shape[3], \".\")), null != i && l(f(r), () => \"Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(r, \".\"));\n    var p = wt.runKernel(\"Conv2DBackpropInput\", {\n      dy: u,\n      filter: n\n    }, {\n      strides: s,\n      pad: r,\n      dataFormat: a,\n      dimRoundingMode: i,\n      inputShape: o\n    });\n    return c ? Es(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;\n  }\n}),\n    Zs = At({\n  conv2dTranspose_: function conv2dTranspose_(e, t, n, s, r, a) {\n    var i = Et(e, \"x\", \"conv2dTranspose\"),\n        o = Et(t, \"filter\", \"conv2dTranspose\");\n    return Js(n, i, o, s, r, \"NHWC\", a);\n  }\n}),\n    Qs = At({\n  conv3d_: function conv3d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NDHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1, 1];\n    var i = Et(e, \"x\", \"conv3d\"),\n        o = Et(t, \"filter\", \"conv3d\");\n    var u = i,\n        c = !1;\n    4 === i.rank && (c = !0, u = Es(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === u.rank, () => \"Error in conv3d: input must be rank 5, but got rank \".concat(u.rank, \".\")), l(5 === o.rank, () => \"Error in conv3d: filter must be rank 5, but got rank \".concat(o.rank, \".\")), l(u.shape[4] === o.shape[3], () => \"Error in conv3d: depth of input (\".concat(u.shape[4], \") must match input depth for filter \").concat(o.shape[3], \".\")), l(Ss(n, a), () => \"Error in conv3D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\")), l(\"NDHWC\" === r, () => \"Error in conv3d: got dataFormat of \".concat(r, \" but only NDHWC is currently supported.\"));\n    var h = wt.runKernel(\"Conv3D\", {\n      x: u,\n      filter: o\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a\n    });\n    return c ? Es(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;\n  }\n}),\n    er = At({\n  conv3DBackpropInput_: function conv3DBackpropInput_(e, t, n, s, r) {\n    l(e.length === t.rank, () => \"Length of inShape (\".concat(e.length, \") and rank of dy (\").concat(t.rank, \") must match\"));\n    var a = e,\n        i = t,\n        o = !1;\n    4 === t.rank && (o = !0, i = Es(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), a = [1, e[0], e[1], e[2], e[3]]);\n    var u = a[4],\n        c = i.shape[4];\n    l(5 === a.length, () => \"Error in conv3dDerInput: inShape must be length 5, but got length \".concat(a.length, \".\")), l(5 === i.rank, () => \"Error in conv3dDerInput: dy must be rank 5, but got rank \".concat(i.rank)), l(5 === n.rank, () => \"Error in conv3dDerInput: filter must be rank 5, but got rank \".concat(n.rank)), l(u === n.shape[3], () => \"Error in conv3dDerInput: depth of input (\".concat(u, \") must match input depth for filter \").concat(n.shape[3], \".\")), l(c === n.shape[4], () => \"Error in conv3dDerInput: depth of output (\".concat(c, \") must match output depth for filter \").concat(n.shape[4], \".\"));\n    var h = wt.runKernel(\"Conv3DBackpropInputV2\", {\n      dy: i,\n      filter: n\n    }, {\n      pad: r,\n      strides: s,\n      inputShape: a\n    });\n    return o ? Es(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;\n  }\n}),\n    tr = At({\n  conv3dTranspose_: function conv3dTranspose_(e, t, n, s, r) {\n    var a = Et(e, \"x\", \"conv3dTranspose\"),\n        i = Et(t, \"filter\", \"conv3dTranspose\");\n    return er(n, a, i, s, r);\n  }\n}),\n    nr = At({\n  cos_: function cos_(e) {\n    var t = Et(e, \"x\", \"cos\");\n    return wt.runKernel(\"Cos\", {\n      x: t\n    });\n  }\n}),\n    sr = At({\n  cosh_: function cosh_(e) {\n    var t = Et(e, \"x\", \"cosh\");\n    return wt.runKernel(\"Cosh\", {\n      x: t\n    });\n  }\n}),\n    rr = At({\n  cumsum_: function cumsum_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Et(e, \"x\", \"cumsum\");\n    return wt.runKernel(\"Cumsum\", {\n      x: r\n    }, {\n      axis: t,\n      exclusive: n,\n      reverse: s\n    });\n  }\n}),\n    ar = At({\n  depthToSpace_: function depthToSpace_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"NHWC\";\n    var s = Et(e, \"x\", \"depthToSpace\"),\n        r = \"NHWC\" === n ? s.shape[1] : s.shape[2],\n        a = \"NHWC\" === n ? s.shape[2] : s.shape[3],\n        i = \"NHWC\" === n ? s.shape[3] : s.shape[1];\n    return l(r * t >= 0, () => \"Negative dimension size caused by overflow when multiplying\\n    \".concat(r, \" and \").concat(t, \"  for depthToSpace with input shape\\n    \").concat(s.shape)), l(a * t >= 0, () => \"Negative dimension size caused by overflow when multiplying\\n    \".concat(a, \" and \").concat(t, \" for depthToSpace with input shape\\n        \").concat(s.shape)), l(i % (t * t) == 0, () => \"Dimension size must be evenly divisible by \".concat(t * t, \" but is \").concat(i, \" for depthToSpace with input shape \").concat(s.shape)), wt.runKernel(\"DepthToSpace\", {\n      x: s\n    }, {\n      blockSize: t,\n      dataFormat: n\n    });\n  }\n}),\n    ir = At({\n  depthwiseConv2d_: function depthwiseConv2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Et(e, \"x\", \"depthwiseConv2d\"),\n        u = Et(t, \"filter\", \"depthwiseConv2d\");\n    var c = o,\n        h = !1;\n    3 === o.rank && (h = !0, c = Es(o, [1, o.shape[0], o.shape[1], o.shape[2]])), l(4 === c.rank, () => \"Error in depthwiseConv2d: input must be rank 4, but got rank \".concat(c.rank, \".\")), l(4 === u.rank, () => \"Error in depthwiseConv2d: filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(c.shape[3] === u.shape[2], () => \"Error in depthwiseConv2d: number of input channels (\".concat(c.shape[3], \") must match the inChannels dimension in filter \").concat(u.shape[2], \".\")), null != i && l(f(s), () => \"Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\"));\n    var d = wt.runKernel(\"DepthwiseConv2dNative\", {\n      x: c,\n      filter: u\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i\n    });\n    return h ? Es(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;\n  }\n}),\n    or = At({\n  dilation2d_: function dilation2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [1, 1];\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = Et(e, \"x\", \"dilation2d\"),\n        o = Et(t, \"filter\", \"dilation2d\");\n    l(3 === i.rank || 4 === i.rank, () => \"Error in dilation2d: input must be rank 3 or 4, but got rank \".concat(i.rank, \".\")), l(3 === o.rank, () => \"Error in dilation2d: filter must be rank 3, but got rank \".concat(o.rank, \".\")), l(\"NHWC\" === a, () => \"Error in dilation2d: Only NHWC is currently supported, but got dataFormat of \".concat(a));\n    var u = i,\n        c = !1;\n    3 === i.rank && (u = Es(i, [1, i.shape[0], i.shape[1], i.shape[2]]), c = !0);\n    var h = wt.runKernel(\"Dilation2D\", {\n      x: u,\n      filter: o\n    }, {\n      strides: n,\n      pad: s,\n      dilations: r\n    });\n    return c ? Es(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;\n  }\n});\n\nfunction lr(e, t) {\n  var n = e.length,\n      s = [];\n\n  for (var _r22 = 0; _r22 < n; _r22++) {\n    var _a12 = n - 1 - _r22,\n        _i9 = e[_a12] || 1;\n\n    (t[t.length - 1 - _r22] || 1) > 1 && 1 === _i9 && s.unshift(_a12);\n  }\n\n  return s;\n}\n\nfunction ur(e, t) {\n  var n = [];\n\n  for (var _s31 = 0; _s31 < t.length; _s31++) {\n    var _r23 = e[e.length - _s31 - 1],\n        _a13 = t.length - _s31 - 1,\n        _i10 = t[_a13];\n\n    (null == _r23 || 1 === _r23 && _i10 > 1) && n.unshift(_a13);\n  }\n\n  return n;\n}\n\nfunction cr(e, t) {\n  var n = [],\n      s = Math.max(e.length, t.length);\n\n  for (var _r24 = 0; _r24 < s; _r24++) {\n    var _s32 = e[e.length - _r24 - 1];\n    null == _s32 && (_s32 = 1);\n    var _a14 = t[t.length - _r24 - 1];\n    if (null == _a14 && (_a14 = 1), 1 === _s32) n.unshift(_a14);else if (1 === _a14) n.unshift(_s32);else {\n      if (_s32 !== _a14) throw Error(\"Operands could not be broadcast together with shapes \".concat(e, \" and \").concat(t, \".\"));\n      n.unshift(_s32);\n    }\n  }\n\n  return n;\n}\n\nvar hr = At({\n  equal_: function equal_(e, t) {\n    var n = Et(e, \"a\", \"equal\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"equal\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"Equal\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    dr = At({\n  where_: function where_(e, t, n) {\n    var s = Et(t, \"a\", \"where\"),\n        r = Et(n, \"b\", \"where\"),\n        a = Et(e, \"condition\", \"where\", \"bool\"),\n        i = cr(cr(a.shape, s.shape), r.shape),\n        o = Us(a, i),\n        l = Us(s, i),\n        u = Us(r, i);\n    return wt.runKernel(\"Select\", {\n      condition: o,\n      t: l,\n      e: u\n    });\n  }\n}),\n    pr = At({\n  zerosLike_: function zerosLike_(e) {\n    var t = Et(e, \"x\", \"zerosLike\");\n    return wt.runKernel(\"ZerosLike\", {\n      x: t\n    });\n  }\n}),\n    fr = At({\n  divNoNan_: function divNoNan_(e, t) {\n    var n = Et(e, \"a\", \"div\"),\n        s = Et(t, \"b\", \"div\");\n    [n, s] = ft(n, s);\n    var r = ns(n, s),\n        a = pr(r),\n        i = hr(s, a);\n    return dr(i, a, r);\n  }\n}),\n    gr = At({\n  dot_: function dot_(e, t) {\n    var n = Et(e, \"t1\", \"dot\"),\n        s = Et(t, \"t2\", \"dot\");\n    l(!(1 !== n.rank && 2 !== n.rank || 1 !== s.rank && 2 !== s.rank), () => \"Error in dot: inputs must all be rank 1 or 2, but got ranks \".concat(n.rank, \" and \").concat(s.rank, \".\"));\n    var r = 1 === n.rank ? n.size : n.shape[1],\n        a = 1 === s.rank ? s.size : s.shape[0];\n\n    if (l(r === a, () => \"Error in dot: inner dimensions of inputs must match, but got \".concat(r, \" and \").concat(a, \".\")), 1 === n.rank && 1 === s.rank) {\n      var _e50 = Es(n, [1, -1]),\n          _t54 = Es(s, [-1, 1]),\n          _r25 = vn(_e50, _t54);\n\n      return Es(_r25, []);\n    }\n\n    if (1 === n.rank && 2 === s.rank) {\n      var _e51 = Es(n, [1, -1]),\n          _t55 = Es(s, [s.shape[0], s.shape[1]]),\n          _r26 = vn(_e51, _t55);\n\n      return Es(_r26, [_r26.size]);\n    }\n\n    if (2 === n.rank && 1 === s.rank) {\n      var _e52 = Es(s, [-1, 1]),\n          _t56 = vn(n, _e52);\n\n      return Es(_t56, [_t56.size]);\n    }\n\n    {\n      var _e53 = Es(s, [s.shape[0], s.shape[1]]);\n\n      return vn(n, _e53);\n    }\n  }\n}),\n    mr = At({\n  elu_: function elu_(e) {\n    var t = Et(e, \"x\", \"elu\");\n    return wt.runKernel(\"Elu\", {\n      x: t\n    });\n  }\n}),\n    br = At({\n  erf_: function erf_(e) {\n    var t = Et(e, \"x\", \"erf\");\n    return l(\"int32\" === t.dtype || \"float32\" === t.dtype, () => \"Input dtype must be `int32` or `float32`.\"), \"int32\" === t.dtype && (t = pn(t, \"float32\")), wt.runKernel(\"Erf\", {\n      x: t\n    });\n  }\n}),\n    xr = At({\n  exp_: function exp_(e) {\n    var t = Et(e, \"x\", \"exp\");\n    return wt.runKernel(\"Exp\", {\n      x: t\n    });\n  }\n}),\n    yr = At({\n  expandDims_: function expandDims_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"expandDims\", \"string_or_numeric\");\n    return l(t <= n.rank, () => \"Axis must be <= rank of the tensor\"), wt.runKernel(\"ExpandDims\", {\n      input: n\n    }, {\n      dim: t\n    });\n  }\n}),\n    kr = At({\n  expm1_: function expm1_(e) {\n    var t = Et(e, \"x\", \"expm1\");\n    return wt.runKernel(\"Expm1\", {\n      x: t\n    });\n  }\n}),\n    wr = At({\n  tile_: function tile_(e, t) {\n    var n = Et(e, \"x\", \"tile\", \"string_or_numeric\");\n    return l(n.rank === t.length, () => \"Error in transpose: rank of input \".concat(n.rank, \" must match length of reps \").concat(t, \".\")), wt.runKernel(\"Tile\", {\n      x: n\n    }, {\n      reps: t\n    });\n  }\n}),\n    vr = At({\n  eye_: function eye_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n    null == t && (t = e);\n    var r = dn([e, t], s),\n        a = e <= t ? e : t;\n\n    for (var _e54 = 0; _e54 < a; ++_e54) {\n      r.set(1, _e54, _e54);\n    }\n\n    var i = Es(r.toTensor(), [e, t]);\n    if (null == n) return i;\n    if (1 === n.length) return wr(yr(i, 0), [n[0], 1, 1]);\n    if (2 === n.length) return wr(yr(yr(i, 0), 0), [n[0], n[1], 1, 1]);\n    if (3 === n.length) return wr(yr(yr(yr(i, 0), 0), 0), [n[0], n[1], n[2], 1, 1]);\n    throw new Error(\"eye() currently supports only 1D and 2D batchShapes, but received \".concat(n.length, \"D.\"));\n  }\n});\n\nfunction Ir(e, t, n) {\n  return wt.runKernel(\"Fill\", {}, {\n    shape: e,\n    value: t,\n    dtype: n\n  });\n}\n\nvar $r = At({\n  floor_: function floor_(e) {\n    var t = Et(e, \"x\", \"floor\");\n    return wt.runKernel(\"Floor\", {\n      x: t\n    });\n  }\n}),\n    Nr = At({\n  gather_: function gather_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = Et(e, \"x\", \"gather\"),\n        a = Et(t, \"indices\", \"gather\", \"int32\");\n    return wt.runKernel(\"GatherV2\", {\n      x: r,\n      indices: a\n    }, {\n      axis: n,\n      batchDims: s\n    });\n  }\n}),\n    Cr = At({\n  greater_: function greater_(e, t) {\n    var n = Et(e, \"a\", \"greater\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"greater\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"Greater\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Sr = At({\n  greaterEqual_: function greaterEqual_(e, t) {\n    var n = Et(e, \"a\", \"greaterEqual\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"greaterEqual\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"GreaterEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Tr = At({\n  imag_: function imag_(e) {\n    var t = Et(e, \"input\", \"imag\");\n    return wt.runKernel(\"Imag\", {\n      input: t\n    });\n  }\n}),\n    Er = At({\n  isFinite_: function isFinite_(e) {\n    var t = Et(e, \"x\", \"isFinite\");\n    return wt.runKernel(\"IsFinite\", {\n      x: t\n    });\n  }\n}),\n    Rr = At({\n  isInf_: function isInf_(e) {\n    var t = Et(e, \"x\", \"isInf\");\n    return wt.runKernel(\"IsInf\", {\n      x: t\n    });\n  }\n}),\n    Ar = At({\n  isNaN_: function isNaN_(e) {\n    var t = Et(e, \"x\", \"isNaN\");\n    return wt.runKernel(\"IsNan\", {\n      x: t\n    });\n  }\n}),\n    Fr = At({\n  leakyRelu_: function leakyRelu_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .2;\n    var n = Et(e, \"x\", \"leakyRelu\");\n    return wt.runKernel(\"LeakyRelu\", {\n      x: n\n    }, {\n      alpha: t\n    });\n  }\n}),\n    Dr = At({\n  less_: function less_(e, t) {\n    var n = Et(e, \"a\", \"less\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"less\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"Less\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    _r = At({\n  lessEqual_: function lessEqual_(e, t) {\n    var n = Et(e, \"a\", \"lessEqual\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"lessEqual\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"LessEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Or = At({\n  localResponseNormalization_: function localResponseNormalization_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 5;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .5;\n    var a = Et(e, \"x\", \"localResponseNormalization\");\n    l(4 === a.rank || 3 === a.rank, () => \"Error in localResponseNormalization: x must be rank 3 or 4 but got\\n               rank \".concat(a.rank, \".\")), l(f(t), () => \"Error in localResponseNormalization: depthRadius must be an integer but got depthRadius \".concat(t, \".\"));\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Es(a, [1, a.shape[0], a.shape[1], a.shape[2]]));\n    var u = wt.runKernel(\"LRN\", {\n      x: i\n    }, {\n      depthRadius: t,\n      bias: n,\n      alpha: s,\n      beta: r\n    });\n    return o ? Es(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    Mr = At({\n  log_: function log_(e) {\n    var t = Et(e, \"x\", \"log\");\n    return wt.runKernel(\"Log\", {\n      x: t\n    });\n  }\n}),\n    Lr = At({\n  log1p_: function log1p_(e) {\n    var t = Et(e, \"x\", \"log1p\");\n    return wt.runKernel(\"Log1p\", {\n      x: t\n    });\n  }\n});\n\nfunction zr(e) {\n  return wt.customGrad(e);\n}\n\nvar Br = At({\n  neg_: function neg_(e) {\n    var t = Et(e, \"x\", \"neg\");\n    return wt.runKernel(\"Neg\", {\n      x: t\n    });\n  }\n}),\n    Pr = At({\n  softplus_: function softplus_(e) {\n    var t = Et(e, \"x\", \"softplus\");\n    return wt.runKernel(\"Softplus\", {\n      x: t\n    });\n  }\n}),\n    Wr = At({\n  logSigmoid_: function logSigmoid_(e) {\n    var t = Et(e, \"x\", \"logSigmoid\");\n    return zr(e => ({\n      value: Br(Pr(Br(e))),\n      gradFunc: t => ss(t, Ds(Br(e)))\n    }))(t);\n  }\n}),\n    Ur = At({\n  max_: function max_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"max\");\n    return wt.runKernel(\"Max\", {\n      x: s\n    }, {\n      reductionIndices: t,\n      keepDims: n\n    });\n  }\n}),\n    Vr = At({\n  sub_: function sub_(e, t) {\n    var n = Et(e, \"a\", \"sub\"),\n        s = Et(t, \"b\", \"sub\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Sub\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Gr = At({\n  sum_: function sum_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"sum\");\n    return \"bool\" === s.dtype && (s = pn(s, \"int32\")), wt.runKernel(\"Sum\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    Hr = At({\n  logSoftmax_: function logSoftmax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    var n = Et(e, \"logits\", \"logSoftmax\");\n    if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error(\"Log Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(n.rank, \" and axis was \").concat(t));\n    return zr((e, n) => {\n      var s = Ur(e, t, !0),\n          r = Vr(e, s),\n          a = Vr(pn(r, \"float32\"), Mr(Gr(xr(r), t, !0)));\n      return n([a]), {\n        value: a,\n        gradFunc: (e, n) => {\n          var [s] = n,\n              r = xr(s);\n          return Vr(e, ss(Gr(e, t, !0), r));\n        }\n      };\n    })(n);\n  }\n});\n\nfunction jr(e, t) {\n  for (var _n27 = 0; _n27 < e.length; ++_n27) {\n    if (e[e.length - _n27 - 1] !== t - 1 - _n27) return !1;\n  }\n\n  return !0;\n}\n\nfunction qr(e, t, n) {\n  var s = e.length + t.length,\n      r = [];\n  var a = 0,\n      i = 0;\n\n  for (var _o9 = 0; _o9 < s; _o9++) {\n    -1 === n.indexOf(_o9) ? r.push(e[a++]) : r.push(t[i++]);\n  }\n\n  return r;\n}\n\nfunction Kr(e, t) {\n  var n = [],\n      s = e.length;\n\n  for (var _r27 = 0; _r27 < s; _r27++) {\n    -1 === t.indexOf(_r27) && n.push(e[_r27]);\n  }\n\n  return [n, t.map(t => e[t])];\n}\n\nfunction Xr(e, t) {\n  return qr(e, t.map(e => 1), t);\n}\n\nfunction Yr(e, t, n) {\n  l(jr(t, n), () => \"\".concat(e, \" supports only inner-most axes for now. Got axes \").concat(t, \" and rank-\").concat(n, \" input.\"));\n}\n\nfunction Jr(e, t) {\n  if (jr(e, t)) return null;\n  var n = [];\n\n  for (var _s33 = 0; _s33 < t; ++_s33) {\n    -1 === e.indexOf(_s33) && n.push(_s33);\n  }\n\n  return e.forEach(e => n.push(e)), n;\n}\n\nfunction Zr(e) {\n  return e.map((e, t) => [t, e]).sort((e, t) => e[1] - t[1]).map(e => e[0]);\n}\n\nfunction Qr(e, t) {\n  var n = [];\n\n  for (var _s34 = t - e; _s34 < t; ++_s34) {\n    n.push(_s34);\n  }\n\n  return n;\n}\n\nvar ea = At({\n  logSumExp_: function logSumExp_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"logSumExp\"),\n        r = y(t, s.shape),\n        a = Ur(s, r, !0),\n        i = Vr(s, a),\n        o = xr(i),\n        l = Gr(o, r),\n        u = Mr(l),\n        c = es(Es(a, u.shape), u);\n\n    if (n) {\n      var _e55 = Xr(c.shape, r);\n\n      return Es(c, _e55);\n    }\n\n    return c;\n  }\n}),\n    ta = At({\n  logicalAnd_: function logicalAnd_(e, t) {\n    var n = Et(e, \"a\", \"logicalAnd\", \"bool\"),\n        s = Et(t, \"b\", \"logicalAnd\", \"bool\");\n    return cr(n.shape, s.shape), wt.runKernel(\"LogicalAnd\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    na = At({\n  logicalNot_: function logicalNot_(e) {\n    var t = Et(e, \"x\", \"logicalNot\", \"bool\");\n    return wt.runKernel(\"LogicalNot\", {\n      x: t\n    });\n  }\n}),\n    sa = At({\n  logicalOr_: function logicalOr_(e, t) {\n    var n = Et(e, \"a\", \"logicalOr\", \"bool\"),\n        s = Et(t, \"b\", \"logicalOr\", \"bool\");\n    return cr(n.shape, s.shape), wt.runKernel(\"LogicalOr\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ra = At({\n  logicalXor_: function logicalXor_(e, t) {\n    var n = Et(e, \"a\", \"logicalXor\", \"bool\"),\n        s = Et(t, \"b\", \"logicalXor\", \"bool\");\n    return cr(n.shape, s.shape), ta(sa(e, t), na(ta(e, t)));\n  }\n}),\n    aa = At({\n  maxPool_: function maxPool_(e, t, n, s, r) {\n    var a = Et(e, \"x\", \"maxPool\");\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Es(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === i.rank, () => \"Error in maxPool: input must be rank 4 but got rank \".concat(i.rank, \".\")), l(Ss(n, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '1'\")), null != r && l(f(s), () => \"Error in maxPool: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var u = wt.runKernel(\"MaxPool\", {\n      x: i\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r\n    });\n    return o ? Es(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    ia = At({\n  maxPool3d_: function maxPool3d_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [1, 1, 1];\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NDHWC\";\n    var i = Et(e, \"x\", \"maxPool3d\");\n    var o = i,\n        u = !1;\n    4 === i.rank && (u = !0, o = Es(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === o.rank, () => \"Error in maxPool3d: x must be rank 5 but got rank \".concat(o.rank, \".\")), l(\"NDHWC\" === a, () => \"Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of \".concat(a)), null != r && l(f(s), () => \"Error in maxPool3d: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var c = wt.runKernel(\"MaxPool3D\", {\n      x: o\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r,\n      dataFormat: a\n    });\n    return u ? Es(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;\n  }\n}),\n    oa = At({\n  maximum_: function maximum_(e, t) {\n    var n = Et(e, \"a\", \"maximum\"),\n        s = Et(t, \"b\", \"maximum\");\n    return [n, s] = ft(n, s), \"bool\" === n.dtype && (n = pn(n, \"int32\"), s = pn(s, \"int32\")), cr(n.shape, s.shape), wt.runKernel(\"Maximum\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    la = At({\n  mean_: function mean_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"mean\");\n    return wt.runKernel(\"Mean\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n});\n\nfunction ua(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n\n  if (\"complex64\" === t) {\n    var _t57 = ua(e, \"float32\"),\n        _n28 = ua(e, \"float32\");\n\n    return Ft(_t57, _n28);\n  }\n\n  var n = O(d(e), t);\n  return wt.makeTensor(n, e, t);\n}\n\nfunction ca(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n\n  if (\"complex64\" === t) {\n    var _t58 = ca(e, \"float32\"),\n        _n29 = ua(e, \"float32\");\n\n    return Ft(_t58, _n29);\n  }\n\n  var n = _(d(e), t);\n\n  return wt.makeTensor(n, e, t);\n}\n\nvar ha = At({\n  min_: function min_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"min\");\n    return wt.runKernel(\"Min\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    da = At({\n  minimum_: function minimum_(e, t) {\n    var n = Et(e, \"a\", \"minimum\"),\n        s = Et(t, \"b\", \"minimum\");\n    return [n, s] = ft(n, s), \"bool\" === n.dtype && (n = pn(n, \"int32\"), s = pn(s, \"int32\")), cr(n.shape, s.shape), wt.runKernel(\"Minimum\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    pa = At({\n  mirrorPad_: function mirrorPad_(e, t, n) {\n    l(\"reflect\" === n || \"symmetric\" === n, () => \"Invalid mode. Mode must be either reflect or symmetric. Got \".concat(n, \".\"));\n    var s = Et(e, \"x\", \"mirrorPad\");\n    if (0 === s.rank) throw new Error(\"mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad\");\n    l(t.length === s.rank, () => \"Padding doesn't match input. Must be \".concat(s.rank, \". Got \").concat(t.length, \".\"));\n    var r = \"reflect\" === n ? 1 : 0;\n\n    var _loop5 = function _loop5(_e56) {\n      l(2 === t[_e56].length, () => \"Invalid number of paddings. Must be length of 2 each.\"), l(t[_e56][0] >= 0 && t[_e56][0] <= s.shape[_e56] - r && t[_e56][1] >= 0 && t[_e56][1] <= s.shape[_e56] - r, () => \"Padding in dimension \".concat(_e56, \" cannot be greater than or equal to \").concat(s.shape[_e56] - r, \" or less than 0 for input of shape \").concat(s.shape));\n    };\n\n    for (var _e56 = 0; _e56 < s.rank; _e56++) {\n      _loop5(_e56);\n    }\n\n    return wt.runKernel(\"MirrorPad\", {\n      x: s\n    }, {\n      paddings: t,\n      mode: n\n    });\n  }\n}),\n    fa = At({\n  mod_: function mod_(e, t) {\n    var n = Et(e, \"a\", \"mod\"),\n        s = Et(t, \"b\", \"mod\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Mod\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ga = At({\n  square_: function square_(e) {\n    var t = Et(e, \"x\", \"square\");\n    return wt.runKernel(\"Square\", {\n      x: t\n    }, {});\n  }\n}),\n    ma = At({\n  moments_: function moments_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = y(t, (e = Et(e, \"x\", \"moments\")).shape),\n        r = la(e, s, n);\n    var a = r.shape;\n    n || (a = Xr(r.shape, s));\n    var i = ga(Vr(pn(e, \"float32\"), Es(r, a)));\n    return {\n      mean: r,\n      variance: la(i, s, n)\n    };\n  }\n}),\n    ba = At({\n  notEqual_: function notEqual_(e, t) {\n    var n = Et(e, \"a\", \"notEqual\", \"string_or_numeric\"),\n        s = Et(t, \"b\", \"notEqual\", \"string_or_numeric\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"NotEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    xa = At({\n  onesLike_: function onesLike_(e) {\n    var t = Et(e, \"x\", \"onesLike\");\n    return wt.runKernel(\"OnesLike\", {\n      x: t\n    });\n  }\n}),\n    ya = At({\n  pad_: function pad_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = Et(e, \"x\", \"pad\");\n    if (0 === s.rank) throw new Error(\"pad(scalar) is not defined. Pass non-scalar to pad\");\n    return wt.runKernel(\"PadV2\", {\n      x: s\n    }, {\n      paddings: t,\n      constantValue: n\n    });\n  }\n}),\n    ka = At({\n  spaceToBatchND_: function spaceToBatchND_(e, t, n) {\n    var s = Et(e, \"x\", \"spaceToBatchND\");\n    return l(s.rank >= 1 + t.length, () => \"input rank \".concat(s.rank, \" should be > than [blockShape] \").concat(t.length)), l(n.length === t.length, () => \"paddings.shape[0] \".concat(n.length, \" must be equal to [blockShape] \").concat(t.length)), l(s.shape.reduce((e, s, r) => r > 0 && r <= t.length ? e && (s + n[r - 1][0] + n[r - 1][1]) % t[r - 1] == 0 : e, !0), () => \"input spatial dimensions \".concat(s.shape.slice(1), \" with paddings \").concat(n.toString(), \" must be divisible by blockShapes \").concat(t.toString())), wt.runKernel(\"SpaceToBatchND\", {\n      x: s\n    }, {\n      blockShape: t,\n      paddings: n\n    });\n  }\n}),\n    wa = At({\n  pool_: function pool_(e, t, n, s, r, a) {\n    null == r && (r = [1, 1]), null == a && (a = 1), 0 === s && (s = \"valid\");\n    var i = Et(e, \"x\", \"maxPool\");\n    var o = i,\n        u = !1;\n    3 === i.rank && (u = !0, o = Es(i, [1, i.shape[0], i.shape[1], i.shape[2]])), l(Ss(a, r), () => \"Error in pool: Either strides or dilations must be 1. Got strides \".concat(a, \" and dilations '\").concat(r, \"'\"));\n    var c = bs(o.shape, t, a, r, s),\n        h = [c.dilationHeight, c.dilationWidth];\n    var d;\n    d = \"same\" === s ? function (e, t) {\n      var n = e.map((e, n) => e + (e - 1) * (t[n] - 1)).map(e => e - 1),\n          s = n.map(e => Math.floor(e / 2)),\n          r = n.map((e, t) => e - s[t]);\n      return n.map((e, t) => [s[t], r[t]]);\n    }([c.filterHeight, c.filterWidth], h) : [[0, 0], [0, 0]];\n\n    var p = 1 === h[0] && 1 === h[1],\n        [f, g] = function (e, t, n) {\n      var s = n.map(e => e[0]),\n          r = n.map(e => e[1]),\n          a = e.concat(s, r),\n          i = t.map((e, t) => (e - a[t] % e) % e),\n          o = r.map((e, t) => e + i[t]);\n      return [t.map((e, t) => [s[t], o[t]]), t.map((e, t) => [0, i[t]])];\n    }([c.inHeight, c.inWidth], h, d),\n        m = p ? s : \"valid\",\n        b = p ? o : ka(o, h, f),\n        x = (\"avg\" === n ? () => Rs(b, t, a, m) : () => aa(b, t, a, m))(),\n        y = p ? x : Ms(x, h, g);\n\n    return u ? Es(y, [y.shape[1], y.shape[2], y.shape[3]]) : y;\n  }\n}),\n    va = At({\n  pow_: function pow_(e, t) {\n    var n = Et(e, \"base\", \"pow\"),\n        s = Et(t, \"exp\", \"pow\");\n    return [n, s] = ft(n, s), wt.runKernel(\"Pow\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Ia = At({\n  prelu_: function prelu_(e, t) {\n    var n = Et(e, \"x\", \"prelu\"),\n        s = Et(t, \"alpha\", \"prelu\");\n    return wt.runKernel(\"Prelu\", {\n      x: n,\n      alpha: s\n    });\n  }\n}),\n    $a = At({\n  prod_: function prod_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Et(e, \"x\", \"prod\");\n    return \"bool\" === s.dtype && (s = pn(s, \"int32\")), wt.runKernel(\"Prod\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n});\n\nfunction Na(e) {\n  var t = {\n    exports: {}\n  };\n  return e(t, t.exports), t.exports;\n}\n\n\"undefined\" != typeof globalThis ? globalThis : \"undefined\" != typeof window ? window : \"undefined\" != typeof global ? global : \"undefined\" != typeof self && self;\nvar Ca = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t,\n          n = this,\n          s = (t = 4022871197, function (e) {\n        e = e.toString();\n\n        for (var n = 0; n < e.length; n++) {\n          var s = .02519603282416938 * (t += e.charCodeAt(n));\n          s -= t = s >>> 0, t = (s *= t) >>> 0, t += 4294967296 * (s -= t);\n        }\n\n        return 2.3283064365386963e-10 * (t >>> 0);\n      });\n      n.next = function () {\n        var e = 2091639 * n.s0 + 2.3283064365386963e-10 * n.c;\n        return n.s0 = n.s1, n.s1 = n.s2, n.s2 = e - (n.c = 0 | e);\n      }, n.c = 1, n.s0 = s(\" \"), n.s1 = s(\" \"), n.s2 = s(\" \"), n.s0 -= s(e), n.s0 < 0 && (n.s0 += 1), n.s1 -= s(e), n.s1 < 0 && (n.s1 += 1), n.s2 -= s(e), n.s2 < 0 && (n.s2 += 1), s = null;\n    }\n\n    function r(e, t) {\n      return t.c = e.c, t.s0 = e.s0, t.s1 = e.s1, t.s2 = e.s2, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = n.next;\n      return i.int32 = function () {\n        return 4294967296 * n.next() | 0;\n      }, i.double = function () {\n        return i() + 11102230246251565e-32 * (2097152 * i() | 0);\n      }, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.alea = a;\n  }(0, e);\n}),\n    Sa = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.next = function () {\n        var e = t.x ^ t.x << 11;\n        return t.x = t.y, t.y = t.z, t.z = t.w, t.w ^= t.w >>> 19 ^ e ^ e >>> 8;\n      }, e === (0 | e) ? t.x = e : n += e;\n\n      for (var s = 0; s < n.length + 64; s++) {\n        t.x ^= 0 | n.charCodeAt(s), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xor128 = a;\n  }(0, e);\n}),\n    Ta = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.next = function () {\n        var e = t.x ^ t.x >>> 2;\n        return t.x = t.y, t.y = t.z, t.z = t.w, t.w = t.v, (t.d = t.d + 362437 | 0) + (t.v = t.v ^ t.v << 4 ^ e ^ e << 1) | 0;\n      }, t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.v = 0, e === (0 | e) ? t.x = e : n += e;\n\n      for (var s = 0; s < n.length + 64; s++) {\n        t.x ^= 0 | n.charCodeAt(s), s == n.length && (t.d = t.x << 10 ^ t.x >>> 4), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t.v = e.v, t.d = e.d, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xorwow = a;\n  }(0, e);\n}),\n    Ea = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this;\n      t.next = function () {\n        var e,\n            n,\n            s = t.x,\n            r = t.i;\n        return e = s[r], n = (e ^= e >>> 7) ^ e << 24, n ^= (e = s[r + 1 & 7]) ^ e >>> 10, n ^= (e = s[r + 3 & 7]) ^ e >>> 3, n ^= (e = s[r + 4 & 7]) ^ e << 7, e = s[r + 7 & 7], s[r] = n ^= (e ^= e << 13) ^ e << 9, t.i = r + 1 & 7, n;\n      }, function (e, t) {\n        var n,\n            s = [];\n        if (t === (0 | t)) s[0] = t;else for (t = \"\" + t, n = 0; n < t.length; ++n) {\n          s[7 & n] = s[7 & n] << 15 ^ t.charCodeAt(n) + s[n + 1 & 7] << 13;\n        }\n\n        for (; s.length < 8;) {\n          s.push(0);\n        }\n\n        for (n = 0; n < 8 && 0 === s[n]; ++n) {\n          ;\n        }\n\n        for (8 == n && (s[7] = -1), e.x = s, e.i = 0, n = 256; n > 0; --n) {\n          e.next();\n        }\n      }(t, e);\n    }\n\n    function r(e, t) {\n      return t.x = e.x.slice(), t.i = e.i, t;\n    }\n\n    function a(e, t) {\n      null == e && (e = +new Date());\n\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (a.x && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xorshift7 = a;\n  }(0, e);\n}),\n    Ra = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this;\n      t.next = function () {\n        var e,\n            n,\n            s = t.w,\n            r = t.X,\n            a = t.i;\n        return t.w = s = s + 1640531527 | 0, n = r[a + 34 & 127], e = r[a = a + 1 & 127], n ^= n << 13, e ^= e << 17, n = r[a] = (n ^= n >>> 15) ^ (e ^= e >>> 12), t.i = a, n + (s ^ s >>> 16) | 0;\n      }, function (e, t) {\n        var n,\n            s,\n            r,\n            a,\n            i,\n            o = [],\n            l = 128;\n\n        for (t === (0 | t) ? (s = t, t = null) : (t += \"\\0\", s = 0, l = Math.max(l, t.length)), r = 0, a = -32; a < l; ++a) {\n          t && (s ^= t.charCodeAt((a + 32) % t.length)), 0 === a && (i = s), s ^= s << 10, s ^= s >>> 15, s ^= s << 4, s ^= s >>> 13, a >= 0 && (r = 0 == (n = o[127 & a] ^= s + (i = i + 1640531527 | 0)) ? r + 1 : 0);\n        }\n\n        for (r >= 128 && (o[127 & (t && t.length || 0)] = -1), r = 127, a = 512; a > 0; --a) {\n          s = o[r + 34 & 127], n = o[r = r + 1 & 127], s ^= s << 13, n ^= n << 17, o[r] = (s ^= s >>> 15) ^ (n ^= n >>> 12);\n        }\n\n        e.w = i, e.X = o, e.i = r;\n      }(t, e);\n    }\n\n    function r(e, t) {\n      return t.i = e.i, t.w = e.w, t.X = e.X.slice(), t;\n    }\n\n    function a(e, t) {\n      null == e && (e = +new Date());\n\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (a.X && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xor4096 = a;\n  }(0, e);\n}),\n    Aa = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.next = function () {\n        var e = t.b,\n            n = t.c,\n            s = t.d,\n            r = t.a;\n        return e = e << 25 ^ e >>> 7 ^ n, n = n - s | 0, s = s << 24 ^ s >>> 8 ^ r, r = r - e | 0, t.b = e = e << 20 ^ e >>> 12 ^ n, t.c = n = n - s | 0, t.d = s << 16 ^ n >>> 16 ^ r, t.a = r - e | 0;\n      }, t.a = 0, t.b = 0, t.c = -1640531527, t.d = 1367130551, e === Math.floor(e) ? (t.a = e / 4294967296 | 0, t.b = 0 | e) : n += e;\n\n      for (var s = 0; s < n.length + 20; s++) {\n        t.b ^= 0 | n.charCodeAt(s), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.a = e.a, t.b = e.b, t.c = e.c, t.d = e.d, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.tychei = a;\n  }(0, e);\n}),\n    Fa = {\n  __proto__: null,\n  default: {}\n},\n    Da = Na(function (e) {\n  !function (t, n) {\n    var s,\n        r = this,\n        a = 256,\n        i = n.pow(a, 6),\n        o = n.pow(2, 52),\n        l = 2 * o,\n        u = 255;\n\n    function c(e, u, c) {\n      var m = [],\n          b = f(p((u = 1 == u ? {\n        entropy: !0\n      } : u || {}).entropy ? [e, g(t)] : null == e ? function () {\n        try {\n          var e;\n          return s && (e = s.randomBytes) ? e = e(a) : (e = new Uint8Array(a), (r.crypto || r.msCrypto).getRandomValues(e)), g(e);\n        } catch (e) {\n          var n = r.navigator,\n              i = n && n.plugins;\n          return [+new Date(), r, i, r.screen, g(t)];\n        }\n      }() : e, 3), m),\n          x = new h(m),\n          y = function y() {\n        for (var e = x.g(6), t = i, n = 0; e < o;) {\n          e = (e + n) * a, t *= a, n = x.g(1);\n        }\n\n        for (; e >= l;) {\n          e /= 2, t /= 2, n >>>= 1;\n        }\n\n        return (e + n) / t;\n      };\n\n      return y.int32 = function () {\n        return 0 | x.g(4);\n      }, y.quick = function () {\n        return x.g(4) / 4294967296;\n      }, y.double = y, f(g(x.S), t), (u.pass || c || function (e, t, s, r) {\n        return r && (r.S && d(r, x), e.state = function () {\n          return d(x, {});\n        }), s ? (n.random = e, t) : e;\n      })(y, b, \"global\" in u ? u.global : this == n, u.state);\n    }\n\n    function h(e) {\n      var t,\n          n = e.length,\n          s = this,\n          r = 0,\n          i = s.i = s.j = 0,\n          o = s.S = [];\n\n      for (n || (e = [n++]); r < a;) {\n        o[r] = r++;\n      }\n\n      for (r = 0; r < a; r++) {\n        o[r] = o[i = u & i + e[r % n] + (t = o[r])], o[i] = t;\n      }\n\n      (s.g = function (e) {\n        for (var t, n = 0, r = s.i, i = s.j, o = s.S; e--;) {\n          t = o[r = u & r + 1], n = n * a + o[u & (o[r] = o[i = u & i + t]) + (o[i] = t)];\n        }\n\n        return s.i = r, s.j = i, n;\n      })(a);\n    }\n\n    function d(e, t) {\n      return t.i = e.i, t.j = e.j, t.S = e.S.slice(), t;\n    }\n\n    function p(e, t) {\n      var n,\n          s = [],\n          r = typeof e;\n      if (t && \"object\" == r) for (n in e) {\n        try {\n          s.push(p(e[n], t - 1));\n        } catch (e) {}\n      }\n      return s.length ? s : \"string\" == r ? e : e + \"\\0\";\n    }\n\n    function f(e, t) {\n      for (var n, s = e + \"\", r = 0; r < s.length;) {\n        t[u & r] = u & (n ^= 19 * t[u & r]) + s.charCodeAt(r++);\n      }\n\n      return g(t);\n    }\n\n    function g(e) {\n      return String.fromCharCode.apply(0, e);\n    }\n\n    if (n.seedrandom = c, f(n.random(), t), e.exports) {\n      e.exports = c;\n\n      try {\n        s = Fa;\n      } catch (e) {}\n    }\n  }([], Math);\n});\nDa.alea = Ca, Da.xor128 = Sa, Da.xorwow = Ta, Da.xorshift7 = Ea, Da.xor4096 = Ra, Da.tychei = Aa;\nvar _a = Da;\n\nclass Oa {\n  constructor(e, t, n, s, r) {\n    this.mean = e, this.stdDev = t, this.dtype = n, this.nextVal = NaN, this.truncated = s, this.truncated && (this.upper = this.mean + 2 * this.stdDev, this.lower = this.mean - 2 * this.stdDev);\n    var a = r || Math.random();\n    this.random = _a.alea(a.toString());\n  }\n\n  nextValue() {\n    if (!isNaN(this.nextVal)) {\n      var _e57 = this.nextVal;\n      return this.nextVal = NaN, _e57;\n    }\n\n    var e,\n        t,\n        n = !1;\n\n    for (; !n;) {\n      var _s35 = void 0,\n          _r28 = void 0,\n          _a15 = void 0;\n\n      do {\n        _s35 = 2 * this.random() - 1, _r28 = 2 * this.random() - 1, _a15 = _s35 * _s35 + _r28 * _r28;\n      } while (_a15 >= 1 || 0 === _a15);\n\n      var _i11 = Math.sqrt(-2 * Math.log(_a15) / _a15);\n\n      e = this.mean + this.stdDev * _s35 * _i11, t = this.mean + this.stdDev * _r28 * _i11, this.truncated && !this.isValidTruncated(e) || (n = !0);\n    }\n\n    return this.truncated && !this.isValidTruncated(t) || (this.nextVal = this.convertValue(t)), this.convertValue(e);\n  }\n\n  convertValue(e) {\n    return null == this.dtype || \"float32\" === this.dtype ? e : Math.round(e);\n  }\n\n  isValidTruncated(e) {\n    return e <= this.upper && e >= this.lower;\n  }\n\n}\n\nclass Ma {\n  constructor() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    if (this.canReturnFloat = () => null == this.dtype || \"float32\" === this.dtype, this.min = e, this.range = t - e, this.dtype = n, null == s && (s = Math.random()), \"number\" == typeof s && (s = s.toString()), !this.canReturnFloat() && this.range <= 1) throw new Error(\"The difference between \".concat(e, \" - \").concat(t, \" <= 1 and dtype is not float\"));\n    this.random = _a.alea(s);\n  }\n\n  convertValue(e) {\n    return this.canReturnFloat() ? e : Math.round(e);\n  }\n\n  nextValue() {\n    return this.convertValue(this.min + this.range * this.random());\n  }\n\n}\n\nvar La = At({\n  randomNormal_: function randomNormal_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    if (null != s && \"bool\" === s) throw new Error(\"Unsupported data type \".concat(s));\n    var a = new Oa(t, n, s, !1, r),\n        i = dn(e, s);\n\n    for (var _e58 = 0; _e58 < i.values.length; _e58++) {\n      i.values[_e58] = a.nextValue();\n    }\n\n    return i.toTensor();\n  }\n}),\n    za = At({\n  randomUniform_: function randomUniform_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    var a = dn(e, s),\n        i = new Ma(t, n, null, r);\n\n    for (var _e59 = 0; _e59 < a.values.length; _e59++) {\n      a.values[_e59] = i.nextValue();\n    }\n\n    return a.toTensor();\n  }\n});\n\nfunction Ba(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n  if (0 === n) throw new Error(\"Cannot have a step of zero\");\n  return wt.runKernel(\"Range\", {}, {\n    start: e,\n    stop: t,\n    step: n,\n    dtype: s\n  });\n}\n\nvar Pa = At({\n  real_: function real_(e) {\n    var t = Et(e, \"input\", \"real\");\n    return wt.runKernel(\"Real\", {\n      input: t\n    });\n  }\n}),\n    Wa = At({\n  reciprocal_: function reciprocal_(e) {\n    var t = Et(e, \"x\", \"reciprocal\");\n    return wt.runKernel(\"Reciprocal\", {\n      x: t\n    });\n  }\n}),\n    Ua = At({\n  relu_: function relu_(e) {\n    var t = Et(e, \"x\", \"relu\");\n    return wt.runKernel(\"Relu\", {\n      x: t\n    });\n  }\n}),\n    Va = At({\n  relu6_: function relu6_(e) {\n    var t = Et(e, \"x\", \"relu6\");\n    return wt.runKernel(\"Relu6\", {\n      x: t\n    });\n  }\n}),\n    Ga = At({\n  reverse_: function reverse_(e, t) {\n    var n = Et(e, \"x\", \"reverse\");\n    return wt.runKernel(\"Reverse\", {\n      x: n\n    }, {\n      dims: t\n    });\n  }\n}),\n    Ha = At({\n  round_: function round_(e) {\n    var t = Et(e, \"x\", \"round\");\n    return wt.runKernel(\"Round\", {\n      x: t\n    });\n  }\n}),\n    ja = At({\n  rsqrt_: function rsqrt_(e) {\n    var t = Et(e, \"x\", \"rsqrt\");\n    return wt.runKernel(\"Rsqrt\", {\n      x: t\n    });\n  }\n});\n\nfunction qa(e, t) {\n  if (($(e) && \"string\" !== t || Array.isArray(e)) && \"complex64\" !== t) throw new Error(\"Error creating a new Scalar: value must be a primitive (number|boolean|string)\");\n  if (\"string\" === t && $(e) && !(e instanceof Uint8Array)) throw new Error(\"When making a scalar from encoded string, the value must be `Uint8Array`.\");\n  return Dt(e, [], [], t);\n}\n\nvar Ka = At({\n  selu_: function selu_(e) {\n    var t = Et(e, \"x\", \"selu\");\n    return wt.runKernel(\"Selu\", {\n      x: t\n    });\n  }\n}),\n    Xa = At({\n  separableConv2d_: function separableConv2d_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"NHWC\";\n    var o = Et(e, \"x\", \"separableConv2d\"),\n        u = Et(t, \"depthwiseFilter\", \"separableConv2d\"),\n        c = Et(n, \"pointwiseFilter\", \"separableConv2d\");\n    var h = o,\n        d = !1;\n    if (3 === o.rank && (d = !0, h = Es(o, [1, o.shape[0], o.shape[1], o.shape[2]])), \"NCHW\" === i) throw new Error(\"separableConv2d currently does not support dataFormat NCHW; only NHWC is supported\");\n    l(4 === h.rank, () => \"Error in separableConv2d: input must be rank 4, but got rank \".concat(h.rank, \".\")), l(4 === u.rank, () => \"Error in separableConv2d: depthwise filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(4 === c.rank, () => \"Error in separableConv2d: pointwise filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(1 === c.shape[0], () => \"Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got \".concat(c.shape[0], \".\")), l(1 === c.shape[1], () => \"Error in separableConv2d: the second dimension of pointwise filter must be 1, but got \".concat(c.shape[1], \".\"));\n    var p = u.shape[2],\n        f = u.shape[3];\n    l(c.shape[2] === p * f, () => \"Error in separableConv2d: the third dimension of pointwise filter must be \".concat(p * f, \", but got \").concat(c.shape[2], \".\"));\n    var g = ir(h, u, s, r, i, a),\n        m = Xs(g, c, 1, \"valid\", i);\n    return d ? Es(m, [m.shape[1], m.shape[2], m.shape[3]]) : m;\n  }\n}),\n    Ya = At({\n  sign_: function sign_(e) {\n    var t = Et(e, \"x\", \"sign\");\n    return wt.runKernel(\"Sign\", {\n      x: t\n    });\n  }\n}),\n    Ja = At({\n  sin_: function sin_(e) {\n    var t = Et(e, \"x\", \"sin\");\n    return wt.runKernel(\"Sin\", {\n      x: t\n    });\n  }\n}),\n    Za = At({\n  sinh_: function sinh_(e) {\n    var t = Et(e, \"x\", \"sinh\");\n    return wt.runKernel(\"Sinh\", {\n      x: t\n    });\n  }\n}),\n    Qa = At({\n  slice1d_: function slice1d_(e, t, n) {\n    var s = Et(e, \"x\", \"slice1d\");\n    return l(1 === s.rank, () => \"slice1d expects a rank-1 tensor, but got a rank-\".concat(s.rank, \" tensor\")), _s(s, [t], [n]);\n  }\n}),\n    ei = At({\n  slice2d_: function slice2d_(e, t, n) {\n    var s = Et(e, \"x\", \"slice2d\");\n    return l(2 === s.rank, () => \"slice2d expects a rank-2 tensor, but got a rank-\".concat(s.rank, \" tensor\")), _s(s, t, n);\n  }\n}),\n    ti = At({\n  slice3d_: function slice3d_(e, t, n) {\n    var s = Et(e, \"x\", \"slice3d\");\n    return l(3 === s.rank, () => \"slice3d expects a rank-3 tensor, but got a rank-\".concat(s.rank, \" tensor\")), _s(s, t, n);\n  }\n}),\n    ni = At({\n  slice4d_: function slice4d_(e, t, n) {\n    var s = Et(e, \"x\", \"slice4d\");\n    return l(4 === s.rank, () => \"slice4d expects a rank-4 tensor, but got a rank-\".concat(s.rank, \" tensor\")), _s(s, t, n);\n  }\n}),\n    si = At({\n  softmax_: function softmax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    var n = Et(e, \"logits\", \"softmax\", \"float32\");\n    if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error(\"Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(n.rank, \" and dim was \").concat(t));\n    return wt.runKernel(\"Softmax\", {\n      logits: n\n    }, {\n      dim: t\n    });\n  }\n}),\n    ri = At({\n  fft_: function fft_(e) {\n    return l(\"complex64\" === e.dtype, () => \"The dtype for tf.spectral.fft() must be complex64 but got \".concat(e.dtype, \".\")), wt.runKernel(\"FFT\", {\n      input: e\n    });\n  }\n}),\n    ai = At({\n  ifft_: function ifft_(e) {\n    return l(\"complex64\" === e.dtype, () => \"The dtype for tf.spectral.ifft() must be complex64 but got \".concat(e.dtype, \".\")), wt.runKernel(\"IFFT\", {\n      input: e\n    });\n  }\n}),\n    ii = At({\n  irfft_: function irfft_(e) {\n    var t = e.shape[e.shape.length - 1],\n        n = e.size / t;\n    var s;\n\n    if (t <= 2) {\n      var _r29 = Es(e, [n, t]);\n\n      s = ai(_r29);\n    } else {\n      var _r30 = [n, 2 * (t - 1)],\n          _a16 = Es(Pa(e), [n, t]),\n          _i12 = Es(Tr(e), [n, t]),\n          _o10 = Ga(_s(_a16, [0, 1], [n, t - 2]), 1),\n          _l5 = ss(Ga(_s(_i12, [0, 1], [n, t - 2]), 1), qa(-1)),\n          _u4 = Fs([_a16, _o10], 1),\n          _c3 = Fs([_i12, _l5], 1),\n          _h2 = Es(Ft(_u4, _c3), [_r30[0], _r30[1]]);\n\n      s = ai(_h2);\n    }\n\n    if (s = Pa(s), 3 === e.rank && 0 !== e.shape[0]) {\n      var _t59 = s,\n          _n30 = e.shape[0];\n      s = Es(s, [_n30, s.shape[0] / _n30, s.shape[1]]), _t59.dispose();\n    }\n\n    return s;\n  }\n}),\n    oi = At({\n  split_: function split_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = Et(e, \"x\", \"split\");\n    return wt.runKernel(\"SplitV\", {\n      x: s\n    }, {\n      numOrSizeSplits: t,\n      axis: n\n    });\n  }\n}),\n    li = At({\n  rfft_: function rfft_(e, t) {\n    l(\"float32\" === e.dtype, () => \"The dtype for rfft() must be real value but got \".concat(e.dtype));\n    var n = e.shape[e.shape.length - 1];\n    var s = e.size / n;\n    var r;\n\n    if (null != t && t < n) {\n      var _s36 = e.shape.map(e => 0),\n          _a17 = e.shape.map(e => e);\n\n      _a17[e.shape.length - 1] = t, r = _s(e, _s36, _a17), n = t;\n    } else if (null != t && t > n) {\n      var _s37 = e.shape.map(e => e);\n\n      _s37[e.shape.length - 1] = t - n, r = Fs([e, ua(_s37)], e.shape.length - 1), n = t;\n    } else r = e;\n\n    var a = pr(r),\n        i = Es(Ft(r, a), [s, n]),\n        o = ri(i),\n        u = Math.floor(n / 2) + 1,\n        c = Pa(o),\n        h = Tr(o),\n        d = oi(c, [u, n - u], c.shape.length - 1),\n        p = oi(h, [u, n - u], h.shape.length - 1),\n        f = r.shape.slice();\n    return f[r.shape.length - 1] = u, Es(Ft(d[0], p[0]), f);\n  }\n}),\n    ui = At({\n  sqrt_: function sqrt_(e) {\n    var t = Et(e, \"x\", \"sqrt\");\n    return wt.runKernel(\"Sqrt\", {\n      x: t\n    });\n  }\n}),\n    ci = At({\n  squaredDifference_: function squaredDifference_(e, t) {\n    var n = Et(e, \"a\", \"squaredDifference\"),\n        s = Et(t, \"b\", \"squaredDifference\");\n    return [n, s] = ft(n, s), cr(n.shape, s.shape), wt.runKernel(\"SquaredDifference\", {\n      a: n,\n      b: s\n    }, {});\n  }\n}),\n    hi = At({\n  squeeze_: function squeeze_(e, t) {\n    var n = Et(e, \"x\", \"squeeze\");\n    return Es(n, k(n.shape, t).newShape);\n  }\n}),\n    di = At({\n  stack_: function stack_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"tensors\", \"stack\", \"string_or_numeric\");\n    return l(n.length >= 1, () => \"Pass at least one tensor to tf.stack\"), n.length > 0 && l(t <= n[0].rank, () => \"Axis must be <= rank of the tensor\"), wt.runKernel(\"Pack\", n, {\n      axis: t\n    });\n  }\n}),\n    pi = At({\n  step_: function step_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"step\");\n    return wt.runKernel(\"Step\", {\n      x: n\n    }, {\n      alpha: t\n    });\n  }\n}),\n    fi = At({\n  stridedSlice_: function stridedSlice_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;\n    var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 0;\n    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : 0;\n    var u = Et(e, \"x\", \"stridedSlice\", \"string_or_numeric\");\n    return wt.runKernel(\"StridedSlice\", {\n      x: u\n    }, {\n      begin: t,\n      end: n,\n      strides: s,\n      beginMask: r,\n      endMask: a,\n      ellipsisMask: i,\n      newAxisMask: o,\n      shrinkAxisMask: l\n    });\n  }\n}),\n    gi = At({\n  tan_: function tan_(e) {\n    var t = Et(e, \"x\", \"tan\");\n    return wt.runKernel(\"Tan\", {\n      x: t\n    });\n  }\n});\n\nfunction mi(e, t) {\n  c(e);\n  var n = Ct(e, t);\n  if (1 !== n.length) throw new Error(\"tensor1d() requires values to be a flat/TypedArray\");\n  return Dt(e, null, n, t);\n}\n\nfunction bi(e, t, n) {\n  if (c(e), null != t && 2 !== t.length) throw new Error(\"tensor2d() requires shape to have two numbers\");\n  var s = Ct(e, n);\n  if (2 !== s.length && 1 !== s.length) throw new Error(\"tensor2d() requires values to be number[][] or flat/TypedArray\");\n  if (1 === s.length && null == t) throw new Error(\"tensor2d() requires shape to be provided when `values` are a flat/TypedArray\");\n  return Dt(e, t, s, n);\n}\n\nvar xi = At({\n  topk_: function topk_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = Et(e, \"x\", \"topk\");\n    if (0 === s.rank) throw new Error(\"topk() expects the input to be of rank 1 or higher\");\n    var r = s.shape[s.shape.length - 1];\n    if (t < 0) throw new Error(\"'k' passed to topk() must be >= 0 but got \".concat(t));\n    if (t > r) throw new Error(\"'k' passed to topk() must be <= the last dimension (\".concat(r, \") but got \").concat(t));\n    var a = {\n      x: s\n    },\n        i = {\n      k: t,\n      sorted: n\n    },\n        [o, l] = wt.runKernel(\"TopK\", a, i);\n    return {\n      values: o,\n      indices: l\n    };\n  }\n}),\n    yi = At({\n  truncatedNormal_: function truncatedNormal_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    if (null != s && \"bool\" === s) throw new Error(\"Unsupported data type $ { dtype }\");\n    var a = new Oa(t, n, s, !0, r),\n        i = dn(e, s);\n\n    for (var _e60 = 0; _e60 < i.values.length; _e60++) {\n      i.values[_e60] = a.nextValue();\n    }\n\n    return i.toTensor();\n  }\n}),\n    ki = At({\n  unique_: function unique_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"unique\", \"string_or_numeric\");\n    l(n.rank > 0, () => \"The input tensor must be at least 1D\");\n    var s = {\n      x: n\n    },\n        r = {\n      axis: t\n    },\n        [a, i] = wt.runKernel(\"Unique\", s, r);\n    return {\n      values: a,\n      indices: i\n    };\n  }\n}),\n    wi = At({\n  unsortedSegmentSum_: function unsortedSegmentSum_(e, t, n) {\n    var s = Et(e, \"x\", \"unsortedSegmentSum\"),\n        r = Et(t, \"segmentIds\", \"unsortedSegmentSum\", \"int32\");\n    return l(f(n), () => \"numSegments must be of dtype int\"), wt.runKernel(\"UnsortedSegmentSum\", {\n      x: s,\n      segmentIds: r\n    }, {\n      numSegments: n\n    });\n  }\n}),\n    vi = At({\n  unstack_: function unstack_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Et(e, \"x\", \"unstack\", \"string_or_numeric\");\n    return l(t >= -n.shape.length && t < n.shape.length, () => \"Axis = \".concat(t, \" is not in [-\").concat(n.shape.length, \", \").concat(n.shape.length, \")\")), wt.runKernel(\"Unpack\", {\n      value: n\n    }, {\n      axis: t\n    });\n  }\n});\n\nfunction Ii(e, t) {\n  var n = [];\n\n  for (var _e61 = 0; _e61 < t.length; _e61++) {\n    t[_e61] && n.push(_e61);\n  }\n\n  var s = dn(e, \"int32\"),\n      r = dn([n.length, e.length], \"int32\");\n\n  for (var _t60 = 0; _t60 < n.length; _t60++) {\n    var _a18 = s.indexToLoc(n[_t60]);\n\n    r.values.set(_a18, _t60 * e.length);\n  }\n\n  return r.toTensor();\n}\n\nfunction $i(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  if (0 === e.rank) return rs(e);\n  if (1 !== e.rank && null === n) return $i(Es(e, [-1]), t, n);\n\n  if (1 === e.rank || \"number\" == typeof n || Array.isArray(n) && 1 === n.length) {\n    if (1 === t) return Gr(rs(e), n);\n    if (Infinity === t) return Ur(rs(e), n);\n    if (-Infinity === t) return ha(rs(e), n);\n    if (\"euclidean\" === t || 2 === t) return ui(Gr(va(rs(e), qa(2, \"int32\")), n));\n    throw new Error(\"Error in norm: invalid ord value: \".concat(t));\n  }\n\n  if (Array.isArray(n) && 2 === n.length) {\n    if (1 === t) return Ur(Gr(rs(e), n[0]), n[1] - 1);\n    if (Infinity === t) return Ur(Gr(rs(e), n[1]), n[0]);\n    if (-Infinity === t) return ha(Gr(rs(e), n[1]), n[0]);\n    if (\"fro\" === t || \"euclidean\" === t) return ui(Gr(ga(e), n));\n    throw new Error(\"Error in norm: invalid ord value: \".concat(t));\n  }\n\n  throw new Error(\"Error in norm: invalid axis: \".concat(n));\n}\n\nvar Ni = At({\n  norm_: function norm_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"euclidean\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = $i(e = Et(e, \"x\", \"norm\"), t, n);\n    var a = r.shape;\n\n    if (s) {\n      var _t61 = y(n, e.shape);\n\n      a = Xr(r.shape, _t61);\n    }\n\n    return Es(r, a);\n  }\n}),\n    Ci = At({\n  dropout_: function dropout_(e, t, n, s) {\n    var r = Et(e, \"x\", \"dropout\");\n    if (l(\"float32\" === r.dtype, () => \"x has to be a floating point tensor since it's going to be scaled, but got a \".concat(r.dtype, \" tensor instead.\")), l(t >= 0 && t < 1, () => \"rate must be a float in the range [0, 1), but got \".concat(t, \".\")), 0 === t) return e instanceof st ? r.clone() : r;\n\n    var a = function (e, t) {\n      if (null == t) return e.shape.slice();\n      if (p(e.shape, t)) return t;\n\n      if (e.shape.length === t.length) {\n        var _n31 = [];\n\n        for (var _s38 = 0; _s38 < e.shape.length; _s38++) {\n          _n31.push(null == t[_s38] && null != e.shape[_s38] ? e.shape[_s38] : t[_s38]);\n        }\n\n        return _n31;\n      }\n\n      return t;\n    }(r, n),\n        i = 1 - t,\n        o = ns($r(es(za(a, 0, 1, \"float32\", s), i)), i);\n\n    return ss(r, o);\n  }\n});\n\nfunction Si(e, t, n) {\n  var s = 1 - e % 2,\n      r = new Float32Array(e);\n\n  for (var _a19 = 0; _a19 < e; ++_a19) {\n    var _i13 = 2 * Math.PI * _a19 / (e + s - 1);\n\n    r[_a19] = t - n * Math.cos(_i13);\n  }\n\n  return mi(r, \"float32\");\n}\n\nvar Ti = At({\n  conv2DBackpropFilter_: function conv2DBackpropFilter_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = e;\n    3 === e.rank && (o = Es(e, [1, e.shape[0], e.shape[1], e.shape[2]]));\n    var u = t;\n    3 === u.rank && (u = Es(t, [1, t.shape[0], t.shape[1], t.shape[2]])), l(4 === o.rank, () => \"Error in conv2dDerFilter: input must be rank 4, but got shape \".concat(o.shape, \".\")), l(4 === u.rank, () => \"Error in conv2dDerFilter: dy must be rank 4, but got shape \".concat(u.shape, \".\")), l(4 === n.length, () => \"Error in conv2dDerFilter: filterShape must be length 4, but got \".concat(n, \".\"));\n    var c = \"NHWC\" === a ? o.shape[3] : o.shape[1],\n        h = \"NHWC\" === a ? u.shape[3] : u.shape[1];\n    return l(c === n[2], () => \"Error in conv2dDerFilter: depth of input \".concat(c, \") must match input depth in filter (\").concat(n[2], \".\")), l(h === n[3], () => \"Error in conv2dDerFilter: depth of dy (\".concat(h, \") must match output depth for filter (\").concat(n[3], \").\")), null != i && l(f(r), () => \"Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(r, \".\")), wt.runKernel(\"Conv2DBackpropFilter\", {\n      x: o,\n      dy: u\n    }, {\n      strides: s,\n      pad: r,\n      dataFormat: a,\n      dimRoundingMode: i,\n      filterShape: n\n    });\n  }\n});\n\nfunction Ei(e, t, n) {\n  if (null == n || \"linear\" === n) return e;\n  if (\"relu\" === n) return ss(e, pi(t));\n  throw new Error(\"Cannot compute gradient for fused activation \".concat(n, \".\"));\n}\n\nfunction Ri(e, t) {\n  var n = t;\n  var s = ur(e.shape, t.shape);\n  return s.length > 0 && (n = Gr(n, s)), Es(n, e.shape);\n}\n\nfunction Ai(e, t, n, s) {\n  if (\"linear\" === t) return e;\n  if (\"relu\" === t) return Ua(e);\n  if (\"elu\" === t) return mr(e);\n  if (\"relu6\" === t) return Va(e);\n  if (\"prelu\" === t) return Ia(e, n);\n  if (\"leakyrelu\" === t) return Fr(e, s);\n  if (\"sigmoid\" === t) return Ds(e);\n  throw new Error(\"Unknown fused activation \".concat(t, \".\"));\n}\n\nvar Fi = (e, t) => !(e > 0) || \"linear\" === t,\n    Di = At({\n  fusedConv2d_: function fusedConv2d_(_ref3) {\n    var {\n      x: e,\n      filter: t,\n      strides: n,\n      pad: s,\n      dataFormat: r = \"NHWC\",\n      dilations: a = [1, 1],\n      dimRoundingMode: i,\n      bias: o,\n      activation: u = \"linear\",\n      preluActivationWeights: c,\n      leakyreluAlpha: h\n    } = _ref3;\n\n    if (!1 === Fi(wt.state.gradientDepth, u = u || \"linear\")) {\n      var _l6 = Xs(e, t, n, s, r, a, i);\n\n      return null != o && (_l6 = es(_l6, o)), Ai(_l6, u, c, h);\n    }\n\n    var d = Et(e, \"x\", \"conv2d\"),\n        p = Et(t, \"filter\", \"conv2d\");\n    var g = d,\n        m = !1;\n    3 === d.rank && (m = !0, g = Es(d, [1, d.shape[0], d.shape[1], d.shape[2]])), l(4 === g.rank, () => \"Error in fused conv2d: input must be rank 4, but got rank \".concat(g.rank, \".\")), l(4 === p.rank, () => \"Error in fused conv2d: filter must be rank 4, but got rank \".concat(p.rank, \".\")), null != i && l(f(s), () => \"Error in fused conv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\")), l(g.shape[3] === p.shape[2], () => \"Error in conv2d: depth of input (\".concat(g.shape[3], \") must match input depth for filter \").concat(p.shape[2], \".\")), l(Ss(n, a), () => \"Error in conv2D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\")), l(\"NHWC\" === r, () => \"Error in conv2d: got dataFormat of \".concat(r, \" but only NHWC is currently supported.\"));\n    var b = ys(g.shape, p.shape, n, a, s, i);\n    var x, y;\n    null != o && (x = Et(o, \"bias\", \"fused conv2d\"), [x] = ft(x, d), cr(b.outShape, x.shape)), null != c && (y = Et(c, \"prelu weights\", \"fused conv2d\"));\n\n    var k = (e, t) => {\n      var [r, i, o, c] = t,\n          h = Ei(e, o, u);\n      l(Cs(a), () => \"Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(a, \"'\"));\n      var d = [Js(i.shape, h, r, n, s), Ti(i, h, r.shape, n, s)];\n\n      if (null != c) {\n        var _e62 = Ri(c, h);\n\n        d.push(_e62);\n      }\n\n      return d;\n    },\n        w = {\n      x: g,\n      filter: p,\n      bias: x,\n      preluActivationWeights: y\n    },\n        v = {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i,\n      activation: u,\n      leakyreluAlpha: h\n    };\n\n    return null == o ? zr((e, t, n) => {\n      var s = wt.runKernel(\"FusedConv2D\", w, v);\n      return n([t, e, s]), m && (s = Es(s, [s.shape[1], s.shape[2], s.shape[3]])), {\n        value: s,\n        gradFunc: k\n      };\n    })(g, p) : zr((e, t, n, s) => {\n      var r = wt.runKernel(\"FusedConv2D\", w, v);\n      return s([t, e, r, n]), m && (r = Es(r, [r.shape[1], r.shape[2], r.shape[3]])), {\n        value: r,\n        gradFunc: k\n      };\n    })(g, p, x);\n  }\n}),\n    _i = At({\n  depthwiseConv2dNativeBackpropFilter_: function depthwiseConv2dNativeBackpropFilter_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = e;\n    3 === e.rank && (o = Es(e, [1, e.shape[0], e.shape[1], e.shape[2]]));\n    var l = t;\n    return 3 === l.rank && (l = Es(t, [1, t.shape[0], t.shape[1], t.shape[2]])), wt.runKernel(\"DepthwiseConv2dNativeBackpropFilter\", {\n      x: o,\n      dy: l\n    }, {\n      strides: s,\n      pad: r,\n      dimRoundingMode: i,\n      dilations: a,\n      filterShape: n\n    });\n  }\n}),\n    Oi = At({\n  depthwiseConv2dNativeBackpropInput_: function depthwiseConv2dNativeBackpropInput_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = t,\n        l = !1;\n    3 === t.rank && (l = !0, o = Es(t, [1, t.shape[0], t.shape[1], t.shape[2]]));\n    var u = wt.runKernel(\"DepthwiseConv2dNativeBackpropInput\", {\n      dy: o,\n      filter: n\n    }, {\n      strides: s,\n      pad: r,\n      dimRoundingMode: i,\n      dilations: a,\n      inputShape: e\n    });\n    return l ? Es(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    Mi = At({\n  fusedMatMul_: function fusedMatMul_(_ref4) {\n    var {\n      a: e,\n      b: t,\n      transposeA: n = !1,\n      transposeB: s = !1,\n      bias: r,\n      activation: a = \"linear\",\n      preluActivationWeights: i,\n      leakyreluAlpha: o\n    } = _ref4;\n\n    if (!1 === Fi(wt.state.gradientDepth, a)) {\n      var _l7 = vn(e, t, n, s);\n\n      return null != r && (_l7 = es(_l7, r)), Ai(_l7, a, i, o);\n    }\n\n    var u = Et(e, \"a\", \"fused matMul\"),\n        c = Et(t, \"b\", \"fused matMul\");\n    [u, c] = ft(u, c);\n    var h = n ? u.shape[u.rank - 2] : u.shape[u.rank - 1],\n        f = s ? c.shape[c.rank - 1] : c.shape[c.rank - 2],\n        g = n ? u.shape[u.rank - 1] : u.shape[u.rank - 2],\n        m = s ? c.shape[c.rank - 2] : c.shape[c.rank - 1],\n        b = u.shape.slice(0, -2),\n        x = c.shape.slice(0, -2),\n        y = d(b),\n        k = d(x);\n    l(u.rank >= 2 && c.rank >= 2 && u.rank === c.rank, () => \"Error in fused matMul: inputs must have the same rank of at least 2, got ranks \".concat(u.rank, \" and \").concat(c.rank, \".\")), l(p(b, x), () => \"Error in fused matMul: outer dimensions (\".concat(b, \") and (\").concat(x, \") of Tensors with shapes \").concat(u.shape, \" and \").concat(c.shape, \" must match.\")), l(h === f, () => \"Error in fused matMul: inner shapes (\".concat(h, \") and (\").concat(f, \") of Tensors with shapes \").concat(u.shape, \" and \").concat(c.shape, \" and transposeA=\").concat(n, \" and transposeB=\").concat(s, \" must match.\"));\n    var w = u.shape.slice(0, -2).concat([g, m]),\n        v = Es(u, n ? [y, h, g] : [y, g, h]),\n        I = Es(c, s ? [k, m, f] : [k, f, m]);\n    var $, N;\n    null != r && ($ = Et(r, \"bias\", \"fused matMul\"), [$] = ft($, u), cr(w, $.shape)), null != i && (N = Et(i, \"prelu weights\", \"fused matMul\"));\n\n    var C = (e, t) => {\n      var [i, o, l, u] = t,\n          c = Ei(Es(e, l.shape), l, a);\n      var h, d;\n      return n || s ? !n && s ? (h = vn(c, o, !1, !1), d = vn(c, i, !0, !1)) : n && !s ? (h = vn(o, c, !1, !0), d = vn(i, c, !1, !1)) : (h = vn(o, c, !0, !0), d = vn(c, i, !0, !0)) : (h = vn(c, o, !1, !0), d = vn(i, c, !0, !1)), null != r ? [h, d, Ri(u, c)] : [h, d];\n    },\n        S = {\n      a: v,\n      b: I,\n      bias: $,\n      preluActivationWeights: N\n    },\n        T = {\n      transposeA: n,\n      transposeB: s,\n      activation: a,\n      leakyreluAlpha: o\n    };\n\n    return null == r ? zr((e, t, n) => {\n      var s = wt.runKernel(\"_FusedMatMul\", S, T);\n      return n([e, t, s]), {\n        value: Es(s, w),\n        gradFunc: C\n      };\n    })(v, I) : zr((e, t, n, s) => {\n      var r = wt.runKernel(\"_FusedMatMul\", S, T);\n      return s([e, t, r, n]), {\n        value: Es(r, w),\n        gradFunc: C\n      };\n    })(v, I, $);\n  }\n});\n\nAt({\n  hammingWindow_: function hammingWindow_(e) {\n    return Si(e, .54, .46);\n  }\n});\nvar Li = At({\n  hannWindow_: function hannWindow_(e) {\n    return Si(e, .5, .5);\n  }\n}),\n    zi = At({\n  frame_: function frame_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = 0;\n    var i = [];\n\n    for (; a + t <= e.size;) {\n      i.push(_s(e, a, t)), a += n;\n    }\n\n    if (s) for (; a < e.size;) {\n      var _s39 = a + t - e.size,\n          _o11 = Fs([_s(e, a, t - _s39), Ir([_s39], r)]);\n\n      i.push(_o11), a += n;\n    }\n    return 0 === i.length ? bi([], [0, t]) : Es(Fs(i), [i.length, t]);\n  }\n});\nAt({\n  stft_: function stft_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Li;\n    null == s && (s = Math.floor(Math.pow(2, Math.ceil(Math.log(t) / Math.log(2)))));\n    var a = zi(e, t, n),\n        i = ss(a, r(t));\n    return li(i, s);\n  }\n});\nvar Bi = At({\n  cropAndResize_: function cropAndResize_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"bilinear\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = Et(e, \"image\", \"cropAndResize\"),\n        o = Et(t, \"boxes\", \"cropAndResize\", \"float32\"),\n        u = Et(n, \"boxInd\", \"cropAndResize\", \"int32\"),\n        c = o.shape[0];\n    return l(4 === i.rank, () => \"Error in cropAndResize: image must be rank 4,but got rank \".concat(i.rank, \".\")), l(2 === o.rank && 4 === o.shape[1], () => \"Error in cropAndResize: boxes must be have size [\".concat(c, \",4] but had shape \").concat(o.shape, \".\")), l(1 === u.rank && u.shape[0] === c, () => \"Error in cropAndResize: boxInd must be have size [\".concat(c, \"] but had shape \").concat(o.shape, \".\")), l(2 === s.length, () => \"Error in cropAndResize: cropSize must be of length 2, but got length \".concat(s.length, \".\")), l(s[0] >= 1 && s[1] >= 1, () => \"cropSize must be atleast [1,1], but was \".concat(s)), l(\"bilinear\" === r || \"nearest\" === r, () => \"method must be bilinear or nearest, but was \".concat(r)), wt.runKernel(\"CropAndResize\", {\n      image: i,\n      boxes: o,\n      boxInd: u\n    }, {\n      method: r,\n      extrapolationValue: a,\n      cropSize: s\n    });\n  }\n}),\n    Pi = At({\n  flipLeftRight_: function flipLeftRight_(e) {\n    var t = Et(e, \"image\", \"flipLeftRight\", \"float32\");\n    return l(4 === t.rank, () => \"Error in flipLeftRight: image must be rank 4,but got rank \".concat(t.rank, \".\")), wt.runKernel(\"FlipLeftRight\", {\n      image: t\n    }, {});\n  }\n}),\n    Wi = At({\n  rotateWithOffset_: function rotateWithOffset_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = Et(e, \"image\", \"rotateWithOffset\", \"float32\");\n    return l(4 === r.rank, () => \"Error in rotateWithOffset: image must be rank 4,but got rank \".concat(r.rank, \".\")), wt.runKernel(\"RotateWithOffset\", {\n      image: r\n    }, {\n      radians: t,\n      fillValue: n,\n      center: s\n    });\n  }\n});\n\nfunction Ui(e, t, n, s, r, a) {\n  null == s && (s = .5), null == r && (r = Number.NEGATIVE_INFINITY), null == a && (a = 0);\n  var i = e.shape[0];\n  return n = Math.min(n, i), l(0 <= s && s <= 1, () => \"iouThreshold must be in [0, 1], but was '\".concat(s, \"'\")), l(2 === e.rank, () => \"boxes must be a 2D tensor, but was of rank '\".concat(e.rank, \"'\")), l(4 === e.shape[1], () => \"boxes must have 4 columns, but 2nd dimension was \".concat(e.shape[1])), l(1 === t.rank, () => \"scores must be a 1D tensor\"), l(t.shape[0] === i, () => \"scores has incompatible shape with boxes. Expected \".concat(i, \", but was \").concat(t.shape[0])), l(0 <= a && a <= 1, () => \"softNmsSigma must be in [0, 1], but was '\".concat(a, \"'\")), {\n    maxOutputSize: n,\n    iouThreshold: s,\n    scoreThreshold: r,\n    softNmsSigma: a\n  };\n}\n\nvar Vi = At({\n  nonMaxSuppression_: function nonMaxSuppression_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = Et(e, \"boxes\", \"nonMaxSuppression\"),\n        i = Et(t, \"scores\", \"nonMaxSuppression\"),\n        o = Ui(a, i, n, s, r);\n    return wt.runKernel(\"NonMaxSuppressionV3\", {\n      boxes: a,\n      scores: i\n    }, {\n      maxOutputSize: n = o.maxOutputSize,\n      iouThreshold: s = o.iouThreshold,\n      scoreThreshold: r = o.scoreThreshold\n    });\n  }\n});\n\nfunction Gi(e, t, n) {\n  var s = function (e, t, n) {\n    return function (e, t, n) {\n      var s = 0,\n          r = e.length,\n          a = 0,\n          i = !1;\n\n      for (; s < r;) {\n        a = s + (r - s >>> 1);\n\n        var _o12 = n(t, e[a]);\n\n        _o12 > 0 ? s = a + 1 : (r = a, i = !_o12);\n      }\n\n      return i ? s : -s - 1;\n    }(e, t, n || Hi);\n  }(e, t, n);\n\n  e.splice(s < 0 ? -(s + 1) : s, 0, t);\n}\n\nfunction Hi(e, t) {\n  return e > t ? 1 : e < t ? -1 : 0;\n}\n\nfunction ji(e, t, n, s, r) {\n  return Xi(e, t, n, s, r, 0);\n}\n\nfunction qi(e, t, n, s, r, a) {\n  return Xi(e, t, n, s, r, 0, !1, a, !0);\n}\n\nfunction Ki(e, t, n, s, r, a) {\n  return Xi(e, t, n, s, r, a, !0);\n}\n\nfunction Xi(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;\n  var u = [];\n\n  for (var _e63 = 0; _e63 < t.length; _e63++) {\n    t[_e63] > r && u.push({\n      score: t[_e63],\n      boxIndex: _e63,\n      suppressBeginIndex: 0\n    });\n  }\n\n  u.sort(Zi);\n  var c = a > 0 ? -.5 / a : 0,\n      h = [],\n      d = [];\n\n  for (; h.length < n && u.length > 0;) {\n    var _t62 = u.pop(),\n        {\n      score: _n32,\n      boxIndex: _a20,\n      suppressBeginIndex: _i14\n    } = _t62;\n\n    if (_n32 < r) break;\n\n    var _o13 = !1;\n\n    for (var _n33 = h.length - 1; _n33 >= _i14; --_n33) {\n      var _i15 = Yi(e, _a20, h[_n33]);\n\n      if (_i15 >= s) {\n        _o13 = !0;\n        break;\n      }\n\n      if (_t62.score = _t62.score * Ji(s, c, _i15), _t62.score <= r) break;\n    }\n\n    _t62.suppressBeginIndex = h.length, _o13 || (_t62.score === _n32 ? (h.push(_a20), d.push(_t62.score)) : _t62.score > r && Gi(u, _t62, Zi));\n  }\n\n  var p = h.length,\n      f = n - p;\n  o && f > 0 && (h.push(...new Array(f).fill(0)), d.push(...new Array(f).fill(0)));\n  var g = {\n    selectedIndices: h\n  };\n  return i && (g.selectedScores = d), l && (g.validOutputs = p), g;\n}\n\nfunction Yi(e, t, n) {\n  var s = e.subarray(4 * t, 4 * t + 4),\n      r = e.subarray(4 * n, 4 * n + 4),\n      a = Math.min(s[0], s[2]),\n      i = Math.min(s[1], s[3]),\n      o = Math.max(s[0], s[2]),\n      l = Math.max(s[1], s[3]),\n      u = Math.min(r[0], r[2]),\n      c = Math.min(r[1], r[3]),\n      h = Math.max(r[0], r[2]),\n      d = Math.max(r[1], r[3]),\n      p = (o - a) * (l - i),\n      f = (h - u) * (d - c);\n  if (p <= 0 || f <= 0) return 0;\n  var g = Math.max(a, u),\n      m = Math.max(i, c),\n      b = Math.min(o, h),\n      x = Math.min(l, d),\n      y = Math.max(b - g, 0) * Math.max(x - m, 0);\n  return y / (p + f - y);\n}\n\nfunction Ji(e, t, n) {\n  var s = Math.exp(t * n * n);\n  return n <= e ? s : 0;\n}\n\nfunction Zi(e, t) {\n  return e.score - t.score || e.score === t.score && t.boxIndex - e.boxIndex;\n}\n\nvar Qi = At({\n  nonMaxSuppressionWithScore_: function nonMaxSuppressionWithScore_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = Et(e, \"boxes\", \"nonMaxSuppression\"),\n        o = Et(t, \"scores\", \"nonMaxSuppression\"),\n        l = Ui(i, o, n, s, r, a),\n        u = wt.runKernel(\"NonMaxSuppressionV5\", {\n      boxes: i,\n      scores: o\n    }, {\n      maxOutputSize: n = l.maxOutputSize,\n      iouThreshold: s = l.iouThreshold,\n      scoreThreshold: r = l.scoreThreshold,\n      softNmsSigma: a = l.softNmsSigma\n    });\n    return {\n      selectedIndices: u[0],\n      selectedScores: u[1]\n    };\n  }\n}),\n    eo = At({\n  nonMaxSuppressionPadded_: function nonMaxSuppressionPadded_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n    var i = Et(e, \"boxes\", \"nonMaxSuppression\"),\n        o = Et(t, \"scores\", \"nonMaxSuppression\"),\n        l = Ui(i, o, n, s, r, null),\n        u = wt.runKernel(\"NonMaxSuppressionV4\", {\n      boxes: i,\n      scores: o\n    }, {\n      maxOutputSize: l.maxOutputSize,\n      iouThreshold: l.iouThreshold,\n      scoreThreshold: l.scoreThreshold,\n      padToMaxOutputSize: a\n    });\n    return {\n      selectedIndices: u[0],\n      validOutputs: u[1]\n    };\n  }\n}),\n    to = At({\n  resizeBilinear_: function resizeBilinear_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Et(e, \"images\", \"resizeBilinear\");\n    l(3 === r.rank || 4 === r.rank, () => \"Error in resizeBilinear: x must be rank 3 or 4, but got rank \".concat(r.rank, \".\")), l(2 === t.length, () => \"Error in resizeBilinear: new shape must 2D, but got shape \".concat(t, \".\")), l(!1 === s || !1 === n, () => \"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.\");\n    var a = r,\n        i = !1;\n    3 === r.rank && (i = !0, a = Es(r, [1, r.shape[0], r.shape[1], r.shape[2]]));\n    var o = wt.runKernel(\"ResizeBilinear\", {\n      images: a\n    }, {\n      alignCorners: n,\n      halfPixelCenters: s,\n      size: t\n    });\n    return i ? Es(o, [o.shape[1], o.shape[2], o.shape[3]]) : o;\n  }\n}),\n    no = At({\n  resizeNearestNeighbor_: function resizeNearestNeighbor_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Et(e, \"images\", \"resizeNearestNeighbor\");\n    l(3 === r.rank || 4 === r.rank, () => \"Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank \".concat(r.rank, \".\")), l(2 === t.length, () => \"Error in resizeNearestNeighbor: new shape must 2D, but got shape \".concat(t, \".\")), l(\"float32\" === r.dtype || \"int32\" === r.dtype, () => \"`images` must have `int32` or `float32` as dtype\"), l(!1 === s || !1 === n, () => \"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.\");\n    var a = r,\n        i = !1;\n    3 === r.rank && (i = !0, a = Es(r, [1, r.shape[0], r.shape[1], r.shape[2]]));\n    var o = wt.runKernel(\"ResizeNearestNeighbor\", {\n      images: a\n    }, {\n      alignCorners: n,\n      halfPixelCenters: s,\n      size: t\n    });\n    return i ? Es(o, [o.shape[1], o.shape[2], o.shape[3]]) : o;\n  }\n}),\n    so = At({\n  threshold_: function threshold_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"binary\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = Et(e, \"image\", \"threshold\"),\n        a = r.shape[0] * r.shape[1];\n    var i,\n        o,\n        u,\n        c,\n        h = ss(mi([s]), 255);\n\n    if (l(3 === r.rank, () => \"Error in threshold: image must be rank 3,but got rank \".concat(r.rank, \".\")), l(3 === r.shape[2] || 1 === r.shape[2], () => \"Error in threshold: image color channel must be equal to 3 or 1but got \".concat(r.shape[2], \".\")), l(\"int32\" === r.dtype || \"float32\" === r.dtype, () => \"Error in dtype: image dtype must be int32 or float32,but got dtype \".concat(r.dtype, \".\")), l(\"otsu\" === t || \"binary\" === t, () => \"Method must be binary or otsu, but was \".concat(t)), 3 === r.shape[2]) {\n      [i, o, u] = oi(r, [1, 1, 1], -1);\n\n      var _e64 = ss(i, .2989),\n          _t63 = ss(o, .587),\n          _n34 = ss(u, .114);\n\n      c = es(es(_e64, _t63), _n34);\n    } else c = e;\n\n    \"otsu\" === t && (h = function (e, t) {\n      var n,\n          s,\n          r,\n          a,\n          i,\n          o,\n          l = mi([-1]),\n          u = mi([0]),\n          c = mi([0]);\n\n      for (var _h3 = 0; _h3 < e.size - 1; _h3++) {\n        n = _s(e, 0, _h3 + 1), s = _s(e, _h3 + 1), i = ns(Gr(n), t), o = ns(Gr(s), t);\n\n        var _d4 = Gr(ss(n, Ba(0, n.size)));\n\n        r = ns(_d4, Gr(n));\n\n        var _p4 = Ir(s.shape, n.size),\n            _f3 = es(Ba(0, s.size), _p4),\n            _g4 = ss(s, _f3);\n\n        a = ns(Gr(_g4), Gr(s));\n\n        var _m3 = Vr(r, a),\n            _b3 = Vr(r, a),\n            _x9 = ss(i, o);\n\n        c = ss(ss(_x9, _m3), _b3);\n\n        var _y3 = Cr(c, u);\n\n        u = dr(_y3, c, u), l = dr(_y3, mi([_h3]), l);\n      }\n\n      return l;\n    }(Ws(pn(Ha(c), \"int32\"), _t([]), 256), a));\n    var d = n ? _r(c, h) : Cr(c, h);\n    return pn(ss(d, 255), \"int32\");\n  }\n}),\n    ro = At({\n  transform_: function transform_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"nearest\";\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"constant\";\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = arguments.length > 5 ? arguments[5] : undefined;\n    var i = Et(e, \"image\", \"transform\", \"float32\"),\n        o = Et(t, \"transforms\", \"transform\", \"float32\");\n    return l(4 === i.rank, () => \"Error in transform: image must be rank 4,but got rank \".concat(i.rank, \".\")), l(2 === o.rank && (o.shape[0] === i.shape[0] || 1 === o.shape[0]) && 8 === o.shape[1], () => \"Error in transform: Input transform should be batch x 8 or 1 x 8\"), l(null == a || 2 === a.length, () => \"Error in transform: outputShape must be [height, width] or null, but got \".concat(a, \".\")), wt.runKernel(\"Transform\", {\n      image: i,\n      transforms: o\n    }, {\n      interpolation: n,\n      fillMode: s,\n      fillValue: r,\n      outputShape: a\n    });\n  }\n}),\n    ao = At({\n  bandPart_: function bandPart_(e, t, n) {\n    l(t % 1 == 0, () => \"bandPart(): numLower must be an integer, got \".concat(t, \".\")), l(n % 1 == 0, () => \"bandPart(): numUpper must be an integer, got \".concat(n, \".\"));\n    var s = Et(e, \"a\", \"bandPart\");\n    l(s.rank >= 2, () => \"bandPart(): Rank must be at least 2, got \".concat(s.rank, \".\"));\n    var r = s.shape,\n        [a, i] = s.shape.slice(-2);\n    if (!(t <= a)) throw new Error(\"bandPart(): numLower (\".concat(t, \") must not be greater than the number of rows (\").concat(a, \").\"));\n    if (!(n <= i)) throw new Error(\"bandPart(): numUpper (\".concat(n, \") must not be greater than the number of columns (\").concat(i, \").\"));\n    t < 0 && (t = a), n < 0 && (n = i);\n    var o = Es(Ba(0, a, 1, \"int32\"), [-1, 1]),\n        u = Ba(0, i, 1, \"int32\"),\n        c = Vr(o, u),\n        h = ta(_r(c, qa(+t, \"int32\")), Sr(c, qa(-n, \"int32\"))),\n        d = ua([a, i], s.dtype);\n    return Es(di(vi(Es(s, [-1, a, i])).map(e => dr(h, e, d))), r);\n  }\n}),\n    io = At({\n  gramSchmidt_: function gramSchmidt_(e) {\n    var t;\n\n    if (Array.isArray(e)) {\n      (function () {\n        t = !1, l(null != e && e.length > 0, () => \"Gram-Schmidt process: input must not be null, undefined, or empty\");\n        var n = e[0].shape[0];\n\n        var _loop6 = function _loop6(_t64) {\n          l(e[_t64].shape[0] === n, () => \"Gram-Schmidt: Non-unique lengths found in the input vectors: (\".concat(e[_t64].shape[0], \" vs. \").concat(n, \")\"));\n        };\n\n        for (var _t64 = 1; _t64 < e.length; ++_t64) {\n          _loop6(_t64);\n        }\n      })();\n    } else t = !0, e = oi(e, e.shape[0], 0).map(e => hi(e, [0]));\n\n    l(e.length <= e[0].shape[0], () => \"Gram-Schmidt: Number of vectors (\".concat(e.length, \") exceeds number of dimensions (\").concat(e[0].shape[0], \").\"));\n    var n = [],\n        s = e;\n\n    var _loop7 = function _loop7(_t65) {\n      n.push(wt.tidy(() => {\n        var e = s[_t65];\n        if (_t65 > 0) for (var _s40 = 0; _s40 < _t65; ++_s40) {\n          var _t66 = ss(Gr(ss(n[_s40], e)), n[_s40]);\n\n          e = Vr(e, _t66);\n        }\n        return ns(e, Ni(e, \"euclidean\"));\n      }));\n    };\n\n    for (var _t65 = 0; _t65 < e.length; ++_t65) {\n      _loop7(_t65);\n    }\n\n    return t ? di(n, 0) : n;\n  }\n});\n\nfunction oo(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  return wt.tidy(() => {\n    l(2 === e.shape.length, () => \"qr2d() requires a 2D Tensor, but got a \".concat(e.shape.length, \"D Tensor.\"));\n    var n = e.shape[0],\n        s = e.shape[1];\n    var r = vr(n),\n        a = fn(e);\n    var i = bi([[1]], [1, 1]);\n    var o = fn(i);\n    var u = n >= s ? s : n;\n\n    var _loop8 = function _loop8(_e65) {\n      var t = a,\n          l = o,\n          u = r;\n      [o, a, r] = wt.tidy(() => {\n        var t = _s(a, [_e65, _e65], [n - _e65, 1]),\n            l = Ni(t),\n            u = _s(a, [_e65, _e65], [1, 1]),\n            c = dr(Cr(u, 0), bi([[-1]]), bi([[1]])),\n            h = Vr(u, ss(c, l)),\n            d = ns(t, h);\n\n        o = 1 === d.shape[0] ? fn(i) : Fs([i, _s(d, [1, 0], [d.shape[0] - 1, d.shape[1]])], 0);\n\n        var p = Br(ns(vn(c, h), l)),\n            f = _s(a, [_e65, 0], [n - _e65, s]),\n            g = ss(p, o),\n            m = $n(o);\n\n        if (0 === _e65) a = Vr(f, vn(g, vn(m, f)));else {\n          var _t67 = Vr(f, vn(g, vn(m, f)));\n\n          a = Fs([_s(a, [0, 0], [_e65, s]), _t67], 0);\n        }\n\n        var b = $n(g),\n            x = _s(r, [0, _e65], [n, r.shape[1] - _e65]);\n\n        if (0 === _e65) r = Vr(x, vn(vn(x, o), b));else {\n          var _t68 = Vr(x, vn(vn(x, o), b));\n\n          r = Fs([_s(r, [0, 0], [n, _e65]), _t68], 1);\n        }\n        return [o, a, r];\n      }), Jn([t, l, u]);\n    };\n\n    for (var _e65 = 0; _e65 < u; ++_e65) {\n      _loop8(_e65);\n    }\n\n    return !t && n > s && (r = _s(r, [0, 0], [n, s]), a = _s(a, [0, 0], [s, s])), [r, a];\n  });\n}\n\nvar lo = At({\n  qr_: function qr_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    if (l(e.rank >= 2, () => \"qr() requires input tensor to have a rank >= 2, but got rank \".concat(e.rank)), 2 === e.rank) return oo(e, t);\n    {\n      var _n35 = e.shape.slice(0, e.shape.length - 2).reduce((e, t) => e * t),\n          _s41 = vi(Es(e, [_n35, e.shape[e.shape.length - 2], e.shape[e.shape.length - 1]]), 0),\n          _r31 = [],\n          _a21 = [];\n\n      return _s41.forEach(e => {\n        var [n, s] = oo(e, t);\n        _r31.push(n), _a21.push(s);\n      }), [Es(di(_r31, 0), e.shape), Es(di(_a21, 0), e.shape)];\n    }\n  }\n});\nvar uo;\n!function (e) {\n  e[e.NONE = 0] = \"NONE\", e[e.MEAN = 1] = \"MEAN\", e[e.SUM = 2] = \"SUM\", e[e.SUM_BY_NONZERO_WEIGHTS = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n}(uo || (uo = {}));\nvar co = At({\n  computeWeightedLoss_: function computeWeightedLoss_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var s = Et(e, \"losses\", \"computeWeightedLoss\");\n    var r = null;\n    null != t && (r = Et(t, \"weights\", \"computeWeightedLoss\"));\n    var a = null == r ? s : ss(s, r);\n    if (n === uo.NONE) return a;\n    if (n === uo.SUM) return Gr(a);\n\n    if (n === uo.MEAN) {\n      if (null == r) return la(a);\n      {\n        var _e66 = s.size / r.size,\n            _t69 = ns(Gr(a), Gr(r));\n\n        return _e66 > 1 ? ns(_t69, qa(_e66)) : _t69;\n      }\n    }\n\n    if (n === uo.SUM_BY_NONZERO_WEIGHTS) {\n      if (null == r) return ns(Gr(a), qa(s.size));\n      {\n        var _e67 = ss(r, ca(s.shape)),\n            _t70 = pn(Gr(ba(_e67, qa(0))), \"float32\");\n\n        return ns(Gr(a), _t70);\n      }\n    }\n\n    throw Error(\"Unknown reduction: \".concat(n));\n  }\n});\nAt({\n  absoluteDifference_: function absoluteDifference_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var r = Et(e, \"labels\", \"absoluteDifference\"),\n        a = Et(t, \"predictions\", \"absoluteDifference\");\n    var i = null;\n    null != n && (i = Et(n, \"weights\", \"absoluteDifference\")), u(r.shape, a.shape, \"Error in absoluteDifference: \");\n    var o = rs(Vr(r, a));\n    return co(o, i, s);\n  }\n}), At({\n  cosineDistance_: function cosineDistance_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var a = Et(e, \"labels\", \"cosineDistance\"),\n        i = Et(t, \"predictions\", \"cosineDistance\");\n    var o = null;\n    null != s && (o = Et(s, \"weights\", \"cosineDistance\")), u(a.shape, i.shape, \"Error in cosineDistance: \");\n    var l = qa(1),\n        c = Vr(l, Gr(ss(a, i), n, !0));\n    return co(c, o, r);\n  }\n}), At({\n  hingeLoss_: function hingeLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var r = Et(e, \"labels\", \"hingeLoss\");\n    var a = Et(t, \"predictions\", \"hingeLoss\");\n    var i = null;\n    null != n && (i = Et(n, \"weights\", \"hingeLoss\")), u(r.shape, a.shape, \"Error in hingeLoss: \");\n    var o = qa(1);\n    r = Vr(ss(qa(2), r), o);\n    var l = Ua(Vr(o, ss(r, a)));\n    return co(l, i, s);\n  }\n}), At({\n  huberLoss_: function huberLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var a = Et(e, \"labels\", \"huberLoss\"),\n        i = Et(t, \"predictions\", \"huberLoss\");\n    var o = null;\n    null != n && (o = Et(n, \"weights\", \"huberLoss\")), u(a.shape, i.shape, \"Error in huberLoss: \");\n    var l = qa(s),\n        c = rs(Vr(i, a)),\n        h = da(c, l),\n        d = Vr(c, h),\n        p = es(ss(qa(.5), ga(h)), ss(l, d));\n    return co(p, o, r);\n  }\n}), At({\n  logLoss_: function logLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1e-7;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var a = Et(e, \"labels\", \"logLoss\"),\n        i = Et(t, \"predictions\", \"logLoss\");\n    var o = null;\n    null != n && (o = Et(n, \"weights\", \"logLoss\")), u(a.shape, i.shape, \"Error in logLoss: \");\n    var l = qa(1),\n        c = qa(s),\n        h = Br(ss(a, Mr(es(i, c)))),\n        d = ss(Vr(l, a), Mr(es(Vr(l, i), c))),\n        p = Vr(h, d);\n    return co(p, o, r);\n  }\n}), At({\n  meanSquaredError_: function meanSquaredError_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var r = Et(e, \"labels\", \"meanSquaredError\"),\n        a = Et(t, \"predictions\", \"meanSquaredError\");\n    var i = null;\n    null != n && (i = Et(n, \"weights\", \"meanSquaredError\")), u(r.shape, a.shape, \"Error in meanSquaredError: \");\n    var o = ci(r, a);\n    return co(o, i, s);\n  }\n}), At({\n  sigmoidCrossEntropy_: function sigmoidCrossEntropy_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var a = Et(e, \"multiClassLabels\", \"sigmoidCrossEntropy\");\n    var i = Et(t, \"logits\", \"sigmoidCrossEntropy\");\n    var o = null;\n\n    if (null != n && (o = Et(n, \"weights\", \"sigmoidCrossEntropy\")), u(a.shape, i.shape, \"Error in sigmoidCrossEntropy: \"), s > 0) {\n      var _e68 = qa(s),\n          _t71 = qa(1),\n          _n36 = qa(.5);\n\n      a = es(ss(a, Vr(_t71, _e68)), ss(_n36, _e68));\n    }\n\n    var l = function (e, t) {\n      var n = Et(e, \"labels\", \"sigmoidCrossEntropyWithLogits\"),\n          s = Et(t, \"logits\", \"sigmoidCrossEntropyWithLogits\");\n      u(n.shape, s.shape, \"Error in sigmoidCrossEntropyWithLogits: \");\n      var r = Ua(s),\n          a = ss(s, n),\n          i = Lr(xr(Br(rs(s))));\n      return es(Vr(r, a), i);\n    }(a, i);\n\n    return co(l, o, r);\n  }\n}), At({\n  softmaxCrossEntropy_: function softmaxCrossEntropy_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : uo.SUM_BY_NONZERO_WEIGHTS;\n    var a = Et(e, \"onehotLabels\", \"softmaxCrossEntropy\");\n    var i = Et(t, \"logits\", \"softmaxCrossEntropy\");\n    var o = null;\n\n    if (null != n && (o = Et(n, \"weights\", \"softmaxCrossEntropy\")), u(a.shape, i.shape, \"Error in softmaxCrossEntropy: \"), s > 0) {\n      var _e69 = qa(s),\n          _t72 = qa(1),\n          _n37 = qa(a.shape[1]);\n\n      a = es(ss(a, Vr(_t72, _e69)), ns(_e69, _n37));\n    }\n\n    var l = function (e, t) {\n      var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;\n      if (-1 === n && (n = t.rank - 1), n !== t.rank - 1) throw Error(\"Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank \".concat(t.rank, \" and dim was \").concat(n));\n      return zr((e, t, s) => {\n        var r = ea(t, [n], !0),\n            a = Vr(pn(t, \"float32\"), r);\n        s([e, a]);\n        var i = Br(ss(a, e));\n        return {\n          value: Gr(i, [n]),\n          gradFunc: (e, t) => {\n            var [s, r] = t,\n                a = Xr(e.shape, [n]);\n            return [ss(Es(e, a), Vr(pn(s, \"float32\"), xr(r))), ss(Es(e, a), Vr(xr(r), pn(s, \"float32\")))];\n          }\n        };\n      })(e, t);\n    }(a, i);\n\n    return co(l, o, r);\n  }\n}), At({\n  sparseFillEmptyRows_: function sparseFillEmptyRows_(e, t, n, s) {\n    var r = Et(e, \"indices\", \"sparseFillEmptyRows\"),\n        a = Et(t, \"values\", \"sparseFillEmptyRows\"),\n        i = Et(n, \"denseShape\", \"sparseFillEmptyRows\"),\n        o = Et(s, \"defaultValue\", \"sparseFillEmptyRows\", a.dtype);\n    if (2 !== r.rank) throw new Error(\"Indices should be Tensor2D but received shape\\n        \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Values should be Tensor1D but received shape \".concat(a.shape));\n    if (1 !== i.rank) throw new Error(\"Dense shape should be Tensor1D but received shape \".concat(i.shape));\n    if (0 !== o.rank) throw new Error(\"Default value should be a scalar but received shape \".concat(o.shape));\n    var l = wt.runKernel(\"SparseFillEmptyRows\", {\n      indices: r,\n      values: a,\n      denseShape: i,\n      defaultValue: o\n    });\n    return {\n      outputIndices: l[0],\n      outputValues: l[1],\n      emptyRowIndicator: l[2],\n      reverseIndexMap: l[3]\n    };\n  }\n}), At({\n  sparseReshape_: function sparseReshape_(e, t, n) {\n    var s = Et(e, \"inputIndices\", \"sparseReshape\"),\n        r = Et(t, \"inputShape\", \"sparseReshape\"),\n        a = Et(n, \"newShape\", \"sparseReshape\");\n    if (2 !== s.rank) throw new Error(\"Input indices should be Tensor2D but received shape\\n        \".concat(s.shape));\n    if (1 !== r.rank) throw new Error(\"Input shape should be Tensor1D but received shape \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"New shape should be Tensor1D but received shape \".concat(a.shape));\n    var i = wt.runKernel(\"SparseReshape\", {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    });\n    return {\n      outputIndices: i[0],\n      outputShape: i[1]\n    };\n  }\n}), At({\n  sparseSegmentMean_: function sparseSegmentMean_(e, t, n) {\n    var s = Et(e, \"data\", \"sparseSegmentMean\"),\n        r = Et(t, \"indices\", \"sparseSegmentMean\"),\n        a = Et(n, \"segmentIds\", \"sparseSegmentMean\");\n    if (s.rank < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.rank) throw new Error(\"Indices should be Tensor1D but received shape\\n          \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Segment ids should be Tensor1D but received shape\\n          \".concat(a.shape));\n    return wt.runKernel(\"SparseSegmentMean\", {\n      data: s,\n      indices: r,\n      segmentIds: a\n    });\n  }\n}), At({\n  sparseSegmentSum_: function sparseSegmentSum_(e, t, n) {\n    var s = Et(e, \"data\", \"sparseSegmentSum\"),\n        r = Et(t, \"indices\", \"sparseSegmentSum\"),\n        a = Et(n, \"segmentIds\", \"sparseSegmentSum\");\n    if (s.rank < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.rank) throw new Error(\"Indices should be Tensor1D but received shape\\n         \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Segment ids should be Tensor1D but received shape\\n         \".concat(a.shape));\n    return wt.runKernel(\"SparseSegmentSum\", {\n      data: s,\n      indices: r,\n      segmentIds: a\n    });\n  }\n}), At({\n  stringNGrams_: function stringNGrams_(e, t, n, s, r, a, i, o) {\n    var l = Et(e, \"data\", \"stringNGrams\", \"string\");\n    if (\"string\" !== l.dtype) throw new Error(\"Data must be of datatype string\");\n    if (1 !== l.shape.length) throw new Error(\"Data must be a vector, saw: \".concat(l.shape));\n    var u = Et(t, \"dataSplits\", \"stringNGrams\");\n    if (\"int32\" !== u.dtype) throw new Error(\"Data splits must be of datatype int32\");\n    var c = wt.runKernel(\"StringNGrams\", {\n      data: l,\n      dataSplits: u\n    }, {\n      separator: n,\n      nGramWidths: s,\n      leftPad: r,\n      rightPad: a,\n      padWidth: i,\n      preserveShortSequences: o\n    });\n    return {\n      nGrams: c[0],\n      nGramsSplits: c[1]\n    };\n  }\n}), At({\n  stringSplit_: function stringSplit_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = Et(e, \"input\", \"stringSplit\", \"string\"),\n        r = Et(t, \"delimiter\", \"stringSplit\", \"string\");\n    if (1 !== s.rank) throw new Error(\"Input should be Tensor1D but received shape \".concat(s.shape));\n    if (0 !== r.rank) throw new Error(\"Delimiter should be a scalar but received shape \".concat(r.shape));\n    var a = wt.runKernel(\"StringSplit\", {\n      input: s,\n      delimiter: r\n    }, {\n      skipEmpty: n\n    });\n    return {\n      indices: a[0],\n      values: a[1],\n      shape: a[2]\n    };\n  }\n}), At({\n  stringToHashBucketFast_: function stringToHashBucketFast_(e, t) {\n    var n = Et(e, \"input\", \"stringToHashBucketFast\", \"string\"),\n        s = {\n      numBuckets: t\n    };\n    if (t <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    return wt.runKernel(\"StringToHashBucketFast\", {\n      input: n\n    }, s);\n  }\n});\nvar ho = {\n  flipLeftRight: Pi,\n  resizeNearestNeighbor: no,\n  resizeBilinear: to,\n  rotateWithOffset: Wi,\n  cropAndResize: Bi,\n  nonMaxSuppression: Vi,\n  nonMaxSuppressionAsync: function () {\n    var _nonMaxSuppressionAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = Et(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          i = Et(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          o = Ui(a, i, n, s, r);\n      n = o.maxOutputSize, s = o.iouThreshold, r = o.scoreThreshold;\n      var l = yield Promise.all([a.data(), i.data()]),\n          u = l[0],\n          c = l[1],\n          {\n        selectedIndices: h\n      } = ji(u, c, n, s, r);\n      return a !== e && a.dispose(), i !== t && i.dispose(), mi(h, \"int32\");\n    });\n\n    function nonMaxSuppressionAsync(_x10, _x11, _x12) {\n      return _nonMaxSuppressionAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionAsync;\n  }(),\n  nonMaxSuppressionWithScore: Qi,\n  nonMaxSuppressionWithScoreAsync: function () {\n    var _nonMaxSuppressionWithScoreAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n      var i = Et(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          o = Et(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          l = Ui(i, o, n, s, r, a);\n      n = l.maxOutputSize, s = l.iouThreshold, r = l.scoreThreshold, a = l.softNmsSigma;\n      var u = yield Promise.all([i.data(), o.data()]),\n          c = u[0],\n          h = u[1],\n          {\n        selectedIndices: d,\n        selectedScores: p\n      } = Ki(c, h, n, s, r, a);\n      return i !== e && i.dispose(), o !== t && o.dispose(), {\n        selectedIndices: mi(d, \"int32\"),\n        selectedScores: mi(p)\n      };\n    });\n\n    function nonMaxSuppressionWithScoreAsync(_x13, _x14, _x15) {\n      return _nonMaxSuppressionWithScoreAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionWithScoreAsync;\n  }(),\n  nonMaxSuppressionPadded: eo,\n  nonMaxSuppressionPaddedAsync: function () {\n    var _nonMaxSuppressionPaddedAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n      var i = Et(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          o = Et(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          l = Ui(i, o, n, s, r, null),\n          u = l.maxOutputSize,\n          c = l.iouThreshold,\n          h = l.scoreThreshold,\n          [d, p] = yield Promise.all([i.data(), o.data()]),\n          {\n        selectedIndices: f,\n        validOutputs: g\n      } = qi(d, p, u, c, h, a);\n      return i !== e && i.dispose(), o !== t && o.dispose(), {\n        selectedIndices: mi(f, \"int32\"),\n        validOutputs: qa(g, \"int32\")\n      };\n    });\n\n    function nonMaxSuppressionPaddedAsync(_x16, _x17, _x18) {\n      return _nonMaxSuppressionPaddedAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionPaddedAsync;\n  }(),\n  threshold: so,\n  transform: ro\n},\n    po = {\n  bandPart: ao,\n  gramSchmidt: io,\n  qr: lo\n};\n\nclass fo extends Hn {\n  minimize(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var {\n      value: s,\n      grads: r\n    } = this.computeGradients(e, n);\n\n    if (null != n) {\n      var _e70 = n.map(e => ({\n        name: e.name,\n        tensor: r[e.name]\n      }));\n\n      this.applyGradients(_e70);\n    } else this.applyGradients(r);\n\n    return Jn(r), t ? s : (s.dispose(), null);\n  }\n\n  get iterations() {\n    return null == this.iterations_ && (this.iterations_ = 0), this.iterations_;\n  }\n\n  incrementIterations() {\n    this.iterations_ = this.iterations + 1;\n  }\n\n  computeGradients(e, t) {\n    return function (e, t) {\n      l(E(e), () => \"The f passed in variableGrads(f) must be a function\"), l(null == t || Array.isArray(t) && t.every(e => e instanceof at), () => \"The varList passed in variableGrads(f, varList) must be an array of variables\");\n      var n = null != t;\n\n      if (!n) {\n        t = [];\n\n        for (var _e71 in wt.registeredVariables) {\n          t.push(wt.registeredVariables[_e71]);\n        }\n      }\n\n      var s = n ? t.filter(e => !e.trainable) : null,\n          r = t.length;\n      l((t = t.filter(e => e.trainable)).length > 0, () => \"variableGrads() expects at least one of the input variables to be trainable, but none of the \".concat(r, \" variables is trainable.\"));\n      var {\n        value: a,\n        grads: i\n      } = wt.gradients(e, t, null, !0);\n      l(i.some(e => null != e), () => \"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().\"), l(0 === a.rank, () => \"The f passed in variableGrads(f) must return a scalar, but it returned a rank-\".concat(a.rank, \" tensor\"));\n      var o = {};\n      return t.forEach((e, t) => {\n        null != i[t] && (o[e.name] = i[t]);\n      }), null != s && s.forEach(e => o[e.name] = null), {\n        value: a,\n        grads: o\n      };\n    }(e, t);\n  }\n\n  dispose() {\n    null != this.iterations_ && Jn(this.iterations_);\n  }\n\n  saveIterations() {\n    var _this23 = this;\n\n    return _asyncToGenerator(function* () {\n      return null == _this23.iterations_ && (_this23.iterations_ = 0), {\n        name: \"iter\",\n        tensor: qa(_this23.iterations_, \"int32\")\n      };\n    })();\n  }\n\n  getWeights() {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"getWeights() is not implemented for this optimizer yet.\");\n    })();\n  }\n\n  setWeights(e) {\n    var _this24 = this;\n\n    return _asyncToGenerator(function* () {\n      throw new Error(\"setWeights() is not implemented for this optimizer class \".concat(_this24.getClassName()));\n    })();\n  }\n\n  extractIterations(e) {\n    var _this25 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this25.iterations_ = (yield e[0].tensor.data())[0], e.slice(1);\n    })();\n  }\n\n}\n\nObject.defineProperty(fo, Symbol.hasInstance, {\n  value: e => null != e.minimize && null != e.computeGradients && null != e.applyGradients\n});\n\nclass go extends fo {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    super(), this.learningRate = e, this.rho = t, this.epsilon = n, this.accumulatedGrads = [], this.accumulatedUpdates = [], null == n && (this.epsilon = wt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = wt.registeredVariables[t];\n      null == this.accumulatedGrads[n] && (this.accumulatedGrads[n] = {\n        originalName: \"\".concat(t, \"/accum_grad\"),\n        variable: Yn(() => pr(s).variable(!1))\n      }), null == this.accumulatedUpdates[n] && (this.accumulatedUpdates[n] = {\n        originalName: \"\".concat(t, \"/accum_var\"),\n        variable: Yn(() => pr(s).variable(!1))\n      });\n      var r = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == r) return;\n      var a = this.accumulatedGrads[n].variable,\n          i = this.accumulatedUpdates[n].variable;\n      Yn(() => {\n        var e = es(ss(a, this.rho), ss(ga(r), 1 - this.rho)),\n            t = ss(ns(ui(es(i, this.epsilon)), ui(es(a, this.epsilon))), r),\n            n = es(ss(i, this.rho), ss(ga(t), 1 - this.rho));\n        a.assign(e), i.assign(n);\n        var o = es(ss(t, -this.learningRate), s);\n        s.assign(o);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedUpdates && (Jn(this.accumulatedGrads.map(e => e.variable)), Jn(this.accumulatedUpdates.map(e => e.variable)));\n  }\n\n  getWeights() {\n    var _this26 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this26.accumulatedGrads, ..._this26.accumulatedUpdates];\n      return [yield _this26.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this27 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = (e = yield _this27.extractIterations(e)).length / 2;\n      _this27.accumulatedGrads = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      })), _this27.accumulatedUpdates = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      rho: this.rho,\n      epsilon: this.epsilon\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.rho, t.epsilon);\n  }\n\n}\n\ngo.className = \"Adadelta\", qn(go);\n\nclass mo extends fo {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;\n    super(), this.learningRate = e, this.initialAccumulatorValue = t, this.accumulatedGrads = [];\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = wt.registeredVariables[t];\n\n      if (null == this.accumulatedGrads[n]) {\n        var _e72 = !1;\n\n        this.accumulatedGrads[n] = {\n          originalName: \"\".concat(t, \"/accumulator\"),\n          variable: Yn(() => Ir(s.shape, this.initialAccumulatorValue).variable(_e72))\n        };\n      }\n\n      var r = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == r) return;\n      var a = this.accumulatedGrads[n].variable;\n      Yn(() => {\n        var e = es(a, ga(r));\n        a.assign(e);\n        var t = es(ss(ns(r, ui(es(e, wt.backend.epsilon()))), -this.learningRate), s);\n        s.assign(t);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedGrads && Jn(this.accumulatedGrads.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this28 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this28.saveIterations()].concat(_this28.accumulatedGrads.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this29 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this29.extractIterations(e), _this29.accumulatedGrads = e.map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      initialAccumulatorValue: this.initialAccumulatorValue\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.initialAccumulatorValue);\n  }\n\n}\n\nmo.className = \"Adagrad\", qn(mo);\n\nclass bo extends fo {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = s, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], Yn(() => {\n      this.accBeta1 = qa(t).variable(), this.accBeta2 = qa(n).variable();\n    }), null == s && (this.epsilon = wt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n    Yn(() => {\n      var n = Vr(1, this.accBeta1),\n          s = Vr(1, this.accBeta2);\n      t.forEach((t, r) => {\n        var a = wt.registeredVariables[t];\n        null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {\n          originalName: \"\".concat(t, \"/m\"),\n          variable: Yn(() => pr(a).variable(!1))\n        }), null == this.accumulatedSecondMoment[r] && (this.accumulatedSecondMoment[r] = {\n          originalName: \"\".concat(t, \"/v\"),\n          variable: Yn(() => pr(a).variable(!1))\n        });\n        var i = Array.isArray(e) ? e[r].tensor : e[t];\n        if (null == i) return;\n        var o = this.accumulatedFirstMoment[r].variable,\n            l = this.accumulatedSecondMoment[r].variable,\n            u = es(ss(o, this.beta1), ss(i, 1 - this.beta1)),\n            c = es(ss(l, this.beta2), ss(ga(i), 1 - this.beta2)),\n            h = ns(u, n),\n            d = ns(c, s);\n        o.assign(u), l.assign(c);\n        var p = es(ss(ns(h, es(ui(d), this.epsilon)), -this.learningRate), a);\n        a.assign(p);\n      }), this.accBeta1.assign(ss(this.accBeta1, this.beta1)), this.accBeta2.assign(ss(this.accBeta2, this.beta2));\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.accBeta1.dispose(), this.accBeta2.dispose(), null != this.accumulatedFirstMoment && Jn(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedSecondMoment && Jn(this.accumulatedSecondMoment.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this30 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this30.accumulatedFirstMoment, ..._this30.accumulatedSecondMoment];\n      return [yield _this30.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this31 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this31.extractIterations(e), Yn(() => {\n        _this31.accBeta1.assign(va(_this31.beta1, _this31.iterations_ + 1)), _this31.accBeta2.assign(va(_this31.beta2, _this31.iterations_ + 1));\n      });\n      var t = e.length / 2;\n      _this31.accumulatedFirstMoment = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      })), _this31.accumulatedSecondMoment = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      beta1: this.beta1,\n      beta2: this.beta2,\n      epsilon: this.epsilon\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon);\n  }\n\n}\n\nbo.className = \"Adam\", qn(bo);\n\nclass xo extends fo {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = s, this.decay = r, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], Yn(() => {\n      this.iteration = qa(0).variable(), this.accBeta1 = qa(t).variable();\n    }), null == s && (this.epsilon = wt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n    Yn(() => {\n      var n = Vr(1, this.accBeta1),\n          s = ns(-this.learningRate, es(ss(this.iteration, this.decay), 1));\n      t.forEach((t, r) => {\n        var a = wt.registeredVariables[t];\n        null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {\n          originalName: \"\".concat(t, \"/m\"),\n          variable: pr(a).variable(!1)\n        }), null == this.accumulatedWeightedInfNorm[r] && (this.accumulatedWeightedInfNorm[r] = {\n          originalName: \"\".concat(t, \"/v\"),\n          variable: pr(a).variable(!1)\n        });\n        var i = Array.isArray(e) ? e[r].tensor : e[t];\n        if (null == i) return;\n        var o = this.accumulatedFirstMoment[r].variable,\n            l = this.accumulatedWeightedInfNorm[r].variable,\n            u = es(ss(o, this.beta1), ss(i, 1 - this.beta1)),\n            c = ss(l, this.beta2),\n            h = rs(i),\n            d = oa(c, h);\n        o.assign(u), l.assign(d);\n        var p = es(ss(ns(s, n), ns(u, es(d, this.epsilon))), a);\n        a.assign(p);\n      }), this.iteration.assign(es(this.iteration, 1)), this.accBeta1.assign(ss(this.accBeta1, this.beta1));\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.accBeta1.dispose(), this.iteration.dispose(), null != this.accumulatedFirstMoment && Jn(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedWeightedInfNorm && Jn(this.accumulatedWeightedInfNorm.map(e => e.variable));\n  }\n\n  getWeights() {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"getWeights() is not implemented for Adamax yet.\");\n    })();\n  }\n\n  setWeights(e) {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"setWeights() is not implemented for Adamax yet.\");\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      beta1: this.beta1,\n      beta2: this.beta2,\n      epsilon: this.epsilon,\n      decay: this.decay\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon, t.decay);\n  }\n\n}\n\nxo.className = \"Adamax\", qn(xo);\n\nclass yo extends fo {\n  constructor(e) {\n    super(), this.learningRate = e, this.setLearningRate(e);\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == s) return;\n      var r = wt.registeredVariables[t];\n      Yn(() => {\n        var e = es(ss(this.c, s), r);\n        r.assign(e);\n      });\n    }), this.incrementIterations();\n  }\n\n  setLearningRate(e) {\n    this.learningRate = e, null != this.c && this.c.dispose(), this.c = Zn(qa(-e));\n  }\n\n  dispose() {\n    this.c.dispose();\n  }\n\n  getWeights() {\n    var _this32 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this32.saveIterations()];\n    })();\n  }\n\n  setWeights(e) {\n    var _this33 = this;\n\n    return _asyncToGenerator(function* () {\n      if (0 !== (e = yield _this33.extractIterations(e)).length) throw new Error(\"SGD optimizer does not have settable weights.\");\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate);\n  }\n\n}\n\nyo.className = \"SGD\", qn(yo);\n\nclass ko extends yo {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    super(e), this.learningRate = e, this.momentum = t, this.useNesterov = n, this.accumulations = [], this.m = qa(this.momentum);\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = wt.registeredVariables[t];\n\n      if (null == this.accumulations[n]) {\n        var _e73 = !1;\n\n        this.accumulations[n] = {\n          originalName: \"\".concat(t, \"/momentum\"),\n          variable: Yn(() => pr(s).variable(_e73))\n        };\n      }\n\n      var r = this.accumulations[n].variable,\n          a = Array.isArray(e) ? e[n].tensor : e[t];\n      null != a && Yn(() => {\n        var e;\n        var t = es(ss(this.m, r), a);\n        e = es(ss(this.c, this.useNesterov ? es(a, ss(t, this.m)) : t), s), r.assign(t), s.assign(e);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.m.dispose(), null != this.accumulations && Jn(this.accumulations.map(e => e.variable));\n  }\n\n  setMomentum(e) {\n    this.momentum = e;\n  }\n\n  getWeights() {\n    var _this34 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this34.saveIterations()].concat(_this34.accumulations.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this35 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this35.extractIterations(e), _this35.accumulations = e.map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      momentum: this.momentum,\n      useNesterov: this.useNesterov\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.momentum, t.useNesterov);\n  }\n\n}\n\nko.className = \"Momentum\", qn(ko);\n\nclass wo extends fo {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (super(), this.learningRate = e, this.decay = t, this.momentum = n, this.epsilon = s, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = r, null == s && (this.epsilon = wt.backend.epsilon()), null == e) throw new Error(\"learningRate for RMSPropOptimizer must be defined.\");\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = wt.registeredVariables[t],\n          r = !1;\n      null == this.accumulatedMeanSquares[n] && (this.accumulatedMeanSquares[n] = {\n        originalName: \"\".concat(t, \"/rms\"),\n        variable: Yn(() => pr(s).variable(r))\n      }), null == this.accumulatedMoments[n] && (this.accumulatedMoments[n] = {\n        originalName: \"\".concat(t, \"/momentum\"),\n        variable: Yn(() => pr(s).variable(r))\n      }), null == this.accumulatedMeanGrads[n] && this.centered && (this.accumulatedMeanGrads[n] = {\n        originalName: \"\".concat(t, \"/mg\"),\n        variable: Yn(() => pr(s).variable(r))\n      });\n      var a = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == a) return;\n      var i = this.accumulatedMeanSquares[n].variable,\n          o = this.accumulatedMoments[n].variable;\n      Yn(() => {\n        var e = es(ss(i, this.decay), ss(ga(a), 1 - this.decay));\n\n        if (this.centered) {\n          var _t73 = this.accumulatedMeanGrads[n].variable,\n              _r32 = es(ss(_t73, this.decay), ss(a, 1 - this.decay)),\n              _l8 = ns(ss(a, this.learningRate), ui(Vr(e, es(ga(_r32), this.epsilon)))),\n              _u5 = es(ss(o, this.momentum), _l8);\n\n          i.assign(e), _t73.assign(_r32), o.assign(_u5);\n\n          var _c4 = Vr(s, _u5);\n\n          s.assign(_c4);\n        } else {\n          var _e74 = es(ss(i, this.decay), ss(ga(a), 1 - this.decay)),\n              _t74 = es(ss(o, this.momentum), ns(ss(a, this.learningRate), ui(es(_e74, this.epsilon))));\n\n          i.assign(_e74), o.assign(_t74);\n\n          var _n38 = Vr(s, _t74);\n\n          s.assign(_n38);\n        }\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedMeanSquares && Jn(this.accumulatedMeanSquares.map(e => e.variable)), null != this.accumulatedMeanGrads && this.centered && Jn(this.accumulatedMeanGrads.map(e => e.variable)), null != this.accumulatedMoments && Jn(this.accumulatedMoments.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this36 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this36.accumulatedMeanSquares, ..._this36.accumulatedMoments];\n      return _this36.centered && e.push(..._this36.accumulatedMeanGrads), [yield _this36.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this37 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this37.extractIterations(e);\n      var t = _this37.centered ? e.length / 3 : e.length / 2,\n          n = !1;\n      _this37.accumulatedMeanSquares = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })), _this37.accumulatedMoments = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })), _this37.centered && (_this37.accumulatedMeanGrads = e.slice(2 * t, 3 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      decay: this.decay,\n      momentum: this.momentum,\n      epsilon: this.epsilon,\n      centered: this.centered\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.decay, t.momentum, t.epsilon, t.centered);\n  }\n\n}\n\nwo.className = \"RMSProp\", qn(wo);\n\nclass vo {\n  static sgd(e) {\n    return new yo(e);\n  }\n\n  static momentum(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    return new ko(e, t, n);\n  }\n\n  static rmsprop(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    return new wo(e, t, n, s, r);\n  }\n\n  static adam() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    return new bo(e, t, n, s);\n  }\n\n  static adadelta() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .95;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    return new go(e, t, n);\n  }\n\n  static adamax() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .002;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    return new xo(e, t, n, s, r);\n  }\n\n  static adagrad(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;\n    return new mo(e, t);\n  }\n\n}\n\nvar Io = {\n  sgd: vo.sgd,\n  momentum: vo.momentum,\n  adadelta: vo.adadelta,\n  adagrad: vo.adagrad,\n  rmsprop: vo.rmsprop,\n  adamax: vo.adamax,\n  adam: vo.adam\n},\n    $o = \"undefined\" != typeof requestAnimationFrame ? requestAnimationFrame : \"undefined\" != typeof setImmediate ? setImmediate : e => e();\n\nfunction No() {\n  return new Promise(e => $o(() => e()));\n}\n\nfunction Co(e, t) {\n  var n = e[0].length;\n  e.forEach((e, t) => {\n    l(e.length === n, () => \"Error in concat\".concat(n, \"D: rank of tensors[\").concat(t, \"] must be the same as the rank of the rest (\").concat(n, \")\"));\n  }), l(t >= 0 && t < n, () => \"Error in concat\".concat(n, \"D: axis must be between 0 and \").concat(n - 1, \".\"));\n  var s = e[0];\n  e.forEach((e, r) => {\n    for (var _a22 = 0; _a22 < n; _a22++) {\n      l(_a22 === t || e[_a22] === s[_a22], () => \"Error in concat\".concat(n, \"D: Shape of tensors[\").concat(r, \"] (\").concat(e, \") does not match the shape of the rest (\").concat(s, \") along the non-concatenated axis \").concat(r, \".\"));\n    }\n  });\n}\n\nfunction So(e, t) {\n  var n = e[0].slice();\n\n  for (var _s42 = 1; _s42 < e.length; _s42++) {\n    n[t] += e[_s42][t];\n  }\n\n  return n;\n}\n\nfunction To(e) {\n  return e <= 30 ? e : R(e, Math.floor(Math.sqrt(e)));\n}\n\nfunction Eo(e, t, n) {\n  return [n * (\"number\" == typeof e ? e : e[0]), t * (\"number\" == typeof e ? e : e[1])];\n}\n\nfunction Ro(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = [];\n  if (s) r = r.concat(t.slice(0)), r.push(e[0] / n), r = r.concat(e.slice(1));else {\n    r = r.concat(e[0]);\n    var _n39 = t.length;\n\n    for (var _s43 = 0; _s43 < _n39; ++_s43) {\n      r = r.concat([e[_s43 + 1] / t[_s43], t[_s43]]);\n    }\n\n    r = r.concat(e.slice(_n39 + 1));\n  }\n  return r;\n}\n\nfunction Ao(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n  var s = [];\n\n  if (n) {\n    s.push(t);\n\n    for (var _n40 = t + 1; _n40 < e; ++_n40) {\n      _n40 <= 2 * t ? (s.push(_n40), s.push(_n40 - (t + 1))) : s.push(_n40);\n    }\n  } else {\n    var _n41 = [],\n        _r33 = [];\n\n    for (var _s44 = 1; _s44 < e; ++_s44) {\n      _s44 >= 2 * t + 1 || _s44 % 2 == 1 ? _r33.push(_s44) : _n41.push(_s44);\n    }\n\n    s.push(..._n41), s.push(0), s.push(..._r33);\n  }\n\n  return s;\n}\n\nfunction Fo(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = [];\n  r.push(s ? e[0] / n : e[0] * n);\n\n  for (var _n42 = 1; _n42 < e.length; ++_n42) {\n    r.push(_n42 <= t.length ? s ? t[_n42 - 1] * e[_n42] : e[_n42] / t[_n42 - 1] : e[_n42]);\n  }\n\n  return r;\n}\n\nfunction Do(e, t) {\n  var n = [0];\n\n  for (var _s45 = 0; _s45 < t; ++_s45) {\n    n.push(e[_s45][0]);\n  }\n\n  return n;\n}\n\nfunction _o(e, t, n) {\n  var s = e.slice(0, 1);\n\n  for (var _r34 = 0; _r34 < n; ++_r34) {\n    s.push(e[_r34 + 1] - t[_r34][0] - t[_r34][1]);\n  }\n\n  return s;\n}\n\nfunction Oo() {\n  V().getBool(\"IS_TEST\") || console.warn(...arguments);\n}\n\nfunction Mo(e, t) {\n  if (e.length !== t.length) throw new Error(\"Cannot merge real and imag arrays of different lengths. real:\".concat(e.length, \", imag: \").concat(t.length, \".\"));\n  var n = new Float32Array(2 * e.length);\n\n  for (var _s46 = 0; _s46 < n.length; _s46 += 2) {\n    n[_s46] = e[_s46 / 2], n[_s46 + 1] = t[_s46 / 2];\n  }\n\n  return n;\n}\n\nfunction Lo(e) {\n  var t = new Float32Array(e.length / 2),\n      n = new Float32Array(e.length / 2);\n\n  for (var _s47 = 0; _s47 < e.length; _s47 += 2) {\n    t[_s47 / 2] = e[_s47], n[_s47 / 2] = e[_s47 + 1];\n  }\n\n  return {\n    real: t,\n    imag: n\n  };\n}\n\nfunction zo(e) {\n  var t = Math.ceil(e.length / 4),\n      n = new Float32Array(t),\n      s = new Float32Array(t);\n\n  for (var _t75 = 0; _t75 < e.length; _t75 += 4) {\n    n[Math.floor(_t75 / 4)] = e[_t75], s[Math.floor(_t75 / 4)] = e[_t75 + 1];\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Bo(e) {\n  var t = Math.floor(e.length / 4),\n      n = new Float32Array(t),\n      s = new Float32Array(t);\n\n  for (var _t76 = 2; _t76 < e.length; _t76 += 4) {\n    n[Math.floor(_t76 / 4)] = e[_t76], s[Math.floor(_t76 / 4)] = e[_t76 + 1];\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Po(e, t) {\n  return {\n    real: e[2 * t],\n    imag: e[2 * t + 1]\n  };\n}\n\nfunction Wo(e, t, n, s) {\n  e[2 * s] = t, e[2 * s + 1] = n;\n}\n\nfunction Uo(e, t) {\n  var n = new Float32Array(e / 2),\n      s = new Float32Array(e / 2);\n\n  for (var _r35 = 0; _r35 < Math.ceil(e / 2); _r35++) {\n    var _a23 = (t ? 2 : -2) * Math.PI * (_r35 / e);\n\n    n[_r35] = Math.cos(_a23), s[_r35] = Math.sin(_a23);\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Vo(e, t, n) {\n  var s = (n ? 2 : -2) * Math.PI * (e / t);\n  return {\n    real: Math.cos(s),\n    imag: Math.sin(s)\n  };\n}\n\nvar Go = /->/g;\n\nfunction Ho(e, t) {\n  var n = ((e = e.replace(/\\s/g, \"\")).length - e.replace(Go, \"\").length) / \"->\".length;\n  if (n < 1) throw new Error(\"Equations without an arrow are not supported.\");\n  if (n > 1) throw new Error('Equation must contain exactly one arrow (\"->\").');\n  var [s, r] = e.split(\"->\");\n  l(-1 === s.indexOf(\"...\"), () => 'The ellipsis notation (\"...\") is not supported yet.');\n  var a = s.split(\",\"),\n      i = a.length;\n  if (t !== i) throw new Error(\"Expected \".concat(i, \" input tensors, received \").concat(t));\n  if (i > 2) throw new Error(\"Support for more than 2 input tensors is not implemented yet.\");\n  var o = [];\n\n  var _loop9 = function _loop9(_e75) {\n    var t = r[_e75];\n    if (!a.some(e => -1 !== e.indexOf(t))) throw new Error(\"Output subscripts contain the label \".concat(t, \" not present in the input subscripts.\"));\n    -1 === o.indexOf(t) && o.push(t);\n  };\n\n  for (var _e75 = 0; _e75 < r.length; ++_e75) {\n    _loop9(_e75);\n  }\n\n  for (var _e76 = 0; _e76 < s.length; ++_e76) {\n    var _t77 = s[_e76];\n    -1 === o.indexOf(_t77) && \",\" !== _t77 && o.push(_t77);\n  }\n\n  var u = new Array(a.length);\n\n  for (var _e77 = 0; _e77 < i; ++_e77) {\n    if (new Set(a[_e77].split(\"\")).size !== a[_e77].length) throw new Error(\"Found duplicate axes in input component \".concat(a[_e77], \". Support for duplicate axes in input is not implemented yet.\"));\n    u[_e77] = [];\n\n    for (var _t78 = 0; _t78 < a[_e77].length; ++_t78) {\n      u[_e77].push(o.indexOf(a[_e77][_t78]));\n    }\n  }\n\n  var c = o.length,\n      h = [];\n\n  for (var _e78 = r.length; _e78 < c; ++_e78) {\n    h.push(_e78);\n  }\n\n  return {\n    allDims: o,\n    summedDims: h,\n    idDims: u\n  };\n}\n\nfunction jo(e, t) {\n  var n = new Array(e);\n  n.fill(-1);\n\n  for (var _e79 = 0; _e79 < t.length; ++_e79) {\n    n[t[_e79]] = _e79;\n  }\n\n  var s = [];\n\n  for (var _t79 = 0; _t79 < e; ++_t79) {\n    -1 === n[_t79] && s.push(_t79);\n  }\n\n  return n = n.filter(e => -1 !== e), {\n    permutationIndices: n,\n    expandDims: s\n  };\n}\n\nfunction qo(e, t, n) {\n  var s = new Array(e);\n\n  var _loop10 = function _loop10(_e80) {\n    var r = n[_e80].shape;\n\n    var _loop11 = function _loop11(_n43) {\n      void 0 === s[t[_e80][_n43]] ? s[t[_e80][_n43]] = r[_n43] : l(s[t[_e80][_n43]] === r[_n43], () => \"Expected dimension \".concat(s[t[_e80][_n43]], \" at axis \").concat(_n43, \" of input shaped \").concat(JSON.stringify(r), \", but got dimension \").concat(r[_n43]));\n    };\n\n    for (var _n43 = 0; _n43 < t[_e80].length; ++_n43) {\n      _loop11(_n43);\n    }\n  };\n\n  for (var _e80 = 0; _e80 < n.length; ++_e80) {\n    _loop10(_e80);\n  }\n}\n\nfunction Ko(e, t) {\n  var n = e,\n      s = [];\n  var r = 0;\n  0 === e.length && n.push(-1), r = e.length + 1;\n\n  for (var _e81 = 0; _e81 < r; ++_e81) {\n    s.push([]);\n  }\n\n  var a = [];\n\n  for (var _e82 = 0; _e82 < n.length; ++_e82) {\n    var _r36 = Yo(t, n[_e82]);\n\n    for (var _t80 of _r36) {\n      -1 === a.indexOf(_t80) && (s[_e82].push(_t80), a.push(_t80));\n    }\n  }\n\n  return {\n    path: n,\n    steps: s\n  };\n}\n\nfunction Xo(e) {\n  return e.every((e, t) => e === t);\n}\n\nfunction Yo(e, t) {\n  var n = [];\n\n  for (var _s48 = 0; _s48 < e.length; ++_s48) {\n    0 !== e[_s48].length && -1 === e[_s48].indexOf(t) && -1 !== t || n.push(_s48);\n  }\n\n  return n;\n}\n\nfunction Jo(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = [];\n  if (\"number\" == typeof t) l(e.shape[n] % t == 0, () => \"Number of splits must evenly divide the axis.\"), s = new Array(t).fill(e.shape[n] / t);else {\n    l(t.reduce((e, t) => (-1 === t && (e += 1), e), 0) <= 1, () => \"There should be only one negative value in split array.\");\n\n    var _r37 = t.indexOf(-1);\n\n    if (-1 !== _r37) {\n      var _s49 = t.reduce((e, t) => t > 0 ? e + t : e);\n\n      t[_r37] = e.shape[n] - _s49;\n    }\n\n    l(e.shape[n] === t.reduce((e, t) => e + t), () => \"The sum of sizes must match the size of the axis dimension.\"), s = t;\n  }\n  return s;\n}\n\nfunction Zo(e, t) {\n  var n,\n      s = !1;\n\n  for (e <= 30 ? (n = e, s = !0) : n = R(e, Math.floor(Math.sqrt(e))); !s;) {\n    n > t || n === e ? s = !0 : n = R(e, n + 1);\n  }\n\n  return n;\n}\n\nfunction Qo(e, t, n) {\n  var s = [],\n      r = e.length;\n\n  for (var _a24 = 0; _a24 < r; _a24++) {\n    s.push(_a24 !== t ? e[_a24] : n);\n  }\n\n  return s;\n}\n\nfunction el(e, t, n, s) {\n  var r = t.shape.length,\n      a = e.shape.length;\n  if (0 !== s && (s < -r || s > r)) throw new Error(\"Expect batchDims in the range of [-\".concat(r, \", \").concat(r, \"], but got \").concat(s));\n  if (s < 0 && (s += r), s > a) throw new Error(\"batchDims (\".concat(s, \") must be less than rank(x) (\\n    \").concat(a, \").\"));\n  if (n < s) throw new Error(\"batchDims (\".concat(s, \") must be less than or equal to axis (\").concat(n, \").\"));\n\n  for (var _n44 = 0; _n44 < s; ++_n44) {\n    if (e.shape[_n44] !== t.shape[_n44]) throw new Error(\"x.shape[\".concat(_n44, \"]: \").concat(e.shape[_n44], \" should be equal to indices.shape[\").concat(_n44, \"]: \").concat(t.shape[_n44], \".\"));\n  }\n\n  var i = e.shape[n],\n      o = [];\n  var l = 1,\n      u = 1,\n      c = 1;\n\n  for (var _t81 = 0; _t81 < s; ++_t81) {\n    o.push(e.shape[_t81]), l *= e.shape[_t81];\n  }\n\n  for (var _t82 = s; _t82 < n; _t82++) {\n    o.push(e.shape[_t82]), u *= e.shape[_t82];\n  }\n\n  for (var _e83 = s; _e83 < r; _e83++) {\n    o.push(t.shape[_e83]);\n  }\n\n  for (var _t83 = n + 1; _t83 < a; _t83++) {\n    o.push(e.shape[_t83]), c *= e.shape[_t83];\n  }\n\n  return {\n    batchSize: l,\n    sliceSize: c,\n    outerSize: u,\n    dimSize: i,\n    outputShape: o\n  };\n}\n\nfunction tl(e) {\n  try {\n    return e.map(e => He(e));\n  } catch (e) {\n    throw new Error(\"Failed to decode encoded string bytes into utf-8, error: \".concat(e));\n  }\n}\n\nfunction nl(e) {\n  return e.map(e => Ge(e));\n}\n\nvar sl = {\n  __proto__: null,\n  slice_util: Gn,\n  segment_util: {\n    __proto__: null,\n    segOpComputeOptimalWindowSize: Zo,\n    computeOutShape: Qo,\n    collectGatherOpShapeInfo: el\n  },\n  fromUint8ToStringArray: tl,\n  fromStringArrayToUint8: nl,\n  upcastType: dt,\n  axesAreInnerMostDims: jr,\n  combineLocations: qr,\n  computeOutAndReduceShapes: Kr,\n  expandShapeToKeepDim: Xr,\n  assertAxesAreInnerMostDims: Yr,\n  getAxesPermutation: Jr,\n  getUndoAxesPermutation: Zr,\n  getInnerMostAxes: Qr,\n  getBroadcastDims: lr,\n  getReductionAxes: ur,\n  assertAndGetBroadcastShape: cr,\n  assertParamsConsistent: Co,\n  computeOutShape: So,\n  computeDilation2DInfo: ms,\n  computePool2DInfo: bs,\n  computePool3DInfo: xs,\n  computeConv2DInfo: ys,\n  computeConv3DInfo: ks,\n  computeDefaultPad: ws,\n  tupleValuesAreOne: Cs,\n  eitherStridesOrDilationsAreOne: Ss,\n  convertConv2DDataFormat: Ts,\n  getFusedDyActivation: Ei,\n  getFusedBiasGradient: Ri,\n  applyActivation: Ai,\n  shouldFuse: Fi,\n  PARALLELIZE_THRESHOLD: 30,\n  computeOptimalWindowSize: To,\n  getImageCenter: Eo,\n  getReshaped: Ro,\n  getPermuted: Ao,\n  getReshapedPermuted: Fo,\n  getSliceBeginCoords: Do,\n  getSliceSize: _o,\n  prepareAndValidate: Nn,\n  validateUpdateShape: Cn,\n  validateInput: function validateInput(e, t, n) {\n    if (t.rank < 1) throw new Error(\"tf.scatterND() expects the indices to be rank 1 or higher, but the rank was \".concat(t.rank, \".\"));\n    if (e.rank < 1) throw new Error(\"tf.scatterND() expects the updates to be rank 1 or higher, but the rank was \".concat(e.rank, \".\"));\n    if (\"int32\" !== t.dtype) throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \".concat(t.dtype));\n    if (n.length < 1) throw new Error(\"Output rank must be greater or equal to 1, but got shape: \".concat(n));\n\n    if (0 === n.length) {\n      if (0 === t.size) throw new Error(\"Indices specified for empty output. indices shape: \".concat(t.shape));\n      if (0 === e.size) throw new Error(\"Updates specified for empty output. updates shape: \".concat(e.shape));\n    }\n\n    Cn(n, t, e);\n  },\n  calculateShapes: Sn,\n  SELU_SCALEALPHA: 1.7580993408473768,\n  SELU_SCALE: 1.0507009873554805,\n  ERF_P: .3275911,\n  ERF_A1: .254829592,\n  ERF_A2: -.284496736,\n  ERF_A3: 1.421413741,\n  ERF_A4: -1.453152027,\n  ERF_A5: 1.061405429,\n  warn: Oo,\n  log: function log() {\n    V().getBool(\"IS_TEST\") || console.log(...arguments);\n  },\n  mergeRealAndImagArrays: Mo,\n  splitRealAndImagArrays: Lo,\n  complexWithEvenIndex: zo,\n  complexWithOddIndex: Bo,\n  getComplexWithIndex: Po,\n  assignToTypedArray: Wo,\n  exponents: Uo,\n  exponent: Vo,\n  decodeEinsumEquation: Ho,\n  getEinsumPermutation: jo,\n  checkEinsumDimSizes: qo,\n  getEinsumComputePath: Ko,\n  isIdentityPermutation: Xo,\n  prepareSplitSize: Jo\n};\nvar rl = {\n  kernelName: \"Abs\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, pi(pn(n, \"float32\"), -1))\n    };\n  }\n},\n    al = {\n  kernelName: \"Acos\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ga(pn(n, \"float32\")),\n            s = ui(Vr(qa(1), t));\n        return Br(ns(e, s));\n      }\n    };\n  }\n},\n    il = {\n  kernelName: \"Acosh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ui(Vr(ga(pn(n, \"float32\")), 1));\n        return ns(e, t);\n      }\n    };\n  }\n},\n    ol = {\n  kernelName: \"Add\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = e;\n        var s = ur(n.shape, r);\n        return s.length > 0 && (t = Gr(t, s)), Es(t, n.shape);\n      },\n      b: () => {\n        var t = e;\n        var n = ur(s.shape, r);\n        return n.length > 0 && (t = Gr(t, n)), Es(t, s.shape);\n      }\n    };\n  }\n},\n    ll = {\n  kernelName: \"ArgMax\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => pr(n)\n    };\n  }\n},\n    ul = {\n  kernelName: \"ArgMin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => pr(n)\n    };\n  }\n},\n    cl = {\n  kernelName: \"Asin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, ui(Vr(qa(1), ga(pn(n, \"float32\")))))\n    };\n  }\n},\n    hl = {\n  kernelName: \"Asinh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ui(es(qa(1), ga(pn(n, \"float32\"))));\n        return ns(e, t);\n      }\n    };\n  }\n},\n    dl = {\n  kernelName: \"Atan2\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = es(ga(n), ga(s));\n        var a = ss(e, ns(s, t));\n        var i = ur(n.shape, r);\n        return i.length > 0 && (a = Gr(a, i)), Es(a, n.shape);\n      },\n      b: () => {\n        var t = es(ga(n), ga(s));\n        var a = Br(ss(e, ns(n, t)));\n        var i = ur(s.shape, r);\n        return i.length > 0 && (a = Gr(a, i)), Es(a, s.shape);\n      }\n    };\n  }\n},\n    pl = {\n  kernelName: \"Atan\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, es(ga(pn(n, \"float32\")), 1))\n    };\n  }\n},\n    fl = {\n  kernelName: \"Atanh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, Vr(qa(1), ga(pn(n, \"float32\"))))\n    };\n  }\n},\n    gl = At({\n  avgPool3dGrad_: function avgPool3dGrad_(e, t, n, s, r, a) {\n    var i = Et(e, \"dy\", \"avgPool3dGrad\"),\n        o = Et(t, \"input\", \"avgPool3dGrad\");\n    var u = i,\n        c = o,\n        h = !1;\n    4 === o.rank && (h = !0, u = Es(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]]), c = Es(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), l(5 === u.rank, () => \"Error in avgPool3dGrad: dy must be rank 5 but got rank \".concat(u.rank, \".\")), l(5 === c.rank, () => \"Error in avgPool3dGrad: input must be rank 5 but got rank \".concat(c.rank, \".\")), null != a && l(f(r), () => \"Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode \".concat(a, \" but got pad \").concat(r, \".\"));\n    var d = wt.runKernel(\"AvgPool3DGrad\", {\n      dy: u,\n      input: c\n    }, {\n      filterSize: n,\n      strides: s,\n      pad: r,\n      dimRoundingMode: a\n    });\n    return h ? Es(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;\n  }\n}),\n    ml = {\n  kernelName: \"AvgPool3D\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      dimRoundingMode: o\n    } = n;\n    return {\n      x: () => gl(e, s, r, a, i, o)\n    };\n  }\n},\n    bl = At({\n  avgPoolGrad_: function avgPoolGrad_(e, t, n, s, r) {\n    var a = Et(e, \"dy\", \"avgPoolGrad\"),\n        i = Et(t, \"input\", \"avgPoolGrad\");\n    l(i.rank === a.rank, () => \"Rank of input (\".concat(i.rank, \") does not match rank of dy (\").concat(a.rank, \")\"));\n    var o = i,\n        u = a,\n        c = !1;\n    3 === i.rank && (c = !0, o = Es(i, [1, i.shape[0], i.shape[1], i.shape[2]]), u = Es(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === u.rank, () => \"Error in avgPoolGrad: dy must be rank 4 but got rank \".concat(u.rank, \".\")), l(4 === o.rank, () => \"Error in avgPoolGrad: input must be rank 4 but got rank \".concat(o.rank, \".\"));\n    var h = wt.runKernel(\"AvgPoolGrad\", {\n      dy: u,\n      input: o\n    }, {\n      filterSize: n,\n      strides: s,\n      pad: r\n    });\n    return c ? Es(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;\n  }\n}),\n    xl = {\n  kernelName: \"AvgPool\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i\n    } = n;\n    return {\n      x: () => bl(e, s, r, a, i)\n    };\n  }\n},\n    yl = {\n  kernelName: \"BatchMatMul\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      transposeA: a,\n      transposeB: i\n    } = n;\n    return a || i ? !a && i ? {\n      a: () => vn(e, r, !1, !1),\n      b: () => vn(e, s, !0, !1)\n    } : a && !i ? {\n      a: () => vn(r, e, !1, !0),\n      b: () => vn(s, e, !1, !1)\n    } : {\n      a: () => vn(r, e, !0, !0),\n      b: () => vn(e, s, !0, !0)\n    } : {\n      a: () => vn(e, r, !1, !0),\n      b: () => vn(s, e, !0, !1)\n    };\n  }\n},\n    kl = {\n  kernelName: \"BatchToSpaceND\",\n  gradFunc: (e, t, n) => {\n    var {\n      blockShape: s,\n      crops: r\n    } = n;\n    return {\n      x: () => ka(e, s, r)\n    };\n  }\n},\n    wl = {\n  kernelName: \"BroadcastTo\",\n  gradFunc: (e, t, n) => {\n    var s = n.inputShape,\n        r = n.shape,\n        a = Array.from(r);\n\n    for (var _e84 = s.length - 1; _e84 >= 0; _e84--) {\n      if (s[_e84] === r[_e84]) a[_e84] = 1;else if (1 !== s[_e84]) throw new Error(\"broadcastTo(): [\".concat(s, \"] cannot be broadcast to [\").concat(r, \"].\"));\n    }\n\n    var i = [];\n\n    for (var _e85 = 0; _e85 < a.length; _e85++) {\n      a[_e85] > 1 && i.push(_e85);\n    }\n\n    return {\n      x: () => Gr(e, i, !0)\n    };\n  }\n},\n    vl = {\n  kernelName: \"Ceil\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n},\n    Il = {\n  kernelName: \"ClipByValue\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      clipValueMin: r,\n      clipValueMax: a\n    } = n;\n    return {\n      x: () => dr(ta(Sr(s, r), _r(s, a)), e, pr(e))\n    };\n  }\n},\n    $l = {\n  kernelName: \"ComplexAbs\",\n  inputsToSave: [\"x\"],\n  gradFunc: rl.gradFunc\n},\n    Nl = {\n  kernelName: \"Concat\",\n  saveAllInputs: !0,\n  gradFunc: (e, t, n) => {\n    var s = t.map(e => e.shape),\n        {\n      axis: r\n    } = n,\n        a = y(r, t[0].shape)[0],\n        i = s.map(e => e[a]);\n    return oi(e, i, a).map(e => () => e);\n  }\n},\n    Cl = {\n  kernelName: \"Conv2D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      dilations: a,\n      strides: i,\n      pad: o,\n      dataFormat: u\n    } = n;\n    return l(Cs(a), () => \"Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(a, \"'\")), {\n      x: () => Js(s.shape, e, r, i, o, u),\n      filter: () => Ti(s, e, r.shape, i, o, u)\n    };\n  }\n},\n    Sl = {\n  kernelName: \"Conv2DBackpropInput\",\n  inputsToSave: [\"dy\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      strides: a,\n      pad: i,\n      dataFormat: o,\n      dimRoundingMode: l\n    } = n;\n    return {\n      dy: () => Xs(e, r, a, i, o, 1, l),\n      filter: () => Ti(e, s, r.shape, a, i, o, l)\n    };\n  }\n},\n    Tl = At({\n  conv3DBackpropFilter_: function conv3DBackpropFilter_(e, t, n, s, r) {\n    var a = e;\n    4 === e.rank && (a = Es(e, [1, e.shape[0], e.shape[1], e.shape[2], e.shape[3]]));\n    var i = t;\n    return 4 === i.rank && (i = Es(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), l(5 === a.rank, () => \"Error in conv3dDerFilter: input must be rank 5, but got shape \".concat(a.shape, \".\")), l(5 === i.rank, () => \"Error in conv3dDerFilter: dy must be rank 5, but got shape \".concat(i.shape, \".\")), l(5 === n.length, () => \"Error in conv3dDerFilter: filterShape must be length 5, but got \".concat(n, \".\")), l(a.shape[4] === n[3], () => \"Error in conv3dDerFilter: depth of input \".concat(a.shape[4], \") must match input depth in filter (\").concat(n[3], \".\")), l(i.shape[4] === n[4], () => \"Error in conv3dDerFilter: depth of dy (\".concat(i.shape[4], \") must match output depth for filter (\").concat(n[4], \").\")), wt.runKernel(\"Conv3DBackpropFilterV2\", {\n      x: a,\n      dy: i\n    }, {\n      strides: s,\n      pad: r,\n      filterShape: n\n    });\n  }\n}),\n    El = {\n  kernelName: \"Conv3D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var {\n      dilations: s,\n      strides: r,\n      pad: a\n    } = n;\n    l(Cs(s), () => \"Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(s, \"'\"));\n    var [i, o] = t;\n    return {\n      x: () => er(i.shape, e, o, r, a),\n      filter: () => Tl(i, e, o.shape, r, a)\n    };\n  }\n},\n    Rl = {\n  kernelName: \"Cos\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(Br(Ja(pn(n, \"float32\"))), e)\n    };\n  }\n},\n    Al = {\n  kernelName: \"Cosh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(Za(pn(n, \"float32\")), e)\n    };\n  }\n},\n    Fl = {\n  kernelName: \"Cumsum\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r,\n      exclusive: a,\n      reverse: i\n    } = n;\n    return {\n      x: () => {\n        var t = Jr([r], s.rank);\n        var n = rr(e, r, a, !i);\n        return null != t && (n = $n(n, t)), n;\n      }\n    };\n  }\n},\n    Dl = {\n  kernelName: \"DepthwiseConv2dNative\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var {\n      dilations: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    } = n,\n        o = null == s ? [1, 1] : s;\n    l(Cs(o), () => \"Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '\".concat(o, \"'\"));\n    var [u, c] = t;\n    return l(4 === u.rank, () => \"Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank \".concat(u.rank, \".\")), l(4 === c.rank, () => \"Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank \".concat(c.rank, \".\")), l(u.shape[3] === c.shape[2], () => \"Error in gradient of depthwiseConv2d: number of input channels (\".concat(u.shape[3], \") must match the inChannels dimension in filter \").concat(c.shape[2], \".\")), l(Ss(r, o), () => \"Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides \".concat(r, \" and dilations '\").concat(o, \"'.\")), null != i && l(f(a), () => \"Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\")), {\n      x: () => Oi(u.shape, e, c, r, a, s, i),\n      filter: () => _i(u, e, c.shape, r, a, s, i)\n    };\n  }\n},\n    _l = {\n  kernelName: \"Dilation2D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        a = {\n      x: s,\n      filter: r,\n      dy: e\n    },\n        i = {\n      x: s,\n      filter: r,\n      dy: e\n    };\n    return {\n      x: () => wt.runKernel(\"Dilation2DBackpropInput\", a, n),\n      filter: () => wt.runKernel(\"Dilation2DBackpropFilter\", i, n)\n    };\n  }\n},\n    Ol = {\n  kernelName: \"Elu\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = {\n      dy: e,\n      y: n\n    };\n    return {\n      x: () => wt.runKernel(\"EluGrad\", s)\n    };\n  }\n},\n    Ml = {\n  kernelName: \"Erf\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = ss(xr(Br(ga(n))), 2 / Math.sqrt(Math.PI));\n    return {\n      x: () => ss(e, s)\n    };\n  }\n},\n    Ll = {\n  kernelName: \"Exp\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, n)\n    };\n  }\n},\n    zl = {\n  kernelName: \"ExpandDims\",\n  inputsToSave: [\"input\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      input: () => Es(e, n.shape)\n    };\n  }\n},\n    Bl = {\n  kernelName: \"Expm1\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, xr(n))\n    };\n  }\n},\n    Pl = {\n  kernelName: \"Floor\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n},\n    Wl = {\n  kernelName: \"FloorDiv\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ns(e, pn(s, \"float32\")),\n            a = ur(n.shape, r);\n        return a.length > 0 ? Es(Gr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = ss(e, pn(n, \"float32\"));\n        var a = ur(s.shape, r);\n        a.length > 0 && (t = Es(Gr(t, a), s.shape));\n        var i = ga(s);\n        return Br(ns(t, pn(i, \"float32\")));\n      }\n    };\n  }\n},\n    Ul = {\n  kernelName: \"FusedBatchNorm\",\n  inputsToSave: [\"x\", \"mean\", \"variance\", \"scale\"],\n  gradFunc: (e, t, n) => {\n    var {\n      varianceEpsilon: s\n    } = n,\n        [r, a, i, o] = t,\n        l = null == o ? qa(1) : o,\n        u = ur(a.shape, r.shape),\n        c = [];\n\n    if (1 === a.rank) {\n      for (var _e86 = 0; _e86 < r.shape.length - 1; ++_e86) {\n        c.push(r.shape[_e86]);\n      }\n\n      c.push(1);\n    }\n\n    var h = Vr(r, a),\n        d = ss(e, l),\n        p = ja(es(i, qa(s))),\n        f = ss(ss(ss(p, p), p), qa(-.5));\n    return {\n      x: () => Es(ss(ss(e, 1 === a.rank ? wr(Es(p, [1, 1, 1, a.shape[0]]), c) : p), l), r.shape),\n      mean: () => {\n        var e = ss(ss(p, qa(-1)), d);\n        return 1 === a.rank && (e = Gr(e, u)), Es(e, a.shape);\n      },\n      variance: () => {\n        var e = ss(ss(f, h), d);\n        return 1 === a.rank && (e = Gr(e, u)), Es(e, a.shape);\n      },\n      scale: () => {\n        var t = ss(h, p);\n        var n = ss(e, t);\n        return 1 === a.rank && (n = Gr(n, u)), Es(n, a.shape);\n      },\n      offset: () => {\n        var t = e;\n        return 1 === a.rank && (t = Gr(t, u)), Es(t, a.shape);\n      }\n    };\n  }\n},\n    Vl = {\n  kernelName: \"GatherV2\",\n  inputsToSave: [\"x\", \"indices\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      axis: a\n    } = n,\n        i = y(a, s.shape)[0];\n    return {\n      x: () => {\n        var t = s.shape,\n            n = r.size,\n            o = t.slice(0, i),\n            l = o.length,\n            u = t.slice(a, t.length).slice(1),\n            c = u.length,\n            h = Gl(0, l),\n            d = Gl(l + 1, l + 1 + c),\n            p = Hl([o, [n], u]),\n            f = Es(e, p),\n            g = Es(r, [n]),\n            m = Hl([[l], h, d]),\n            b = $n(f, m);\n        var x = wi(b, g, s.shape[i]);\n        var y = Zr(m);\n        return x = $n(x, y), x;\n      },\n      indices: () => r\n    };\n  }\n};\n\nfunction Gl(e, t) {\n  var n = [];\n\n  for (var _s50 = e; _s50 < t; ++_s50) {\n    n.push(_s50);\n  }\n\n  return n;\n}\n\nfunction Hl(e) {\n  var t = [];\n\n  for (var _n45 = 0; _n45 < e.length; ++_n45) {\n    for (var _s51 = 0; _s51 < e[_n45].length; ++_s51) {\n      t.push(e[_n45][_s51]);\n    }\n  }\n\n  return t;\n}\n\nvar jl = {\n  kernelName: \"GreaterEqual\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => pr(n),\n      b: () => pr(s)\n    };\n  }\n},\n    ql = {\n  kernelName: \"Identity\",\n  gradFunc: e => ({\n    x: () => pn(e, \"float32\")\n  })\n},\n    Kl = {\n  kernelName: \"IsFinite\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n},\n    Xl = {\n  kernelName: \"IsInf\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n},\n    Yl = {\n  kernelName: \"IsNan\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n},\n    Jl = {\n  kernelName: \"LeakyRelu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      alpha: r\n    } = n,\n        a = Cr(s, 0);\n    return {\n      x: () => dr(a, e, ss(e, r))\n    };\n  }\n},\n    Zl = {\n  kernelName: \"Log1p\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, es(n, 1))\n    };\n  }\n},\n    Ql = {\n  kernelName: \"Log\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, pn(n, \"float32\"))\n    };\n  }\n},\n    eu = {\n  kernelName: \"LogSoftmax\",\n  inputsToSave: [],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r\n    } = n;\n    return {\n      logits: () => {\n        var t = xr(s);\n        return Vr(e, ss(Gr(e, r, !0), t));\n      }\n    };\n  }\n},\n    tu = At({\n  localResponseNormalizationBackprop_: function localResponseNormalizationBackprop_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : .5;\n    return wt.runKernel(\"LRNGrad\", {\n      x: e,\n      y: t,\n      dy: n\n    }, {\n      depthRadius: s,\n      bias: r,\n      alpha: a,\n      beta: i\n    });\n  }\n}),\n    nu = {\n  kernelName: \"LRN\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = n;\n    return {\n      x: () => tu(s, r, e, a, i, o, l)\n    };\n  }\n};\n\nfunction su(e, t, n, s) {\n  return t.rank < n.rank && (t = Es(t, Xr(t.shape, s))), e.rank < n.rank && (e = Es(e, Xr(e.shape, s))), {\n    x: () => ss(e, pn(hr(n, t), e.dtype))\n  };\n}\n\nvar ru = {\n  kernelName: \"Max\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      reductionIndices: r\n    } = s,\n        a = t[0],\n        i = su(e, t[1], a, y(r, a.shape));\n    return {\n      x: () => i.x()\n    };\n  }\n},\n    au = {\n  kernelName: \"Maximum\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => ss(e, pn(Sr(n, s), \"float32\")),\n      b: () => ss(e, pn(Dr(n, s), \"float32\"))\n    };\n  }\n},\n    iu = At({\n  maxPool3dGrad_: function maxPool3dGrad_(e, t, n, s, r, a, i) {\n    var o = Et(e, \"dy\", \"maxPool3dGrad\"),\n        u = Et(t, \"input\", \"maxPool3dGrad\"),\n        c = Et(n, \"output\", \"maxPool3dGrad\");\n    var h = o,\n        d = u,\n        p = c,\n        g = !1;\n    4 === u.rank && (g = !0, h = Es(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]]), d = Es(u, [1, u.shape[0], u.shape[1], u.shape[2], u.shape[3]]), p = Es(c, [1, c.shape[0], c.shape[1], c.shape[2], c.shape[3]])), l(5 === h.rank, () => \"Error in maxPool3dGrad: dy must be rank 5 but got rank \".concat(h.rank, \".\")), l(5 === d.rank, () => \"Error in maxPool3dGrad: input must be rank 5 but got rank \".concat(d.rank, \".\")), l(5 === p.rank, () => \"Error in maxPool3dGrad: output must be rank 5 but got rank \".concat(p.rank, \".\")), null != i && l(f(a), () => \"Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\"));\n    var m = wt.runKernel(\"MaxPool3DGrad\", {\n      dy: h,\n      input: d,\n      output: p\n    }, {\n      filterSize: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    });\n    return g ? Es(m, [m.shape[1], m.shape[2], m.shape[3], m.shape[4]]) : m;\n  }\n}),\n    ou = {\n  kernelName: \"MaxPool3D\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l\n    } = n;\n    return {\n      x: () => iu(e, s, r, a, i, o, l)\n    };\n  }\n},\n    lu = At({\n  maxPoolGrad_: function maxPoolGrad_(e, t, n, s, r, a, i) {\n    var o = Et(e, \"dy\", \"maxPoolGrad\"),\n        u = Et(t, \"input\", \"maxPoolGrad\"),\n        c = Et(n, \"output\", \"maxPoolGrad\");\n    return l(u.rank === o.rank, () => \"Rank of input (\".concat(u.rank, \") does not match rank of dy (\").concat(o.rank, \")\")), l(4 === o.rank, () => \"Error in maxPoolGrad: dy must be rank 4 but got rank \".concat(o.rank, \".\")), l(4 === u.rank, () => \"Error in maxPoolGrad: input must be rank 4 but got rank \".concat(u.rank, \".\")), null != i && l(f(a), () => \"Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\")), wt.runKernel(\"MaxPoolGrad\", {\n      dy: o,\n      input: u,\n      output: c\n    }, {\n      filterSize: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    });\n  }\n}),\n    uu = {\n  kernelName: \"PadV2\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var s = t[0],\n        {\n      paddings: r\n    } = n,\n        a = r.map(e => e[0]);\n    return {\n      x: () => _s(e, a, s.shape)\n    };\n  }\n},\n    cu = {\n  kernelName: \"SpaceToBatchND\",\n  gradFunc: (e, t, n) => {\n    var {\n      blockShape: s,\n      paddings: r\n    } = n;\n    return {\n      x: () => Ms(e, s, r)\n    };\n  }\n},\n    hu = {\n  kernelName: \"SplitV\",\n  gradFunc: (e, t, n) => {\n    var {\n      axis: s\n    } = n;\n    return {\n      x: () => Fs(e, s)\n    };\n  }\n},\n    du = [rl, al, il, ol, {\n  kernelName: \"AddN\",\n  saveAllInputs: !0,\n  gradFunc: (e, t) => {\n    var n = {};\n    return t.forEach((t, s) => {\n      n[s] = () => e.clone();\n    }), n;\n  }\n}, ll, ul, cl, hl, dl, pl, fl, ml, xl, yl, kl, wl, {\n  kernelName: \"Cast\",\n  gradFunc: e => ({\n    x: () => e.clone()\n  })\n}, vl, Il, $l, Nl, Sl, Cl, El, Rl, Al, Fl, Dl, _l, {\n  kernelName: \"RealDiv\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ns(e, pn(s, \"float32\")),\n            a = ur(n.shape, r);\n        return a.length > 0 ? Es(Gr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = ss(e, pn(n, \"float32\"));\n        var a = ur(s.shape, r);\n        a.length > 0 && (t = Es(Gr(t, a), s.shape));\n        var i = ga(s);\n        return Br(ns(t, pn(i, \"float32\")));\n      }\n    };\n  }\n}, Ol, Ml, Ll, zl, Bl, Wl, Pl, Ul, Vl, jl, ql, Kl, Xl, Yl, Jl, Zl, Ql, eu, nu, ru, ru, au, ou, {\n  kernelName: \"MaxPool\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o\n    } = n;\n    return {\n      x: () => lu(e, s, r, a, i, o)\n    };\n  }\n}, {\n  kernelName: \"Mean\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r\n    } = n,\n        a = y(r, s.shape),\n        i = d(Kr(s.shape, a)[1]);\n    return {\n      x: () => {\n        var t = s.shape.slice();\n        a.forEach(e => {\n          t[e] = 1;\n        });\n        var n = Es(e, t);\n        return ns(ss(n, ca(s.shape, \"float32\")), i);\n      }\n    };\n  }\n}, {\n  kernelName: \"Min\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      axis: r\n    } = s,\n        [a, i] = t,\n        o = su(e, i, a, y(r, a.shape));\n    return {\n      x: () => o.x()\n    };\n  }\n}, {\n  kernelName: \"Minimum\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => ss(e, pn(_r(n, s), \"float32\")),\n      b: () => ss(e, pn(Cr(n, s), \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"MirrorPad\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var s = t[0],\n        {\n      paddings: r\n    } = n,\n        a = r.map(e => e[0]);\n    return {\n      x: () => _s(e, a, s.shape)\n    };\n  }\n}, {\n  kernelName: \"Mod\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ur(n.shape, r);\n        return t.length > 0 ? Es(Gr(e, t), n.shape) : e;\n      },\n      b: () => {\n        var t = ss(e, Br($r(ns(n, s)))),\n            a = ur(s.shape, r);\n        return a.length > 0 ? Es(Gr(t, a), s.shape) : t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Multiply\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ss(e, pn(s, \"float32\")),\n            a = ur(n.shape, r);\n        return a.length > 0 ? Es(Gr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = ss(e, pn(n, \"float32\")),\n            a = ur(s.shape, r);\n        return a.length > 0 ? Es(Gr(t, a), s.shape) : t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Neg\",\n  gradFunc: e => ({\n    x: () => Br(e)\n  })\n}, {\n  kernelName: \"OneHot\",\n  inputsToSave: [\"indices\"],\n  gradFunc: (e, t) => {\n    var n = t[0];\n    return {\n      indices: () => ua(n.shape, \"float32\")\n    };\n  }\n}, {\n  kernelName: \"OnesLike\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n}, {\n  kernelName: \"Pack\",\n  saveAllInputs: !0,\n  gradFunc: (e, t, n) => {\n    var {\n      axis: s\n    } = n;\n    return vi(e, s).map(e => () => e);\n  }\n}, uu, uu, {\n  kernelName: \"Pow\",\n  inputsToSave: [\"a\", \"b\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n, s, r] = t,\n        _a25 = n,\n        i = s,\n        o = cr(_a25.shape, i.shape);\n    return {\n      a: () => {\n        var t = pn(i, \"float32\");\n        var n = ss(e, ss(t, va(_a25, Vr(t, qa(1)))));\n        var s = ur(_a25.shape, o);\n        return s.length > 0 && (n = Gr(n, s)), Es(n, _a25.shape);\n      },\n      b: () => {\n        var t = Cr(_a25, 0),\n            n = dr(t, Mr(_a25), pr(_a25));\n        var s = ss(e, ss(r, n));\n        var l = ur(i.shape, o);\n        return l.length > 0 && (s = Gr(s, l)), Es(s, i.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Prelu\",\n  inputsToSave: [\"x\", \"alpha\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = Cr(n, 0);\n    return {\n      x: () => dr(r, e, ss(e, s)),\n      alpha: () => {\n        var t = dr(r, pr(e), ss(e, n));\n        var a = ur(s.shape, e.shape);\n        return a.length > 0 && (t = Gr(t, a)), Es(t, s.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Reciprocal\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, Br(ga(n)))\n    };\n  }\n}, {\n  kernelName: \"Relu6\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = ss(_r(n, 6), pi(n));\n    return {\n      x: () => ss(e, pn(s, \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"Relu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, pn(pi(n), \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"Reshape\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => Es(e, n.shape)\n    };\n  }\n}, {\n  kernelName: \"ResizeBilinear\",\n  inputsToSave: [\"images\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = {\n      dy: e,\n      images: s\n    };\n    return {\n      images: () => wt.runKernel(\"ResizeBilinearGrad\", r, n)\n    };\n  }\n}, {\n  kernelName: \"ResizeNearestNeighbor\",\n  inputsToSave: [\"images\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = {\n      dy: e,\n      images: s\n    };\n    return {\n      images: () => wt.runKernel(\"ResizeNearestNeighborGrad\", r, n)\n    };\n  }\n}, {\n  kernelName: \"Reverse\",\n  gradFunc: (e, t, n) => {\n    var {\n      dims: s\n    } = n,\n        r = y(s, e.shape);\n    return {\n      x: () => Ga(e, r)\n    };\n  }\n}, {\n  kernelName: \"Round\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n}, {\n  kernelName: \"Rsqrt\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => Br(ns(e, ss(va(n, 1.5), 2)))\n    };\n  }\n}, {\n  kernelName: \"Select\",\n  inputsToSave: [\"condition\"],\n  gradFunc: (_e87, t) => {\n    var [n] = t;\n    return {\n      condition: () => pn(pr(n), \"float32\"),\n      t: () => ss(_e87, pn(n, _e87.dtype)),\n      e: () => ss(_e87, pn(na(n), _e87.dtype))\n    };\n  }\n}, {\n  kernelName: \"Selu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = Cr(n, qa(0)),\n            s = qa(1.7580993408473768),\n            r = qa(1.0507009873554805),\n            a = ss(e, r),\n            i = ss(ss(e, s), xr(pn(n, \"float32\")));\n        return dr(t, a, i);\n      }\n    };\n  }\n}, {\n  kernelName: \"Sigmoid\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ss(n, Vr(qa(1), n)))\n    };\n  }\n}, {\n  kernelName: \"Sign\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n}, {\n  kernelName: \"Sin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(nr(pn(n, \"float32\")), e)\n    };\n  }\n}, {\n  kernelName: \"Sinh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(sr(pn(n, \"float32\")), e)\n    };\n  }\n}, {\n  kernelName: \"Slice\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      begin: r,\n      size: a\n    } = n,\n        i = s.shape,\n        [o, l] = Un(s, r, a),\n        u = [];\n\n    for (var _t84 = 0; _t84 < e.rank; _t84++) {\n      u.push([o[_t84], i[_t84] - o[_t84] - l[_t84]]);\n    }\n\n    return {\n      x: () => ya(e, u)\n    };\n  }\n}, {\n  kernelName: \"Softmax\",\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      dim: r\n    } = n,\n        a = ss(e, s);\n    return {\n      logits: () => Vr(a, ss(Gr(a, [r], !0), s))\n    };\n  }\n}, {\n  kernelName: \"Softplus\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, Ds(n))\n    };\n  }\n}, cu, cu, hu, hu, {\n  kernelName: \"Sqrt\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, ss(ui(pn(n, \"float32\")), 2))\n    };\n  }\n}, {\n  kernelName: \"SquaredDifference\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = qa(2);\n    return {\n      a: () => ss(e, ss(r, Vr(n, s))),\n      b: () => ss(e, ss(r, Vr(s, n)))\n    };\n  }\n}, {\n  kernelName: \"Square\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ss(pn(n, \"float32\"), 2))\n    };\n  }\n}, {\n  kernelName: \"Step\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n}, {\n  kernelName: \"Sub\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = cr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = e;\n        var s = ur(n.shape, r);\n        return s.length > 0 && (t = Gr(t, s)), Es(t, n.shape);\n      },\n      b: () => {\n        var t = e;\n        var n = ur(s.shape, r);\n        return n.length > 0 && (t = Gr(t, n)), Es(Br(t), s.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Sum\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = s.shape.slice(),\n        {\n      axis: a\n    } = n;\n    y(a, s.shape).forEach(e => {\n      r[e] = 1;\n    });\n    var i = Es(e, r),\n        o = ss(i, ca(s.shape, \"float32\"));\n    return {\n      x: () => o\n    };\n  }\n}, {\n  kernelName: \"Tan\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ns(e, ga(nr(n)))\n    };\n  }\n}, {\n  kernelName: \"Tanh\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(Vr(qa(1), ga(n)), e)\n    };\n  }\n}, {\n  kernelName: \"Tile\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      reps: r\n    } = n;\n    return {\n      x: () => {\n        var t = pr(s);\n        if (1 === s.rank) for (var _n46 = 0; _n46 < r[0]; ++_n46) {\n          t = es(t, _s(e, [_n46 * s.shape[0]], [s.shape[0]]));\n        } else if (2 === s.rank) for (var _n47 = 0; _n47 < r[0]; ++_n47) {\n          for (var _a26 = 0; _a26 < r[1]; ++_a26) {\n            t = es(t, _s(e, [_n47 * s.shape[0], _a26 * s.shape[1]], [s.shape[0], s.shape[1]]));\n          }\n        } else if (3 === s.rank) for (var _n48 = 0; _n48 < r[0]; ++_n48) {\n          for (var _a27 = 0; _a27 < r[1]; ++_a27) {\n            for (var _i16 = 0; _i16 < r[2]; ++_i16) {\n              t = es(t, _s(e, [_n48 * s.shape[0], _a27 * s.shape[1], _i16 * s.shape[2]], [s.shape[0], s.shape[1], s.shape[2]]));\n            }\n          }\n        } else {\n          if (4 !== s.rank) throw new Error(\"Gradient for tile operation is not implemented for rank-\".concat(s.rank, \" tensors yet.\"));\n\n          for (var _n49 = 0; _n49 < r[0]; ++_n49) {\n            for (var _a28 = 0; _a28 < r[1]; ++_a28) {\n              for (var _i17 = 0; _i17 < r[2]; ++_i17) {\n                for (var _o14 = 0; _o14 < r[3]; ++_o14) {\n                  t = es(t, _s(e, [_n49 * s.shape[0], _a28 * s.shape[1], _i17 * s.shape[2], _o14 * s.shape[3]], [s.shape[0], s.shape[1], s.shape[2], s.shape[3]]));\n                }\n              }\n            }\n          }\n        }\n        return t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Transpose\",\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      perm: r\n    } = s,\n        a = Zr(r);\n    return {\n      x: () => $n(e, a)\n    };\n  }\n}, {\n  kernelName: \"Unpack\",\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      axis: r\n    } = s;\n    return {\n      value: () => di(e, r)\n    };\n  }\n}, {\n  kernelName: \"UnsortedSegmentSum\",\n  inputsToSave: [\"segmentIds\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => function (e, t) {\n        var n = oa(t, pr(t)),\n            s = Nr(e, n);\n        var r = Sr(t, qa(0, \"int32\"));\n        var a = s.rank - r.rank;\n\n        for (var _e88 = 0; _e88 < a; ++_e88) {\n          r = yr(r, _e88 + 1);\n        }\n\n        r = ta(r, ca(s.shape, \"bool\"));\n        var i = pr(s);\n        return dr(r, s, i);\n      }(e, n)\n    };\n  }\n}, {\n  kernelName: \"ZerosLike\",\n  gradFunc: e => ({\n    x: () => pr(e)\n  })\n}];\n\nfor (var _e89 of du) {\n  ee(_e89);\n}\n\nvar pu;\n\nfunction fu() {\n  return null == pu && (pu = wt.backend.epsilon()), pu;\n}\n\nrt().prototype.abs = function () {\n  return this.throwIfDisposed(), rs(this);\n}, rt().prototype.acos = function () {\n  return this.throwIfDisposed(), as(this);\n}, rt().prototype.acosh = function () {\n  return this.throwIfDisposed(), is(this);\n}, rt().prototype.add = function (e) {\n  return this.throwIfDisposed(), es(this, e);\n}, rt().prototype.all = function (e, t) {\n  return this.throwIfDisposed(), os(this, e, t);\n}, rt().prototype.any = function (e, t) {\n  return this.throwIfDisposed(), ls(this, e, t);\n}, rt().prototype.argMax = function (e) {\n  return this.throwIfDisposed(), us(this, e);\n}, rt().prototype.argMin = function (e) {\n  return this.throwIfDisposed(), cs(this, e);\n}, rt().prototype.asScalar = function () {\n  return this.throwIfDisposed(), l(1 === this.size, () => \"The array must have only 1 element.\"), Es(this, []);\n}, rt().prototype.asType = function (e) {\n  return this.throwIfDisposed(), pn(this, e);\n}, rt().prototype.as1D = function () {\n  return this.throwIfDisposed(), Es(this, [this.size]);\n}, rt().prototype.as2D = function (e, t) {\n  return this.throwIfDisposed(), Es(this, [e, t]);\n}, rt().prototype.as3D = function (e, t, n) {\n  return this.throwIfDisposed(), Es(this, [e, t, n]);\n}, rt().prototype.as4D = function (e, t, n, s) {\n  return this.throwIfDisposed(), Es(this, [e, t, n, s]);\n}, rt().prototype.as5D = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), Es(this, [e, t, n, s, r]);\n}, rt().prototype.asin = function () {\n  return this.throwIfDisposed(), hs(this);\n}, rt().prototype.asinh = function () {\n  return this.throwIfDisposed(), ds(this);\n}, rt().prototype.atan = function () {\n  return this.throwIfDisposed(), ps(this);\n}, rt().prototype.atan2 = function (e) {\n  return this.throwIfDisposed(), fs(this, e);\n}, rt().prototype.atanh = function () {\n  return this.throwIfDisposed(), gs(this);\n}, rt().prototype.avgPool = function (e, t, n, s) {\n  return this.throwIfDisposed(), Rs(this, e, t, n, s);\n}, rt().prototype.batchToSpaceND = function (e, t) {\n  return this.throwIfDisposed(), Ms(this, e, t);\n}, rt().prototype.batchNorm = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), Ls(this, e, t, n, s, r);\n}, rt().prototype.broadcastTo = function (e) {\n  return this.throwIfDisposed(), Us(this, e);\n}, rt().prototype.cast = function (e) {\n  return this.throwIfDisposed(), pn(this, e);\n}, rt().prototype.ceil = function () {\n  return this.throwIfDisposed(), Vs(this);\n}, rt().prototype.clipByValue = function (e, t) {\n  return this.throwIfDisposed(), Gs(this, e, t);\n}, rt().prototype.concat = function (e, t) {\n  return this.throwIfDisposed(), e instanceof st && (e = [e]), Fs([this, ...e], t);\n}, rt().prototype.conv1d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Ys(this, e, t, n, s, r, a);\n}, rt().prototype.conv2dTranspose = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), Zs(this, e, t, n, s, r);\n}, rt().prototype.conv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Xs(this, e, t, n, s, r, a);\n}, rt().prototype.cos = function () {\n  return this.throwIfDisposed(), nr(this);\n}, rt().prototype.cosh = function () {\n  return this.throwIfDisposed(), sr(this);\n}, rt().prototype.cumsum = function (e, t, n) {\n  return this.throwIfDisposed(), rr(this, e, t, n);\n}, rt().prototype.depthToSpace = function (e, t) {\n  return this.throwIfDisposed(), ar(this, e, t);\n}, rt().prototype.depthwiseConv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), ir(this, e, t, n, s, r, a);\n}, rt().prototype.dilation2d = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), or(this, e, t, n, s, r);\n}, rt().prototype.divNoNan = function (e) {\n  return this.throwIfDisposed(), fr(this, e);\n}, rt().prototype.div = function (e) {\n  return this.throwIfDisposed(), ns(this, e);\n}, rt().prototype.dot = function (e) {\n  return this.throwIfDisposed(), gr(this, e);\n}, rt().prototype.elu = function () {\n  return this.throwIfDisposed(), mr(this);\n}, rt().prototype.equal = function (e) {\n  return this.throwIfDisposed(), hr(this, e);\n}, rt().prototype.erf = function () {\n  return this.throwIfDisposed(), br(this);\n}, rt().prototype.exp = function () {\n  return this.throwIfDisposed(), xr(this);\n}, rt().prototype.expandDims = function (e) {\n  return this.throwIfDisposed(), yr(this, e);\n}, rt().prototype.expm1 = function () {\n  return this.throwIfDisposed(), kr(this);\n}, rt().prototype.fft = function () {\n  return this.throwIfDisposed(), ri(this);\n}, rt().prototype.flatten = function () {\n  return this.throwIfDisposed(), Es(this, [this.size]);\n}, rt().prototype.floor = function () {\n  return this.throwIfDisposed(), $r(this);\n}, rt().prototype.floorDiv = function (e) {\n  return this.throwIfDisposed(), ts(this, e);\n}, rt().prototype.gather = function (e, t) {\n  return this.throwIfDisposed(), Nr(this, e, t);\n}, rt().prototype.greaterEqual = function (e) {\n  return this.throwIfDisposed(), Sr(this, e);\n}, rt().prototype.greater = function (e) {\n  return this.throwIfDisposed(), Cr(this, e);\n}, rt().prototype.ifft = function () {\n  return this.throwIfDisposed(), ai(this);\n}, rt().prototype.irfft = function () {\n  return this.throwIfDisposed(), ii(this);\n}, rt().prototype.isFinite = function () {\n  return this.throwIfDisposed(), Er(this);\n}, rt().prototype.isInf = function () {\n  return this.throwIfDisposed(), Rr(this);\n}, rt().prototype.isNaN = function () {\n  return this.throwIfDisposed(), Ar(this);\n}, rt().prototype.leakyRelu = function (e) {\n  return this.throwIfDisposed(), Fr(this, e);\n}, rt().prototype.lessEqual = function (e) {\n  return this.throwIfDisposed(), _r(this, e);\n}, rt().prototype.less = function (e) {\n  return this.throwIfDisposed(), Dr(this, e);\n}, rt().prototype.localResponseNormalization = function (e, t, n, s) {\n  return this.throwIfDisposed(), Or(this, e, t, n, s);\n}, rt().prototype.logSigmoid = function () {\n  return this.throwIfDisposed(), Wr(this);\n}, rt().prototype.logSoftmax = function (e) {\n  return this.throwIfDisposed(), Hr(this, e);\n}, rt().prototype.logSumExp = function (e, t) {\n  return this.throwIfDisposed(), ea(this, e, t);\n}, rt().prototype.log = function () {\n  return this.throwIfDisposed(), Mr(this);\n}, rt().prototype.log1p = function () {\n  return this.throwIfDisposed(), Lr(this);\n}, rt().prototype.logicalAnd = function (e) {\n  return this.throwIfDisposed(), ta(this, e);\n}, rt().prototype.logicalNot = function () {\n  return this.throwIfDisposed(), na(this);\n}, rt().prototype.logicalOr = function (e) {\n  return this.throwIfDisposed(), sa(this, e);\n}, rt().prototype.logicalXor = function (e) {\n  return this.throwIfDisposed(), ra(this, e);\n}, rt().prototype.matMul = function (e, t, n) {\n  return this.throwIfDisposed(), vn(this, e, t, n);\n}, rt().prototype.maxPool = function (e, t, n, s) {\n  return this.throwIfDisposed(), aa(this, e, t, n, s);\n}, rt().prototype.max = function (e, t) {\n  return this.throwIfDisposed(), Ur(this, e, t);\n}, rt().prototype.maximum = function (e) {\n  return this.throwIfDisposed(), oa(this, e);\n}, rt().prototype.mean = function (e, t) {\n  return this.throwIfDisposed(), la(this, e, t);\n}, rt().prototype.min = function (e, t) {\n  return this.throwIfDisposed(), ha(this, e, t);\n}, rt().prototype.minimum = function (e) {\n  return this.throwIfDisposed(), da(this, e);\n}, rt().prototype.mirrorPad = function (e, t) {\n  return this.throwIfDisposed(), pa(this, e, t);\n}, rt().prototype.mod = function (e) {\n  return this.throwIfDisposed(), fa(this, e);\n}, rt().prototype.mul = function (e) {\n  return this.throwIfDisposed(), ss(this, e);\n}, rt().prototype.neg = function () {\n  return this.throwIfDisposed(), Br(this);\n}, rt().prototype.norm = function (e, t, n) {\n  return this.throwIfDisposed(), Ni(this, e, t, n);\n}, rt().prototype.notEqual = function (e) {\n  return this.throwIfDisposed(), ba(this, e);\n}, rt().prototype.oneHot = function (e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  return this.throwIfDisposed(), In(this, e, t, n);\n}, rt().prototype.onesLike = function () {\n  return this.throwIfDisposed(), xa(this);\n}, rt().prototype.pad = function (e, t) {\n  return this.throwIfDisposed(), ya(this, e, t);\n}, rt().prototype.pool = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), wa(this, e, t, n, s, r);\n}, rt().prototype.pow = function (e) {\n  return this.throwIfDisposed(), va(this, e);\n}, rt().prototype.prelu = function (e) {\n  return this.throwIfDisposed(), Ia(this, e);\n}, rt().prototype.prod = function (e, t) {\n  return this.throwIfDisposed(), $a(this, e, t);\n}, rt().prototype.reciprocal = function () {\n  return this.throwIfDisposed(), Wa(this);\n}, rt().prototype.relu = function () {\n  return this.throwIfDisposed(), Ua(this);\n}, rt().prototype.relu6 = function () {\n  return this.throwIfDisposed(), Va(this);\n}, rt().prototype.reshapeAs = function (e) {\n  return this.throwIfDisposed(), Es(this, e.shape);\n}, rt().prototype.reshape = function (e) {\n  return this.throwIfDisposed(), Es(this, e);\n}, rt().prototype.resizeBilinear = function (e, t, n) {\n  return this.throwIfDisposed(), to(this, e, t, n);\n}, rt().prototype.resizeNearestNeighbor = function (e, t, n) {\n  return this.throwIfDisposed(), no(this, e, t, n);\n}, rt().prototype.reverse = function (e) {\n  return this.throwIfDisposed(), Ga(this, e);\n}, rt().prototype.rfft = function () {\n  return this.throwIfDisposed(), li(this);\n}, rt().prototype.round = function () {\n  return this.throwIfDisposed(), Ha(this);\n}, rt().prototype.rsqrt = function () {\n  return this.throwIfDisposed(), ja(this);\n}, rt().prototype.selu = function () {\n  return this.throwIfDisposed(), Ka(this);\n}, rt().prototype.separableConv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Xa(this, e, t, n, s, r, a);\n}, rt().prototype.sigmoid = function () {\n  return this.throwIfDisposed(), Ds(this);\n}, rt().prototype.sign = function () {\n  return this.throwIfDisposed(), Ya(this);\n}, rt().prototype.sin = function () {\n  return this.throwIfDisposed(), Ja(this);\n}, rt().prototype.sinh = function () {\n  return this.throwIfDisposed(), Za(this);\n}, rt().prototype.slice = function (e, t) {\n  return this.throwIfDisposed(), _s(this, e, t);\n}, rt().prototype.softmax = function (e) {\n  return this.throwIfDisposed(), si(this, e);\n}, rt().prototype.softplus = function () {\n  return this.throwIfDisposed(), Pr(this);\n}, rt().prototype.spaceToBatchND = function (e, t) {\n  return this.throwIfDisposed(), ka(this, e, t);\n}, rt().prototype.split = function (e, t) {\n  return this.throwIfDisposed(), oi(this, e, t);\n}, rt().prototype.sqrt = function () {\n  return this.throwIfDisposed(), ui(this);\n}, rt().prototype.square = function () {\n  return this.throwIfDisposed(), ga(this);\n}, rt().prototype.squaredDifference = function (e) {\n  return this.throwIfDisposed(), ci(this, e);\n}, rt().prototype.squeeze = function (e) {\n  return this.throwIfDisposed(), hi(this, e);\n}, rt().prototype.stack = function (e, t) {\n  this.throwIfDisposed();\n  var n = e instanceof st ? [this, e] : [this, ...e];\n  return di(n, t);\n}, rt().prototype.step = function (e) {\n  return this.throwIfDisposed(), pi(this, e);\n}, rt().prototype.stridedSlice = function (e, t, n, s, r, a, i, o) {\n  return this.throwIfDisposed(), fi(this, e, t, n, s, r, a, i, o);\n}, rt().prototype.sub = function (e) {\n  return this.throwIfDisposed(), Vr(this, e);\n}, rt().prototype.sum = function (e, t) {\n  return this.throwIfDisposed(), Gr(this, e, t);\n}, rt().prototype.tan = function () {\n  return this.throwIfDisposed(), gi(this);\n}, rt().prototype.tanh = function () {\n  return this.throwIfDisposed(), Os(this);\n}, rt().prototype.tile = function (e) {\n  return this.throwIfDisposed(), wr(this, e);\n}, rt().prototype.toBool = function () {\n  return this.throwIfDisposed(), pn(this, \"bool\");\n}, rt().prototype.toFloat = function () {\n  return this.throwIfDisposed(), pn(this, \"float32\");\n}, rt().prototype.toInt = function () {\n  return this.throwIfDisposed(), pn(this, \"int32\");\n}, rt().prototype.topk = function (e, t) {\n  return this.throwIfDisposed(), xi(this, e, t);\n}, rt().prototype.transpose = function (e) {\n  return this.throwIfDisposed(), $n(this, e);\n}, rt().prototype.unique = function (e) {\n  return this.throwIfDisposed(), ki(this, e);\n}, rt().prototype.unsortedSegmentSum = function (e, t) {\n  return this.throwIfDisposed(), wi(this, e, t);\n}, rt().prototype.unstack = function (e) {\n  return this.throwIfDisposed(), vi(this, e);\n}, rt().prototype.where = function (e, t) {\n  return this.throwIfDisposed(), dr(e, this, t);\n}, rt().prototype.zerosLike = function () {\n  return this.throwIfDisposed(), pr(this);\n};\n\nclass gu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, gu.prototype);\n  }\n\n}\n\nclass mu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, mu.prototype);\n  }\n\n}\n\nclass bu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, bu.prototype);\n  }\n\n}\n\nclass xu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, xu.prototype);\n  }\n\n}\n\nclass yu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, yu.prototype);\n  }\n\n}\n\nfunction ku(e, t) {\n  if (Array.isArray(e)) {\n    var _n50 = [];\n\n    for (var _s52 = 0; _s52 < t; _s52++) {\n      _n50 = _n50.concat(e);\n    }\n\n    return _n50;\n  }\n\n  {\n    var _n51 = new Array(t);\n\n    return _n51.fill(e), _n51;\n  }\n}\n\nfunction wu(e, t) {\n  if (!e) throw new yu(t);\n}\n\nfunction vu(e, t) {\n  var n = 0;\n\n  for (var _s53 of e) {\n    _s53 === t && n++;\n  }\n\n  return n;\n}\n\nfunction Iu(e) {\n  return 1 === e.length ? e[0] : e;\n}\n\nfunction $u(e) {\n  return Array.isArray(e) ? e : [e];\n}\n\nfunction Nu(e) {\n  var t = e.replace(/(.)([A-Z][a-z0-9]+)/g, \"$1_$2\").replace(/([a-z])([A-Z])/g, \"$1_$2\").toLowerCase();\n  return \"_\" !== t[0] ? t : \"private\" + t;\n}\n\nfunction Cu(e) {\n  return e.length <= 1 || -1 === e.indexOf(\"_\") ? e : e.replace(/[_]+(\\w|$)/g, (e, t) => t.toUpperCase());\n}\n\nvar Su = {};\n\nfunction Tu(e) {\n  if (null == e) return null;\n  var t = {};\n  return t.className = e.getClassName(), t.config = e.getConfig(), t;\n}\n\nfunction Eu(e) {\n  if (null != e && \"object\" == typeof e) if (Array.isArray(e)) e.forEach(e => Eu(e));else {\n    var _t85 = Object.keys(e);\n\n    for (var _n52 of _t85) {\n      var _t86 = e[_n52];\n      null != _t86 && \"object\" == typeof _t86 && (Array.isArray(_t86) || \"ndarray\" !== _t86.type || \"number\" != typeof _t86.value ? Eu(_t86) : e[_n52] = _t86.value);\n    }\n  }\n}\n\nfunction Ru(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"object\";\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n\n  if (\"string\" == typeof e) {\n    var _r38 = e;\n\n    var _a29;\n\n    if (_r38 in n) _a29 = n[_r38];else if (_r38 in Su) _a29 = Su[_r38];else if (_a29 = t[_r38], null == _a29) throw new bu(\"Unknown \".concat(s, \": \").concat(e, \". This may be due to one of the following reasons:\\n1. The \").concat(s, \" is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\\n2. The custom \").concat(s, \" is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().\"));\n    return _a29;\n  }\n\n  {\n    var _a30 = e;\n    if (null == _a30.className || null == _a30.config) throw new bu(\"\".concat(s, \": Improper config format: \").concat(JSON.stringify(_a30), \".\\n'className' and 'config' must set.\"));\n    var _i18 = _a30.className;\n\n    var _o15, _l9;\n\n    if (_i18 in n ? [_o15, _l9] = n[_i18] : _i18 in Su ? [_o15, _l9] = Su.className : _i18 in t && ([_o15, _l9] = t[_i18]), null == _o15) throw new bu(\"Unknown \".concat(s, \": \").concat(_i18, \". This may be due to one of the following reasons:\\n1. The \").concat(s, \" is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\\n2. The custom \").concat(s, \" is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().\"));\n\n    if (null != _l9) {\n      var _e90 = {};\n\n      for (var _t88 of Object.keys(Su)) {\n        _e90[_t88] = Su[_t88];\n      }\n\n      for (var _t89 of Object.keys(n)) {\n        _e90[_t89] = n[_t89];\n      }\n\n      _a30.config.customObjects = _e90;\n\n      var _t87 = Object.assign({}, Su);\n\n      for (var _e91 of Object.keys(n)) {\n        Su[_e91] = n[_e91];\n      }\n\n      Eu(_a30.config);\n\n      var _s54 = _l9(_o15, _a30.config, n, r);\n\n      return Su = Object.assign({}, _t87), _s54;\n    }\n\n    {\n      var _e92 = Object.assign({}, Su);\n\n      for (var _e93 of Object.keys(n)) {\n        Su[_e93] = n[_e93];\n      }\n\n      var _t90 = new _o15(_a30.config);\n\n      return Su = Object.assign({}, _e92), _t90;\n    }\n  }\n}\n\nfunction Au(e, t) {\n  return -1 * function (e, t) {\n    return e < t ? -1 : e > t ? 1 : 0;\n  }(e, t);\n}\n\nfunction Fu(e) {\n  if (null == e) return e;\n  var t = [];\n\n  for (var _n53 of e) {\n    -1 === t.indexOf(_n53) && t.push(_n53);\n  }\n\n  return t;\n}\n\nfunction Du(e) {\n  if (null == e) throw new bu(\"Invalid value in obj: \".concat(JSON.stringify(e)));\n\n  for (var _t91 in e) {\n    if (e.hasOwnProperty(_t91)) return !1;\n  }\n\n  return !0;\n}\n\nfunction _u(e, t, n) {\n  if (null != n && e.indexOf(n) < 0) throw new bu(\"\".concat(n, \" is not a valid \").concat(t, \".  Valid values are \").concat(e, \" or null/undefined.\"));\n}\n\nfunction Ou(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Infinity;\n  return wu(n >= 0), wu(s >= n), Array.isArray(e) && e.length >= n && e.length <= s && e.every(e => typeof e === t);\n}\n\nfunction Mu(e, t) {\n  Array.isArray(e) ? (l(e.length > 0, () => \"\".concat(t, \" is unexpectedly an empty array.\")), e.forEach((e, n) => Mu(e, \"element \".concat(n + 1, \" of \").concat(t)))) : l(Number.isInteger(e) && e > 0, () => \"Expected \".concat(t, \" to be a positive integer, but got \").concat(Lu(e), \".\"));\n}\n\nfunction Lu(e) {\n  return null === e ? \"null\" : Array.isArray(e) ? \"[\" + e.map(e => Lu(e)).join(\",\") + \"]\" : \"string\" == typeof e ? \"\\\"\".concat(e, \"\\\"\") : \"\".concat(e);\n}\n\nfunction zu(e) {\n  return \"relu\" === e ? \"relu\" : \"linear\" === e ? \"linear\" : \"elu\" === e ? \"elu\" : null;\n}\n\nfunction Bu(e, t) {\n  return Yn(() => ui(Gr(ss(e, e), t, !0)));\n}\n\nclass Pu extends Hn {\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass Wu extends Pu {\n  constructor(e) {\n    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Yn(() => {\n      var t = Bu(e, this.axis),\n          n = Gs(t, 0, this.maxValue);\n      return ss(e, ns(n, es(fu(), t)));\n    });\n  }\n\n  getConfig() {\n    return {\n      maxValue: this.maxValue,\n      axis: this.axis\n    };\n  }\n\n}\n\nWu.className = \"MaxNorm\", qn(Wu);\n\nclass Uu extends Pu {\n  constructor(e) {\n    super(), this.defaultAxis = 0, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Yn(() => ns(e, es(fu(), Bu(e, this.axis))));\n  }\n\n  getConfig() {\n    return {\n      axis: this.axis\n    };\n  }\n\n}\n\nUu.className = \"UnitNorm\", qn(Uu);\n\nclass Vu extends Pu {\n  apply(e) {\n    return Ua(e);\n  }\n\n}\n\nVu.className = \"NonNeg\", qn(Vu);\n\nclass Gu extends Pu {\n  constructor(e) {\n    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = null != e.minValue ? e.minValue : this.defaultMinValue, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.rate = null != e.rate ? e.rate : this.defaultRate, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Yn(() => {\n      var t = Bu(e, this.axis),\n          n = es(ss(this.rate, Gs(t, this.minValue, this.maxValue)), ss(1 - this.rate, t));\n      return ss(e, ns(n, es(fu(), t)));\n    });\n  }\n\n  getConfig() {\n    return {\n      minValue: this.minValue,\n      maxValue: this.maxValue,\n      rate: this.rate,\n      axis: this.axis\n    };\n  }\n\n}\n\nGu.className = \"MinMaxNorm\", qn(Gu);\nvar Hu = {\n  maxNorm: \"MaxNorm\",\n  minMaxNorm: \"MinMaxNorm\",\n  nonNeg: \"NonNeg\",\n  unitNorm: \"UnitNorm\"\n};\n\nfunction ju(e) {\n  return Tu(e);\n}\n\nfunction qu(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Ru(e, jn.getMap().classNameMap, t, \"constraint\");\n}\n\nfunction Ku(e) {\n  return null == e ? null : \"string\" == typeof e ? qu({\n    className: e in Hu ? Hu[e] : e,\n    config: {}\n  }) : e instanceof Pu ? e : qu(e);\n}\n\nvar Xu = [\"channelsFirst\", \"channelsLast\"],\n    Yu = [\"nearest\", \"bilinear\"],\n    Ju = [\"valid\", \"same\", \"causal\"],\n    Zu = [\"max\", \"avg\"],\n    Qu = [\"sum\", \"mul\", \"concat\", \"ave\"],\n    ec = new Map();\n\nfunction tc(e) {\n  _u(Xu, \"DataFormat\", e);\n}\n\nfunction nc(e) {\n  _u(Ju, \"PaddingMode\", e);\n}\n\nfunction sc(e) {\n  _u(Zu, \"PoolMode\", e);\n}\n\nvar rc = [];\n\nfunction ac(e, t) {\n  rc.push(e);\n\n  try {\n    var _e94 = t();\n\n    return rc.pop(), _e94;\n  } catch (e) {\n    throw rc.pop(), e;\n  }\n}\n\nfunction ic(e) {\n  if (!uc(e)) throw new Error(\"Not a valid tensor name: '\" + e + \"'\");\n  return (0 === rc.length ? \"\" : rc.join(\"/\") + \"/\") + e;\n}\n\nfunction oc(e) {\n  if (!uc(e)) throw new Error(\"Not a valid tensor name: '\" + e + \"'\");\n  ec.has(e) || ec.set(e, 0);\n  var t = ec.get(e);\n\n  if (ec.set(e, ec.get(e) + 1), t > 0) {\n    var _n54 = \"\".concat(e, \"_\").concat(t);\n\n    return ec.set(_n54, 1), _n54;\n  }\n\n  return e;\n}\n\nvar lc = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\\._\\/]*$/);\n\nfunction uc(e) {\n  return !!e.match(lc);\n}\n\nfunction cc(e, t, n) {\n  null == t && (t = 0), null == n && (n = e.length);\n  var s = 1;\n\n  for (var _r39 = t; _r39 < n; ++_r39) {\n    s *= e[_r39];\n  }\n\n  return s;\n}\n\nfunction hc(e) {\n  if (0 === e.length) return Number.NaN;\n  var t = Number.POSITIVE_INFINITY;\n\n  for (var _n55 = 0; _n55 < e.length; _n55++) {\n    var _s55 = e[_n55];\n    _s55 < t && (t = _s55);\n  }\n\n  return t;\n}\n\nfunction dc(e) {\n  if (0 === e.length) return Number.NaN;\n  var t = Number.NEGATIVE_INFINITY;\n\n  for (var _n56 = 0; _n56 < e.length; _n56++) {\n    var _s56 = e[_n56];\n    _s56 > t && (t = _s56);\n  }\n\n  return t;\n}\n\nfunction pc(e, t) {\n  if (t < e) throw new bu(\"end (\".concat(t, \") < begin (\").concat(e, \") is forbidden.\"));\n  var n = [];\n\n  for (var _s57 = e; _s57 < t; ++_s57) {\n    n.push(_s57);\n  }\n\n  return n;\n}\n\nfunction fc(e, t) {\n  return pn(e, t);\n}\n\nfunction gc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var n = e.shape.slice();\n  return t < 0 && (t = n.length + t + 1), n.splice(t, 0, 1), Es(e, n);\n}\n\nfunction mc(e, t, n) {\n  return Yn(() => {\n    switch (e.rank) {\n      case 1:\n        return Qa(e, t, n);\n\n      case 2:\n        return ei(e, [t, 0], [n, e.shape[1]]);\n\n      case 3:\n        return ti(e, [t, 0, 0], [n, e.shape[1], e.shape[2]]);\n\n      case 4:\n        return ni(e, [t, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3]]);\n\n      case 5:\n        return _s(e, [t, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4]]);\n\n      case 6:\n        return _s(e, [t, 0, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4], e.shape[5]]);\n\n      default:\n        throw new bu(\"sliceAlongFirstAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction bc(e, t, n) {\n  return Yn(() => {\n    switch (e.rank) {\n      case 1:\n        return Qa(e, t, n);\n\n      case 2:\n        return ei(e, [0, t], [e.shape[0], n]);\n\n      case 3:\n        return ti(e, [0, 0, t], [e.shape[0], e.shape[1], n]);\n\n      case 4:\n        return ni(e, [0, 0, 0, t], [e.shape[0], e.shape[1], e.shape[2], n]);\n\n      default:\n        throw new bu(\"sliceAlongLastAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction xc(e, t, n, s) {\n  return Yn(() => {\n    switch (e.rank) {\n      case 1:\n        return Qa(e, t, n);\n\n      case 2:\n        switch (s) {\n          case 1:\n            return mc(e, t, n);\n\n          case 2:\n            return bc(e, t, n);\n\n          default:\n            throw new bu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      case 3:\n        switch (s) {\n          case 1:\n            return mc(e, t, n);\n\n          case 2:\n            return ti(e, [0, t, 0], [e.shape[0], n, e.shape[2]]);\n\n          case 3:\n            return bc(e, t, n);\n\n          default:\n            throw new bu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      case 4:\n        switch (s) {\n          case 1:\n            return mc(e, t, n);\n\n          case 2:\n            return ni(e, [0, t, 0, 0], [e.shape[0], n, e.shape[2], e.shape[3]]);\n\n          case 3:\n            return ni(e, [0, 0, t, 0], [e.shape[0], e.shape[1], n, e.shape[3]]);\n\n          case 4:\n            return bc(e, t, n);\n\n          default:\n            throw new bu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      default:\n        throw new bu(\"sliceAlongLastAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction yc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var n;\n  return t < 0 && (n = e[0].rank, t = 0 !== n ? n : 0), t === e[0].rank && (t = -1), Fs(e, t);\n}\n\nfunction kc(e, t) {\n  switch (e.rank) {\n    case 1:\n      return Hs([e, t]);\n\n    case 2:\n      return js([e, t], 0);\n\n    case 3:\n      return qs([e, t], 0);\n\n    case 4:\n      return Ks([e, t], 0);\n\n    default:\n      throw new bu(\"concatAlongFirstAxis() received an unsupported tensor rank: \".concat(e.rank));\n  }\n}\n\nfunction wc(e, t) {\n  if (Array.isArray(t) || (t = [t]), e.rank !== t.length) throw new bu(\"The length of input n (\".concat(t.length, \") does not match the number of dimensions in input x (\").concat(e.rank, \")\"));\n  return wr(e, t);\n}\n\nfunction vc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  var s = arguments.length > 3 ? arguments[3] : undefined;\n  var r = arguments.length > 4 ? arguments[4] : undefined;\n  return La(e, t, n, s, r);\n}\n\nfunction Ic(e, t, n, s) {\n  if (e.rank < 2 || t.rank < 2) throw new xu(\"dot requires both inputs to be rank >= 2 but got x shape = \".concat(e.shape, \" and y shape = \").concat(t.shape));\n  if (t.rank >= 3 && e.shape.slice(-1)[0] !== t.shape.slice(-2)[0]) throw new xu(\"If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = \".concat(e.shape, \" and  y shape = \").concat(t.shape));\n  if (2 === e.rank && 2 === t.rank) return Mi({\n    a: e,\n    b: t,\n    transposeA: !1,\n    transposeB: !1,\n    bias: s ? Cc(e.rank, s, \"channelsLast\") : null,\n    activation: n\n  });\n  {\n    var _r40 = e.shape.slice(),\n        _a31 = _r40.pop();\n\n    e = Es(e, [-1, _a31]);\n\n    var _i19 = t.shape.slice(),\n        _o16 = _i19.pop(),\n        _l10 = _i19.pop(),\n        _u6 = [..._i19, _o16],\n        _c5 = Array.from({\n      length: t.rank\n    }, (e, n) => 0 === n ? t.rank - 2 : n <= t.rank - 2 ? n - 1 : n);\n\n    t = Es($n(t, _c5), [_l10, -1]);\n    var _h4 = [..._r40, ..._u6];\n    return Es(Mi({\n      a: e,\n      b: t,\n      transposeA: !1,\n      transposeB: !1,\n      bias: s ? Cc(e.rank, s, \"channelsLast\") : null,\n      activation: n\n    }), _h4);\n  }\n}\n\nfunction $c(e, t, n) {\n  return Yn(() => (t = Array.isArray(t) ? mi(t, \"int32\") : pn(t, \"int32\"), Nr(e, t, n)));\n}\n\nfunction Nc(e) {\n  return ss(e, e);\n}\n\nfunction Cc(e, t, n) {\n  var s = t.shape;\n  if (1 !== t.rank && t.rank !== e) throw new bu(\"Unexpected bias dimensions: \".concat(t.rank, \"; expected it to be 1 or \").concat(e));\n\n  if (5 === e) {\n    if (\"channelsFirst\" === n) return Es(t, 1 === s.length ? [1, s[0], 1, 1, 1] : [1, s[3], s[0], s[1], s[2]]);\n    if (\"channelsLast\" === n) return Es(t, 1 === s.length ? [1, 1, 1, 1, s[0]] : [1].concat(s));\n  } else if (4 === e) {\n    if (\"channelsFirst\" === n) return Es(t, 1 === s.length ? [1, s[0], 1, 1] : [1, s[2], s[0], s[1]]);\n    if (\"channelsLast\" === n) return Es(t, 1 === s.length ? [1, 1, 1, s[0]] : [1].concat(s));\n  } else if (3 === e) {\n    if (\"channelsFirst\" === n) return Es(t, 1 === s.length ? [1, s[0], 1] : [1, s[1], s[0]]);\n    if (\"channelsLast\" === n) return Es(t, 1 === s.length ? [1, 1, s[0]] : [1].concat(s));\n  } else if (e < 3) return t;\n\n  throw new bu(\"Unsupported input rank by biasAdd: \".concat(t.rank));\n}\n\nfunction Sc(e, t, n) {\n  return Yn(() => (null == n && (n = \"channelsLast\"), tc(n), es(e, Cc(e.rank, t, n))));\n}\n\nfunction Tc(e, t, n, s) {\n  return Yn(() => Ci(e, t, n, s));\n}\n\nfunction Ec(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return n ? e() : t();\n}\n\nvar Rc = [\"fanIn\", \"fanOut\", \"fanAvg\"],\n    Ac = [\"normal\", \"uniform\", \"truncatedNormal\"];\n\nclass Fc extends Hn {\n  fromConfigUsesCustomObjects() {\n    return !1;\n  }\n\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass Dc extends Fc {\n  apply(e, t) {\n    return ua(e, t);\n  }\n\n}\n\nDc.className = \"Zeros\", qn(Dc);\n\nclass _c extends Fc {\n  apply(e, t) {\n    return ca(e, t);\n  }\n\n}\n\n_c.className = \"Ones\", qn(_c);\n\nclass Oc extends Fc {\n  constructor(e) {\n    if (super(), \"object\" != typeof e) throw new bu(\"Expected argument of type ConstantConfig but got \".concat(e));\n    if (void 0 === e.value) throw new bu(\"config must have value set but got \".concat(e));\n    this.value = e.value;\n  }\n\n  apply(e, t) {\n    return Yn(() => ss(qa(this.value), ca(e, t)));\n  }\n\n  getConfig() {\n    return {\n      value: this.value\n    };\n  }\n\n}\n\nOc.className = \"Constant\", qn(Oc);\n\nclass Mc extends Fc {\n  constructor(e) {\n    super(), this.DEFAULT_MINVAL = -.05, this.DEFAULT_MAXVAL = .05, this.minval = e.minval || this.DEFAULT_MINVAL, this.maxval = e.maxval || this.DEFAULT_MAXVAL, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    return za(e, this.minval, this.maxval, t);\n  }\n\n  getConfig() {\n    return {\n      minval: this.minval,\n      maxval: this.maxval,\n      seed: this.seed\n    };\n  }\n\n}\n\nMc.className = \"RandomUniform\", qn(Mc);\n\nclass Lc extends Fc {\n  constructor(e) {\n    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new xu(\"randomNormal does not support dType \".concat(t, \".\"));\n    return vc(e, this.mean, this.stddev, t, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n\nLc.className = \"RandomNormal\", qn(Lc);\n\nclass zc extends Fc {\n  constructor(e) {\n    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new xu(\"truncatedNormal does not support dType \".concat(t, \".\"));\n    return yi(e, this.mean, this.stddev, t, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n\nzc.className = \"TruncatedNormal\", qn(zc);\n\nclass Bc extends Fc {\n  constructor(e) {\n    super(), this.gain = null != e.gain ? e.gain : 1;\n  }\n\n  apply(e, t) {\n    return Yn(() => {\n      if (2 !== e.length || e[0] !== e[1]) throw new bu(\"Identity matrix initializer can only be used for 2D square matrices.\");\n      return ss(this.gain, vr(e[0]));\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain\n    };\n  }\n\n}\n\nBc.className = \"Identity\", qn(Bc);\n\nclass Pc extends Fc {\n  constructor(e) {\n    if (super(), e.scale < 0) throw new bu(\"scale must be a positive float. Got: \".concat(e.scale));\n    this.scale = null == e.scale ? 1 : e.scale, this.mode = null == e.mode ? \"fanIn\" : e.mode, _u(Rc, \"FanMode\", this.mode), this.distribution = null == e.distribution ? \"normal\" : e.distribution, _u(Ac, \"Distribution\", this.distribution), this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    var n = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"channelsLast\";\n      var n, s;\n      if (tc(t), 2 === e.length) n = e[0], s = e[1];else if (-1 !== [3, 4, 5].indexOf(e.length)) {\n        if (\"channelsFirst\" === t) {\n          var _t92 = cc(e, 2);\n\n          n = e[1] * _t92, s = e[0] * _t92;\n        } else if (\"channelsLast\" === t) {\n          var _t93 = cc(e, 0, e.length - 2);\n\n          n = e[e.length - 2] * _t93, s = e[e.length - 1] * _t93;\n        }\n      } else {\n        var _t94 = cc(e);\n\n        n = Math.sqrt(_t94), s = Math.sqrt(_t94);\n      }\n      return [n, s];\n    }(e),\n        s = n[0],\n        r = n[1];\n\n    var a = this.scale;\n\n    if (a /= \"fanIn\" === this.mode ? Math.max(1, s) : \"fanOut\" === this.mode ? Math.max(1, r) : Math.max(1, (s + r) / 2), \"normal\" === this.distribution) {\n      var _n57 = Math.sqrt(a);\n\n      if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new xu(\"\".concat(this.getClassName(), \" does not support dType \").concat(t, \".\"));\n      return yi(e, 0, _n57, t, this.seed);\n    }\n\n    {\n      var _n58 = Math.sqrt(3 * a);\n\n      return za(e, -_n58, _n58, t);\n    }\n  }\n\n  getConfig() {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n\n}\n\nPc.className = \"VarianceScaling\", qn(Pc);\n\nclass Wc extends Pc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanAvg\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\nWc.className = \"GlorotUniform\", qn(Wc);\n\nclass Uc extends Pc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanAvg\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\nUc.className = \"GlorotNormal\", qn(Uc);\n\nclass Vc extends Pc {\n  constructor(e) {\n    super({\n      scale: 2,\n      mode: \"fanIn\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\nVc.className = \"HeNormal\", qn(Vc);\n\nclass Gc extends Pc {\n  constructor(e) {\n    super({\n      scale: 2,\n      mode: \"fanIn\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\nGc.className = \"HeUniform\", qn(Gc);\n\nclass Hc extends Pc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanIn\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\nHc.className = \"LeCunNormal\", qn(Hc);\n\nclass jc extends Pc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanIn\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Pc.className;\n  }\n\n}\n\njc.className = \"LeCunNormal\", qn(jc);\n\nclass qc extends Fc {\n  constructor(e) {\n    if (super(), this.DEFAULT_GAIN = 1, this.gain = null == e.gain ? this.DEFAULT_GAIN : e.gain, this.seed = e.seed, null != this.seed) throw new xu(\"Random seed is not implemented for Orthogonal Initializer yet.\");\n  }\n\n  apply(e, t) {\n    return Yn(() => {\n      if (e.length < 2) throw new xu(\"Shape must be at least 2D.\");\n      e[0] * e[1] > 2e3 && console.warn(\"Orthogonal initializer is being called on a matrix with more than 2000 (\".concat(e[0] * e[1], \") elements: Slowness may result.\"));\n      var t = vc(e[0] > e[1] ? [e[1], e[0]] : e, 0, 1, \"float32\");\n      var n = po.gramSchmidt(t);\n      return e[0] > e[1] && (n = $n(n)), ss(this.gain, n);\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain,\n      seed: this.seed\n    };\n  }\n\n}\n\nqc.className = \"Orthogonal\", qn(qc);\nvar Kc = {\n  constant: \"Constant\",\n  glorotNormal: \"GlorotNormal\",\n  glorotUniform: \"GlorotUniform\",\n  heNormal: \"HeNormal\",\n  heUniform: \"HeUniform\",\n  identity: \"Identity\",\n  leCunNormal: \"LeCunNormal\",\n  leCunUniform: \"LeCunUniform\",\n  ones: \"Ones\",\n  orthogonal: \"Orthogonal\",\n  randomNormal: \"RandomNormal\",\n  randomUniform: \"RandomUniform\",\n  truncatedNormal: \"TruncatedNormal\",\n  varianceScaling: \"VarianceScaling\",\n  zeros: \"Zeros\"\n};\n\nfunction Xc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Ru(e, jn.getMap().classNameMap, t, \"initializer\");\n}\n\nfunction Yc(e) {\n  return Tu(e);\n}\n\nfunction Jc(e) {\n  if (\"string\" == typeof e) {\n    var _t95 = e in Kc ? Kc[e] : e;\n\n    if (\"GlorotNormal\" === _t95) return new Uc();\n    if (\"GlorotUniform\" === _t95) return new Wc();\n    if (\"HeNormal\" === _t95) return new Vc();\n    if (\"HeUniform\" === _t95) return new Gc();\n    if (\"LeCunNormal\" === _t95) return new Hc();\n    if (\"LeCunUniform\" === _t95) return new jc();\n    {\n      var _e95 = {};\n      return _e95.className = _t95, _e95.config = {}, Xc(_e95);\n    }\n  }\n\n  return e instanceof Fc ? e : Xc(e);\n}\n\nvar Zc = 0;\n\nfunction Qc() {\n  return Zc++;\n}\n\nvar eh = {};\n\nfunction th() {\n  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"\";\n  return e in eh || (eh[e] = 0), eh[e] += 1, e + eh[e].toString();\n}\n\nfunction nh(e) {\n  return Array.isArray(e) && Array.isArray(e[0]);\n}\n\nfunction sh(e) {\n  return 0 === e.length ? [] : Array.isArray(e[0]) ? e : [e];\n}\n\nfunction rh(e) {\n  var t;\n\n  if (Array.isArray(e)) {\n    if (1 !== e.length) throw new bu(\"Expected Tensor length to be 1; got \".concat(e.length));\n    t = e[0];\n  } else t = e;\n\n  return t;\n}\n\nfunction ah(e) {\n  if (Array.isArray(e) && Array.isArray(e[0])) {\n    if (1 === e.length) return (e = e)[0];\n    throw new bu(\"Expected exactly 1 Shape; got \".concat(e.length));\n  }\n\n  return e;\n}\n\nfunction ih(e) {\n  var t = 0;\n\n  for (var _n59 of e) {\n    t += 0 === _n59.shape.length ? 1 : _n59.shape.reduce((e, t) => e * t);\n  }\n\n  return t;\n}\n\nclass oh {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"Variable\";\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n    this.dtype = null == t ? \"float32\" : t, this.shape = e.shape, this.id = Qc(), this.originalName = ic(n = null == n ? \"Variable\" : n), this.name = oc(this.originalName), this.trainable_ = s, this.constraint = r, this.val = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n      var n = arguments.length > 2 ? arguments[2] : undefined;\n      var s = arguments.length > 3 ? arguments[3] : undefined;\n      return wt.makeVariable(e, t, n, s);\n    }(e, this.trainable_, this.name, this.dtype);\n  }\n\n  read() {\n    return this.assertNotDisposed(), this.val;\n  }\n\n  write(e) {\n    return this.assertNotDisposed(), function (e, t) {\n      if (e.shape.toString() !== t.shape.toString()) throw new Error(\"Shape mismatch: \" + JSON.stringify(e.shape) + \" vs. \" + JSON.stringify(t.shape));\n    }(this.val, e), this.val.id !== e.id && (this.val.assign(e), null != this.constraint && this.val.assign(this.constraint.apply(this.val))), this;\n  }\n\n  dispose() {\n    this.assertNotDisposed(), this.val.dispose();\n  }\n\n  assertNotDisposed() {\n    if (this.val.isDisposed) throw new Error(\"LayersVariable \".concat(this.name, \" is already disposed.\"));\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this.trainable_ = e, this.val.trainable = e;\n  }\n\n}\n\nfunction lh(e) {\n  return e.map(e => e.read());\n}\n\nfunction uh(e) {\n  e.forEach(e => {\n    e[0].write(e[1]);\n  });\n}\n\nclass ch {\n  constructor(e) {\n    this.dtype = e.dtype, this.shape = e.shape, this.ndim = null != e.shape ? e.shape.length : e.ndim, this.maxNDim = e.maxNDim, this.minNDim = e.minNDim, this.axes = e.axes || {};\n  }\n\n}\n\nclass hh {\n  constructor(e, t, n, s, r, a, i) {\n    this.dtype = e, this.shape = t, this.sourceLayer = n, this.inputs = s, this.callArgs = r, this.outputTensorIndex = i, this.id = Qc(), null != a && (this.originalName = ic(a), this.name = oc(this.originalName)), this.rank = t.length;\n  }\n\n}\n\nvar dh = 0;\n\nclass ph {\n  constructor(e, t) {\n    this.callArgs = t, this.id = dh++, this.outboundLayer = e.outboundLayer, this.inboundLayers = e.inboundLayers, this.nodeIndices = e.nodeIndices, this.tensorIndices = e.tensorIndices, this.inputTensors = e.inputTensors, this.outputTensors = e.outputTensors, this.inputMasks = e.inputMasks, this.outputMasks = e.outputMasks, this.inputShapes = e.inputShapes, this.outputShapes = e.outputShapes;\n\n    for (var _t96 of e.inboundLayers) {\n      null != _t96 && _t96.outboundNodes.push(this);\n    }\n\n    e.outboundLayer.inboundNodes.push(this);\n  }\n\n  getConfig() {\n    var e = [];\n\n    for (var _t97 of this.inboundLayers) {\n      e.push(null != _t97 ? _t97.name : null);\n    }\n\n    return {\n      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,\n      inboundLayers: e,\n      nodeIndices: this.nodeIndices,\n      tensorIndices: this.tensorIndices\n    };\n  }\n\n}\n\nvar fh = 0;\n\nclass gh extends Hn {\n  constructor() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = !1, this.id = fh++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = !1, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = !1, this.inboundNodes = [], this.outboundNodes = [];\n    var t = e.name;\n\n    if (!t) {\n      var _e96 = this.getClassName();\n\n      t = Nu(_e96) + \"_\" + th(_e96);\n    }\n\n    if (this.name = t, this.trainable_ = null == e.trainable || e.trainable, null != e.inputShape || null != e.batchInputShape) {\n      var _t98;\n\n      if (null != e.batchInputShape) _t98 = e.batchInputShape;else if (null != e.inputShape) {\n        var _n61 = null;\n        null != e.batchSize && (_n61 = e.batchSize), _t98 = [_n61].concat(e.inputShape);\n      }\n      this.batchInputShape = _t98;\n      var _n60 = e.dtype;\n      null == _n60 && (_n60 = e.inputDType), null == _n60 && (_n60 = \"float32\"), this.dtype = _n60;\n    }\n\n    this.initialWeights = null != e.weights ? e.weights : null, this._refCount = null, this.fastWeightInitDuringBuild = !1;\n  }\n\n  static nodeKey(e, t) {\n    return e.name + \"_ib-\" + t.toString();\n  }\n\n  getNodeAtIndex(e, t) {\n    if (0 === this.inboundNodes.length) throw new mu(\"The layer has never been called and thus has no defined \".concat(t, \".\"));\n    if (this.inboundNodes.length <= e) throw new bu(\"Asked to get \".concat(t, \" at node \").concat(e, \", but the layer has only \").concat(this.inboundNodes.length, \" inbound nodes.\"));\n    return this.inboundNodes[e];\n  }\n\n  getInputAt(e) {\n    return Iu(this.getNodeAtIndex(e, \"input\").inputTensors);\n  }\n\n  getOutputAt(e) {\n    return Iu(this.getNodeAtIndex(e, \"output\").outputTensors);\n  }\n\n  get input() {\n    if (this.inboundNodes.length > 1) throw new gu(\"Layer \".concat(this.name, \" has multiple inbound nodes, hence the notion of \\\"layer input\\\" is ill-defined. Use `getInputAt(nodeIndex)` instead.\"));\n    if (0 === this.inboundNodes.length) throw new gu(\"Layer \".concat(this.name, \" is not connected, no input to return.\"));\n    return Iu(this.getNodeAtIndex(0, \"input\").inputTensors);\n  }\n\n  get output() {\n    if (0 === this.inboundNodes.length) throw new gu(\"Layer \".concat(this.name, \" has no inbound nodes.\"));\n    if (this.inboundNodes.length > 1) throw new gu(\"Layer \".concat(this.name, \" has multiple inbound nodes, hence the notion of \\\"layer output\\\" is ill-defined. Use `getOutputAt(nodeIndex)` instead.\"));\n    return Iu(this.getNodeAtIndex(0, \"output\").outputTensors);\n  }\n\n  get losses() {\n    return this._losses;\n  }\n\n  calculateLosses() {\n    return this.losses.map(e => e());\n  }\n\n  get updates() {\n    return this._updates;\n  }\n\n  get built() {\n    return this._built;\n  }\n\n  set built(e) {\n    this._built = e;\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this._trainableWeights.forEach(t => t.trainable = e), this.trainable_ = e;\n  }\n\n  get trainableWeights() {\n    return this.trainable_ ? this._trainableWeights.filter(e => e.trainable) : [];\n  }\n\n  set trainableWeights(e) {\n    this._trainableWeights = e;\n  }\n\n  get nonTrainableWeights() {\n    return this.trainable ? this._trainableWeights.filter(e => !e.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);\n  }\n\n  set nonTrainableWeights(e) {\n    this._nonTrainableWeights = e;\n  }\n\n  get weights() {\n    return this.trainableWeights.concat(this.nonTrainableWeights);\n  }\n\n  get stateful() {\n    return this._stateful;\n  }\n\n  resetStates() {\n    if (!this.stateful) throw new Error(\"Cannot call the resetStates() method of a non-stateful Layer object.\");\n  }\n\n  assertInputCompatibility(e) {\n    if (e = $u(e), null == this.inputSpec || 0 === this.inputSpec.length) return;\n    var t = $u(this.inputSpec);\n    if (e.length !== t.length) throw new bu(\"Layer \".concat(this.name, \" expects \").concat(t.length, \" inputs, but it received \").concat(e.length, \" input tensors. Input received: \").concat(e));\n\n    for (var _n62 = 0; _n62 < e.length; _n62++) {\n      var _s58 = e[_n62],\n          _r41 = t[_n62];\n      if (null == _r41) continue;\n      var _a32 = _s58.rank;\n      if (null != _r41.ndim && _a32 !== _r41.ndim) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected ndim=\").concat(_r41.ndim, \", found ndim=\").concat(_a32));\n      if (null != _r41.maxNDim && _a32 > _r41.maxNDim) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected max_ndim=\").concat(_r41.maxNDim, \", found ndim=\").concat(_a32));\n      if (null != _r41.minNDim && _a32 < _r41.minNDim) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected min_ndim=\").concat(_r41.minNDim, \", found ndim=\").concat(_a32, \".\"));\n      if (null != _r41.dtype && _s58.dtype !== _r41.dtype) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \" : expected dtype=\").concat(_r41.dtype, \", found dtype=\").concat(_s58.dtype, \".\"));\n\n      if (_r41.axes) {\n        var _e97 = _s58.shape;\n\n        for (var _t99 in _r41.axes) {\n          var _s59 = Number(_t99),\n              _a33 = _r41.axes[_t99],\n              _i20 = _s59 >= 0 ? _e97[_s59] : _e97[_e97.length + _s59];\n\n          if (null != _a33 && -1 === [_a33, null].indexOf(_i20)) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected axis \").concat(_s59, \" of input shape to have value \").concat(_a33, \" but got shape \").concat(_e97, \".\"));\n        }\n      }\n\n      if (null != _r41.shape) for (var _e98 = 0; _e98 < _r41.shape.length; ++_e98) {\n        var _t100 = _r41.shape[_e98],\n            _a34 = _s58.shape[_e98];\n        if (null != _t100 && null != _a34 && _t100 !== _a34) throw new bu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_r41.shape, \", found shape=\").concat(_s58.shape, \".\"));\n      }\n    }\n  }\n\n  call(e, t) {\n    return e;\n  }\n\n  invokeCallHook(e, t) {\n    null != this._callHook && this._callHook(e, t);\n  }\n\n  setCallHook(e) {\n    this._callHook = e;\n  }\n\n  clearCallHook() {\n    this._callHook = null;\n  }\n\n  apply(e, t) {\n    t = t || {}, this.assertNotDisposed();\n    var n = $u(e);\n    var s = !0;\n\n    for (var _e99 of n) {\n      if (!(_e99 instanceof hh)) {\n        s = !1;\n        break;\n      }\n    }\n\n    var r = !0;\n\n    for (var _e100 of n) {\n      if (_e100 instanceof hh) {\n        r = !1;\n        break;\n      }\n    }\n\n    if (s === r) throw new bu(\"Arguments to apply() must be all SymbolicTensors or all Tensors\");\n    return ac(this.name, () => {\n      if (!this.built) {\n        this.assertInputCompatibility(e);\n        var _t101 = [];\n\n        for (var _n63 of $u(e)) {\n          _t101.push(_n63.shape);\n        }\n\n        this.build(Iu(_t101)), this.built = !0, this.initialWeights && this.setWeights(this.initialWeights), null === this._refCount && r && (this._refCount = 1);\n      }\n\n      if (this.assertInputCompatibility(e), r) {\n        var _s60 = this.call(e, t);\n\n        var _r42 = $u(_s60),\n            _a35 = [];\n\n        for (var _e101 of _r42) {\n          -1 !== n.indexOf(_e101) && (_e101 = _e101.clone()), _a35.push(_e101);\n        }\n\n        if (_s60 = Iu(_a35), null != this.activityRegularizer) throw new xu(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");\n        return _s60;\n      }\n\n      {\n        var _n64 = function (e) {\n          e = $u(e);\n          var t = [];\n\n          for (var _n65 of e) {\n            t.push(_n65.shape);\n          }\n\n          return Iu(t);\n        }(e),\n            _s61 = this.computeOutputShape(_n64);\n\n        var _r43;\n\n        var _a36 = \"float32\";\n        if (this.warnOnIncompatibleInputShape(Array.isArray(e) ? _n64[0] : _n64), _r43 = null != _s61 && _s61.length > 0 && Array.isArray(_s61[0]) ? _s61.map((n, s) => new hh(_a36, n, this, $u(e), t, this.name, s)) : new hh(_a36, _s61, this, $u(e), t, this.name), this.addInboundNode(e, _r43, null, null, _n64, _s61, t), this._refCount++, null != this.activityRegularizer) throw new xu(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");\n        return _r43;\n      }\n    });\n  }\n\n  warnOnIncompatibleInputShape(e) {\n    if (null != this.batchInputShape) if (e.length !== this.batchInputShape.length) console.warn(\"The rank of the input tensor provided (shape: \".concat(JSON.stringify(e), \") does not match that of the batchInputShape (\").concat(JSON.stringify(this.batchInputShape), \") of the layer \").concat(this.name));else {\n      var _t102 = !1;\n\n      this.batchInputShape.forEach((n, s) => {\n        null != n && null != e[s] && e[s] !== n && (_t102 = !0);\n      }), _t102 && console.warn(\"The shape of the input tensor (\".concat(JSON.stringify(e), \") does not match the expectation of layer \").concat(this.name, \": \").concat(JSON.stringify(this.batchInputShape)));\n    }\n  }\n\n  get outputShape() {\n    if (null == this.inboundNodes || 0 === this.inboundNodes.length) throw new gu(\"The layer \".concat(this.name, \" has never been called and thus has no defined output shape.\"));\n    var e = [];\n\n    for (var _t103 of this.inboundNodes) {\n      var _n66 = JSON.stringify(_t103.outputShapes);\n\n      -1 === e.indexOf(_n66) && e.push(_n66);\n    }\n\n    if (1 === e.length) {\n      var _e102 = this.inboundNodes[0].outputShapes;\n      return Array.isArray(_e102) && Array.isArray(_e102[0]) && 1 === _e102.length ? _e102[0] : _e102;\n    }\n\n    throw new gu(\"The layer \".concat(this.name, \" has multiple inbound nodes with different output shapes. Hence the notion of \\\"output shape\\\" is ill-defined for the layer.\"));\n  }\n\n  countParams() {\n    if (!this.built) throw new mu(\"You tried to call countParams() on \".concat(this.name, \", but the layer is not built yet. Build it first by calling build(batchInputShape).\"));\n    return ih(this.weights);\n  }\n\n  build(e) {\n    this.built = !0;\n  }\n\n  getWeights() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return lh(e ? this.trainableWeights : this.weights);\n  }\n\n  setWeights(e) {\n    Yn(() => {\n      var t = this.weights;\n      if (t.length !== e.length) throw new bu(\"You called setWeights(weights) on layer \\\"\".concat(this.name, \"\\\" with a weight list of length \").concat(e.length, \", but the layer was expecting \").concat(t.length, \" weights. Provided weights: \").concat(e, \"...\"));\n      if (0 === t.length) return;\n      var n = [],\n          s = lh(t);\n\n      for (var _r44 = 0; _r44 < s.length; ++_r44) {\n        var _a37 = s[_r44],\n            _i21 = t[_r44],\n            _o17 = e[_r44];\n        if (!p(_a37.shape, _o17.shape)) throw new bu(\"Layer weight shape \".concat(_a37.shape, \" not compatible with provided weight shape \").concat(_o17.shape));\n        n.push([_i21, _o17]);\n      }\n\n      uh(n);\n    });\n  }\n\n  addWeight(e, t, n, s, r, a, i) {\n    if (-1 !== this._addedWeightNames.indexOf(e)) throw new bu(\"Duplicate weight name \".concat(e, \" for layer \").concat(this.name));\n    this._addedWeightNames.push(e), null == n && (n = \"float32\"), this.fastWeightInitDuringBuild && (s = Jc(\"zeros\"));\n    var o = s.apply(t, n),\n        l = new oh(o, n, e, a, i);\n    return o.dispose(), null != r && this.addLoss(() => r.apply(l.read())), null == a && (a = !0), a ? this._trainableWeights.push(l) : this._nonTrainableWeights.push(l), l;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    this.fastWeightInitDuringBuild = e;\n  }\n\n  addLoss(e) {\n    null == e || Array.isArray(e) && 0 === e.length || (e = $u(e), null != this._losses && this.losses.push(...e));\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  computeMask(e, t) {\n    if (!this.supportsMasking) {\n      if (null != t) {\n        if (!Array.isArray(t)) throw new TypeError(\"Layer \".concat(this.name, \" does not support masking, but was passed an inputMask.\"));\n        t.forEach(e => {\n          if (null != e) throw new TypeError(\"Layer \".concat(this.name, \" does not support masking, but was passed an inputMask.\"));\n        });\n      }\n\n      return null;\n    }\n\n    return t;\n  }\n\n  addInboundNode(e, t, n, s, r, a) {\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    var o = $u(e);\n    t = $u(t), n = $u(n), s = $u(s), r = sh(r), a = sh(a);\n    var l = [],\n        u = [],\n        c = [];\n\n    for (var _e103 of o) {\n      l.push(_e103.sourceLayer), u.push(_e103.nodeIndex), c.push(_e103.tensorIndex);\n    }\n\n    new ph({\n      outboundLayer: this,\n      inboundLayers: l,\n      nodeIndices: u,\n      tensorIndices: c,\n      inputTensors: o,\n      outputTensors: t,\n      inputMasks: n,\n      outputMasks: s,\n      inputShapes: r,\n      outputShapes: a\n    }, i);\n\n    for (var _e104 = 0; _e104 < t.length; _e104++) {\n      t[_e104].sourceLayer = this, t[_e104].nodeIndex = this.inboundNodes.length - 1, t[_e104].tensorIndex = _e104;\n    }\n  }\n\n  getConfig() {\n    var e = {\n      name: this.name,\n      trainable: this.trainable\n    };\n    return null != this.batchInputShape && (e.batchInputShape = this.batchInputShape), null != this.dtype && (e.dtype = this.dtype), e;\n  }\n\n  disposeWeights() {\n    return this.weights.forEach(e => e.dispose()), this.weights.length;\n  }\n\n  assertNotDisposed() {\n    if (0 === this._refCount) throw new Error(\"Layer '\".concat(this.name, \"' is already disposed.\"));\n  }\n\n  dispose() {\n    if (!this.built) throw new Error(\"Cannot dispose Layer \".concat(this.name, \" because it has not been built yet.\"));\n    if (null === this._refCount) throw new Error(\"Cannot dispose Layer \".concat(this.name, \" because it has not been used yet.\"));\n    this.assertNotDisposed();\n    var e = 0;\n    return 0 == --this._refCount && (e = this.disposeWeights()), {\n      refCountAfterDispose: this._refCount,\n      numDisposedVariables: e\n    };\n  }\n\n}\n\nfunction mh(e, t, n) {\n  if ((null == t || null != n && n > 0) && (t = e.sourceLayer, n = e.nodeIndex), 0 === t.inboundNodes.length) return [e];\n  {\n    var _e105 = t.inboundNodes[n];\n    if (0 === _e105.inboundLayers.length) return _e105.inputTensors;\n    {\n      var _t104 = [];\n\n      for (var _n67 = 0; _n67 < _e105.inboundLayers.length; _n67++) {\n        var _s62 = mh(_e105.inputTensors[_n67], _e105.inboundLayers[_n67], _e105.nodeIndices[_n67]);\n\n        for (var _e106 of _s62) {\n          -1 === _t104.indexOf(_e106) && _t104.push(_e106);\n        }\n      }\n\n      return _t104;\n    }\n  }\n}\n\nclass bh extends gh {\n  constructor(e) {\n    if (super({\n      dtype: e.dtype,\n      name: null != e.name ? e.name : th(\"input\").toString()\n    }), null == e.batchSize && (e.batchSize = null), null == e.sparse && (e.sparse = !1), this.trainable = !1, this.built = !0, this.sparse = e.sparse, null != e.inputShape && null != e.batchInputShape) throw new bu(\"Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.\");\n    var t = e.batchInputShape;\n\n    if (null == t) {\n      if (null == e.inputShape) throw new bu(\"An InputLayer should be passed either a `batchInputShape` or an `inputShape`.\");\n      t = [e.batchSize].concat(e.inputShape);\n    } else if (null != e.batchSize) throw new bu(\"Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.\");\n\n    var n = e.dtype || \"float32\";\n    this.batchInputShape = t, this.dtype = n, this.inputSpec = [{\n      shape: t\n    }];\n    var s = new hh(this.dtype, this.batchInputShape, this, [], {}, this.name);\n    s.nodeIndex = 0, s.tensorIndex = 0, new ph({\n      outboundLayer: this,\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: [s],\n      outputTensors: [s],\n      inputMasks: [null],\n      outputMasks: [null],\n      inputShapes: [t],\n      outputShapes: [t]\n    });\n  }\n\n  apply(e, t) {\n    throw new bu(\"Cannot pass any input to an InputLayer's apply() method. InputLayer name: \".concat(this.name));\n  }\n\n  dispose() {\n    return {\n      refCountAfterDispose: this._refCount,\n      numDisposedVariables: 0\n    };\n  }\n\n  getConfig() {\n    return {\n      batchInputShape: this.batchInputShape,\n      dtype: this.dtype,\n      sparse: this.sparse,\n      name: this.name\n    };\n  }\n\n}\n\nfunction xh(_x19) {\n  return _xh.apply(this, arguments);\n}\n\nfunction _xh() {\n  _xh = _asyncToGenerator(function* (e) {\n    if (null == e) return;\n    var t = [],\n        n = [],\n        s = [];\n\n    for (var _r174 in e) {\n      var _a147 = e[_r174];\n\n      if (\"number\" != typeof _a147) {\n        var _e527 = _a147;\n        t.push(_e527.data()), n.push(_r174), s.push(_e527);\n      }\n    }\n\n    if (t.length > 0) {\n      var _r175 = yield Promise.all(t);\n\n      for (var _t426 = 0; _t426 < _r175.length; ++_t426) {\n        e[n[_t426]] = _r175[_t426][0];\n      }\n\n      Jn(s);\n    }\n  });\n  return _xh.apply(this, arguments);\n}\n\nfunction yh(e) {\n  if (null != e) for (var _t105 in e) {\n    var _n68 = e[_t105];\n    \"number\" != typeof _n68 && _n68.dispose();\n  }\n}\n\nvar kh;\nbh.className = \"InputLayer\", qn(bh), function (e) {\n  e[e.SILENT = 0] = \"SILENT\", e[e.VERBOSE = 1] = \"VERBOSE\";\n}(kh || (kh = {}));\n\nclass wh {\n  constructor() {\n    this.validationData = null;\n  }\n\n  setParams(e) {\n    this.params = e;\n  }\n\n  onEpochBegin(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onEpochEnd(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onBatchBegin(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onBatchEnd(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onTrainBegin(e) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onTrainEnd(e) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  setModel(e) {}\n\n}\n\nclass vh {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 10;\n    null == e && (e = []), this.callbacks = e, this.queueLength = t;\n  }\n\n  append(e) {\n    this.callbacks.push(e);\n  }\n\n  setParams(e) {\n    for (var _t106 of this.callbacks) {\n      _t106.setParams(e);\n    }\n  }\n\n  setModel(e) {\n    for (var _t107 of this.callbacks) {\n      _t107.setModel(e);\n    }\n  }\n\n  onEpochBegin(e, t) {\n    var _this38 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n69 of _this38.callbacks) {\n        yield _n69.onEpochBegin(e, t);\n      }\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this39 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n70 of _this39.callbacks) {\n        yield _n70.onEpochEnd(e, t);\n      }\n    })();\n  }\n\n  onBatchBegin(e, t) {\n    var _this40 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n71 of _this40.callbacks) {\n        yield _n71.onBatchBegin(e, t);\n      }\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this41 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n72 of _this41.callbacks) {\n        yield _n72.onBatchEnd(e, t);\n      }\n    })();\n  }\n\n  onTrainBegin(e) {\n    var _this42 = this;\n\n    return _asyncToGenerator(function* () {\n      null == e && (e = {});\n\n      for (var _t108 of _this42.callbacks) {\n        yield _t108.onTrainBegin(e);\n      }\n    })();\n  }\n\n  onTrainEnd(e) {\n    var _this43 = this;\n\n    return _asyncToGenerator(function* () {\n      null == e && (e = {});\n\n      for (var _t109 of _this43.callbacks) {\n        yield _t109.onTrainEnd(e);\n      }\n    })();\n  }\n\n}\n\nclass Ih extends wh {\n  constructor() {\n    super();\n  }\n\n  onEpochBegin(e) {\n    var _this44 = this;\n\n    return _asyncToGenerator(function* () {\n      _this44.seen = 0, _this44.totals = {};\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this45 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n      var n = null == t.size ? 0 : t.size;\n      _this45.seen += n;\n\n      var _loop12 = function _loop12(_e107) {\n        var s = t[_e107];\n        if (\"number\" == typeof s) _this45.totals.hasOwnProperty(_e107) || (_this45.totals[_e107] = 0), _this45.totals[_e107] = _this45.totals[_e107] + s * n;else {\n          var _t110;\n\n          _e107 in _this45.totals ? _t110 = _this45.totals[_e107] : _this45.totals[_e107] = 0;\n\n          var _r45 = Yn(() => es(_this45.totals[_e107], ss(s, n)));\n\n          _this45.totals[_e107] = _r45, null != _t110 && _t110.dispose();\n        }\n      };\n\n      for (var _e107 in t) {\n        _loop12(_e107);\n      }\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this46 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null != t) {\n        var _loop13 = function _loop13(_e108) {\n          null != _this46.totals[_e108] && (\"number\" == typeof _this46.totals[_e108] ? t[_e108] = _this46.totals[_e108] / _this46.seen : Yn(() => {\n            var n = ss(ns(1, _this46.seen), _this46.totals[_e108]);\n            t[_e108] = n, _this46.totals[_e108].dispose(), Zn(t[_e108]);\n          }));\n        };\n\n        for (var _e108 of _this46.params.metrics) {\n          _loop13(_e108);\n        }\n      }\n    })();\n  }\n\n}\n\nclass $h extends wh {\n  onTrainBegin(e) {\n    var _this47 = this;\n\n    return _asyncToGenerator(function* () {\n      _this47.epoch = [], _this47.history = {};\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this48 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {}), _this48.epoch.push(e);\n\n      for (var _e109 in t) {\n        null == _this48.history[_e109] && (_this48.history[_e109] = []), _this48.history[_e109].push(t[_e109]);\n      }\n    })();\n  }\n\n  syncData() {\n    var _this49 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [],\n          t = [],\n          n = [];\n\n      for (var _s63 in _this49.history) {\n        var _r46 = _this49.history[_s63];\n\n        for (var _a38 = 0; _a38 < _r46.length; ++_a38) {\n          \"number\" != typeof _r46[_a38] && (e.push(_r46[_a38].data()), t.push(_s63), n.push(_a38));\n        }\n      }\n\n      var s = yield Promise.all(e);\n\n      for (var _e110 = 0; _e110 < s.length; ++_e110) {\n        _this49.history[t[_e110]][n[_e110]].dispose(), _this49.history[t[_e110]][n[_e110]] = s[_e110][0];\n      }\n    })();\n  }\n\n}\n\nclass Nh extends wh {\n  constructor(e, t) {\n    if (super(), this.currentEpoch = 0, this.yieldEvery = t || \"auto\", \"auto\" === this.yieldEvery && (this.yieldEvery = 125), \"never\" === this.yieldEvery && null != e.onYield) throw new Error(\"yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback\");\n    S(this.yieldEvery) && (this.maybeWait = function (e, t) {\n      var n,\n          s = Ve();\n      return function () {\n        var a = Ve();\n        return a - s < t || (s = a, n = e(...arguments)), n;\n      };\n    }(this.maybeWait.bind(this), this.yieldEvery)), this.trainBegin = e.onTrainBegin, this.trainEnd = e.onTrainEnd, this.epochBegin = e.onEpochBegin, this.epochEnd = e.onEpochEnd, this.batchBegin = e.onBatchBegin, this.batchEnd = e.onBatchEnd, this.yield = e.onYield;\n  }\n\n  maybeWait(e, t, n) {\n    var _this50 = this;\n\n    return _asyncToGenerator(function* () {\n      var s = [];\n      null != _this50.yield && (yield xh(n), s.push(_this50.yield(e, t, n))), s.push(No()), yield Promise.all(s);\n    })();\n  }\n\n  onEpochBegin(e, t) {\n    var _this51 = this;\n\n    return _asyncToGenerator(function* () {\n      _this51.currentEpoch = e, null != _this51.epochBegin && (yield xh(t), yield _this51.epochBegin(e, t));\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this52 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = [];\n      null != _this52.epochEnd && (yield xh(t), n.push(_this52.epochEnd(e, t))), \"epoch\" === _this52.yieldEvery && n.push(No()), yield Promise.all(n);\n    })();\n  }\n\n  onBatchBegin(e, t) {\n    var _this53 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this53.batchBegin && (yield xh(t), yield _this53.batchBegin(e, t));\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this54 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = [];\n      null != _this54.batchEnd && (yield xh(t), n.push(_this54.batchEnd(e, t))), \"batch\" === _this54.yieldEvery ? n.push(No()) : S(_this54.yieldEvery) && n.push(_this54.maybeWait(_this54.currentEpoch, e, t)), yield Promise.all(n);\n    })();\n  }\n\n  onTrainBegin(e) {\n    var _this55 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this55.trainBegin && (yield xh(e), yield _this55.trainBegin(e));\n    })();\n  }\n\n  onTrainEnd(e) {\n    var _this56 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this56.trainEnd && (yield xh(e), yield _this56.trainEnd(e));\n    })();\n  }\n\n}\n\nfunction Ch(e, t) {\n  return null == e && (e = {}), e instanceof wh ? [e] : Array.isArray(e) && e[0] instanceof wh ? e : $u(e).map(e => new Nh(e, t));\n}\n\nclass Sh {\n  constructor() {}\n\n  static registerCallbackConstructor(e, t) {\n    l(e >= 0 && Number.isInteger(e), () => \"Verbosity level is expected to be an integer >= 0, but got \".concat(e)), Sh.checkForDuplicate(t), null == Sh.constructors[e] && (Sh.constructors[e] = []), Sh.constructors[e].push(t);\n  }\n\n  static checkForDuplicate(e) {\n    for (var _t111 in Sh.constructors) {\n      Sh.constructors[+_t111].forEach(t => {\n        if (t === e) throw new bu(\"Duplicate callback constructor.\");\n      });\n    }\n  }\n\n  static clear() {\n    Sh.constructors = {};\n  }\n\n  static createCallbacks(e) {\n    var t = [];\n\n    for (var _n73 in Sh.constructors) {\n      var _s64 = +_n73;\n\n      e >= _s64 && t.push(...Sh.constructors[_s64]);\n    }\n\n    return t.map(e => new e());\n  }\n\n}\n\nfunction Th(e, t, n, s, r, a, i, o, l) {\n  var u = new $h(),\n      c = [new Ih(), ...Sh.createCallbacks(t)];\n  null != e && c.push(...e), c.push(u);\n  var h = new vh(c);\n  return h.setParams({\n    epochs: n,\n    initialEpoch: s,\n    samples: r,\n    steps: a,\n    batchSize: i,\n    verbose: t,\n    doValidation: o,\n    metrics: l\n  }), {\n    callbackList: h,\n    history: u\n  };\n}\n\nfunction Eh(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Ru(e, jn.getMap().classNameMap, t, \"layer\", n);\n}\n\nfunction Rh(e, t) {\n  return Yn(() => {\n    \"float32\" !== e.dtype && (e = pn(e, \"float32\"));\n    var n = Gr(Nc(e), t, !0),\n        s = Ir(n.shape, fu()),\n        r = ui(oa(n, s));\n    return ns(e, r);\n  });\n}\n\nfunction Ah(e, t) {\n  return Yn(() => la(Nc(Vr(t, e)), -1));\n}\n\nfunction Fh(e, t) {\n  return Yn(() => la(rs(Vr(t, e)), -1));\n}\n\nfunction Dh(e, t) {\n  return Yn(() => {\n    var n = Vr(e, t),\n        s = Gs(rs(e), fu(), Number.MAX_VALUE),\n        r = rs(ns(n, s));\n    return ss(100, la(r, -1));\n  });\n}\n\nfunction _h(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Yn(() => {\n    if (n) t = si(t);else {\n      var _e111 = Gr(t, t.shape.length - 1, !0);\n\n      t = ns(t, _e111);\n    }\n    return t = Gs(t, fu(), 1 - fu()), Br(Gr(ss(pn(e, \"float32\"), Mr(t)), t.shape.length - 1));\n  });\n}\n\nfunction Oh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Yn(() => {\n    var s = pn($r(function (e) {\n      var t = [cc(e.shape)];\n      return Es(e, t);\n    }(e)), \"int32\"),\n        r = (t = Gs(t, fu(), 1 - fu())).shape;\n    return _h(Es(In(s, r[r.length - 1]), r), t, n);\n  });\n}\n\nfunction Mh(e, t) {\n  return Yn(() => {\n    var n;\n    return n = Gs(t, fu(), 1 - fu()), n = Mr(ns(n, Vr(1, n))), la(function (e, t) {\n      if (!p(e.shape, t.shape)) throw new bu(\"logits and labels must have the same shape, but got shapes \".concat(JSON.stringify(e.shape), \" and \").concat(JSON.stringify(t.shape)));\n      return Yn(() => {\n        var n = Ua(t),\n            s = Br(rs(t));\n        return es(Vr(n, ss(t, e)), Lr(xr(s)));\n      });\n    }(e, n), -1);\n  });\n}\n\nfunction Lh(e, t) {\n  return Yn(() => {\n    var n = Rh(e, -1),\n        s = Rh(t, -1),\n        r = ss(n, s);\n    return Br(Gr(r, -1));\n  });\n}\n\nSh.constructors = {};\nvar zh = {\n  meanSquaredError: Ah,\n  meanAbsoluteError: Fh,\n  meanAbsolutePercentageError: Dh,\n  meanSquaredLogarithmicError: function meanSquaredLogarithmicError(e, t) {\n    return Yn(() => {\n      var n = Gs(t, fu(), Number.MAX_VALUE),\n          s = Mr(es(1, n)),\n          r = Gs(e, fu(), Number.MAX_VALUE),\n          a = Mr(es(1, r));\n      return la(Nc(Vr(s, a)), -1);\n    });\n  },\n  squaredHinge: function squaredHinge(e, t) {\n    return Yn(() => {\n      var n = oa(0, Vr(1, ss(e, t)));\n      return la(Nc(n), -1);\n    });\n  },\n  hinge: function hinge(e, t) {\n    return Yn(() => {\n      var n = oa(0, Vr(1, ss(e, t)));\n      return la(n, -1);\n    });\n  },\n  categoricalHinge: function categoricalHinge(e, t) {\n    return Yn(() => {\n      var n = Gr(ss(e, t), -1),\n          s = Ur(ss(Vr(1, e), t), -1);\n      return oa(0, es(1, Vr(s, n)));\n    });\n  },\n  logcosh: function logcosh(e, t) {\n    return Yn(() => {\n      var n = Math.log(2),\n          s = Vr(t, e),\n          r = Vr(es(s, Pr(ss(-2, s))), n);\n      return la(r, -1);\n    });\n  },\n  categoricalCrossentropy: _h,\n  sparseCategoricalCrossentropy: Oh,\n  binaryCrossentropy: Mh,\n  kullbackLeiblerDivergence: function kullbackLeiblerDivergence(e, t) {\n    return Yn(() => {\n      var n = Gs(e, fu(), 1),\n          s = Gs(t, fu(), 1);\n      return Gr(ss(e, Mr(ns(n, s))), -1);\n    });\n  },\n  poisson: function poisson(e, t) {\n    return Yn(() => {\n      var n = Mr(es(fu(), t));\n      return la(Vr(t, ss(e, n)), -1);\n    });\n  },\n  cosineProximity: Lh\n};\n\nfunction Bh(e) {\n  if (\"string\" == typeof e) {\n    if (e in zh) return zh[e];\n\n    var _t112 = \"Unknown loss \".concat(e);\n\n    throw e.toLowerCase().includes(\"softmaxcrossentropy\") && (_t112 = \"Unknown loss \".concat(e, \". Use \\\"categoricalCrossentropy\\\" as the string name for tf.losses.softmaxCrossEntropy\")), new bu(_t112);\n  }\n\n  return e;\n}\n\nfunction Ph(e, t) {\n  return Yn(() => {\n    var n = ss(.5, xa(t)),\n        s = fc(Cr(t, n), e.dtype);\n    return la(hr(e, s), -1);\n  });\n}\n\nfunction Wh(e, t) {\n  return Yn(() => fc(hr(us(e, -1), us(t, -1)), \"float32\"));\n}\n\nfunction Uh(e, t) {\n  return Mh(e, t);\n}\n\nfunction Vh(e, t) {\n  return e.rank === t.rank && (e = hi(e, [e.rank - 1])), (t = us(t, -1)).dtype !== e.dtype && (t = pn(t, e.dtype)), pn(hr(e, t), \"float32\");\n}\n\nvar Gh = _h,\n    Hh = Oh,\n    jh = {\n  binaryAccuracy: Ph,\n  categoricalAccuracy: Wh,\n  precision: function precision(e, t) {\n    return Yn(() => {\n      var n = function (e, t) {\n        return Yn(() => pn(Gr(ta(hr(e, 1), hr(t, 1))), \"float32\"));\n      }(e, t),\n          s = function (e, t) {\n        return Yn(() => pn(Gr(ta(hr(e, 0), hr(t, 1))), \"float32\"));\n      }(e, t),\n          r = es(n, s);\n\n      return pn(dr(Cr(r, 0), ns(n, r), 0), \"float32\");\n    });\n  },\n  categoricalCrossentropy: Gh,\n  sparseCategoricalCrossentropy: Hh,\n  mse: Ah,\n  MSE: Ah,\n  mae: Fh,\n  MAE: Fh,\n  mape: Dh,\n  MAPE: Dh,\n  cosine: Lh\n};\n\nfunction qh(e) {\n  if (\"string\" == typeof e && e in jh) return jh[e];\n  if (\"string\" != typeof e && null != e) return e;\n  throw new bu(\"Unknown metric \".concat(e));\n}\n\nfunction Kh(e) {\n  if (wu(null !== e, \"Unknown LossOrMetricFn \".concat(e)), \"string\" == typeof e) return e;\n  {\n    var _t113;\n\n    for (var _n74 of Object.keys(zh)) {\n      if (zh[_n74] === e) {\n        _t113 = _n74;\n        break;\n      }\n    }\n\n    if (void 0 !== _t113) return _t113;\n\n    for (var _n75 of Object.keys(jh)) {\n      if (jh[_n75] === e) {\n        _t113 = _n75;\n        break;\n      }\n    }\n\n    return void 0 !== _t113 ? _t113 : e.name;\n  }\n}\n\nfunction Xh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (null == e || \"object\" != typeof e || Object.getPrototypeOf(e) !== Object.prototype || !Yh(e)) throw new Error(\"User-defined metadata is expected to be a JSON object, but is not.\");\n\n  if (n) {\n    var _n76 = JSON.stringify(e);\n\n    _n76.length > 1048576 && console.warn(\"User-defined metadata of model \\\"\".concat(t, \"\\\" is too large in size (length=\").concat(_n76.length, \" when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.\"));\n  }\n}\n\nfunction Yh(e) {\n  if (null === e) return !0;\n\n  if (\"object\" == typeof e) {\n    if (Object.getPrototypeOf(e) === Object.prototype) {\n      var _t114 = Object.keys(e);\n\n      for (var _n77 of _t114) {\n        if (\"string\" != typeof _n77) return !1;\n        if (!Yh(e[_n77])) return !1;\n      }\n\n      return !0;\n    }\n\n    if (Array.isArray(e)) {\n      for (var _t115 of e) {\n        if (!Yh(_t115)) return !1;\n      }\n\n      return !0;\n    }\n\n    return !1;\n  }\n\n  {\n    var _t116 = typeof e;\n\n    return \"string\" === _t116 || \"number\" === _t116 || \"boolean\" === _t116;\n  }\n}\n\nfunction Jh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n  var s = \"\";\n\n  for (var _n78 = 0; _n78 < e.length; ++_n78) {\n    _n78 > 0 && (s = s.slice(0, s.length - 1) + \" \"), s += e[_n78], s = s.slice(0, t[_n78]), s += \" \".repeat(t[_n78] - s.length);\n  }\n\n  n(s);\n}\n\nfunction Zh(e, t, n) {\n  var s;\n\n  try {\n    s = JSON.stringify(e.outputShape);\n  } catch (e) {\n    s = \"multiple\";\n  }\n\n  Jh([\"\".concat(e.name, \" (\").concat(e.getClassName(), \")\"), s, e.countParams().toString()], t, n);\n}\n\nfunction Qh(e, t, n, s) {\n  var r;\n\n  try {\n    r = JSON.stringify(e.outputShape);\n  } catch (e) {\n    r = \"multiple\";\n  }\n\n  var a = [];\n\n  for (var _t117 of e.inboundNodes) {\n    if (!(null != n && n.length > 0 && -1 === n.indexOf(_t117))) for (var _e112 = 0; _e112 < _t117.inboundLayers.length; ++_e112) {\n      a.push(\"\".concat(_t117.inboundLayers[_e112].name, \"[\").concat(_t117.nodeIndices[_e112], \"][\").concat(_t117.tensorIndices[_e112], \"]\"));\n    }\n  }\n\n  var i = e.name,\n      o = e.getClassName(),\n      l = 0 === a.length ? \"\" : a[0];\n  Jh([\"\".concat(i, \" (\").concat(o, \")\"), r, e.countParams().toString(), l], t, s);\n\n  for (var _e113 = 1; _e113 < a.length; ++_e113) {\n    Jh([\"\", \"\", \"\", a[_e113]], t, s);\n  }\n}\n\nfunction ed(e, t, n) {\n  return (\"inboundNodes\" === e || \"outputLayers\" === e || \"inputLayers\" === e) && 0 === t && \"string\" == typeof n;\n}\n\nfunction td(e, t) {\n  if (null === e) return null;\n  if (\"string\" == typeof e) return Cu(e);\n  if (\"number\" == typeof e || \"boolean\" == typeof e) return e;\n\n  if (e instanceof Array) {\n    var _n79 = [],\n        _s65 = e.length;\n\n    for (var _r47 = 0; _r47 < _s65; ++_r47) {\n      var _s66 = e[_r47];\n      ed(t, _r47, _s66) ? _n79.push(_s66) : _n79.push(td(_s66, t));\n    }\n\n    return _n79;\n  }\n\n  {\n    var _t118 = {};\n\n    for (var _n80 of Object.keys(e)) {\n      var _s67 = e[_n80];\n      if (\"name\" === _n80 && \"string\" == typeof _s67) _t118[_n80] = _s67;else {\n        var _e114 = Cu(_n80);\n\n        _t118[_e114] = td(_s67, _e114);\n      }\n    }\n\n    return _t118;\n  }\n}\n\nfunction nd(e, t) {\n  if (null == e) return null;\n  if (\"string\" == typeof e) return Nu(e);\n  if (\"number\" == typeof e || \"boolean\" == typeof e) return e;\n\n  if (e instanceof Array) {\n    var _n81 = [],\n        _s68 = e.length;\n\n    for (var _r48 = 0; _r48 < _s68; ++_r48) {\n      var _s69 = e[_r48];\n      ed(t, _r48, _s69) ? _n81.push(_s69) : _n81.push(nd(_s69, t));\n    }\n\n    return _n81;\n  }\n\n  {\n    var _t119 = {};\n\n    for (var _n82 of Object.keys(e)) {\n      var _s70 = e[_n82];\n      _t119[Nu(_n82)] = \"name\" !== _n82 && \"className\" !== _n82 || \"string\" != typeof _s70 ? nd(_s70, _n82) : _s70;\n    }\n\n    return _t119;\n  }\n}\n\nclass sd {\n  constructor(e) {\n    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, e instanceof sd) for (var _t120 in e.id2Value) {\n      this.id2Value[_t120] = e.id2Value[_t120], _t120 in e.id2Mask && (this.id2Mask[_t120] = e.id2Mask[_t120]);\n    } else {\n      if (null == e) return;\n\n      for (var _t121 of e) {\n        this.add(_t121.key, _t121.value);\n      }\n    }\n  }\n\n  add(e, t, n) {\n    if (null != this.id2Value[e.id]) throw new bu(\"Duplicate key: name=\".concat(e.name, \", id=\").concat(e.id));\n    return this.id2Value[e.id] = function (e, t) {\n      if (null == e.dtype || e.dtype === t.dtype) return t;\n\n      try {\n        return pn(t, e.dtype);\n      } catch (n) {\n        throw new bu(\"The dtype of the feed (\".concat(t.dtype, \") can not be cast to the dtype of the key '\").concat(e.name, \"' (\").concat(e.dtype, \").\"));\n      }\n    }(e, t), this.name2Id[e.name] = e.id, null != n && (this.id2Mask[e.id] = n), this;\n  }\n\n  addFeed(e) {\n    this.add(e.key, e.value);\n  }\n\n  hasKey(e) {\n    return null != this.id2Value[e.id];\n  }\n\n  names() {\n    return Object.keys(this.name2Id);\n  }\n\n  getValue(e) {\n    if (e instanceof hh) {\n      if (null == this.id2Value[e.id]) throw new bu(\"Nonexistent key: \".concat(e.name));\n      return this.id2Value[e.id];\n    }\n\n    {\n      var _t122 = this.name2Id[e];\n      if (null == _t122) throw new bu(\"Feed dict has no SymbolicTensor name: \".concat(e));\n      return this.id2Value[_t122];\n    }\n  }\n\n  getMask(e) {\n    if (e instanceof hh) {\n      if (null == this.id2Value[e.id]) throw new bu(\"Nonexistent key: \".concat(e.name));\n      return this.id2Mask[e.id];\n    }\n\n    {\n      var _t123 = this.name2Id[e];\n      if (null == _t123) throw new bu(\"Feed dict has no SymbolicTensor name: \".concat(e));\n      return this.id2Mask[_t123];\n    }\n  }\n\n  disposeMasks() {\n    null != this.id2Mask && Jn(this.id2Mask);\n  }\n\n}\n\nvar rd = {},\n    ad = {};\n\nfunction id(e, t, n, s) {\n  var r = null != n && n.training,\n      a = Array.isArray(e),\n      i = a ? e : [e],\n      o = i.map(e => e.name),\n      u = [],\n      c = t.names();\n\n  for (var _e115 of o) {\n    -1 !== c.indexOf(_e115) ? u.push(t.getValue(_e115)) : u.push(null);\n  }\n\n  null != s && (s.maxNumTensors = -Infinity, s.minNumTensors = Infinity);\n  var h = o.join(\",\") + \"|\" + t.names().join(\",\");\n  var d, p;\n\n  if (null == rd[h]) {\n    var _e116 = function (e, t) {\n      l(null != e && e.length > 0, () => \"Expected at least one fetch, got none\");\n      var n = [],\n          s = {};\n\n      if (1 === e.length) {\n        var _r49 = ld(e[0], t);\n\n        n = _r49.sorted, s = _r49.recipientMap;\n      } else {\n        var _r50 = new Set();\n\n        for (var _a39 of e) {\n          var {\n            sorted: _e117,\n            recipientMap: _i22\n          } = ld(_a39, t);\n\n          for (var _t124 of _e117) {\n            _r50.has(_t124.name) || (n.push(_t124), _r50.add(_t124.name));\n          }\n\n          var _loop14 = function _loop14(_e118) {\n            null == s[_e118] && (s[_e118] = new Set()), _i22[_e118].forEach(t => s[_e118].add(t));\n          };\n\n          for (var _e118 in _i22) {\n            _loop14(_e118);\n          }\n        }\n      }\n\n      return {\n        sorted: n,\n        recipientCounts: od(s)\n      };\n    }(i, t);\n\n    d = _e116.sorted, p = _e116.recipientCounts, rd[h] = d, ad[h] = p;\n  }\n\n  d = rd[h], p = {}, r || Object.assign(p, ad[h]);\n  var f = new sd(t);\n\n  for (var _e119 = 0; _e119 < d.length; ++_e119) {\n    if (null != s) {\n      var _e120 = Xn().numTensors;\n      _e120 > s.maxNumTensors && (s.maxNumTensors = _e120), _e120 < s.minNumTensors && (s.minNumTensors = _e120);\n    }\n\n    var _a40 = d[_e119],\n        _i23 = _a40.sourceLayer;\n    if (_i23 instanceof bh) continue;\n    var _l11 = [],\n        _c6 = [],\n        _h5 = [];\n\n    var _g5 = !1;\n\n    for (var _e121 of _a40.inputs) {\n      var _n83 = f.getValue(_e121),\n          _s71 = f.getMask(_e121);\n\n      _l11.push(_n83), _c6.push(_s71), null != _s71 && (_g5 = !0), r || (p[_e121.name]--, 0 !== p[_e121.name] || t.hasKey(_e121) || -1 !== o.indexOf(_e121.name) || _n83.isDisposed || !0 === _e121.sourceLayer.stateful || _h5.push(_n83));\n    }\n\n    _g5 && ((n = n || {}).mask = _c6[0]);\n\n    var _m4 = $u(_i23.apply(_l11, n));\n\n    var _b4 = null;\n    _i23.supportsMasking && (_b4 = _i23.computeMask(_l11, _c6));\n\n    var _x20 = ud(_a40),\n        _y4 = Array.isArray(_x20) ? _x20 : [_x20];\n\n    for (var _e122 = 0; _e122 < _y4.length; ++_e122) {\n      f.hasKey(_y4[_e122]) || f.add(_y4[_e122], _m4[_e122], Array.isArray(_b4) ? _b4[0] : _b4);\n\n      var _t125 = o.indexOf(_y4[_e122].name);\n\n      -1 !== _t125 && (u[_t125] = _m4[_e122]);\n    }\n\n    r || Jn(_h5);\n  }\n\n  return f.disposeMasks(), a ? u : u[0];\n}\n\nfunction od(e) {\n  var t = {};\n\n  for (var _n84 in e) {\n    t[_n84] = e[_n84].size;\n  }\n\n  return t;\n}\n\nfunction ld(e, t) {\n  var n = new Set(),\n      s = [],\n      r = {};\n\n  for (var _e123 of t.names()) {\n    n.add(_e123);\n  }\n\n  var a = [],\n      i = [];\n\n  for (a.push(e); a.length > 0;) {\n    var _e124 = a[a.length - 1];\n\n    if (n.has(_e124.name)) {\n      a.pop();\n      continue;\n    }\n\n    var _t126 = i[i.length - 1] === a.length - 1;\n\n    if (0 === _e124.inputs.length || _t126) a.pop(), s.push(_e124), n.add(_e124.name), _t126 && i.pop();else {\n      i.push(a.length - 1);\n\n      for (var _t127 of _e124.inputs) {\n        null == r[_t127.name] && (r[_t127.name] = new Set()), r[_t127.name].add(_e124.name), n.has(_t127.name) || a.push(_t127);\n      }\n    }\n  }\n\n  return {\n    sorted: s,\n    recipientMap: r\n  };\n}\n\nfunction ud(e) {\n  var t;\n  if (1 === e.sourceLayer.inboundNodes.length) t = e.sourceLayer.output;else {\n    var _n85 = null;\n\n    for (var _t128 = 0; _t128 < e.sourceLayer.inboundNodes.length; ++_t128) {\n      for (var _s72 of e.sourceLayer.inboundNodes[_t128].outputTensors) {\n        if (_s72.id === e.id) {\n          _n85 = _t128;\n          break;\n        }\n      }\n    }\n\n    t = e.sourceLayer.getOutputAt(_n85);\n  }\n  return t;\n}\n\nclass cd extends gh {\n  constructor(e) {\n    if (super({}), this.containerNodes = new Set(), this.name = e.name, null == this.name) {\n      var _e125 = this.getClassName().toLowerCase();\n\n      this.name = th(_e125);\n    }\n\n    if (this.supportsMasking = !1, this.trainable_ = !0, this.inputs = Array.isArray(e.inputs) ? e.inputs.slice() : [e.inputs], this.outputs = Array.isArray(e.outputs) ? e.outputs.slice() : [e.outputs], Fu(this.inputs).length !== this.inputs.length) throw new bu(\"The list of inputs passed to the model is redundant. All inputs should only appear once. Found: \".concat(this.inputs.map(e => e.name)));\n    Fu(this.outputs).length !== this.outputs.length && console.warn(\"The list of outputs passed to the model is redundant. All outputs should only appear once. Found: \".concat(this.outputs.map(e => e.name))), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];\n\n    for (var _e126 of this.outputs) {\n      var _t129 = _e126.nodeIndex,\n          _n86 = _e126.tensorIndex;\n      this.outputLayers.push(_e126.sourceLayer), this.outputLayersNodeIndices.push(_t129), this.outputLayersTensorIndices.push(_n86);\n    }\n\n    for (var _e127 of this.inputs) {\n      var _t130 = _e127.sourceLayer,\n          _n87 = _e127.nodeIndex,\n          _s73 = _e127.tensorIndex;\n      wu(0 === _n87, \"input layer has >1 nodes\"), wu(0 === _s73, \"input layer has >1 tensors\"), this.inputLayers.push(_t130), this.inputLayersNodeIndices.push(_n87), this.inputLayersTensorIndices.push(_s73);\n    }\n\n    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];\n\n    for (var _t131 = 0; _t131 < this.inputLayers.length; _t131++) {\n      var _n88 = this.inputLayers[_t131];\n      if (!(_n88 instanceof bh)) throw new TypeError(\"Input layers to a LayersModel must be InputLayer objects. Received inputs: \".concat(e.inputs, \". Input \").concat(_t131, \" (0-based) originates from layer type \").concat(_n88.getClassName(), \".\"));\n      this.inputNames.push(_n88.name), this.feedInputShapes.push(_n88.batchInputShape), this.feedInputNames.push(_n88.name);\n    }\n\n    for (var _e128 of this.outputLayers) {\n      this.outputNames.push(_e128.name);\n    }\n\n    this.internalInputShapes = this.inputs.map(e => e.shape), this.internalOutputShapes = this.outputs.map(e => e.shape);\n\n    var t = {},\n        n = {},\n        s = {},\n        r = {},\n        a = {},\n        i = [],\n        o = (e, t, n, s, r, l) => {\n      null != s && null != r && null != l || (s = e.sourceLayer, r = e.nodeIndex, l = e.tensorIndex);\n      var u = s.inboundNodes[r];\n      if (-1 !== n.indexOf(u)) throw new mu(\"The tensor \".concat(e.name, \" at layer \\\"\").concat(s.name, \"\\\" is part of a cycle.\"));\n      if (-1 !== t.indexOf(u)) return;\n      this.containerNodes.add(cd.nodeKey(s, r)), s.id in a || (a[s.id] = Object.keys(a).length), -1 === n.indexOf(u) && n.push(u);\n      var c = u.inboundLayers.length;\n\n      for (var _e129 = 0; _e129 < c; _e129++) {\n        o(u.inputTensors[_e129], t, n, u.inboundLayers[_e129], u.nodeIndices[_e129], u.tensorIndices[_e129]);\n      }\n\n      for (t.push(u); n.indexOf(u) >= 0;) {\n        n.splice(n.indexOf(u), 1);\n      }\n\n      i.push(u);\n    },\n        l = [],\n        u = [];\n\n    for (var _e130 of this.outputs) {\n      o(_e130, l, u);\n    }\n\n    var c = i.slice().reverse();\n\n    for (var _e131 of c) {\n      n[_e131.id] = _e131, _e131.id in t || (t[_e131.id] = 0);\n      var _a41 = t[_e131.id];\n      _a41 = Math.max(_a41, null == s[_e131.outboundLayer.id] ? 0 : s[_e131.outboundLayer.id]), s[_e131.outboundLayer.id] = _a41, r[_e131.outboundLayer.id] = _e131.outboundLayer, t[_e131.id] = _a41;\n\n      for (var _s74 = 0; _s74 < _e131.inboundLayers.length; _s74++) {\n        var _r51 = _e131.inboundLayers[_s74].inboundNodes[_e131.nodeIndices[_s74]];\n        t[_r51.id] = Math.max(_a41 + 1, null == t[_r51.id] ? 0 : t[_r51.id]), n[_r51.id] = _r51;\n      }\n    }\n\n    var h = {};\n\n    for (var _e132 in t) {\n      var _s75 = t[_e132];\n      _s75 in h || (h[_s75] = []), h[_s75].push(n[_e132]);\n    }\n\n    var d = {};\n\n    for (var _e133 in s) {\n      var _t132 = s[_e133];\n      _t132 in d || (d[_t132] = []), d[_t132].push(r[_e133]);\n    }\n\n    var p = Object.keys(d).map(e => parseInt(e, 10)).sort(Au);\n    this.layers = [];\n\n    for (var _e134 of p) {\n      var _t133 = d[_e134];\n\n      _t133.sort((e, t) => {\n        var n = a[e.id],\n            s = a[t.id];\n        return n < s ? -1 : n > s ? 1 : 0;\n      });\n\n      for (var _e135 of _t133) {\n        _e135 instanceof cd && this.internalContainerRefs.push(_e135), this.layers.push(_e135);\n      }\n    }\n\n    this.layersByDepth = d, p = Object.keys(h).map(e => parseInt(e, 10)).sort(Au);\n    var f = this.inputs.slice(),\n        g = [];\n\n    for (var _e136 of p) {\n      for (var _t134 of h[_e136]) {\n        var _e137 = _t134.outboundLayer;\n\n        if (null != _e137) {\n          for (var _n89 of _t134.inputTensors) {\n            if (-1 === f.indexOf(_n89)) throw new mu(\"Graph disconnected: cannot obtain value for tensor \".concat(_n89, \" at layer \\\"\").concat(_e137.name, \"\\\". The following previous layers were accessed without issue: \").concat(g));\n          }\n\n          for (var _e138 of _t134.outputTensors) {\n            f.push(_e138);\n          }\n\n          g.push(_e137.name);\n        }\n      }\n    }\n\n    this.nodesByDepth = h;\n    var m = this.layers.map(e => e.name);\n\n    var _loop15 = function _loop15(_e139) {\n      var t = m.filter(t => t === _e139).length;\n      if (1 !== t) throw new mu(\"The name \\\"\".concat(_e139, \"\\\" is used \").concat(t, \" times in the model. All layer names should be unique. Layer names: \") + JSON.stringify(m));\n    };\n\n    for (var _e139 of m) {\n      _loop15(_e139);\n    }\n\n    this.outboundNodes = [], this.inboundNodes = [], new ph({\n      outboundLayer: this,\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: this.inputs,\n      outputTensors: this.outputs,\n      inputMasks: this.inputs.map(e => null),\n      outputMasks: this.outputs.map(e => null),\n      inputShapes: this.inputs.map(e => e.shape),\n      outputShapes: this.outputs.map(e => e.shape)\n    }), this.built = !0, this._refCount = 1;\n  }\n\n  assertNotDisposed() {\n    if (0 === this._refCount) throw new Error(\"Container '\".concat(this.name, \"' is already disposed.\"));\n  }\n\n  dispose() {\n    this.assertNotDisposed();\n    var e = {\n      refCountAfterDispose: null,\n      numDisposedVariables: 0\n    };\n\n    if (0 == --this._refCount) {\n      for (var _t135 of this.layers) {\n        e.numDisposedVariables += _t135.dispose().numDisposedVariables;\n      }\n\n      for (var _t136 of this.internalContainerRefs) {\n        e.numDisposedVariables += _t136.dispose().numDisposedVariables;\n      }\n    }\n\n    return e.refCountAfterDispose = this._refCount, e;\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this.layers.forEach(t => {\n      t._trainableWeights.forEach(t => t.trainable = e);\n    }), this.trainable_ = e;\n  }\n\n  get trainableWeights() {\n    if (this._trainableWeights.length > 0) throw new bu(\"Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.\");\n    if (!this.trainable) return [];\n    var e = [];\n\n    for (var _t137 of this.layers) {\n      e = e.concat(_t137.trainableWeights);\n    }\n\n    return e;\n  }\n\n  get nonTrainableWeights() {\n    var e = [];\n\n    for (var _t138 of this.layers) {\n      e.push(..._t138.nonTrainableWeights);\n    }\n\n    if (!this.trainable) {\n      var _t139 = [];\n\n      for (var _e140 of this.layers) {\n        _t139.push(..._e140.trainableWeights);\n      }\n\n      return _t139.concat(e);\n    }\n\n    return e;\n  }\n\n  get weights() {\n    return this.trainableWeights.concat(this.nonTrainableWeights);\n  }\n\n  loadWeights(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = {};\n    var s = 0;\n\n    for (var _e141 of this.layers) {\n      for (var _t140 of _e141.weights) {\n        if (null != n[_t140.originalName]) throw new bu(\"Duplicate weight name: \".concat(_t140.originalName));\n        n[_t140.originalName] = _t140, s++;\n      }\n    }\n\n    var r = [];\n\n    for (var _s76 in e) {\n      var _a42 = _s76;\n\n      if (null == n[_s76]) {\n        var _e142 = _s76.split(\"/\");\n\n        _a42 = _e142.slice(0, -2).concat([_e142[_e142.length - 1]]).join(\"/\");\n      }\n\n      if (null != n[_a42]) r.push([n[_a42], e[_s76]]);else if (t) throw new bu(\"Provided weight data has no target variable: \".concat(_s76));\n      delete n[_a42];\n    }\n\n    if (t) {\n      var _e143 = [];\n\n      for (var _t141 in n) {\n        _e143.push(_t141);\n      }\n\n      if (_e143.length > 0) throw new bu(\"\".concat(_e143.length, \" of \").concat(s, \" weights are not set: \").concat(_e143));\n    }\n\n    uh(r);\n  }\n\n  updatedConfig() {\n    var e = this.getConfig(),\n        t = {};\n    return t.className = this.getClassName(), t.config = e, t.kerasVersion = \"tfjs-layers 3.8.0\", t.backend = \"TensorFlow.js\", t;\n  }\n\n  toJSON(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = nd(this.updatedConfig());\n    return t ? JSON.stringify(n) : n;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      e = $u(e);\n      var n = new sd();\n\n      for (var _t142 = 0; _t142 < this.inputs.length; ++_t142) {\n        n.add(this.inputs[_t142], e[_t142]);\n      }\n\n      return id(this.outputs, n, t);\n    });\n  }\n\n  computeMask(e, t) {\n    return Yn(() => {\n      var n;\n      return e = $u(e), n = null == t ? ku(null, e.length) : $u(t), this.runInternalGraph(e, n)[1];\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = sh(e);\n    if (t.length !== this.inputLayers.length) throw new bu(\"Invalid inputShape argument \".concat(e, \": model has \").concat(this.inputLayers.length, \" tensor inputs.\"));\n    var n = {};\n\n    for (var _e144 = 0; _e144 < t.length; _e144++) {\n      n[this.inputLayers[_e144].name + \"_0_0\"] = t[_e144];\n    }\n\n    var s = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(Au);\n    if (s.length > 1) for (var _e145 of s) {\n      var _t143 = this.nodesByDepth[_e145];\n\n      for (var _e146 of _t143) {\n        var _t144 = _e146.outboundLayer;\n        if (-1 !== this.inputLayers.map(e => e.id).indexOf(_t144.id)) continue;\n        var _s77 = [];\n\n        for (var _t145 = 0; _t145 < _e146.inboundLayers.length; _t145++) {\n          _s77.push(n[\"\".concat(_e146.inboundLayers[_t145].name, \"_\").concat(_e146.nodeIndices[_t145], \"_\").concat(_e146.tensorIndices[_t145])]);\n        }\n\n        var _r52 = sh(_t144.computeOutputShape(Iu(_s77))),\n            _a43 = _t144.inboundNodes.indexOf(_e146);\n\n        for (var _e147 = 0; _e147 < _r52.length; _e147++) {\n          n[\"\".concat(_t144.name, \"_\").concat(_a43, \"_\").concat(_e147)] = _r52[_e147];\n        }\n      }\n    }\n    var r = [],\n        a = [];\n\n    for (var _e148 = 0; _e148 < this.outputLayers.length; _e148++) {\n      a.push(\"\".concat(this.outputLayers[_e148].name, \"_\").concat(this.outputLayersNodeIndices[_e148], \"_\").concat(this.outputLayersTensorIndices[_e148]));\n    }\n\n    for (var _e149 = 0; _e149 < a.length; _e149++) {\n      var _t146 = a[_e149];\n      wu(_t146 in n), r.push(n[_t146]);\n    }\n\n    return Iu(r);\n  }\n\n  runInternalGraph(e, t) {\n    null == t && (t = ku(null, e.length));\n    var n = {};\n\n    for (var _s78 = 0; _s78 < this.inputs.length; ++_s78) {\n      n[this.inputs[_s78].id] = [e[_s78], t[_s78]];\n    }\n\n    var s = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(Au);\n\n    for (var _e150 of s) {\n      var _t147 = this.nodesByDepth[_e150];\n\n      for (var _e151 of _t147) {\n        var _t148 = _e151.outboundLayer,\n            _s79 = _e151.inputTensors,\n            _r53 = _e151.outputTensors,\n            _a44 = new Array();\n\n        for (var _e152 of _s79) {\n          _e152.id in n && _a44.push(n[_e152.id]);\n        }\n\n        if (_a44.length === _s79.length) {\n          var _s80 = void 0,\n              _i24 = void 0,\n              _o18 = void 0,\n              _l12 = void 0,\n              _u7 = {};\n\n          if (null != _e151.callArgs && (_u7 = _e151.callArgs), 1 === _a44.length) {\n            var [_e153, _n90] = _a44[0];\n            null == _u7.mask && (_u7.mask = _n90), _o18 = $u(_t148.call(_e153, _u7)), _l12 = $u(_t148.computeMask(_e153, _n90)), _s80 = [_e153], _i24 = [_n90];\n          } else _s80 = _a44.map(e => e[0]), _i24 = _a44.map(e => e[1]), null == _u7.mask && (_u7.mask = _i24), _o18 = $u(_t148.call(_s80, _u7)), _l12 = $u(_t148.computeMask(_s80, _i24));\n\n          if (_t148.activityRegularizer) throw new xu(\"LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.\");\n\n          for (var _e154 = 0; _e154 < _r53.length; ++_e154) {\n            n[_r53[_e154].id] = [_o18[_e154], _l12[_e154]];\n          }\n        }\n      }\n    }\n\n    var r = [],\n        a = [],\n        i = [];\n\n    for (var _e155 of this.outputs) {\n      wu(_e155.id in n, \"Could not compute output \".concat(_e155.name, \" : \").concat(_e155.id));\n      var [_t149, _s81] = n[_e155.id];\n      i.push(_t149.shape), r.push(_t149), a.push(_s81);\n    }\n\n    return [r, a, i];\n  }\n\n  buildNodeConversionMap(e) {\n    var t = {};\n    var n;\n\n    for (var _e156 of this.layers) {\n      n = _e156 instanceof cd ? 1 : 0;\n\n      for (var _s82 = 0; _s82 < _e156.inboundNodes.length; _s82++) {\n        var _r54 = cd.nodeKey(_e156, _s82);\n\n        this.containerNodes.has(_r54) && (t[_r54] = n, n += 1);\n      }\n    }\n\n    return t;\n  }\n\n  getLayer(e, t) {\n    if (null != t) {\n      if (this.layers.length <= t) throw new bu(\"Was asked to retrieve layer at index \".concat(t, \", but model only has \").concat(this.layers.length, \" layer(s).\"));\n      return this.layers[t];\n    }\n\n    if (null == e) throw new bu(\"Provide either a layer name or layer index\");\n\n    for (var _t150 of this.layers) {\n      if (_t150.name === e) return _t150;\n    }\n\n    throw new bu(\"No such layer: \".concat(e));\n  }\n\n  calculateLosses() {\n    return Yn(() => {\n      var e = [];\n\n      for (var _t151 of this.layers) {\n        for (var _n91 = 0; _n91 < _t151.inboundNodes.length; ++_n91) {\n          var _s83 = cd.nodeKey(_t151, _n91);\n\n          this.containerNodes.has(_s83) && e.push(..._t151.calculateLosses());\n        }\n      }\n\n      return e;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      name: this.name\n    },\n        t = this.buildNodeConversionMap(this.layers),\n        n = [];\n\n    for (var _e157 of this.layers) {\n      var _s84 = _e157.getClassName(),\n          _r55 = _e157.getConfig(),\n          _a45 = [];\n\n      for (var _n92 = 0; _n92 < _e157.inboundNodes.length; _n92++) {\n        var _s85 = _e157.inboundNodes[_n92],\n            _r56 = cd.nodeKey(_e157, _n92);\n\n        var _i26 = {};\n\n        if (this.containerNodes.has(_r56)) {\n          if (_s85.callArgs) try {\n            JSON.stringify(_s85.callArgs), _i26 = _s85.callArgs;\n          } catch (t) {\n            console.warn(\"Layer \".concat(_e157.name, \" was passed non-serializable keyword arguments: \").concat(_s85.callArgs, \". They will not be included in the serialized model (and thus will be missing at deserialization time).\")), _i26 = {};\n          }\n\n          if (_s85.inboundLayers.length > 0) {\n            var _e158 = [];\n\n            for (var _n93 = 0; _n93 < _s85.inboundLayers.length; _n93++) {\n              var _r57 = _s85.inboundLayers[_n93],\n                  _a46 = _s85.tensorIndices[_n93];\n              var _o19 = t[cd.nodeKey(_r57, _s85.nodeIndices[_n93])];\n              null == _o19 && (_o19 = 0), _e158.push([_r57.name, _o19, _a46, _i26]);\n            }\n\n            _a45.push(_e158);\n          }\n        }\n      }\n\n      var _i25 = {};\n      _i25.name = _e157.name, _i25.className = _s84, _i25.config = _r55, _i25.inboundNodes = _a45, n.push(_i25);\n    }\n\n    e.layers = n;\n    var s = [];\n\n    for (var _e159 = 0; _e159 < this.inputLayers.length; _e159++) {\n      var _n94 = this.inputLayers[_e159],\n          _r58 = cd.nodeKey(_n94, this.inputLayersNodeIndices[_e159]);\n\n      if (!this.containerNodes.has(_r58)) continue;\n      var _a47 = t[_r58];\n      null == _a47 && (_a47 = 0), s.push([_n94.name, _a47, this.inputLayersTensorIndices[_e159]]);\n    }\n\n    e.inputLayers = s;\n    var r = [];\n\n    for (var _e160 = 0; _e160 < this.outputLayers.length; _e160++) {\n      var _n95 = this.outputLayers[_e160],\n          _s86 = cd.nodeKey(_n95, this.outputLayersNodeIndices[_e160]);\n\n      if (!this.containerNodes.has(_s86)) continue;\n      var _a48 = t[_s86];\n      null == _a48 && (_a48 = 0), r.push([_n95.name, _a48, this.outputLayersTensorIndices[_e160]]);\n    }\n\n    return e.outputLayers = r, e;\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = {},\n        a = {};\n\n    function i(e, t) {\n      e.name in a ? a[e.name].push(t) : a[e.name] = [t];\n    }\n\n    function o(e, t) {\n      var n = [];\n      var s;\n\n      for (var _a49 of t) {\n        var _o20 = _a49[0],\n            _l13 = _a49[1],\n            _u8 = _a49[2];\n        if (s = null == _a49[3] ? {} : _a49[3], !(_o20 in r)) return void i(e, t);\n        var _c7 = r[_o20];\n        if (_c7.inboundNodes.length <= _l13) return void i(e, t);\n        n.push(_c7.inboundNodes[_l13].outputTensors[_u8]);\n      }\n\n      n.length > 0 && e.apply(Iu(n), s);\n    }\n\n    function l(e) {\n      var n = e.name,\n          a = Eh(e, null != t.customObjects ? t.customObjects : {});\n      a.setFastWeightInitDuringBuild(s), r[n] = a, e.inboundNodes.forEach(e => {\n        if (!(e instanceof Array)) throw new bu(\"Corrupted configuration, expected array for nodeData: \".concat(e));\n        i(a, e);\n      });\n    }\n\n    var u = t.name,\n        c = t.layers;\n\n    for (var _e161 of c) {\n      l(_e161);\n    }\n\n    for (; !Du(a);) {\n      for (var _e162 of c) {\n        var _t152 = r[_e162.name];\n\n        if (_t152.name in a) {\n          var _e163 = a[_t152.name];\n          delete a[_t152.name];\n\n          for (var _n96 of _e163) {\n            o(_t152, _n96);\n          }\n        }\n      }\n    }\n\n    var h = [],\n        d = [],\n        p = t.inputLayers;\n\n    for (var _e164 of p) {\n      var _t153 = _e164[0],\n          _n97 = _e164[1],\n          _s87 = _e164[2];\n      wu(_t153 in r), h.push(r[_t153].inboundNodes[_n97].outputTensors[_s87]);\n    }\n\n    var f = t.outputLayers;\n\n    for (var _e165 of f) {\n      var _t154 = _e165[0],\n          _n98 = _e165[1],\n          _s88 = _e165[2];\n      wu(_t154 in r), d.push(r[_t154].inboundNodes[_n98].outputTensors[_s88]);\n    }\n\n    return new e({\n      inputs: h,\n      outputs: d,\n      name: u\n    });\n  }\n\n  get stateful() {\n    if (this._stateful) throw new bu(\"Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.\");\n\n    for (var _e166 of this.layers) {\n      if (_e166.stateful) return !0;\n    }\n\n    return !1;\n  }\n\n  resetStates() {\n    Yn(() => {\n      this.layers.forEach(e => {\n        e.stateful && e.resetStates();\n      });\n    });\n  }\n\n}\n\nfunction hd(e, t) {\n  return function (e, t, n) {\n    var s = t.length;\n    if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => null);\n    if (1 === s) return Array.isArray(e) && 1 === e.length ? e : \"object\" == typeof e && t[0] in e ? [e[t[0]]] : [e];\n\n    if (Array.isArray(e)) {\n      if (e.length !== s) throw new Error(\"Provided classWeight is an array of \".concat(e.length, \" element(s), but the model has \").concat(s, \" outputs. Make sure a set of weights is provided for each model output.\"));\n      return e;\n    }\n\n    if (\"object\" == typeof e && Object.keys(e).length > 0 && \"object\" == typeof e[Object.keys(e)[0]]) {\n      var _n99 = [];\n      return t.forEach(t => {\n        _n99.push(t in e ? e[t] : null);\n      }), _n99;\n    }\n\n    throw new Error(\"The model has multiple (\".concat(s, \") outputs, so classWeight must be either an array with \").concat(s, \" elements or an object with \").concat(t, \" keys. Provided classWeight not understood: \").concat(JSON.stringify(e)));\n  }(e, t);\n}\n\nfunction dd(_x21, _x22, _x23, _x24) {\n  return _dd.apply(this, arguments);\n}\n\nfunction _dd() {\n  _dd = _asyncToGenerator(function* (e, t, n, s) {\n    if (null != t || null != s) throw new Error(\"Support sampleWeight is not implemented yet\");\n\n    if (null != n) {\n      var _t427 = Yn(() => {\n        if (1 === e.shape.length) return fn(e);\n\n        if (2 === e.shape.length) {\n          if (e.shape[1] > 1) return us(e, 1);\n          if (1 === e.shape[1]) return Es(e, [e.shape[0]]);\n          throw new Error(\"Encountered unexpected last-dimension size (\".concat(e.shape[1], \") during handling of class weights. The size is expected to be >= 1.\"));\n        }\n\n        throw new Error(\"Unexpected rank of target (y) tensor (\".concat(e.rank, \") during handling of class weights. The rank is expected to be 1 or 2.\"));\n      }),\n          _s247 = Array.from(yield _t427.data());\n\n      Jn(_t427);\n      var _r176 = [];\n      return _s247.forEach(e => {\n        if (null == n[e]) throw new Error(\"classWeight must contain all classes in the training data. The class \".concat(e, \" exists in the data but not in classWeight\"));\n\n        _r176.push(n[e]);\n      }), mi(_r176, \"float32\");\n    }\n\n    return null;\n  });\n  return _dd.apply(this, arguments);\n}\n\nfunction pd(e, t) {\n  return ss(e, t);\n}\n\nfunction fd(e, t) {\n  var n, s;\n  n = t.xs, s = t.ys, l(null != n && null != s, () => \"A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates \".concat(t));\n  var r = gd(\"input\", e.inputNames, n),\n      a = gd(\"output\", e.outputNames, s),\n      i = r[0].shape[0];\n  l(r.length === e.inputs.length, () => \"LayersModel has \".concat(e.inputs.length, \" inputs, but the dataset provides \").concat(r.length, \" inputs.  (Expected input keys: \").concat(JSON.stringify(e.inputNames), \")\")), l(a.length === e.outputs.length, () => \"LayersModel has \".concat(e.outputs.length, \" outputs, but the dataset provides \").concat(a.length, \" outputs.  (Expected output keys: \").concat(JSON.stringify(e.outputNames), \")\"));\n\n  var _loop16 = function _loop16(_t155) {\n    l(r[_t155].shape[0] === i, () => \"Batch size mismatch: input \".concat(e.inputNames[_t155], \" has \").concat(r[_t155].shape[0], \"; expected  \").concat(i, \" based on input \").concat(e.inputNames[0], \".\"));\n  };\n\n  for (var _t155 = 0; _t155 < r.length; _t155++) {\n    _loop16(_t155);\n  }\n\n  var _loop17 = function _loop17(_t156) {\n    l(a[_t156].shape[0] === i, () => \"Batch size mismatch: output \".concat(e.outputNames[_t156], \" has \").concat(a[_t156].shape[0], \"; expected  \").concat(i, \" based on input \").concat(e.inputNames[0], \".\"));\n  };\n\n  for (var _t156 = 0; _t156 < a.length; _t156++) {\n    _loop17(_t156);\n  }\n\n  return {\n    xs: r,\n    ys: a\n  };\n}\n\nfunction gd(e, t, n) {\n  if (n instanceof st) return [n];\n  if (Array.isArray(n)) return l(n.length === t.length, () => \"Received an array of \".concat(n.length, \" Tensors, but expected \").concat(t.length, \" to match the \").concat(e, \" keys \").concat(t, \".\")), n;\n  {\n    var _s89 = [];\n\n    for (var _r59 of t) {\n      if (null == n[_r59]) throw new bu(\"The feature data generated by the dataset lacks the required \".concat(e, \" key '\").concat(_r59, \"'.\"));\n\n      _s89.push(n[_r59]);\n    }\n\n    return _s89;\n  }\n}\n\nfunction md(e) {\n  return \"function\" == typeof e.iterator;\n}\n\nfunction bd(e) {\n  l(e > 0 && Number.isInteger(e), () => \"batchSize is required to be a positive integer, but got \".concat(e));\n}\n\nfunction xd(e, t, n) {\n  return null == e ? [null] : Array.isArray(e) ? e.map(e => mc(e, t, n - t)) : mc(e, t, n - t);\n}\n\nfunction yd(e, t) {\n  return Yn(() => null == e ? null : Array.isArray(e) ? e.map(e => yd(e, t)) : $c(e, \"int32\" === t.dtype ? t : pn(t, \"int32\")));\n}\n\nfunction kd(e, t) {\n  var n = [];\n  var s = 0,\n      r = null;\n\n  for (; s < e;) {\n    r = s + t, r >= e && (r = e), n.push([s, r]), s = r;\n  }\n\n  return n;\n}\n\nfunction wd(e) {\n  var t = [];\n  e instanceof st && (e = [e]);\n\n  for (var _n100 = 0; _n100 < e.length; ++_n100) {\n    var _s90 = e[_n100];\n    if (1 === _s90.rank) t.push(gc(_s90, 1));else {\n      if (0 === _s90.rank) throw new Error(\"Expected tensor to be at least 1D, but received a 0D tensor (scalar).\");\n      t.push(_s90);\n    }\n  }\n\n  return t;\n}\n\nfunction vd(e, t) {\n  if (null == e) return;\n  var n = [];\n  if (t instanceof st) n.push(t.id);else if (Array.isArray(t)) t.forEach(e => n.push(e.id));else if (null != t) for (var _e167 in t) {\n    n.push(t[_e167].id);\n  }\n  var s = [];\n  if (e instanceof st) -1 === n.indexOf(e.id) && s.push(e);else if (Array.isArray(e)) e.forEach(e => {\n    -1 === n.indexOf(e.id) && s.push(e);\n  });else if (null != e) for (var _t157 in e) {\n    var _r60 = e[_t157];\n    -1 === n.indexOf(_r60.id) && s.push(_r60);\n  }\n  s.forEach(e => {\n    e.isDisposed || e.dispose();\n  });\n}\n\nfunction Id(e) {\n  return Array.isArray(e);\n}\n\nfunction $d(e) {\n  return !function (e) {\n    return e instanceof st;\n  }(e) && !Id(e);\n}\n\nfunction Nd(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"\";\n\n  if (null == t || 0 === t.length) {\n    if (null != e) {\n      var _t158 = !1;\n\n      if (Id(e) && e.length > 0) _t158 = !0;else if ($d(e)) {\n        for (var _n101 in e) {\n          if (e.hasOwnProperty(_n101)) {\n            _t158 = !0;\n            break;\n          }\n        }\n      } else _t158 = !0;\n      if (_t158) throw new bu(\"Error when checking model \".concat(r, \" expected no data, but got \").concat(e));\n    }\n\n    return [];\n  }\n\n  if (null == e) return t.map(e => null);\n  var a;\n\n  if ($d(e)) {\n    e = e, a = [];\n\n    for (var _n102 of t) {\n      if (null == e[_n102]) throw new bu(\"No data provided for \\\"\".concat(_n102, \"\\\". Need data for each key in: \").concat(t));\n      a.push(e[_n102]);\n    }\n  } else if (Id(e)) {\n    if ((e = e).length !== t.length) throw new bu(\"Error when checking model \".concat(r, \": the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see \").concat(t.length, \" Tensor(s), but instead got the following list of Tensor(s): \").concat(e));\n    a = e;\n  } else {\n    if (e = e, t.length > 1) throw new bu(\"The model \".concat(r, \" expects \").concat(t.length, \" Tensor(s), but only received one Tensor. Found: Tensor with shape \").concat(e.shape));\n    a = [e];\n  }\n\n  if (a = wd(a), null != n) for (var _e168 = 0; _e168 < t.length; ++_e168) {\n    if (null == n[_e168]) continue;\n    var _i27 = a[_e168];\n    if (_i27.shape.length !== n[_e168].length) throw new bu(\"Error when checking \".concat(r, \": expected \").concat(t[_e168], \" to have \").concat(n[_e168].length, \" dimension(s). but got array with shape \").concat(_i27.shape));\n\n    for (var _a50 = 0; _a50 < n[_e168].length; ++_a50) {\n      if (0 === _a50 && !s) continue;\n      var _o21 = _i27.shape[_a50],\n          _l14 = n[_e168][_a50];\n      if (null != _l14 && _l14 >= 0 && _o21 !== _l14) throw new bu(\"Error when checking \".concat(r, \": expected \").concat(t[_e168], \" to have shape [\").concat(n[_e168], \"], but got array with shape [\").concat(_i27.shape, \"].\"));\n    }\n  }\n  return a;\n}\n\nfunction Cd(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"\";\n  var a;\n\n  if (Array.isArray(e)) {\n    if (e.length !== t.length) throw new bu(\"Error when checking model \".concat(r, \": the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see \").concat(t.length, \" Tensor(s), but instead got \").concat(e.length, \" Tensors(s).\"));\n    a = e;\n  } else {\n    if (t.length > 1) throw new bu(\"The model expects \".concat(t.length, \" \").concat(r, \" Tensors, but only received one Tensor. Found: array with shape \").concat(JSON.stringify(e.shape), \".\"));\n    a = [e];\n  }\n\n  if (null != n) for (var _e169 = 0; _e169 < t.length; ++_e169) {\n    if (null == n[_e169]) continue;\n    var _i28 = a[_e169];\n    if (_i28.shape.length !== n[_e169].length) throw new bu(\"Error when checking \".concat(r, \": expected \").concat(t[_e169], \" to have \").concat(n[_e169].length, \" dimension(s), but got array with shape \").concat(JSON.stringify(_i28.shape)));\n\n    for (var _a51 = 0; _a51 < n[_e169].length; ++_a51) {\n      if (0 === _a51 && !s) continue;\n      var _o22 = _i28.shape[_a51],\n          _l15 = n[_e169][_a51];\n      if (null != _l15 && _l15 !== _o22) throw new bu(\"Error when checking \".concat(r, \": expected \").concat(t[_e169], \" to have shape \").concat(JSON.stringify(n[_e169]), \" but got array with shape \").concat(JSON.stringify(_i28.shape), \".\"));\n    }\n  }\n}\n\nclass Sd extends cd {\n  constructor(e) {\n    super(e), this.isTraining = !1;\n  }\n\n  summary(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n    if (!this.built) throw new bu(\"This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).\");\n    !function (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : console.log;\n\n      var r = function (e) {\n        var t = !0;\n        var n = [],\n            s = [];\n\n        for (var _t159 in e.nodesByDepth) {\n          n.push(e.nodesByDepth[_t159]);\n        }\n\n        for (var _e170 of n) {\n          if (_e170.length > 1 || 1 === _e170.length && _e170[0].inboundLayers.length > 1) {\n            t = !1;\n            break;\n          }\n\n          s.push(..._e170);\n        }\n\n        if (t) for (var _n103 of e.layers) {\n          var _e171 = !1;\n\n          for (var _r61 of _n103.inboundNodes) {\n            if (-1 !== s.indexOf(_r61)) {\n              if (_e171) {\n                t = !1;\n                break;\n              }\n\n              _e171 = !0;\n            }\n          }\n\n          if (!t) break;\n        }\n        return t;\n      }(e),\n          a = [\"Layer (type)\", \"Output shape\", \"Param #\"];\n\n      var i;\n\n      if (r ? (t = t || 65, n = n || [.45, .85, 1]) : (t = t || 98, n = n || [.33, .55, .67, 1]), n[n.length - 1] <= 1 && (n = n.map(e => Math.floor(t * e))), !r) {\n        a.push(\"Receives inputs\"), i = [];\n\n        for (var _t160 in e.nodesByDepth) {\n          i.push(...e.nodesByDepth[_t160]);\n        }\n      }\n\n      s(\"_\".repeat(t)), Jh(a, n, s), s(\"=\".repeat(t));\n      var o = e.layers;\n\n      for (var _e172 = 0; _e172 < o.length; ++_e172) {\n        r ? Zh(o[_e172], n, s) : Qh(o[_e172], n, i, s), s((_e172 === o.length - 1 ? \"=\" : \"_\").repeat(t));\n      }\n\n      e.checkTrainableWeightsConsistency();\n\n      var l = function (e) {\n        var t;\n        return t = ih(null != e.collectedTrainableWeights ? e.collectedTrainableWeights : e.trainableWeights), t;\n      }(e),\n          u = ih(e.nonTrainableWeights);\n\n      s(\"Total params: \".concat(l + u)), s(\"Trainable params: \".concat(l)), s(\"Non-trainable params: \".concat(u)), s(\"_\".repeat(t));\n    }(this, e, t, n);\n  }\n\n  compile(e) {\n    var _this57 = this;\n\n    if (null == e.loss && (e.loss = []), this.loss = e.loss, \"string\" == typeof e.optimizer) this.optimizer_ = function (e) {\n      var t = {\n        Adagrad: () => Io.adagrad(.01),\n        Adadelta: () => Io.adadelta(1, .95, fu()),\n        Adam: () => Io.adam(.001, .9, .999, fu()),\n        Adamax: () => Io.adamax(.002, .9, .999, fu(), 0),\n        RMSProp: () => Io.rmsprop(.001, .9, 0, fu()),\n        SGD: () => Io.sgd(.01)\n      };\n      if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, e in t) return t[e]();\n      throw new bu(\"Unknown Optimizer \".concat(e));\n    }(e.optimizer), this.isOptimizerOwned = !0;else {\n      if (!(e.optimizer instanceof fo)) throw new bu(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n      this.optimizer_ = e.optimizer, this.isOptimizerOwned = !1;\n    }\n    var t = [];\n    if (Array.isArray(e.loss) || \"string\" == typeof e.loss || \"function\" == typeof e.loss) {\n      if (Array.isArray(e.loss)) {\n        if (e.loss.length !== this.outputs.length) throw new bu(\"When passing an Array as loss, it should have one entry per model output. The model has \".concat(this.outputs.length, \" output(s), but you passed loss=\").concat(e.loss, \".\"));\n        t = e.loss.map(e => Bh(e));\n      } else {\n        var _n104 = Bh(e.loss);\n\n        this.outputs.forEach(e => {\n          t.push(_n104);\n        });\n      }\n    } else {\n      e.loss = e.loss;\n\n      for (var _t161 in e.loss) {\n        if (-1 === this.outputNames.indexOf(_t161)) throw new bu(\"Unknown entry in loss dictionary: \\\"\".concat(_t161, \"\\\". Only expected the following keys: \").concat(this.outputNames));\n      }\n\n      for (var _n105 of this.outputNames) {\n        null == e.loss[_n105] && console.warn(\"Output \\\"\".concat(_n105, \"\\\" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to \").concat(_n105, \" during training\")), t.push(Bh(e.loss[_n105]));\n      }\n    }\n    this.lossFunctions = t, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];\n\n    for (var _e173 = 0; _e173 < this.outputs.length; ++_e173) {\n      var _t162 = this.internalOutputShapes[_e173];\n      this.feedOutputNames.push(this.outputNames[_e173]), this.feedOutputShapes.push(_t162), this.feedLossFns.push(this.lossFunctions[_e173]);\n    }\n\n    var n = [];\n    this.metrics = e.metrics, this.metricsNames = [\"loss\"], this.metricsTensors = [], ac(\"loss\", () => {\n      for (var _e174 = 0; _e174 < this.outputs.length; ++_e174) {\n        if (-1 !== n.indexOf(_e174)) continue;\n        var _t163 = this.lossFunctions[_e174];\n        this.outputs.length > 1 && (this.metricsTensors.push([_t163, _e174]), this.metricsNames.push(this.outputNames[_e174] + \"_loss\"));\n      }\n    });\n\n    var s = function (e, t) {\n      if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => []);\n      var n;\n      if (\"string\" == typeof e || \"function\" == typeof e) n = [e];else {\n        if (!Array.isArray(e) && \"object\" != typeof e) throw new TypeError(\"Type of metrics argument not understood. Expected an string,function, Array, or Object, found: \".concat(e));\n        n = e;\n      }\n      if (Array.isArray(n)) return t.map(e => n);\n      {\n        var _e175 = [];\n\n        for (var _s91 of t) {\n          var _t164 = n.hasOwnProperty(_s91) ? n[_s91] : [];\n\n          Array.isArray(_t164) || (_t164 = [_t164]), _e175.push(_t164);\n        }\n\n        return _e175;\n      }\n    }(e.metrics, this.outputNames),\n        r = (e, t, n) => {\n      this.outputNames.length > 1 && (t = this.outputNames[e] + \"_\" + t), this.metricsNames.push(t), this.metricsTensors.push([n, e]);\n    };\n\n    ac(\"metric\", () => {\n      var _loop18 = function _loop18(_e176) {\n        -1 === n.indexOf(_e176) && (t => {\n          var n, s, a;\n\n          for (var _i29 of t) {\n            if (\"string\" == typeof _i29 && -1 !== [\"accuracy\", \"acc\", \"crossentropy\", \"ce\"].indexOf(_i29)) {\n              var _t166 = _this57.internalOutputShapes[_e176];\n\n              var _r62 = void 0;\n\n              1 === _t166[_t166.length - 1] || _this57.lossFunctions[_e176] === Mh ? -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Ph : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = Uh) : _this57.lossFunctions[_e176] === Oh ? -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Vh : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = Hh) : -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Wh : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = Gh), -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? _r62 = \"acc\" : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (_r62 = \"ce\"), a = s, n = \"\" + _r62;\n            } else {\n              var _e177 = qh(_i29);\n\n              a = _e177, n = \"\" + Kh(_i29);\n            }\n\n            var _t165 = void 0;\n\n            ac(n, () => {\n              _t165 = a;\n            }), r(_e176, n, _t165);\n          }\n        })(s[_e176]);\n      };\n\n      for (var _e176 = 0; _e176 < this.outputs.length; ++_e176) {\n        _loop18(_e176);\n      }\n    }), this.collectedTrainableWeights = this.trainableWeights;\n  }\n\n  checkTrainableWeightsConsistency() {\n    null != this.collectedTrainableWeights && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn(\"Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?\");\n  }\n\n  evaluate(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = null == n.batchSize ? 32 : n.batchSize;\n    bd(s);\n    var r = this.standardizeUserDataXY(e, t, !0, s);\n\n    try {\n      var _a52 = r[0].concat(r[1]);\n\n      return this.makeTestFunction(), Iu(this.testLoop(this.testFunction, _a52, s, n.verbose, n.steps));\n    } finally {\n      vd(r[0], e), vd(r[1], t);\n    }\n  }\n\n  evaluateDataset(e, t) {\n    var _this58 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this58.makeTestFunction(), function () {\n        var _ref5 = _asyncToGenerator(function* (e, t, n) {\n          var s = null != (n = n || {}).batches,\n              r = e.testFunction;\n          var a = [];\n          if (n.verbose > 0) throw new xu(\"Verbose mode is not implemented yet.\");\n          l(!s || n.batches > 0 && Number.isInteger(n.batches), () => \"Test loop expects `batches` to be a positive integer, but received \".concat(JSON.stringify(n.batches)));\n          var i = \"function\" == typeof t.next ? t : yield t.iterator();\n          var o = 0,\n              u = 0;\n\n          var _loop19 = function* _loop19() {\n            var t = yield i.next();\n\n            if (a = Yn(() => {\n              if (t.value) {\n                (function () {\n                  var {\n                    xs: n,\n                    ys: s\n                  } = fd(e, t.value),\n                      i = n.concat(s),\n                      l = Yn(() => r(i));\n                  if (Jn(i), 0 === u) for (var _e179 = 0; _e179 < l.length; ++_e179) {\n                    a.push(qa(0));\n                  }\n                  var c = i[0].shape[0];\n\n                  var _loop20 = function _loop20(_e180) {\n                    var t = l[_e180],\n                        n = a[_e180];\n                    a[_e180] = Yn(() => es(a[_e180], ss(c, t))), u > 0 && Jn(n);\n                  };\n\n                  for (var _e180 = 0; _e180 < l.length; ++_e180) {\n                    _loop20(_e180);\n                  }\n\n                  Jn(l), o += c, ++u;\n                })();\n              }\n\n              return a;\n            }), t.done) {\n              s && console.warn(\"Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least `batches` batches (in this case, \".concat(n.batches, \" batches). You may need to use the repeat() function when building your dataset.\"));\n              return \"break\";\n            }\n          };\n\n          for (; !s || u < n.batches;) {\n            var _ret = yield* _loop19();\n\n            if (_ret === \"break\") break;\n          }\n\n          for (var _e178 = 0; _e178 < a.length; ++_e178) {\n            var _t167 = a[_e178];\n            a[_e178] = ns(a[_e178], o), Jn(_t167);\n          }\n\n          return Iu(a);\n        });\n\n        return function (_x25, _x26, _x27) {\n          return _ref5.apply(this, arguments);\n        };\n      }()(_this58, e, t);\n    })();\n  }\n\n  checkNumSamples(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"steps\";\n    var r;\n\n    if (null != n) {\n      if (r = null, null != t) throw new bu(\"If \".concat(s, \" is set, batchSize must be null or undefined.Got batchSize = \").concat(t));\n    } else {\n      if (null == e) throw new bu(\"Either the input data should have a defined shape, or \".concat(s, \" shoud be specified.\"));\n      r = Array.isArray(e) ? e[0].shape[0] : e.shape[0];\n    }\n\n    return r;\n  }\n\n  execute(e, t) {\n    if (Array.isArray(t) && 0 === t.length) throw new bu(\"`outputs` is an empty Array, which is not allowed.\");\n    var n = Array.isArray(t),\n        s = this.retrieveSymbolicTensors(n ? t : [t]),\n        r = new sd();\n\n    if (e instanceof st && (e = [e]), Array.isArray(e)) {\n      if (e.length !== this.inputs.length) throw new bu(\"The number of inputs provided (\".concat(e.length, \") does not match the number of inputs of this model (\").concat(this.inputs.length, \").\"));\n\n      for (var _t168 = 0; _t168 < this.inputs.length; ++_t168) {\n        r.add(this.inputs[_t168], e[_t168]);\n      }\n    } else for (var _t169 of this.inputs) {\n      var _n106 = e[_t169.name];\n      if (null == _n106) throw new bu(\"No value is provided for the model's input \".concat(_t169.name));\n      r.add(_t169, _n106);\n    }\n\n    var a = id(s, r);\n    return n ? a : a[0];\n  }\n\n  retrieveSymbolicTensors(e) {\n    var t = ku(null, e.length);\n    var n = e.length;\n\n    for (var _s92 of this.layers) {\n      var _r63 = Array.isArray(_s92.output) ? _s92.output : [_s92.output],\n          _a53 = _r63.map(e => e.name);\n\n      for (var _s93 = 0; _s93 < e.length; ++_s93) {\n        var _i30 = _a53.indexOf(e[_s93]);\n\n        if (-1 !== _i30 && (t[_s93] = _r63[_i30], n--), 0 === n) break;\n      }\n\n      if (0 === n) break;\n    }\n\n    if (n > 0) {\n      var _n107 = [];\n      throw t.forEach((t, s) => {\n        null == t && _n107.push(e[s]);\n      }), new bu(\"Cannot find SymbolicTensors for output name(s): \".concat(JSON.stringify(_n107)));\n    }\n\n    return t;\n  }\n\n  predictLoop(e) {\n    var _this59 = this;\n\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    return Yn(() => {\n      var s = this.checkNumSamples(e);\n      if (n) throw new xu(\"Verbose predictLoop() is not implemented yet.\");\n      var r = kd(s, t),\n          a = this.outputs.map(e => []);\n\n      var _loop21 = function _loop21(_t170) {\n        Yn(() => {\n          var n = xd(e, r[_t170][0], r[_t170][1]),\n              s = [];\n          if (Array.isArray(n)) for (var _e181 = 0; _e181 < n.length; ++_e181) {\n            s.push({\n              key: _this59.inputs[_e181],\n              value: n[_e181]\n            });\n          } else s.push({\n            key: _this59.inputs[0],\n            value: n\n          });\n          var a = new sd(s);\n          return id(_this59.outputs, a);\n        }).forEach((e, t) => a[t].push(e));\n      };\n\n      for (var _t170 = 0; _t170 < r.length; ++_t170) {\n        _loop21(_t170);\n      }\n\n      return Iu(a.map(e => Fs(e, 0)));\n    });\n  }\n\n  predict(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    var n = wd(e);\n    Cd(n, this.inputNames, this.feedInputShapes, !1);\n\n    try {\n      var _s94 = null == t.batchSize ? 32 : t.batchSize;\n\n      return bd(_s94), this.predictLoop(n, _s94);\n    } finally {\n      vd(n, e);\n    }\n  }\n\n  predictOnBatch(e) {\n    Cd(e, this.inputNames, this.feedInputShapes, !0);\n    var t = (Array.isArray(e) ? e[0] : e).shape[0];\n    return this.predictLoop(e, t);\n  }\n\n  standardizeUserDataXY(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    if (null == this.optimizer_) throw new mu(\"You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).\");\n    var r = [];\n\n    for (var _e182 = 0; _e182 < this.feedOutputShapes.length; ++_e182) {\n      var _t171 = this.feedOutputShapes[_e182];\n      r.push(this.feedLossFns[_e182] === Oh ? _t171.slice(0, _t171.length - 1).concat([1]) : _t171);\n    }\n\n    if (function (e, t, n) {\n      var s = Fu(e.map(e => e.shape[0]));\n      s.sort();\n      var r = Fu(t.map(e => e.shape[0]));\n      if (r.sort(), s.length > 1) throw new bu(\"All input Tensors (x) should have the same number of samples. Got array shapes: \".concat(JSON.stringify(e.map(e => e.shape))));\n      if (r.length > 1) throw new bu(\"All target Tensors (y) should have the same number of samples. Got array shapes: \".concat(JSON.stringify(t.map(e => e.shape))));\n      if (s.length > 0 && r.length > 0 && !p(s, r)) throw new bu(\"Input Tensors should have the same number of samples as target Tensors. Found \".concat(s[0], \" input sample(s) and \").concat(r[0], \" target sample(s).\"));\n    }(e = Nd(e, this.feedInputNames, this.feedInputShapes, !1, \"input\"), t = Nd(t, this.feedOutputNames, r, !1, \"target\")), function (e, t, n) {\n      var s = [Ah, Mh, _h];\n\n      for (var _r64 = 0; _r64 < e.length; ++_r64) {\n        var _a54 = e[_r64],\n            _i31 = t[_r64],\n            _o23 = n[_r64];\n\n        if (null != _i31) {\n          if (_i31 === _h && 1 === _a54.shape[_a54.shape.length - 1]) throw new bu(\"You are passing a target array of shape \".concat(_a54.shape, \" while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].\"));\n\n          if (-1 !== s.indexOf(_i31)) {\n            var _e183 = _a54.shape.slice(1),\n                _t172 = _o23.slice(1);\n\n            for (var _n108 = 0; _n108 < _e183.length; ++_n108) {\n              var _s95 = _e183[_n108],\n                  _r65 = _t172[_n108];\n              if (null != _r65 && _s95 !== _r65) throw new bu(\"A target Tensor with shape \".concat(_a54.shape, \" was passed for an output of shape \").concat(_o23, \", while using a loss function that expects targets to have the same shape as the output.\"));\n            }\n          }\n        }\n      }\n    }(t, this.feedLossFns, this.feedOutputShapes), this.stateful && null != s && s > 0 && e[0].shape[0] % s != 0) throw new bu(\"In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size \".concat(s, \". Found: \").concat(e[0].shape[0], \" sample(s).\"));\n    return [e, t];\n  }\n\n  standardizeUserData(e, t, n, s) {\n    var _arguments = arguments,\n        _this60 = this;\n\n    return _asyncToGenerator(function* () {\n      var r = _arguments.length > 4 && _arguments[4] !== undefined ? _arguments[4] : !0;\n      var a = _arguments.length > 5 ? _arguments[5] : undefined;\n\n      var [i, o] = _this60.standardizeUserDataXY(e, t, r, a);\n\n      if (null != n) throw new Error(\"sample weight is not supported yet.\");\n      var l = null;\n\n      if (null != s) {\n        var _e184 = hd(s, _this60.outputNames);\n\n        l = [];\n\n        for (var _t173 = 0; _t173 < _e184.length; ++_t173) {\n          l.push(yield dd(o[_t173], null, _e184[_t173]));\n        }\n      }\n\n      return [i, o, l];\n    })();\n  }\n\n  testLoop(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    return Yn(() => {\n      var a = this.checkNumSamples(t, n, r, \"steps\"),\n          i = [];\n      if (s > 0) throw new xu(\"Verbose mode is not implemented yet.\");\n      if (null != r) throw new xu(\"steps mode in testLoop() is not implemented yet\");\n      {\n        var _s96 = kd(a, n),\n            _r66 = mi(pc(0, a));\n\n        for (var _n109 = 0; _n109 < _s96.length; ++_n109) {\n          var _a55 = _s96[_n109][0],\n              _o24 = _s96[_n109][1],\n              _l16 = mc(_r66, _a55, _o24 - _a55),\n              _u9 = yd(t, _l16),\n              _c8 = e(_u9);\n\n          if (0 === _n109) for (var _e185 = 0; _e185 < _c8.length; ++_e185) {\n            i.push(qa(0));\n          }\n\n          for (var _e186 = 0; _e186 < _c8.length; ++_e186) {\n            i[_e186] = es(i[_e186], ss(_o24 - _a55, _c8[_e186]));\n          }\n        }\n\n        for (var _e187 = 0; _e187 < i.length; ++_e187) {\n          i[_e187] = ns(i[_e187], a);\n        }\n      }\n      return i;\n    });\n  }\n\n  getDedupedMetricsNames() {\n    var e = this.metricsNames,\n        t = [];\n\n    for (var _n110 = 0; _n110 < e.length; ++_n110) {\n      var _s97 = e[_n110];\n      var _r67 = _s97;\n      vu(e, _s97) > 1 && (_r67 += \"_\".concat(vu(e.slice(0, _n110), _s97))), t.push(_r67);\n    }\n\n    return t;\n  }\n\n  makeTrainFunction() {\n    return e => {\n      var t = [],\n          n = e.slice(0, this.inputs.length),\n          s = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),\n          r = e.slice(this.inputs.length + this.outputs.length, this.inputs.length + 2 * this.outputs.length),\n          a = [],\n          i = this.collectedTrainableWeights.map(e => e.read());\n      return [this.optimizer_.minimize(() => {\n        var e = [];\n\n        for (var _t174 = 0; _t174 < this.inputs.length; ++_t174) {\n          e.push({\n            key: this.inputs[_t174],\n            value: n[_t174]\n          });\n        }\n\n        var i = new sd(e),\n            o = id(this.outputs, i, {\n          training: !0\n        });\n        var l;\n\n        for (var _e188 = 0; _e188 < this.lossFunctions.length; ++_e188) {\n          var _n111 = (0, this.lossFunctions[_e188])(s[_e188], o[_e188]);\n\n          null != r[_e188] && (_n111 = pd(_n111, r[_e188]));\n\n          var _a56 = la(_n111);\n\n          t.push(_a56), l = 0 === _e188 ? _n111 : es(l, _n111);\n        }\n\n        for (var _e189 = 0; _e189 < this.metricsTensors.length; ++_e189) {\n          var _n112 = void 0;\n\n          if (this.outputs.length > 1 && _e189 < this.outputs.length) _n112 = t[_e189];else {\n            var _t175 = this.metricsTensors[_e189][1];\n            _n112 = la((0, this.metricsTensors[_e189][0])(s[_t175], o[_t175]));\n          }\n          Zn(_n112), a.push(_n112);\n        }\n\n        return l = la(l), this.calculateLosses().forEach(e => {\n          l = es(l, e);\n        }), l;\n      }, !0, i)].concat(a);\n    };\n  }\n\n  makeTestFunction() {\n    this.testFunction = e => Yn(() => {\n      var t = [];\n      var n;\n      var s = e.slice(0, this.inputs.length),\n          r = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),\n          a = [];\n\n      for (var _e190 = 0; _e190 < this.inputs.length; ++_e190) {\n        a.push({\n          key: this.inputs[_e190],\n          value: s[_e190]\n        });\n      }\n\n      var i = new sd(a),\n          o = id(this.outputs, i);\n\n      for (var _e191 = 0; _e191 < this.lossFunctions.length; ++_e191) {\n        var _s98 = la((0, this.lossFunctions[_e191])(r[_e191], o[_e191]));\n\n        n = 0 === _e191 ? _s98 : es(n, _s98), t.push(n);\n      }\n\n      for (var _e192 = 0; _e192 < this.metricsTensors.length; ++_e192) {\n        var _n113 = this.metricsTensors[_e192][1],\n            _s99 = la((0, this.metricsTensors[_e192][0])(r[_n113], o[_n113]));\n\n        t.push(_s99);\n      }\n\n      return t;\n    });\n  }\n\n  fit(e, t) {\n    var _arguments2 = arguments,\n        _this61 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = _arguments2.length > 2 && _arguments2[2] !== undefined ? _arguments2[2] : {};\n      return function () {\n        var _ref6 = _asyncToGenerator(function* (e, t, n) {\n          var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n          if (e.isTraining) throw new Error(\"Cannot start training because another fit() call is ongoing.\");\n          var a, i, o, l, u, c, h;\n          e.isTraining = !0;\n\n          try {\n            var _d5 = null == s.batchSize ? 32 : s.batchSize;\n\n            bd(_d5);\n\n            var _p5 = !1,\n                _f4 = yield e.standardizeUserData(t, n, s.sampleWeight, s.classWeight, _p5, _d5);\n\n            a = _f4[0], i = _f4[1], h = _f4[2];\n\n            var _g6,\n                _m5 = !1;\n\n            if (null != s.validationData && s.validationData.length > 0) {\n              if (_m5 = !0, 2 !== s.validationData.length) throw 3 === s.validationData.length ? new xu(\"validationData including sample weights is not supported yet.\") : new bu(\"When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; \".concat(s.validationData, \" is invalid.\"));\n              o = s.validationData[0], l = s.validationData[1];\n\n              var _t176 = !0,\n                  _n114 = yield e.standardizeUserData(o, l, null, null, _t176, _d5);\n\n              u = _n114[0], c = _n114[1], _g6 = u.concat(c);\n            } else if (null != s.validationSplit && s.validationSplit > 0 && s.validationSplit < 1) {\n              _m5 = !0;\n\n              var _e193 = Math.floor(a[0].shape[0] * (1 - s.validationSplit)),\n                  _t177 = a[0].shape[0];\n\n              u = xd(a, _e193, _t177), a = xd(a, 0, _e193), c = xd(i, _e193, _t177), i = xd(i, 0, _e193), _g6 = u.concat(c);\n            } else null != s.validationSteps && (_m5 = !0);\n\n            var _b5 = a.concat(i).concat(h);\n\n            e.checkTrainableWeightsConsistency();\n\n            var _x31 = e.makeTrainFunction(),\n                _y5 = e.getDedupedMetricsNames();\n\n            var _k3, _w2;\n\n            _m5 ? (e.makeTestFunction(), _k3 = e.testFunction, _w2 = _y5.slice().concat(_y5.map(e => \"val_\" + e))) : (_k3 = null, _g6 = [], _w2 = _y5.slice());\n\n            var _v2 = Ch(s.callbacks, s.yieldEvery);\n\n            return yield function () {\n              var _ref7 = _asyncToGenerator(function* (e, t, n, s, a, i, o, l, u, c, h, d, p, f, g) {\n                null == a && (a = 32), null == i && (i = 1), null == h && (h = !0), null == p && (p = 0);\n                var m = !1;\n                null != u && null != c && (m = !0);\n                var b = e.checkNumSamples(n, a, null, \"steps_per_epoch\");\n                var x;\n                null != b && (x = pc(0, b)), null == o && (o = 1);\n                var {\n                  callbackList: y,\n                  history: k\n                } = Th(l, o, i, p, b, null, a, m, d);\n                y.setModel(e), e.history = k, yield y.onTrainBegin(), e.stopTraining_ = !1;\n\n                var _loop22 = function* _loop22(_o25) {\n                  yield y.onEpochBegin(_o25);\n                  var i = {};\n                  {\n                    yield* function* () {\n                      if (\"batch\" === h) throw new xu(\"batch shuffling is not implemneted yet\");\n                      h && r(x);\n                      var o = mi(x),\n                          l = kd(b, a);\n\n                      var _loop23 = function* _loop23(_r68) {\n                        var h = {};\n                        if (yield y.onBatchBegin(_r68, h), Yn(() => {\n                          var d = l[_r68][0],\n                              p = l[_r68][1],\n                              f = mc(o, d, p - d);\n                          h.batch = _r68, h.size = p - d;\n                          var g = yd(n, f),\n                              b = t(g);\n\n                          for (var _e194 = 0; _e194 < s.length; ++_e194) {\n                            var _t178 = b[_e194];\n                            h[s[_e194]] = _t178, Zn(_t178);\n                          }\n\n                          if (_r68 === l.length - 1 && m) {\n                            var _t179 = e.testLoop(u, c, a);\n\n                            for (var _e195 = 0; _e195 < s.length; ++_e195) {\n                              var _n115 = s[_e195],\n                                  _r69 = _t179[_e195];\n                              Zn(_r69), i[\"val_\" + _n115] = _r69;\n                            }\n                          }\n                        }), yield y.onBatchEnd(_r68, h), yh(h), e.stopTraining_) return \"break\";\n                      };\n\n                      for (var _r68 = 0; _r68 < l.length; ++_r68) {\n                        var _ret3 = yield* _loop23(_r68);\n\n                        if (_ret3 === \"break\") break;\n                      }\n\n                      o.dispose();\n                    }();\n                  }\n                  if (yield y.onEpochEnd(_o25, i), e.stopTraining_) return \"break\";\n                };\n\n                for (var _o25 = p; _o25 < i; ++_o25) {\n                  var _ret2 = yield* _loop22(_o25);\n\n                  if (_ret2 === \"break\") break;\n                }\n\n                return yield y.onTrainEnd(), yield e.history.syncData(), e.history;\n              });\n\n              return function (_x32, _x33, _x34, _x35, _x36, _x37, _x38, _x39, _x40, _x41, _x42, _x43, _x44, _x45, _x46) {\n                return _ref7.apply(this, arguments);\n              };\n            }()(e, _x31, _b5, _y5, _d5, s.epochs, s.verbose, _v2, _k3, _g6, s.shuffle, _w2, s.initialEpoch);\n          } finally {\n            e.isTraining = !1, vd(a, t), vd(i, n), vd(u, o), vd(c, l), null != h && Jn(h);\n          }\n        });\n\n        return function (_x28, _x29, _x30) {\n          return _ref6.apply(this, arguments);\n        };\n      }()(_this61, e, t, n);\n    })();\n  }\n\n  fitDataset(e, t) {\n    var _this62 = this;\n\n    return _asyncToGenerator(function* () {\n      return function () {\n        var _ref8 = _asyncToGenerator(function* (e, t, n) {\n          var s = null != n.batchesPerEpoch;\n          if (l(null != e.optimizer, () => \"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).\"), l(null != n, () => \"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.\"), l(null != n.epochs && n.epochs > 0 && Number.isInteger(n.epochs), () => \"For fitDataset(), config.epochs is expected to be a positive integer, but got \".concat(n.epochs)), l(!s || n.batchesPerEpoch > 0 && Number.isInteger(n.batchesPerEpoch), () => \"For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got \".concat(n.batchesPerEpoch)), l(null == n.validationSplit, () => \"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.\"), e.isTraining) throw new Error(\"Cannot start training because another fit() call is ongoing.\");\n          e.isTraining = !0;\n\n          try {\n            var _r70 = null != n.validationData;\n\n            var _a57, _i32;\n\n            if (_r70) if (md(n.validationData)) l(null == n.validationBatches || n.validationBatches > 0 && Number.isInteger(n.validationBatches), () => \"For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got \".concat(n.validationBatches));else {\n              var _e196 = function (e) {\n                if (3 === e.length) throw new xu(\"Validation with sample weights is not implemented yet.\");\n                return {\n                  xs: e[0],\n                  ys: e[1]\n                };\n              }(n.validationData);\n\n              _a57 = _e196.xs, _i32 = _e196.ys;\n            }\n\n            var _o26 = e.makeTrainFunction(),\n                _u10 = e.getDedupedMetricsNames();\n\n            var _c9;\n\n            _c9 = _r70 ? _u10.slice().concat(_u10.map(e => \"val_\" + e)) : _u10.slice();\n\n            var _h6 = Ch(n.callbacks, n.yieldEvery),\n                _d6 = null == n.verbose ? 1 : n.verbose,\n                {\n              callbackList: _p6,\n              history: _f5\n            } = Th(_h6, _d6, n.epochs, null, null, function (e, t) {\n              var n = null;\n              return null != t.batchesPerEpoch ? n = t.batchesPerEpoch : Number.isFinite(e.size) && (n = e.size), n;\n            }(t, n), null, _r70, _c9);\n\n            _p6.setModel(e), e.history = _f5, yield _p6.onTrainBegin(), e.stopTraining_ = !1;\n\n            var _g7 = null == n.initialEpoch ? 0 : n.initialEpoch,\n                _m6 = yield t.iterator();\n\n            for (; _g7 < n.epochs;) {\n              var _l17 = {};\n              yield _p6.onEpochBegin(_g7);\n              var _c10 = 0,\n                  _h7 = 0;\n\n              for (s || (_m6 = yield t.iterator()); !s || _c10 < n.batchesPerEpoch;) {\n                var _t180 = yield _m6.next();\n\n                if (s && _t180.done) {\n                  console.warn(\"You provided `batchesPerEpoch` as \".concat(n.batchesPerEpoch, \", but your dataset iterator ran out of data after \").concat(_c10, \" batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, \") + n.batchesPerEpoch * n.epochs + \" batches). You may need to use the repeat() function when building your dataset.\");\n                  break;\n                }\n\n                if (null != _t180.value) {\n                  var {\n                    xs: _s100,\n                    ys: _r71\n                  } = fd(e, _t180.value),\n                      _a58 = {};\n                  _a58.batch = _h7, _a58.size = _s100[0].shape[0], yield _p6.onBatchBegin(_h7, _a58);\n                  var _i33 = [];\n\n                  if (null != n.classWeight) {\n                    var _t181 = hd(n.classWeight, e.outputNames);\n\n                    for (var _e197 = 0; _e197 < _t181.length; ++_e197) {\n                      _i33.push(yield dd(_r71[_e197], null, _t181[_e197]));\n                    }\n                  }\n\n                  var _l18 = _s100.concat(_r71).concat(_i33),\n                      _d7 = _o26(_l18);\n\n                  Jn(_l18);\n\n                  for (var _e198 = 0; _e198 < _u10.length; ++_e198) {\n                    var _t182 = _d7[_e198];\n                    _a58[_u10[_e198]] = _t182, Zn(_t182);\n                  }\n\n                  yield _p6.onBatchEnd(_h7, _a58), yh(_a58), _h7++, _c10++;\n                }\n\n                if (s ? _c10 >= n.batchesPerEpoch : _t180.done) {\n                  if (_r70) {\n                    var _t183 = void 0;\n\n                    _t183 = md(n.validationData) ? $u(yield e.evaluateDataset(n.validationData, {\n                      batches: n.validationBatches\n                    })) : $u(e.evaluate(_a57, _i32, {\n                      batchSize: null == n.validationBatchSize ? 32 : n.validationBatchSize,\n                      verbose: 0\n                    }));\n\n                    for (var _n116 = 0; _n116 < e.metricsNames.length; ++_n116) {\n                      _l17[\"val_\".concat(e.metricsNames[_n116])] = _t183[_n116];\n                    }\n                  }\n\n                  break;\n                }\n\n                if (e.stopTraining_) break;\n              }\n\n              if (yield _p6.onEpochEnd(_g7, _l17), _g7++, e.stopTraining_) break;\n            }\n\n            return yield _p6.onTrainEnd(), yield e.history.syncData(), e.history;\n          } finally {\n            e.isTraining = !1;\n          }\n        });\n\n        return function (_x47, _x48, _x49) {\n          return _ref8.apply(this, arguments);\n        };\n      }()(_this62, e, t);\n    })();\n  }\n\n  trainOnBatch(e, t) {\n    var _this63 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = yield _this63.standardizeUserData(e, t),\n          s = n[0],\n          r = n[1],\n          a = _this63.makeTrainFunction()(s.concat(r)),\n          i = [];\n\n      for (var _e199 of a) {\n        var _t184 = yield _e199.data();\n\n        i.push(_t184[0]);\n      }\n\n      return Jn(a), Iu(i);\n    })();\n  }\n\n  getNamedWeights(e) {\n    var t = [],\n        n = null != e && e.trainableOnly,\n        s = n ? this.trainableWeights : this.weights,\n        r = this.getWeights(n);\n\n    for (var _e200 = 0; _e200 < s.length; ++_e200) {\n      n && !s[_e200].trainable || t.push({\n        name: s[_e200].originalName,\n        tensor: r[_e200]\n      });\n    }\n\n    return t;\n  }\n\n  set stopTraining(e) {\n    this.stopTraining_ = e;\n  }\n\n  get stopTraining() {\n    return this.stopTraining_;\n  }\n\n  get optimizer() {\n    return this.optimizer_;\n  }\n\n  set optimizer(e) {\n    this.optimizer_ !== e && (this.optimizer_ = e, this.isOptimizerOwned = !1);\n  }\n\n  dispose() {\n    var e = super.dispose();\n\n    if (0 === e.refCountAfterDispose && null != this.optimizer && this.isOptimizerOwned) {\n      var _t185 = Xn().numTensors;\n      this.optimizer_.dispose(), e.numDisposedVariables += _t185 - Xn().numTensors;\n    }\n\n    return e;\n  }\n\n  getLossIdentifiers() {\n    var e;\n    if (\"string\" == typeof this.loss) e = Nu(this.loss);else if (Array.isArray(this.loss)) {\n      for (var _e201 of this.loss) {\n        if (\"string\" != typeof _e201) throw new Error(\"Serialization of non-string loss is not supported.\");\n      }\n\n      e = this.loss.map(e => Nu(e));\n    } else {\n      var _t186 = Object.keys(this.loss);\n\n      e = {};\n      var _n117 = this.loss;\n\n      for (var _s101 of _t186) {\n        if (\"string\" != typeof _n117[_s101]) throw new Error(\"Serialization of non-string loss is not supported.\");\n        e[_s101] = Nu(_n117[_s101]);\n      }\n    }\n    return e;\n  }\n\n  getMetricIdentifiers() {\n    if (\"string\" == typeof this.metrics || \"function\" == typeof this.metrics) return [Nu(Kh(this.metrics))];\n    if (Array.isArray(this.metrics)) return this.metrics.map(e => Nu(Kh(e)));\n    {\n      var _e202 = {};\n\n      for (var _t187 in this.metrics) {\n        _e202[_t187] = Nu(Kh(this.metrics[_t187]));\n      }\n\n      return _e202;\n    }\n  }\n\n  getTrainingConfig() {\n    return {\n      loss: this.getLossIdentifiers(),\n      metrics: this.getMetricIdentifiers(),\n      optimizer_config: {\n        class_name: this.optimizer.getClassName(),\n        config: this.optimizer.getConfig()\n      }\n    };\n  }\n\n  loadTrainingConfig(e) {\n    if (null != e.weighted_metrics) throw new Error(\"Loading weight_metrics is not supported yet.\");\n    if (null != e.loss_weights) throw new Error(\"Loading loss_weights is not supported yet.\");\n    if (null != e.sample_weight_mode) throw new Error(\"Loading sample_weight_mode is not supported yet.\");\n    var t = Eh(td(e.optimizer_config));\n    var n, s;\n    if (\"string\" == typeof e.loss) n = Cu(e.loss);else if (Array.isArray(e.loss)) n = e.loss.map(e => Cu(e));else if (null != e.loss) {\n      n = {};\n\n      for (var _t188 in e.loss) {\n        n[_t188] = Cu(e.loss[_t188]);\n      }\n    }\n    if (Array.isArray(e.metrics)) s = e.metrics.map(e => Cu(e));else if (null != e.metrics) {\n      s = {};\n\n      for (var _t189 in e.metrics) {\n        s[_t189] = Cu(e.metrics[_t189]);\n      }\n    }\n    this.compile({\n      loss: n,\n      metrics: s,\n      optimizer: t\n    });\n  }\n\n  save(e, t) {\n    var _this64 = this;\n\n    return _asyncToGenerator(function* () {\n      if (\"string\" == typeof e) {\n        var _t190 = Gt.getSaveHandlers(e);\n\n        if (0 === _t190.length) throw new bu(\"Cannot find any save handlers for URL '\".concat(e, \"'\"));\n        if (_t190.length > 1) throw new bu(\"Found more than one (\".concat(_t190.length, \") save handlers for URL '\").concat(e, \"'\"));\n        e = _t190[0];\n      }\n\n      if (null == e.save) throw new bu(\"LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.\");\n      var n = yield Mt(_this64.getNamedWeights(t)),\n          s = {\n        modelTopology: _this64.toJSON(null, !1),\n        format: \"layers-model\",\n        generatedBy: \"TensorFlow.js tfjs-layers v3.8.0\",\n        convertedBy: null\n      };\n\n      if (null != t && t.includeOptimizer && null != _this64.optimizer) {\n        s.trainingConfig = _this64.getTrainingConfig();\n        var _e203 = \"optimizer\",\n            {\n          data: _t191,\n          specs: _r72\n        } = yield Mt(yield _this64.optimizer.getWeights(), _e203);\n        n.specs.push(..._r72), n.data = Pt([n.data, _t191]);\n      }\n\n      return null != _this64.userDefinedMetadata && (Xh(_this64.userDefinedMetadata, _this64.name, !0), s.userDefinedMetadata = _this64.userDefinedMetadata), s.weightData = n.data, s.weightSpecs = n.specs, e.save(s);\n    })();\n  }\n\n  setUserDefinedMetadata(e) {\n    Xh(e, this.name), this.userDefinedMetadata = e;\n  }\n\n  getUserDefinedMetadata() {\n    return this.userDefinedMetadata;\n  }\n\n}\n\nSd.className = \"Model\", qn(Sd);\n\nclass Td extends Sd {}\n\nTd.className = \"Functional\", qn(Td);\n\nclass Ed extends Sd {\n  constructor(e) {\n    if (super({\n      inputs: [],\n      outputs: []\n    }), e = e || {}, this.trainable = !0, this.built = !1, this.name = null != e.name ? e.name : th(\"sequential_\"), null != e.layers) for (var _t192 of e.layers) {\n      this.add(_t192);\n    }\n  }\n\n  checkShape(e) {\n    if (e.inboundNodes[0].outputTensors[0].shape.some(e => e < 0)) throw new bu(\"Negative dimension size caused by adding layer \".concat(e.name, \" with input shape [\").concat(e.inboundNodes[0].inputTensors[0].shape, \"]\"));\n  }\n\n  add(e) {\n    var t = e instanceof Ed || e instanceof Sd;\n    var n;\n\n    if (t) {\n      if (n = e, 1 !== n.outputs.length) throw new bu(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n      if (1 !== n.inputs.length) throw new bu(\"All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.\");\n    }\n\n    if (0 === this.outputs.length) {\n      if (0 === e.inboundNodes.length) {\n        if (null == e.batchInputShape) throw new bu(\"The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.\");\n\n        var _t193 = function (e) {\n          if (null == e.batchShape && null == e.shape) throw new Error(\"Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.\");\n          if (null != e.batchShape && null != e.shape) throw new bu(\"Please provide either a `shape` or `batchShape` argument to Input, but not both.\");\n          var t = e.batchShape;\n          null != e.shape && null == t && (t = [null].concat(e.shape));\n          var n = e.dtype;\n          return null == n && (n = \"float32\"), new bh({\n            batchInputShape: t,\n            name: e.name,\n            dtype: n,\n            sparse: e.sparse\n          }).inboundNodes[0].outputTensors[0];\n        }({\n          batchShape: e.batchInputShape,\n          dtype: e.dtype,\n          name: e.name + \"_input\"\n        });\n\n        e.apply(_t193);\n      }\n\n      if (t) this.outputs = n.outputs, this.inputs = n.inputs;else {\n        if (1 !== e.inboundNodes.length) throw new bu(\"A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer \".concat(e.name, \" which has \").concat(e.inboundNodes.length, \" pre-existing inbound connections.\"));\n        if (1 !== e.inboundNodes[0].outputTensors.length) throw new bu(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n        this.checkShape(e), this.outputs = [e.inboundNodes[0].outputTensors[0]], this.inputs = mh(this.outputs[0]);\n      }\n      this.inboundNodes = [], new ph({\n        outboundLayer: this,\n        inboundLayers: [],\n        nodeIndices: [],\n        tensorIndices: [],\n        inputTensors: this.inputs,\n        outputTensors: this.outputs,\n        inputMasks: ku(null, this.inputs.length),\n        outputMasks: [null],\n        inputShapes: this.inputs.map(e => e.shape),\n        outputShapes: this.outputs[0].shape\n      });\n    } else {\n      var _t194 = e.apply(this.outputs[0]);\n\n      if (Array.isArray(_t194)) throw new TypeError(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n      this.checkShape(e), this.outputs = [_t194], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n\n    this.layers.push(e), this.built = !1;\n  }\n\n  pop() {\n    if (0 === this.layers.length) throw new TypeError(\"There are no layers in the model.\");\n    if (this.layers.pop(), 0 === this.layers.length) this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];else {\n      var _e204 = this.layers.length - 1;\n\n      this.layers[_e204].outboundNodes = [], this.outputs = [this.layers[_e204].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n  }\n\n  call(e, t) {\n    return null == this.model && this.build(), this.model.call(e, t);\n  }\n\n  build(e) {\n    if (ah(e), 0 === this.inputs.length || 0 === this.outputs.length) throw new TypeError(\"Sequential model cannot be built: model is empty. Add some layers first.\");\n    this.model = new Sd({\n      inputs: this.inputs,\n      outputs: this.outputs[0],\n      name: this.name + \"_model\"\n    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = !0;\n  }\n\n  countParams() {\n    return this.built || this.build(), super.countParams();\n  }\n\n  summary(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n    this.built || this.build(), super.summary(e, t, n);\n  }\n\n  setWeights(e) {\n    null == this.model && this.build(), this.model.setWeights(e);\n  }\n\n  evaluate(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    if (!this.built) throw new mu(\"The model needs to be compiled before being used.\");\n    return this.model.evaluate(e, t, n);\n  }\n\n  evaluateDataset(e, t) {\n    var _this65 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!_this65.built) throw new mu(\"The model needs to be compiled before being used.\");\n      return _this65.model.evaluateDataset(e, t);\n    })();\n  }\n\n  predict(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    return null == this.model && this.build(), this.model.predict(e, t);\n  }\n\n  predictOnBatch(e) {\n    return null == this.model && this.build(), this.model.predictOnBatch(e);\n  }\n\n  compile(e) {\n    this.build(), this.model.compile(e), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;\n  }\n\n  get optimizer() {\n    return null == this.model ? void 0 : this.model.optimizer;\n  }\n\n  set optimizer(e) {\n    this.model.optimizer = e;\n  }\n\n  fit(e, t) {\n    var _arguments3 = arguments,\n        _this66 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = _arguments3.length > 2 && _arguments3[2] !== undefined ? _arguments3[2] : {};\n      if (!_this66.built) throw new mu(\"The model needs to be compiled before being used.\");\n      return _this66.model.fit(e, t, n);\n    })();\n  }\n\n  fitDataset(e, t) {\n    var _this67 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!_this67.built) throw new mu(\"The model needs to be compiled before being used.\");\n      return _this67.model.fitDataset(e, t);\n    })();\n  }\n\n  trainOnBatch(e, t) {\n    var _this68 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this68.model.trainOnBatch(e, t);\n    })();\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r,\n        a = {};\n\n    if (t instanceof Array) {\n      if (null == t[0].className || \"Merge\" === t[0].className) throw new bu(\"Legacy serialization format not supported yet.\");\n      r = t;\n    } else l(null != t.layers, () => \"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.\"), r = t.layers, delete t.layers, a = t;\n\n    var i = new e(a);\n    if (!(i instanceof Ed)) throw new xu(\"Sequential.fromConfig called on non-Sequential input: \".concat(i));\n\n    for (var _e205 of r) {\n      var _t195 = Eh(_e205, void 0, s);\n\n      s && _t195.setFastWeightInitDuringBuild(!0), i.add(_t195);\n    }\n\n    return i;\n  }\n\n  set stopTraining(e) {\n    if (null == this.model) throw new bu(\"Cannot set the stopTraining property of a sequential model before it is compiled.\");\n    this.model.stopTraining = e;\n  }\n\n  get stopTraining() {\n    if (null == this.model) throw new bu(\"Cannot get the stopTraining property of a sequential model before it is compiled.\");\n    return this.model.stopTraining;\n  }\n\n  getConfig() {\n    var e = [];\n\n    for (var _t196 of this.layers) {\n      var _n118 = {};\n      _n118.className = _t196.getClassName(), _n118.config = _t196.getConfig(), e.push(_n118);\n    }\n\n    return {\n      name: this.name,\n      layers: e\n    };\n  }\n\n}\n\nEd.className = \"Sequential\", qn(Ed);\n\nclass Rd extends Hn {\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass Ad extends Rd {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n      if (1 !== t) throw new xu(\"Support for alpha values other than 1 (\".concat(t, \") is not implemented yet.\"));\n      return mr(e);\n    }(e, t);\n  }\n\n}\n\nAd.className = \"elu\", qn(Ad);\n\nclass Fd extends Rd {\n  apply(e) {\n    return Ka(e);\n  }\n\n}\n\nFd.className = \"selu\", qn(Fd);\n\nclass Dd extends Rd {\n  apply(e) {\n    return Ua(e);\n  }\n\n}\n\nDd.className = \"relu\", qn(Dd);\n\nclass _d extends Rd {\n  apply(e) {\n    return Yn(() => da(6, Ua(e)));\n  }\n\n}\n\n_d.className = \"relu6\", qn(_d);\n\nclass Od extends Rd {\n  apply(e) {\n    return e;\n  }\n\n}\n\nOd.className = \"linear\", qn(Od);\n\nclass Md extends Rd {\n  apply(e) {\n    return Ds(e);\n  }\n\n}\n\nMd.className = \"sigmoid\", qn(Md);\n\nclass Ld extends Rd {\n  apply(e) {\n    return function (e) {\n      return Yn(() => {\n        var t = es(.5, ss(.2, e));\n        return Gs(t, 0, 1);\n      });\n    }(e);\n  }\n\n}\n\nLd.className = \"hardSigmoid\", qn(Ld);\n\nclass zd extends Rd {\n  apply(e) {\n    return Pr(e);\n  }\n\n}\n\nzd.className = \"softplus\", qn(zd);\n\nclass Bd extends Rd {\n  apply(e) {\n    return function (e) {\n      return Yn(() => ns(e, es(rs(e), 1)));\n    }(e);\n  }\n\n}\n\nBd.className = \"softsign\", qn(Bd);\n\nclass Pd extends Rd {\n  apply(e) {\n    return Os(e);\n  }\n\n}\n\nPd.className = \"tanh\", qn(Pd);\n\nclass Wd extends Rd {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    return si(e, t);\n  }\n\n}\n\nWd.className = \"softmax\", qn(Wd);\n\nclass Ud extends Rd {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    return Hr(e, t);\n  }\n\n}\n\nUd.className = \"logSoftmax\", qn(Ud);\n\nclass Vd extends Rd {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return Yn(() => ss(Ds(ss(e, t)), e));\n  }\n\n}\n\nVd.className = \"swish\", qn(Vd);\n\nclass Gd extends Rd {\n  apply(e) {\n    return Yn(() => ss(e, Os(Pr(e))));\n  }\n\n}\n\nfunction Hd(e) {\n  return e.getClassName();\n}\n\nfunction jd(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Ru(e, jn.getMap().classNameMap, t, \"activation\");\n}\n\nfunction qd(e) {\n  if (null == e) return jd({\n    className: \"linear\",\n    config: {}\n  });\n\n  if (\"string\" == typeof e) {\n    var _t197 = {};\n    return _t197.className = e, _t197.config = {}, jd(_t197);\n  }\n\n  return e instanceof Rd ? e : jd(e);\n}\n\nGd.className = \"mish\", qn(Gd);\n\nclass Kd extends Hn {}\n\nclass Xd extends Kd {\n  constructor(e) {\n    super(), function (e) {\n      if (null != e && \"object\" != typeof e) throw new Error(\"Argument to L1L2 regularizer's constructor is expected to be an object, but received: \".concat(e));\n    }(e), this.l1 = null == e || null == e.l1 ? .01 : e.l1, this.l2 = null == e || null == e.l2 ? .01 : e.l2, this.hasL1 = 0 !== this.l1, this.hasL2 = 0 !== this.l2;\n  }\n\n  apply(e) {\n    return Yn(() => {\n      var t = ua([1]);\n      return this.hasL1 && (t = es(t, Gr(ss(this.l1, rs(e))))), this.hasL2 && (t = es(t, Gr(ss(this.l2, Nc(e))))), Es(t, []);\n    });\n  }\n\n  getConfig() {\n    return {\n      l1: this.l1,\n      l2: this.l2\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e({\n      l1: t.l1,\n      l2: t.l2\n    });\n  }\n\n}\n\nXd.className = \"L1L2\", qn(Xd);\nvar Yd = {\n  l1l2: \"L1L2\"\n};\n\nfunction Jd(e) {\n  return Tu(e);\n}\n\nfunction Zd(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Ru(e, jn.getMap().classNameMap, t, \"regularizer\");\n}\n\nfunction Qd(e) {\n  return null == e ? null : \"string\" == typeof e ? Zd({\n    className: e in Yd ? Yd[e] : e,\n    config: {}\n  }) : e instanceof Kd ? e : Zd(e);\n}\n\nclass ep extends gh {\n  constructor(e) {\n    super(null == e ? {} : e), this.supportsMasking = !0, null != e && (this.maxValue = e.maxValue);\n  }\n\n  call(e, t) {\n    e = rh(e);\n    var n = Ua(e);\n    return null != this.maxValue && (n = Gs(n, 0, this.maxValue)), n;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      maxValue: this.maxValue\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nep.className = \"ReLU\", qn(ep);\n\nclass tp extends gh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_ALPHA = .3, null == e && (e = {}), this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;\n  }\n\n  call(e, t) {\n    var n = rh(e);\n    return Fr(n, this.alpha);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      alpha: this.alpha\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\ntp.className = \"LeakyReLU\", qn(tp);\n\nclass np extends gh {\n  constructor(e) {\n    if (super(null == e ? {} : e), this.DEFAULT_ALPHA_INITIALIZER = \"zeros\", null == e && (e = {}), this.supportsMasking = !0, this.alphaInitializer = Jc(e.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = Qd(e.alphaRegularizer), this.alphaConstraint = Ku(e.alphaConstraint), null == e.sharedAxes) this.sharedAxes = null;else if (Array.isArray(e.sharedAxes)) this.sharedAxes = e.sharedAxes;else {\n      if (\"number\" != typeof e.sharedAxes) throw new bu(\"Expected sharedAxes to be a number or an array of numbers, but got \".concat(e.sharedAxes));\n      this.sharedAxes = [e.sharedAxes];\n    }\n  }\n\n  build(e) {\n    var t = (e = ah(e)).slice(1);\n    if (null != this.sharedAxes) for (var _e206 of this.sharedAxes) {\n      t[_e206 - 1] = 1;\n    }\n    this.alpha = this.addWeight(\"alpha\", t, \"float32\", this.alphaInitializer, this.alphaRegularizer, !0, this.alphaConstraint);\n    var n = {};\n    if (null != this.sharedAxes) for (var _t198 = 1; _t198 < e.length; ++_t198) {\n      n[_t198] = e[_t198];\n    }\n    this.inputSpec = [new ch({\n      ndim: e.length,\n      axes: n\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return e = rh(e), Ia(e, this.alpha.read());\n  }\n\n  getConfig() {\n    var e = {\n      alphaInitializer: Yc(this.alphaInitializer),\n      alphaRegularizer: Jd(this.alphaRegularizer),\n      alphaConstraint: ju(this.alphaConstraint),\n      sharedAxes: this.sharedAxes\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nnp.className = \"PReLU\", qn(np);\n\nclass sp extends gh {\n  constructor(e) {\n    if (super(null == e ? {} : e), this.DEFAULT_ALPHA = 1, null == e && (e = {}), null != e.alpha && e.alpha !== this.DEFAULT_ALPHA) throw new xu(\"Non-default alpha value (\".concat(e.alpha, \") is not supported by the ELU layer yet.\"));\n    this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;\n  }\n\n  call(e, t) {\n    var n = rh(e);\n    return mr(n);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      alpha: this.alpha\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nsp.className = \"ELU\", qn(sp);\n\nclass rp extends gh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_THETA = 1, null == e && (e = {}), this.theta = null == e.theta ? this.DEFAULT_THETA : e.theta;\n  }\n\n  call(e, t) {\n    var n = rh(e);\n    return ss(n, pn(Cr(n, this.theta), \"float32\"));\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      theta: this.theta\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nrp.className = \"ThresholdedReLU\", qn(rp);\n\nclass ap extends gh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_AXIS = 1, null == e && (e = {}), this.softmax = new Wd().apply, this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis;\n  }\n\n  call(e, t) {\n    var n = rh(e);\n    return this.softmax(n, this.axis);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction ip(e, t, n) {\n  if (\"number\" == typeof e) return ku(e, t);\n  if (e.length !== t) throw new bu(\"The \".concat(n, \" argument must be an integer or tuple of \").concat(t, \" integers. Received: \").concat(e.length, \" elements.\"));\n\n  for (var _r73 = 0; _r73 < t; ++_r73) {\n    var _a59 = e[_r73];\n    if ((s = _a59) !== parseInt(s.toString(), 10)) throw new bu(\"The \".concat(n, \" argument must be an integer or tuple of \").concat(t, \" integers. Received: \").concat(JSON.stringify(e), \" including a non-integer number \").concat(_a59));\n  }\n\n  return e;\n  var s;\n}\n\nfunction op(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;\n  if (null == e) return e;\n  var a;\n  return a = \"same\" === n ? e : e - (t + (t - 1) * (r - 1)) + 1, Math.floor((a + s - 1) / s);\n}\n\nfunction lp(e, t, n, s) {\n  if (null == e) return null;\n  if (\"valid\" === s) e = e * t + dc([n - t, 0]);else {\n    if (\"same\" !== s) throw new bu(\"Unsupport padding mode: \".concat(s, \".\"));\n    e *= t;\n  }\n  return e;\n}\n\nfunction up(e, t) {\n  return Yn(() => (tc(t), \"channelsFirst\" === t ? $n(e, [0, 2, 3, 1]) : e));\n}\n\nfunction cp(e, t) {\n  return Yn(() => (tc(t), \"channelsFirst\" === t ? $n(e, [0, 2, 3, 4, 1]) : e));\n}\n\nfunction hp(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1];\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  var i = arguments.length > 6 ? arguments[6] : undefined;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : null;\n  return Yn(() => {\n    if (null == a && (a = \"channelsLast\"), tc(a), 3 !== e.rank && 4 !== e.rank) throw new bu(\"conv2dWithBiasActivation expects input to be of rank 3 or 4, but received \".concat(e.rank, \".\"));\n    if (3 !== t.rank && 4 !== t.rank) throw new bu(\"conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received \".concat(e.rank, \".\"));\n    var l = up(e, a);\n    if (\"causal\" === r) throw new xu(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");\n    return l = Di({\n      x: l,\n      filter: t,\n      strides: s,\n      pad: \"same\" === r ? \"same\" : \"valid\",\n      dilations: i,\n      dataFormat: \"NHWC\",\n      bias: n,\n      activation: o\n    }), \"channelsFirst\" === a && (l = $n(l, [0, 3, 1, 2])), l;\n  });\n}\n\nap.className = \"Softmax\", qn(ap);\n\nclass dp extends gh {\n  constructor(e, t) {\n    if (super(t), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", dp.verifyArgs(t), this.rank = e, Mu(this.rank, \"rank\"), 1 !== this.rank && 2 !== this.rank && 3 !== this.rank) throw new xu(\"Convolution layer for rank other than 1, 2, or 3 (\".concat(this.rank, \") is not implemented yet.\"));\n    if (this.kernelSize = ip(t.kernelSize, e, \"kernelSize\"), this.strides = ip(null == t.strides ? 1 : t.strides, e, \"strides\"), this.padding = null == t.padding ? \"valid\" : t.padding, nc(this.padding), this.dataFormat = null == t.dataFormat ? \"channelsLast\" : t.dataFormat, tc(this.dataFormat), this.activation = qd(t.activation), this.useBias = null == t.useBias || t.useBias, this.biasInitializer = Jc(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = Ku(t.biasConstraint), this.biasRegularizer = Qd(t.biasRegularizer), this.activityRegularizer = Qd(t.activityRegularizer), this.dilationRate = ip(null == t.dilationRate ? 1 : t.dilationRate, e, \"dilationRate\"), 1 === this.rank && Array.isArray(this.dilationRate) && 1 !== this.dilationRate.length) throw new bu(\"dilationRate must be a number or an array of a single number for 1D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n\n    if (2 === this.rank) {\n      if (\"number\" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate];else if (2 !== this.dilationRate.length) throw new bu(\"dilationRate must be a number or array of two numbers for 2D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n    } else if (3 === this.rank) if (\"number\" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];else if (3 !== this.dilationRate.length) throw new bu(\"dilationRate must be a number or array of three numbers for 3D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n  }\n\n  static verifyArgs(e) {\n    if (wu(\"kernelSize\" in e, \"required key 'kernelSize' not in config\"), \"number\" != typeof e.kernelSize && !Ou(e.kernelSize, \"number\", 1, 3)) throw new bu(\"BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n  getConfig() {\n    var e = {\n      kernelSize: this.kernelSize,\n      strides: this.strides,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      activation: Hd(this.activation),\n      useBias: this.useBias,\n      biasInitializer: Yc(this.biasInitializer),\n      biasRegularizer: Jd(this.biasRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      biasConstraint: ju(this.biasConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass pp extends dp {\n  constructor(e, t) {\n    super(e, t), this.kernel = null, pp.verifyArgs(t), this.filters = t.filters, Mu(this.filters, \"filters\"), this.kernelInitializer = Jc(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = Ku(t.kernelConstraint), this.kernelRegularizer = Qd(t.kernelRegularizer);\n  }\n\n  build(e) {\n    e = ah(e);\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new bu(\"The channel dimension of the input should be defined. Found \".concat(e[t]));\n    var n = e[t],\n        s = this.kernelSize.concat([n, this.filters]);\n    this.kernel = this.addWeight(\"kernel\", s, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [{\n      ndim: this.rank + 2,\n      axes: {\n        [t]: n\n      }\n    }], this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t;\n      e = rh(e);\n      var n = null == this.bias ? null : this.bias.read(),\n          s = zu(this.activation.getClassName());\n      if (null != s && 2 === this.rank) t = hp(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate, s);else {\n        if (1 === this.rank) t = function (e, t, n) {\n          var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n          var a = arguments.length > 5 ? arguments[5] : undefined;\n          var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 1;\n          return Yn(() => {\n            if (null == a && (a = \"channelsLast\"), tc(a), 3 !== e.shape.length) throw new bu(\"The input of a conv1dWithBias operation should be 3, but is \".concat(e.shape.length, \" instead.\"));\n            if (3 !== t.shape.length) throw new bu(\"The kernel for a conv1dWithBias operation should be 3, but is \".concat(t.shape.length, \" instead\"));\n            if (null != n && 1 !== n.shape.length) throw new bu(\"The bias for a conv1dWithBias operation should be 1, but is \".concat(t.shape.length, \" instead\"));\n            if (\"channelsFirst\" === a && (e = $n(e, [0, 2, 1])), \"causal\" === r) throw new xu(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");\n            var o = Ys(e, t, s, \"same\" === r ? \"same\" : \"valid\", \"NWC\", i);\n            return null != n && (o = Sc(o, n)), o;\n          });\n        }(e, this.kernel.read(), n, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);else if (2 === this.rank) t = hp(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);else {\n          if (3 !== this.rank) throw new xu(\"convolutions greater than 3D are not implemented yet.\");\n\n          t = function (e, t, n) {\n            var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1, 1];\n            var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n            var a = arguments.length > 5 ? arguments[5] : undefined;\n            var i = arguments.length > 6 ? arguments[6] : undefined;\n            return Yn(() => {\n              if (null == a && (a = \"channelsLast\"), tc(a), 4 !== e.rank && 5 !== e.rank) throw new bu(\"conv3dWithBias expects input to be of rank 4 or 5, but received \".concat(e.rank, \".\"));\n              if (4 !== t.rank && 5 !== t.rank) throw new bu(\"conv3dWithBias expects kernel to be of rank 4 or 5, but received \".concat(e.rank, \".\"));\n              var o = cp(e, a);\n              if (\"causal\" === r) throw new xu(\"The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.\");\n              return o = Qs(o, t, s, \"same\" === r ? \"same\" : \"valid\", \"NDHWC\", i), null != n && (o = Sc(o, n)), \"channelsFirst\" === a && (o = $n(o, [0, 4, 1, 2, 3])), o;\n            });\n          }(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);\n        }\n        null != this.activation && (t = this.activation.apply(t));\n      }\n      return t;\n    });\n  }\n\n  computeOutputShape(e) {\n    e = ah(e);\n    var t = [],\n        n = \"channelsLast\" === this.dataFormat ? e.slice(1, e.length - 1) : e.slice(2);\n\n    for (var _e207 = 0; _e207 < n.length; ++_e207) {\n      var _s102 = op(n[_e207], this.kernelSize[_e207], this.padding, this.strides[_e207], \"number\" == typeof this.dilationRate ? this.dilationRate : this.dilationRate[_e207]);\n\n      t.push(_s102);\n    }\n\n    var s = [e[0]];\n    return \"channelsLast\" === this.dataFormat ? (s = s.concat(t), s.push(this.filters)) : (s.push(this.filters), s = s.concat(t)), s;\n  }\n\n  getConfig() {\n    var e = {\n      filters: this.filters,\n      kernelInitializer: Yc(this.kernelInitializer),\n      kernelRegularizer: Jd(this.kernelRegularizer),\n      kernelConstraint: ju(this.kernelConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  static verifyArgs(e) {\n    if (!(\"filters\" in e) || \"number\" != typeof e.filters || e.filters < 1) throw new bu(\"Convolution layer expected config.filters to be a 'number' > 0 but got \".concat(JSON.stringify(e.filters)));\n  }\n\n}\n\nclass fp extends pp {\n  constructor(e) {\n    super(2, e), fp.verifyArgs(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && !Ou(e.kernelSize, \"number\", 1, 2)) throw new bu(\"Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\nfp.className = \"Conv2D\", qn(fp);\n\nclass gp extends pp {\n  constructor(e) {\n    super(3, e), gp.verifyArgs(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && (!Array.isArray(e.kernelSize) || 1 !== e.kernelSize.length && 3 !== e.kernelSize.length)) throw new bu(\"Conv3D expects config.kernelSize to be number or [number, number, number], but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\ngp.className = \"Conv3D\", qn(gp);\n\nclass mp extends fp {\n  constructor(e) {\n    if (super(e), this.inputSpec = [new ch({\n      ndim: 4\n    })], \"same\" !== this.padding && \"valid\" !== this.padding) throw new bu(\"Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode \".concat(this.padding));\n  }\n\n  build(e) {\n    if (4 !== (e = ah(e)).length) throw new bu(\"Input should have rank 4; Received input shape: \" + JSON.stringify(e));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new bu(\"The channel dimension of the inputs should be defined. Found `None`.\");\n    var n = e[t],\n        s = this.kernelSize.concat([this.filters, n]);\n    this.kernel = this.addWeight(\"kernel\", s, \"float32\", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new ch({\n      ndim: 4,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      if (4 !== t.shape.length) throw new bu(\"Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-\".concat(t.shape.length));\n      var n = t.shape;\n      var s, r;\n      \"channelsFirst\" === this.dataFormat ? (s = 2, r = 3) : (s = 1, r = 2);\n      var a = n[r],\n          i = this.kernelSize[1],\n          o = this.strides[1],\n          l = [n[0], lp(n[s], this.strides[0], this.kernelSize[0], this.padding), lp(a, o, i, this.padding), this.filters];\n      \"channelsLast\" !== this.dataFormat && (t = $n(t, [0, 2, 3, 1]));\n      var u = Zs(t, this.kernel.read(), l, this.strides, this.padding);\n      return \"channelsLast\" !== this.dataFormat && (u = $n(u, [0, 3, 1, 2])), null != this.bias && (u = Sc(u, this.bias.read(), this.dataFormat)), null != this.activation && (u = this.activation.apply(u)), u;\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ah(e)).slice();\n    var n, s, r;\n    \"channelsFirst\" === this.dataFormat ? (n = 1, s = 2, r = 3) : (n = 3, s = 1, r = 2);\n    var a = this.kernelSize[0],\n        i = this.kernelSize[1],\n        o = this.strides[0],\n        l = this.strides[1];\n    return t[n] = this.filters, t[s] = lp(t[s], o, a, this.padding), t[r] = lp(t[r], l, i, this.padding), t;\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.dilationRate, e;\n  }\n\n}\n\nmp.className = \"Conv2DTranspose\", qn(mp);\n\nclass bp extends gp {\n  constructor(e) {\n    if (super(e), this.inputSpec = [new ch({\n      ndim: 5\n    })], \"same\" !== this.padding && \"valid\" !== this.padding) throw new bu(\"Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode \".concat(this.padding));\n  }\n\n  build(e) {\n    if (5 !== (e = ah(e)).length) throw new bu(\"Input should have rank 5; Received input shape: \" + JSON.stringify(e));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new bu(\"The channel dimension of the inputs should be defined. Found `None`.\");\n    var n = e[t],\n        s = this.kernelSize.concat([this.filters, n]);\n    this.kernel = this.addWeight(\"kernel\", s, \"float32\", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new ch({\n      ndim: 5,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      if (5 !== t.shape.length) throw new bu(\"Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-\".concat(t.shape.length));\n      var n = t.shape;\n      var s, r, a;\n      \"channelsFirst\" === this.dataFormat ? (a = 2, s = 3, r = 4) : (a = 1, s = 2, r = 3);\n      var i = n[s],\n          o = n[r],\n          l = this.kernelSize[1],\n          u = this.kernelSize[2],\n          c = this.strides[1],\n          h = this.strides[2],\n          d = [n[0], lp(n[a], this.strides[0], this.kernelSize[0], this.padding), lp(i, c, l, this.padding), lp(o, h, u, this.padding), this.filters];\n      \"channelsLast\" !== this.dataFormat && (t = $n(t, [0, 2, 3, 4, 1]));\n      var p = tr(t, this.kernel.read(), d, this.strides, this.padding);\n      return \"channelsLast\" !== this.dataFormat && (p = $n(p, [0, 4, 1, 2, 3])), null !== this.bias && (p = Sc(p, this.bias.read(), this.dataFormat)), null !== this.activation && (p = this.activation.apply(p)), p;\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ah(e)).slice();\n    var n, s, r, a;\n    \"channelsFirst\" === this.dataFormat ? (n = 1, s = 2, r = 3, a = 4) : (n = 4, s = 1, r = 2, a = 3);\n    var i = this.kernelSize[0],\n        o = this.kernelSize[1],\n        l = this.kernelSize[2],\n        u = this.strides[0],\n        c = this.strides[1],\n        h = this.strides[2];\n    return t[n] = this.filters, t[s] = lp(t[s], u, i, this.padding), t[r] = lp(t[r], c, o, this.padding), t[a] = lp(t[a], h, l, this.padding), t;\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.dilationRate, e;\n  }\n\n}\n\nbp.className = \"Conv3DTranspose\", qn(bp);\n\nclass xp extends pp {\n  constructor(e, t) {\n    if (super(e, t), this.DEFAULT_DEPTHWISE_INITIALIZER = \"glorotUniform\", this.DEFAULT_POINTWISE_INITIALIZER = \"glorotUniform\", this.depthwiseKernel = null, this.pointwiseKernel = null, null == t.filters) throw new bu(\"The `filters` configuration field is required by SeparableConv, but is unspecified.\");\n    if (null != t.kernelInitializer || null != t.kernelRegularizer || null != t.kernelConstraint) throw new bu(\"Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.\");\n    if (null != t.padding && \"same\" !== t.padding && \"valid\" !== t.padding) throw new bu(\"SeparableConv\".concat(this.rank, \"D supports only padding modes: 'same' and 'valid', but received \").concat(JSON.stringify(t.padding)));\n    this.depthMultiplier = null == t.depthMultiplier ? 1 : t.depthMultiplier, this.depthwiseInitializer = Jc(t.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = Qd(t.depthwiseRegularizer), this.depthwiseConstraint = Ku(t.depthwiseConstraint), this.pointwiseInitializer = Jc(t.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = Qd(t.pointwiseRegularizer), this.pointwiseConstraint = Ku(t.pointwiseConstraint);\n  }\n\n  build(e) {\n    if ((e = ah(e)).length < this.rank + 2) throw new bu(\"Inputs to SeparableConv\".concat(this.rank, \"D should have rank \").concat(this.rank + 2, \", but received input shape: \").concat(JSON.stringify(e)));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t] || e[t] < 0) throw new bu(\"The channel dimension of the inputs should be defined, but found \".concat(JSON.stringify(e[t])));\n    var n = e[t],\n        s = this.kernelSize.concat([n, this.depthMultiplier]),\n        r = [];\n\n    for (var _e208 = 0; _e208 < this.rank; ++_e208) {\n      r.push(1);\n    }\n\n    r.push(n * this.depthMultiplier, this.filters);\n    var a = !0;\n    this.depthwiseKernel = this.addWeight(\"depthwise_kernel\", s, \"float32\", this.depthwiseInitializer, this.depthwiseRegularizer, a, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight(\"pointwise_kernel\", r, \"float32\", this.pointwiseInitializer, this.pointwiseRegularizer, a, this.pointwiseConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, a, this.biasConstraint) : null, this.inputSpec = [new ch({\n      ndim: this.rank + 2,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t;\n      if (e = rh(e), 1 === this.rank) throw new xu(\"1D separable convolution is not implemented yet.\");\n      return 2 === this.rank && (\"channelsFirst\" === this.dataFormat && (e = $n(e, [0, 2, 3, 1])), t = Xa(e, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, \"NHWC\")), this.useBias && (t = Sc(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), \"channelsFirst\" === this.dataFormat && (t = $n(t, [0, 3, 1, 2])), t;\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, delete e.kernelInitializer, delete e.kernelRegularizer, delete e.kernelConstraint, e.depthwiseInitializer = Yc(this.depthwiseInitializer), e.pointwiseInitializer = Yc(this.pointwiseInitializer), e.depthwiseRegularizer = Jd(this.depthwiseRegularizer), e.pointwiseRegularizer = Jd(this.pointwiseRegularizer), e.depthwiseConstraint = ju(this.depthwiseConstraint), e.pointwiseConstraint = ju(this.pointwiseConstraint), e;\n  }\n\n}\n\nxp.className = \"SeparableConv\";\n\nclass yp extends xp {\n  constructor(e) {\n    super(2, e);\n  }\n\n}\n\nyp.className = \"SeparableConv2D\", qn(yp);\n\nclass kp extends pp {\n  constructor(e) {\n    super(1, e), kp.verifyArgs(e), this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, delete e.dataFormat, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && !Ou(e.kernelSize, \"number\", 1, 1)) throw new bu(\"Conv1D expects config.kernelSize to be number or number[] with length 1, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\nkp.className = \"Conv1D\", qn(kp);\n\nclass wp extends gh {\n  constructor(e) {\n    super(e), this.cropping = \"number\" == typeof e.cropping ? [[e.cropping, e.cropping], [e.cropping, e.cropping]] : \"number\" == typeof e.cropping[0] ? [[e.cropping[0], e.cropping[0]], [e.cropping[1], e.cropping[1]]] : e.cropping, this.dataFormat = void 0 === e.dataFormat ? \"channelsLast\" : e.dataFormat, this.inputSpec = [{\n      ndim: 4\n    }];\n  }\n\n  computeOutputShape(e) {\n    return \"channelsFirst\" === this.dataFormat ? [e[0], e[1], e[2] - this.cropping[0][0] - this.cropping[0][1], e[3] - this.cropping[1][0] - this.cropping[1][1]] : [e[0], e[1] - this.cropping[0][0] - this.cropping[0][1], e[2] - this.cropping[1][0] - this.cropping[1][1], e[3]];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (e = rh(e), \"channelsLast\" === this.dataFormat) {\n        var _t199 = xc(e, this.cropping[0][0], e.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);\n\n        return xc(_t199, this.cropping[1][0], e.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);\n      }\n\n      {\n        var _t200 = xc(e, this.cropping[0][0], e.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);\n\n        return xc(_t200, this.cropping[1][0], e.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);\n      }\n    });\n  }\n\n  getConfig() {\n    var e = {\n      cropping: this.cropping,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nwp.className = \"Cropping2D\", qn(wp);\n\nclass vp extends gh {\n  constructor(e) {\n    super(e), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{\n      ndim: 4\n    }], this.size = null == e.size ? this.DEFAULT_SIZE : e.size, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, tc(this.dataFormat), this.interpolation = null == e.interpolation ? \"nearest\" : e.interpolation, _u(Yu, \"InterpolationFormat\", this.interpolation);\n  }\n\n  computeOutputShape(e) {\n    return \"channelsFirst\" === this.dataFormat ? [e[0], e[1], null == e[2] ? null : this.size[0] * e[2], null == e[3] ? null : this.size[1] * e[3]] : [e[0], null == e[1] ? null : this.size[0] * e[1], null == e[2] ? null : this.size[1] * e[2], e[3]];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      var n = t.shape;\n\n      if (\"channelsFirst\" === this.dataFormat) {\n        t = $n(t, [0, 2, 3, 1]);\n\n        var _e209 = this.size[0] * n[2],\n            _s103 = this.size[1] * n[3],\n            _r74 = \"nearest\" === this.interpolation ? ho.resizeNearestNeighbor(t, [_e209, _s103]) : ho.resizeBilinear(t, [_e209, _s103]);\n\n        return $n(_r74, [0, 3, 1, 2]);\n      }\n\n      {\n        var _e210 = this.size[0] * n[1],\n            _s104 = this.size[1] * n[2];\n\n        return \"nearest\" === this.interpolation ? ho.resizeNearestNeighbor(t, [_e210, _s104]) : ho.resizeBilinear(t, [_e210, _s104]);\n      }\n    });\n  }\n\n  getConfig() {\n    var e = {\n      size: this.size,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nvp.className = \"UpSampling2D\", qn(vp);\n\nclass Ip extends dp {\n  constructor(e) {\n    super(2, e), this.depthwiseKernel = null, this.depthMultiplier = null == e.depthMultiplier ? 1 : e.depthMultiplier, this.depthwiseInitializer = Jc(e.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = Ku(e.depthwiseConstraint), this.depthwiseRegularizer = Qd(e.depthwiseRegularizer);\n  }\n\n  build(e) {\n    if ((e = ah(e)).length < 4) throw new bu(\"Inputs to DepthwiseConv2D should have rank 4. Received input shape: \".concat(JSON.stringify(e), \".\"));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : 3;\n    if (null == e[t] || e[t] < 0) throw new bu(\"The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (\".concat(e[t], \").\"));\n    var n = e[t];\n    this.depthwiseKernel = this.addWeight(\"depthwise_kernel\", [this.kernelSize[0], this.kernelSize[1], n, this.depthMultiplier], null, this.depthwiseInitializer, this.depthwiseRegularizer, !0, this.depthwiseConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [n * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = function (e, t) {\n        var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1];\n        var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"valid\";\n        var r = arguments.length > 4 ? arguments[4] : undefined;\n        var a = arguments.length > 5 ? arguments[5] : undefined;\n        return Yn(() => {\n          null == r && (r = \"channelsLast\"), tc(r);\n          var i = up(e, r);\n          if (4 !== e.rank) throw new bu(\"Input for depthwiseConv2d is required to be 4-D, but is instead \".concat(e.rank, \"-D\"));\n          if (4 !== t.rank) throw new bu(\"depthwiseKernel is required to be 4-D, but is instead \".concat(t.rank, \"-D\"));\n          return i = ir(i, t, n, \"same\" === s ? \"same\" : \"valid\", \"NHWC\", a), \"channelsFirst\" === r && (i = $n(i, [0, 3, 1, 2])), i;\n        });\n      }(e = rh(e), this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);\n\n      return this.useBias && (t = Sc(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), t;\n    });\n  }\n\n  computeOutputShape(e) {\n    e = ah(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[3] : e[2],\n        n = \"channelsFirst\" === this.dataFormat ? e[1] * this.depthMultiplier : e[3] * this.depthMultiplier,\n        s = op(\"channelsFirst\" === this.dataFormat ? e[2] : e[1], this.kernelSize[0], this.padding, this.strides[0]),\n        r = op(t, this.kernelSize[1], this.padding, this.strides[1]);\n    return \"channelsFirst\" === this.dataFormat ? [e[0], n, s, r] : [e[0], s, r, n];\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return e.depthMultiplier = this.depthMultiplier, e.depthwiseInitializer = Yc(this.depthwiseInitializer), e.depthwiseRegularizer = Jd(this.depthwiseRegularizer), e.depthwiseConstraint = ju(this.depthwiseRegularizer), e;\n  }\n\n}\n\nfunction $p(e, t, n, s) {\n  if (Array.isArray(e)) {\n    if (null != t || null != n) throw new bu(\"When inputs is an array, neither initialState or constants should be provided\");\n    null != s && (n = e.slice(e.length - s, e.length), e = e.slice(0, e.length - s)), e.length > 1 && (t = e.slice(1, e.length)), e = e[0];\n  }\n\n  function r(e) {\n    return null == e || Array.isArray(e) ? e : [e];\n  }\n\n  return {\n    inputs: e,\n    initialState: t = r(t),\n    constants: n = r(n)\n  };\n}\n\nfunction Np(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = arguments.length > 4 ? arguments[4] : undefined;\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n  return Yn(() => {\n    var l = t.shape.length;\n    if (l < 3) throw new bu(\"Input should be at least 3D, but is \".concat(l, \"D.\"));\n    var u = [1, 0].concat(pc(2, l));\n    if (t = $n(t, u), null != a) throw new xu(\"The rnn() functoin of the deeplearn.js backend does not support constants yet.\");\n    i && console.warn(\"Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend.\"), null != r && ((r = pn(pn(r, \"bool\"), \"float32\")).rank === l - 1 && (r = yr(r, -1)), r = $n(r, u)), s && (t = Ga(t, 0), null != r && (r = Ga(r, 0)));\n    var c = [];\n    var h,\n        d = n;\n    var p = t.shape[0],\n        f = vi(t);\n    var g, m;\n    null != r && (g = vi(r));\n\n    var _loop24 = function _loop24(_t201) {\n      var n = f[_t201],\n          s = Yn(() => e(n, d));\n      if (null == r) h = s[0], d = s[1];else {\n        var _e211 = Yn(() => {\n          var e = g[_t201],\n              n = Vr(xa(e), e);\n          return {\n            output: es(ss(s[0], e), ss(d[0], n)),\n            newStates: d.map((t, r) => es(ss(s[1][r], e), ss(t, n)))\n          };\n        });\n\n        h = _e211.output, d = _e211.newStates;\n      }\n      o && c.push(h);\n    };\n\n    for (var _t201 = 0; _t201 < p; ++_t201) {\n      _loop24(_t201);\n    }\n\n    return o && (m = di(c, 1)), [h, m, d];\n  });\n}\n\nIp.className = \"DepthwiseConv2D\", qn(Ip);\n\nclass Cp extends gh {\n  constructor(e) {\n    var t;\n    if (super(e), null == e.cell) throw new bu(\"cell property is missing for the constructor of RNN.\");\n    if (t = Array.isArray(e.cell) ? new _p({\n      cells: e.cell\n    }) : e.cell, null == t.stateSize) throw new bu(\"The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).\");\n    this.cell = t, this.returnSequences = null != e.returnSequences && e.returnSequences, this.returnState = null != e.returnState && e.returnState, this.goBackwards = null != e.goBackwards && e.goBackwards, this._stateful = null != e.stateful && e.stateful, this.unroll = null != e.unroll && e.unroll, this.supportsMasking = !0, this.inputSpec = [new ch({\n      ndim: 3\n    })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];\n  }\n\n  getStates() {\n    return null == this.states_ ? pc(0, Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1).map(e => null) : this.states_;\n  }\n\n  setStates(e) {\n    this.states_ = e;\n  }\n\n  computeOutputShape(e) {\n    nh(e) && (e = e[0]), e = e;\n    var t = this.cell.stateSize;\n    Array.isArray(t) || (t = [t]);\n    var n = t[0];\n    var s;\n\n    if (s = this.returnSequences ? [e[0], e[1], n] : [e[0], n], this.returnState) {\n      var _n119 = [];\n\n      for (var _s105 of t) {\n        _n119.push([e[0], _s105]);\n      }\n\n      return [s].concat(_n119);\n    }\n\n    return s;\n  }\n\n  computeMask(e, t) {\n    return Yn(() => {\n      Array.isArray(t) && (t = t[0]);\n      var e = this.returnSequences ? t : null;\n\n      if (this.returnState) {\n        var _t202 = this.states.map(e => null);\n\n        return [e].concat(_t202);\n      }\n\n      return e;\n    });\n  }\n\n  get states() {\n    if (null == this.states_) {\n      var _e212 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1,\n          _t203 = [];\n\n      for (var _n120 = 0; _n120 < _e212; ++_n120) {\n        _t203.push(null);\n      }\n\n      return _t203;\n    }\n\n    return this.states_;\n  }\n\n  set states(e) {\n    this.states_ = e;\n  }\n\n  build(e) {\n    if (null != this.numConstants) throw new xu(\"Constants support is not implemented in RNN yet.\");\n    nh(e) && (e = e[0]), e = e;\n    var t = this.stateful ? e[0] : null,\n        n = e.slice(2);\n    this.inputSpec[0] = new ch({\n      shape: [t, null, ...n]\n    });\n    var s = [e[0]].concat(e.slice(2));\n    var r;\n\n    if (this.cell.build(s), r = Array.isArray(this.cell.stateSize) ? this.cell.stateSize : [this.cell.stateSize], null != this.stateSpec) {\n      if (!p(this.stateSpec.map(e => e.shape[e.shape.length - 1]), r)) throw new bu(\"An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=\".concat(this.stateSpec, \"; However cell.stateSize is \").concat(this.cell.stateSize));\n    } else this.stateSpec = r.map(e => new ch({\n      shape: [null, e]\n    }));\n\n    this.stateful && this.resetStates();\n  }\n\n  resetStates(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    Yn(() => {\n      if (!this.stateful) throw new gu(\"Cannot call resetStates() on an RNN Layer that is not stateful.\");\n      var n = this.inputSpec[0].shape[0];\n      if (null == n) throw new bu(\"If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \\n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.\");\n      if (null == this.states_) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => ua([n, e])) : [ua([n, this.cell.stateSize])];else if (null == e) Jn(this.states_), null != this.keptStates && (Jn(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(e => ua([n, e])) : this.states_[0] = ua([n, this.cell.stateSize]);else {\n        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new bu(\"Layer \".concat(this.name, \" expects \").concat(this.states_.length, \" state(s), but it received \").concat(e.length, \" state value(s). Input received: \").concat(e));\n        !0 === t ? this.keptStates.push(this.states_.slice()) : Jn(this.states_);\n\n        for (var _t204 = 0; _t204 < this.states_.length; ++_t204) {\n          var _s106 = e[_t204],\n              _r75 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[_t204] : this.cell.stateSize,\n              _a60 = [n, _r75];\n\n          if (!p(_s106.shape, _a60)) throw new bu(\"State \".concat(_t204, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_a60, \", received shape=\").concat(_s106.shape));\n          this.states_[_t204] = _s106;\n        }\n      }\n      this.states_ = this.states_.map(e => Zn(e.clone()));\n    });\n  }\n\n  apply(e, t) {\n    var n = null == t ? null : t.initialState,\n        s = null == t ? null : t.constants;\n    null == t && (t = {});\n    var r = $p(e, n, s, this.numConstants);\n    e = r.inputs, n = r.initialState, s = r.constants;\n    var a = [],\n        i = [];\n\n    if (null != n) {\n      t.initialState = n, a = a.concat(n), this.stateSpec = [];\n\n      for (var _e213 of n) {\n        this.stateSpec.push(new ch({\n          shape: _e213.shape\n        }));\n      }\n\n      i = i.concat(this.stateSpec);\n    }\n\n    if (null != s && (t.constants = s, a = a.concat(s), this.numConstants = s.length), a[0] instanceof hh) {\n      var _n121 = [e].concat(a),\n          _s107 = this.inputSpec.concat(i),\n          _r76 = this.inputSpec;\n\n      this.inputSpec = _s107;\n\n      var _o27 = super.apply(_n121, t);\n\n      return this.inputSpec = _r76, _o27;\n    }\n\n    return super.apply(e, t);\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var n = null == t ? null : t.mask,\n          s = null == t ? null : t.training;\n      var r = null == t ? null : t.initialState;\n      e = rh(e), null == r && (r = this.stateful ? this.states_ : this.getInitialState(e));\n      var a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n      if (r.length !== a) throw new bu(\"RNN Layer has \".concat(a, \" state(s) but was passed \").concat(r.length, \" initial state(s).\"));\n      this.unroll && console.warn(\"Ignoring unroll = true for RNN layer, due to imperative backend.\");\n      var i = {\n        training: s\n      },\n          o = Np((e, t) => {\n        var n = this.cell.call([e].concat(t), i);\n        return [n[0], n.slice(1)];\n      }, e, r, this.goBackwards, n, null, this.unroll, this.returnSequences),\n          l = o[0],\n          u = o[1],\n          c = o[2];\n      this.stateful && this.resetStates(c, s);\n      var h = this.returnSequences ? u : l;\n      return this.returnState ? [h].concat(c) : h;\n    });\n  }\n\n  getInitialState(e) {\n    return Yn(() => {\n      var t = ua(e.shape);\n      return t = Gr(t, [1, 2]), t = gc(t), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => e > 1 ? wc(t, [1, e]) : t) : this.cell.stateSize > 1 ? [wc(t, [1, this.cell.stateSize])] : [t];\n    });\n  }\n\n  get trainableWeights() {\n    return this.trainable ? this.cell.trainableWeights : [];\n  }\n\n  get nonTrainableWeights() {\n    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.cell && this.cell.setFastWeightInitDuringBuild(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      returnSequences: this.returnSequences,\n      returnState: this.returnState,\n      goBackwards: this.goBackwards,\n      stateful: this.stateful,\n      unroll: this.unroll\n    };\n    null != this.numConstants && (t.numConstants = this.numConstants);\n    var n = this.cell.getConfig();\n    return this.getClassName() === Cp.className && (t.cell = {\n      className: this.cell.getClassName(),\n      config: n\n    }), Object.assign({}, n, e, t);\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = Eh(t.cell, n);\n    return new e(Object.assign(t, {\n      cell: s\n    }));\n  }\n\n}\n\nCp.className = \"RNN\", qn(Cp);\n\nclass Sp extends gh {}\n\nclass Tp extends Sp {\n  constructor(e) {\n    super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", this.units = e.units, Mu(this.units, \"units\"), this.activation = qd(null == e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Jc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Jc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Jc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Qd(e.kernelRegularizer), this.recurrentRegularizer = Qd(e.recurrentRegularizer), this.biasRegularizer = Qd(e.biasRegularizer), this.kernelConstraint = Ku(e.kernelConstraint), this.recurrentConstraint = Ku(e.recurrentConstraint), this.biasConstraint = Ku(e.biasConstraint), this.dropout = hc([1, dc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = hc([1, dc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    e = ah(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (2 !== (e = e).length) throw new bu(\"SimpleRNNCell expects 2 input Tensors, got \".concat(e.length, \".\"));\n      var n = e[1];\n      e = e[0];\n      var s = null != t.training && t.training;\n      var r;\n      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Op({\n        ones: () => xa(e),\n        rate: this.dropout,\n        training: s\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Op({\n        ones: () => xa(n),\n        rate: this.recurrentDropout,\n        training: s\n      }));\n      var a = this.dropoutMask,\n          i = this.recurrentDropoutMask;\n      r = Ic(null != a ? ss(e, a) : e, this.kernel.read()), null != this.bias && (r = Sc(r, this.bias.read())), null != i && (n = ss(n, i));\n      var o = es(r, Ic(n, this.recurrentKernel.read()));\n      return null != this.activation && (o = this.activation.apply(o)), [o, o];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: Hd(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: Yc(this.kernelInitializer),\n      recurrentInitializer: Yc(this.recurrentInitializer),\n      biasInitializer: Yc(this.biasInitializer),\n      kernelRegularizer: Jd(this.kernelRegularizer),\n      recurrentRegularizer: Jd(this.recurrentRegularizer),\n      biasRegularizer: Jd(this.biasRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nTp.className = \"SimpleRNNCell\", qn(Tp);\n\nclass Ep extends Cp {\n  constructor(e) {\n    e.cell = new Tp(e), super(e);\n  }\n\n  call(e, t) {\n    return Yn(() => (null != this.cell.dropoutMask && (Jn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Jn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nEp.className = \"SimpleRNN\", qn(Ep);\n\nclass Rp extends Sp {\n  constructor(e) {\n    if (super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_RECURRENT_ACTIVATION = \"hardSigmoid\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", e.resetAfter) throw new bu(\"GRUCell does not support reset_after parameter set to true.\");\n    this.units = e.units, Mu(this.units, \"units\"), this.activation = qd(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = qd(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Jc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Jc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Jc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Qd(e.kernelRegularizer), this.recurrentRegularizer = Qd(e.recurrentRegularizer), this.biasRegularizer = Qd(e.biasRegularizer), this.kernelConstraint = Ku(e.kernelConstraint), this.recurrentConstraint = Ku(e.recurrentConstraint), this.biasConstraint = Ku(e.biasConstraint), this.dropout = hc([1, dc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = hc([1, dc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    e = ah(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], 3 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, 3 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [3 * this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (2 !== (e = e).length) throw new bu(\"GRUCell expects 2 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var n = null != t.training && t.training;\n      var s = e[1];\n      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Op({\n        ones: () => xa(e),\n        rate: this.dropout,\n        training: n,\n        count: 3\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Op({\n        ones: () => xa(s),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 3\n      }));\n      var r = this.recurrentDropoutMask;\n      var a, i, o;\n      0 < this.dropout && this.dropout < 1 && (e = ss(e, this.dropoutMask[0]));\n      var l = Ic(e, this.kernel.read());\n      this.useBias && (l = Sc(l, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = ss(s, r[0]));\n      var u = this.recurrentKernel.read(),\n          [c, h] = oi(u, [2 * this.units, this.units], u.rank - 1),\n          d = Ic(s, c),\n          [p, f, g] = oi(l, 3, l.rank - 1),\n          [m, b] = oi(d, 2, d.rank - 1);\n      a = this.recurrentActivation.apply(es(p, m)), i = this.recurrentActivation.apply(es(f, b));\n      var x = Ic(ss(i, s), h);\n      o = this.activation.apply(es(g, x));\n      var y = es(ss(a, s), ss(es(1, Br(a)), o));\n      return [y, y];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: Hd(this.activation),\n      recurrentActivation: Hd(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: Yc(this.kernelInitializer),\n      recurrentInitializer: Yc(this.recurrentInitializer),\n      biasInitializer: Yc(this.biasInitializer),\n      kernelRegularizer: Jd(this.kernelRegularizer),\n      recurrentRegularizer: Jd(this.recurrentRegularizer),\n      biasRegularizer: Jd(this.biasRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation,\n      resetAfter: !1\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nRp.className = \"GRUCell\", qn(Rp);\n\nclass Ap extends Cp {\n  constructor(e) {\n    0 === e.implementation && console.warn(\"`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.\"), e.cell = new Rp(e), super(e);\n  }\n\n  call(e, t) {\n    return Yn(() => (null != this.cell.dropoutMask && (Jn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Jn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return 0 === t.implmentation && (t.implementation = 1), new e(t);\n  }\n\n}\n\nAp.className = \"GRU\", qn(Ap);\n\nclass Fp extends Sp {\n  constructor(e) {\n    super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_RECURRENT_ACTIVATION = \"hardSigmoid\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", this.units = e.units, Mu(this.units, \"units\"), this.activation = qd(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = qd(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Jc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Jc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Jc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = e.unitForgetBias, this.kernelRegularizer = Qd(e.kernelRegularizer), this.recurrentRegularizer = Qd(e.recurrentRegularizer), this.biasRegularizer = Qd(e.biasRegularizer), this.kernelConstraint = Ku(e.kernelConstraint), this.recurrentConstraint = Ku(e.recurrentConstraint), this.biasConstraint = Ku(e.biasConstraint), this.dropout = hc([1, dc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = hc([1, dc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    var t;\n    var n;\n\n    if (e = ah(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], 4 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, 4 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {\n      if (this.unitForgetBias) {\n        var _e214 = this.biasInitializer,\n            _s108 = this.units;\n        n = new ((t = class extends Fc {\n          apply(t, n) {\n            var r = _e214.apply([_s108]),\n                a = new _c().apply([_s108]),\n                i = _e214.apply([2 * _s108]);\n\n            return kc(kc(r, a), i);\n          }\n\n        }).className = \"CustomInit\", t)();\n      } else n = this.biasInitializer;\n\n      this.bias = this.addWeight(\"bias\", [4 * this.units], null, n, this.biasRegularizer, !0, this.biasConstraint);\n    } else this.bias = null;\n\n    this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var n = null != t.training && t.training;\n      if (3 !== (e = e).length) throw new bu(\"LSTMCell expects 3 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var s = e[1];\n      var r = e[2];\n      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Op({\n        ones: () => xa(e),\n        rate: this.dropout,\n        training: n,\n        count: 4\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Op({\n        ones: () => xa(s),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 4\n      }));\n      var a = this.recurrentDropoutMask;\n      var i, o, l, u;\n      0 < this.dropout && this.dropout < 1 && (e = ss(e, this.dropoutMask[0]));\n      var c = Ic(e, this.kernel.read());\n      0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = ss(s, a[0])), c = es(c, Ic(s, this.recurrentKernel.read())), this.useBias && (c = Sc(c, this.bias.read()));\n      var [h, d, p, f] = oi(c, 4, c.rank - 1);\n      i = this.recurrentActivation.apply(h), o = this.recurrentActivation.apply(d), l = es(ss(o, r), ss(i, this.activation.apply(p))), u = this.recurrentActivation.apply(f);\n      var g = ss(u, this.activation.apply(l));\n      return [g, g, l];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: Hd(this.activation),\n      recurrentActivation: Hd(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: Yc(this.kernelInitializer),\n      recurrentInitializer: Yc(this.recurrentInitializer),\n      biasInitializer: Yc(this.biasInitializer),\n      unitForgetBias: this.unitForgetBias,\n      kernelRegularizer: Jd(this.kernelRegularizer),\n      recurrentRegularizer: Jd(this.recurrentRegularizer),\n      biasRegularizer: Jd(this.biasRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nFp.className = \"LSTMCell\", qn(Fp);\n\nclass Dp extends Cp {\n  constructor(e) {\n    0 === e.implementation && console.warn(\"`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.\"), e.cell = new Fp(e), super(e);\n  }\n\n  call(e, t) {\n    return Yn(() => (null != this.cell.dropoutMask && (Jn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Jn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return 0 === t.implmentation && (t.implementation = 1), new e(t);\n  }\n\n}\n\nDp.className = \"LSTM\", qn(Dp);\n\nclass _p extends Sp {\n  constructor(e) {\n    super(e), this.cells = e.cells;\n  }\n\n  get stateSize() {\n    var e = [];\n\n    for (var _t205 of this.cells.slice().reverse()) {\n      Array.isArray(_t205.stateSize) ? e.push(..._t205.stateSize) : e.push(_t205.stateSize);\n    }\n\n    return e;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var n = (e = e).slice(1);\n      var s = [];\n\n      for (var _e215 of this.cells.slice().reverse()) {\n        Array.isArray(_e215.stateSize) ? s.push(n.splice(0, _e215.stateSize.length)) : s.push(n.splice(0, 1));\n      }\n\n      s.reverse();\n      var r = [];\n      var a;\n\n      for (var _i34 = 0; _i34 < this.cells.length; ++_i34) {\n        var _o28 = this.cells[_i34];\n        n = s[_i34], a = 0 === _i34 ? [e[0]].concat(n) : [a[0]].concat(n), a = _o28.call(a, t), r.push(a.slice(1));\n      }\n\n      n = [];\n\n      for (var _e216 of r.slice().reverse()) {\n        n.push(..._e216);\n      }\n\n      return [a[0]].concat(n);\n    });\n  }\n\n  build(e) {\n    var t;\n    nh(e) && (e = e[0]), e = e, this.cells.forEach((n, s) => {\n      ac(\"RNNCell_\".concat(s), () => {\n        n.build(e), t = Array.isArray(n.stateSize) ? n.stateSize[0] : n.stateSize, e = [e[0], t];\n      });\n    }), this.built = !0;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = this.cells.map(e => ({\n      className: e.getClassName(),\n      config: e.getConfig()\n    }));\n    return Object.assign({}, e, {\n      cells: t\n    });\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = [];\n\n    for (var _e217 of t.cells) {\n      s.push(Eh(_e217, n));\n    }\n\n    return new e({\n      cells: s\n    });\n  }\n\n  get trainableWeights() {\n    if (!this.trainable) return [];\n    var e = [];\n\n    for (var _t206 of this.cells) {\n      e.push(..._t206.trainableWeights);\n    }\n\n    return e;\n  }\n\n  get nonTrainableWeights() {\n    var e = [];\n\n    for (var _t207 of this.cells) {\n      e.push(..._t207.nonTrainableWeights);\n    }\n\n    if (!this.trainable) {\n      var _t208 = [];\n\n      for (var _e218 of this.cells) {\n        _t208.push(..._e218.trainableWeights);\n      }\n\n      return _t208.concat(e);\n    }\n\n    return e;\n  }\n\n  getWeights() {\n    var e = [];\n\n    for (var _t209 of this.cells) {\n      e.push(..._t209.weights);\n    }\n\n    return lh(e);\n  }\n\n  setWeights(e) {\n    var t = [];\n\n    for (var _n122 of this.cells) {\n      var _s109 = e.splice(_n122.weights.length);\n\n      for (var _e219 = 0; _e219 < _n122.weights.length; ++_e219) {\n        t.push([_n122.weights[_e219], _s109[_e219]]);\n      }\n    }\n\n    uh(t);\n  }\n\n}\n\nfunction Op(e) {\n  var {\n    ones: t,\n    rate: n,\n    training: s = !1,\n    count: r = 1\n  } = e,\n      a = () => Tc(t(), n),\n      i = () => Ec(a, t, s);\n\n  return !r || r <= 1 ? Zn(i().clone()) : Array(r).fill(void 0).map(i).map(e => Zn(e.clone()));\n}\n\nvar Mp, Lp, zp;\n_p.className = \"StackedRNNCells\", qn(_p);\n\nclass Bp extends Cp {\n  constructor(e) {\n    if (e.unroll) throw new xu(\"Unrolling is not possible with convolutional RNNs.\");\n    if (Array.isArray(e.cell)) throw new xu(\"It is not possible at the moment to stack convolutional cells.\");\n    super(e), this.inputSpec = [new ch({\n      ndim: 5\n    })];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (null != this.cell.dropoutMask && (Jn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Jn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), t && t.constants) throw new bu(\"ConvRNN2D cell does not support constants\");\n      return super.call(e, {\n        mask: null == t ? null : t.mask,\n        training: null == t ? null : t.training,\n        initialState: null == t ? null : t.initialState\n      });\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = this.computeSingleOutputShape(e);\n    return this.returnSequences || (t = [t[0], ...t.slice(2)]), this.returnState && (t = [t, ...Array(2).fill([e[0], ...t.slice(-3)])]), t;\n  }\n\n  getInitialState(e) {\n    return Yn(() => {\n      var {\n        stateSize: t\n      } = this.cell,\n          n = this.computeSingleOutputShape(e.shape),\n          s = ua([n[0], ...n.slice(2)]);\n      return Array.isArray(t) ? Array(t.length).fill(s) : [s];\n    });\n  }\n\n  resetStates(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    Yn(() => {\n      if (!this.stateful) throw new gu(\"Cannot call resetStates() on an RNN Layer that is not stateful.\");\n      var n = this.inputSpec[0].shape,\n          s = this.computeSingleOutputShape(n),\n          r = [s[0], ...s.slice(2)];\n      if (null == n[0]) throw new bu(\"If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \\n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.\");\n      if (null == this.getStates()) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(() => ua(r)) : [ua(r)];else if (null == e) Jn(this.states_), null != this.keptStates && (Jn(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => ua(r)) : this.states_[0] = ua(r);else {\n        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new bu(\"Layer \".concat(this.name, \" expects \").concat(this.states_.length, \" state(s), but it received \").concat(e.length, \" state value(s). Input received: \").concat(e));\n        t ? this.keptStates.push(this.states_.slice()) : Jn(this.states_);\n\n        for (var _t210 = 0; _t210 < this.states_.length; ++_t210) {\n          var _n123 = e[_t210],\n              _s110 = r;\n          if (!p(_n123.shape, _s110)) throw new bu(\"State \".concat(_t210, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_s110, \", received shape=\").concat(_n123.shape));\n          this.states_[_t210] = _n123;\n        }\n      }\n      this.states_ = this.states_.map(e => Zn(e.clone()));\n    });\n  }\n\n  computeSingleOutputShape(e) {\n    var {\n      dataFormat: t,\n      filters: n,\n      kernelSize: s,\n      padding: r,\n      strides: a,\n      dilationRate: i\n    } = this.cell,\n        o = \"channelsFirst\" === t,\n        l = e[o ? 4 : 3],\n        u = op(e[o ? 3 : 2], s[0], r, a[0], i[0]),\n        c = op(l, s[1], r, a[1], i[1]);\n    return [...e.slice(0, 2), ...(o ? [n, u, c] : [u, c, n])];\n  }\n\n}\n\nBp.className = \"ConvRNN2D\";\n\nclass Pp extends Fp {\n  constructor(e) {\n    var {\n      filters: t,\n      kernelSize: n,\n      strides: s,\n      padding: r,\n      dataFormat: a,\n      dilationRate: i\n    } = e;\n    super(Object.assign({}, e, {\n      units: t\n    })), this.filters = t, Mu(this.filters, \"filters\"), this.kernelSize = ip(n, 2, \"kernelSize\"), this.kernelSize.forEach(e => Mu(e, \"kernelSize\")), this.strides = ip(s || 1, 2, \"strides\"), this.strides.forEach(e => Mu(e, \"strides\")), this.padding = r || \"valid\", nc(this.padding), this.dataFormat = a || \"channelsLast\", tc(this.dataFormat), this.dilationRate = ip(i || 1, 2, \"dilationRate\"), this.dilationRate.forEach(e => Mu(e, \"dilationRate\"));\n  }\n\n  build(e) {\n    var t;\n    e = ah(e);\n    var n = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[n]) throw new bu(\"The channel dimension of the input should be defined. Found \".concat(e[n]));\n    var s = this.kernelSize.concat([e[n], 4 * this.filters]);\n    this.kernel = this.addWeight(\"kernel\", s, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint);\n    var r = this.kernelSize.concat([this.filters, 4 * this.filters]);\n\n    if (this.recurrentKernel = this.addWeight(\"recurrent_kernel\", r, null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {\n      var _e220;\n\n      if (this.unitForgetBias) {\n        var _n124 = this.biasInitializer,\n            _s111 = this.filters;\n        _e220 = new ((t = class extends Fc {\n          apply(e, t) {\n            return yc([_n124.apply([_s111]), ca([_s111]), _n124.apply([2 * _s111])]);\n          }\n\n        }).className = \"CustomInit\", t)();\n      } else _e220 = this.biasInitializer;\n\n      this.bias = this.addWeight(\"bias\", [4 * this.filters], null, _e220, this.biasRegularizer, !0, this.biasConstraint);\n    }\n\n    this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (3 !== e.length) throw new bu(\"ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var n = t.training || !1,\n          s = e[0],\n          r = e[1],\n          a = e[2];\n      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Op({\n        ones: () => xa(s),\n        rate: this.dropout,\n        training: n,\n        count: 4\n      }));\n\n      var i = this.dropoutMask,\n          o = (e, t, n) => t && t[n] ? ss(t[n], e) : e;\n\n      var l = o(s, i, 0),\n          u = o(s, i, 1),\n          c = o(s, i, 2),\n          h = o(s, i, 3);\n      0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Op({\n        ones: () => xa(r),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 4\n      }));\n      var d = this.recurrentDropoutMask;\n      var p = o(r, d, 0),\n          f = o(r, d, 1),\n          g = o(r, d, 2),\n          m = o(r, d, 3);\n      var [b, x, y, k] = oi(this.kernel.read(), 4, 3),\n          [w, v, I, $] = this.useBias ? oi(this.bias.read(), 4) : [null, null, null, null];\n      l = this.inputConv(l, b, w, this.padding), u = this.inputConv(u, x, v, this.padding), c = this.inputConv(c, y, I, this.padding), h = this.inputConv(h, k, $, this.padding);\n      var [N, C, S, T] = oi(this.recurrentKernel.read(), 4, 3);\n      p = this.recurrentConv(p, N), f = this.recurrentConv(f, C), g = this.recurrentConv(g, S), m = this.recurrentConv(m, T);\n      var E = this.recurrentActivation.apply(es(l, p)),\n          R = this.recurrentActivation.apply(es(u, f)),\n          A = es(ss(R, a), ss(E, this.activation.apply(es(c, g)))),\n          F = ss(this.recurrentActivation.apply(es(h, m)), this.activation.apply(A));\n      return [F, F, A];\n    });\n  }\n\n  getConfig() {\n    var e = function (e, t) {\n      var n = {};\n\n      for (var s in e) {\n        Object.prototype.hasOwnProperty.call(e, s) && t.indexOf(s) < 0 && (n[s] = e[s]);\n      }\n\n      if (null != e && \"function\" == typeof Object.getOwnPropertySymbols) {\n        var r = 0;\n\n        for (s = Object.getOwnPropertySymbols(e); r < s.length; r++) {\n          t.indexOf(s[r]) < 0 && Object.prototype.propertyIsEnumerable.call(e, s[r]) && (n[s[r]] = e[s[r]]);\n        }\n      }\n\n      return n;\n    }(super.getConfig(), [\"units\"]);\n\n    return Object.assign({}, e, {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides\n    });\n  }\n\n  inputConv(e, t, n, s) {\n    var r = Xs(e, t, this.strides, s || \"valid\", \"channelsFirst\" === this.dataFormat ? \"NCHW\" : \"NHWC\", this.dilationRate);\n    return n ? Sc(r, n, this.dataFormat) : r;\n  }\n\n  recurrentConv(e, t) {\n    return Xs(e, t, 1, \"same\", \"channelsFirst\" === this.dataFormat ? \"NCHW\" : \"NHWC\");\n  }\n\n}\n\nPp.className = \"ConvLSTM2DCell\", qn(Pp);\n\nclass Wp extends Bp {\n  constructor(e) {\n    var t = new Pp(e);\n    super(Object.assign({}, e, {\n      cell: t\n    }));\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nWp.className = \"ConvLSTM2D\", qn(Wp);\n\nclass Up extends gh {\n  constructor(e) {\n    super(e), this.rate = Math.max(Math.min(e.rate, 1), 0), this.noiseShape = e.noiseShape, this.seed = e.seed, this.supportsMasking = !0;\n  }\n\n  getNoiseShape(e) {\n    if (null == this.noiseShape) return this.noiseShape;\n    var t = e.shape,\n        n = [];\n\n    for (var _e221 = 0; _e221 < this.noiseShape.length; ++_e221) {\n      n.push(null == this.noiseShape[_e221] ? t[_e221] : this.noiseShape[_e221]);\n    }\n\n    return n;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n\n      if (0 < this.rate && this.rate < 1) {\n        var _e222 = null != t.training && t.training,\n            _s112 = this.getNoiseShape(n);\n\n        return Ec(() => Tc(n, this.rate, _s112, this.seed), () => n, _e222);\n      }\n\n      return e;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  dispose() {\n    return super.dispose();\n  }\n\n}\n\nUp.className = \"Dropout\", qn(Up);\n\nclass Vp extends Up {\n  constructor(e) {\n    super(e), this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getNoiseShape(e) {\n    var t = e.shape;\n    return [t[0], 1, t[2]];\n  }\n\n}\n\nVp.className = \"SpatialDropout1D\", qn(Vp);\n\nclass Gp extends gh {\n  constructor(e) {\n    if (super(e), this.activation = null, this.useBias = !0, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", null == e.batchInputShape && null == e.inputShape && null != e.inputDim) {\n      var _t211 = null;\n      null != e.batchSize && (_t211 = e.batchSize), this.batchInputShape = [_t211, e.inputDim];\n    }\n\n    this.units = e.units, Mu(this.units, \"units\"), this.activation = qd(e.activation), null != e.useBias && (this.useBias = e.useBias), this.kernelInitializer = Jc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = Jc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = Ku(e.kernelConstraint), this.biasConstraint = Ku(e.biasConstraint), this.kernelRegularizer = Qd(e.kernelRegularizer), this.biasRegularizer = Qd(e.biasRegularizer), this.activityRegularizer = Qd(e.activityRegularizer), this.supportsMasking = !0, this.inputSpec = [{\n      minNDim: 2\n    }];\n  }\n\n  build(e) {\n    var t = (e = ah(e))[e.length - 1];\n    null == this.kernel && (this.kernel = this.addWeight(\"kernel\", [t, this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint))), this.inputSpec = [{\n      minNDim: 2,\n      axes: {\n        [-1]: t\n      }\n    }], this.built = !0;\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ah(e)).slice();\n    return t[t.length - 1] = this.units, t;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e),\n          s = zu(this.activation.getClassName());\n      var r;\n      return null != s ? r = Ic(n, this.kernel.read(), s, this.bias ? this.bias.read() : null) : (r = Ic(n, this.kernel.read()), null != this.bias && (r = Sc(r, this.bias.read())), null != this.activation && (r = this.activation.apply(r))), r;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      units: this.units,\n      activation: Hd(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: Yc(this.kernelInitializer),\n      biasInitializer: Yc(this.biasInitializer),\n      kernelRegularizer: Jd(this.kernelRegularizer),\n      biasRegularizer: Jd(this.biasRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      biasConstraint: ju(this.biasConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nGp.className = \"Dense\", qn(Gp);\n\nclass Hp extends gh {\n  constructor(e) {\n    super(e = e || {}), this.inputSpec = [{\n      minNDim: 3\n    }], this.dataFormat = e.dataFormat;\n  }\n\n  computeOutputShape(e) {\n    e = ah(e);\n\n    for (var _t212 of e.slice(1)) {\n      if (null == _t212) throw new bu(\"The shape of the input to \\\"Flatten\\\" is not fully defined (got \".concat(e.slice(1), \"). Make sure to pass a complete \\\"input_shape\\\" or \\\"batch_input_shape\\\" argument to the first layer in your model.\"));\n    }\n\n    return [e[0], cc(e, 1)];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n\n      if (\"channelsFirst\" === this.dataFormat && n.rank > 1) {\n        var _e223 = [0];\n\n        for (var _t213 = 2; _t213 < n.rank; ++_t213) {\n          _e223.push(_t213);\n        }\n\n        _e223.push(1), n = $n(n, _e223);\n      }\n\n      return function (e) {\n        if (e.rank <= 1) throw new bu(\"batchFlatten requires a minimum rank of 2. Got rank: \".concat(e.rank, \".\"));\n        var t = [e.shape[0], cc(e.shape, 1)];\n        return Es(e, t);\n      }(n);\n    });\n  }\n\n  getConfig() {\n    var e = {};\n    null != this.dataFormat && (e.dataFormat = this.dataFormat);\n    var t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nHp.className = \"Flatten\", qn(Hp);\n\nclass jp extends gh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.activation = qd(e.activation);\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n      return this.activation.apply(n);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      activation: Hd(this.activation)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\njp.className = \"Activation\", qn(jp);\n\nclass qp extends gh {\n  constructor(e) {\n    super(e), this.n = e.n, this.inputSpec = [{\n      ndim: 2\n    }];\n  }\n\n  computeOutputShape(e) {\n    return [e[0], this.n, e[1]];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      return e = rh(e), t = e, n = this.n, Yn(() => {\n        if (2 !== t.shape.length) throw new bu(\"repeat() expects a rank-2 tensor, but received a rank-\".concat(t.shape.length, \" tensor.\"));\n        return wc(gc(t, 1), [1, n, 1]);\n      });\n      var t, n;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      n: this.n\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nqp.className = \"RepeatVector\", qn(qp);\n\nclass Kp extends gh {\n  constructor(e) {\n    super(e), this.targetShape = e.targetShape;\n\n    for (var _e224 = 0; _e224 < this.targetShape.length; ++_e224) {\n      this.isUnknown(this.targetShape[_e224]) && (this.targetShape[_e224] = null);\n    }\n  }\n\n  isUnknown(e) {\n    return e < 0 || null == e;\n  }\n\n  fixUnknownDimension(e, t) {\n    var n = \"Total size of new array must be unchanged.\",\n        s = t.slice();\n    var r = 1,\n        a = null;\n\n    for (var _e225 = 0; _e225 < s.length; ++_e225) {\n      var _t214 = s[_e225];\n\n      if (this.isUnknown(_t214)) {\n        if (null !== a) throw new bu(\"Can only specifiy one unknown dimension.\");\n        a = _e225;\n      } else r *= _t214;\n    }\n\n    var i = cc(e);\n\n    if (null !== a) {\n      if (0 === r || i % r != 0) throw new bu(n);\n      s[a] = i / r;\n    } else if (i !== r) throw new bu(n);\n\n    return s;\n  }\n\n  computeOutputShape(e) {\n    var t = !1;\n\n    for (var _n125 = 0; _n125 < e.length; ++_n125) {\n      if (this.isUnknown(e[_n125])) {\n        t = !0;\n        break;\n      }\n    }\n\n    return t ? e.slice(0, 1).concat(this.targetShape) : e.slice(0, 1).concat(this.fixUnknownDimension(e.slice(1), this.targetShape));\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e),\n          s = n.shape,\n          r = s.slice(0, 1).concat(this.fixUnknownDimension(s.slice(1), this.targetShape));\n      return Es(n, r);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      targetShape: this.targetShape\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nKp.className = \"Reshape\", qn(Kp);\n\nclass Xp extends gh {\n  constructor(e) {\n    if (super(e), null == e.dims) throw new Error(\"Required configuration field `dims` is missing during Permute constructor call.\");\n    if (!Array.isArray(e.dims)) throw new Error(\"Permute constructor requires `dims` to be an Array, but received \".concat(e.dims, \" instead.\"));\n    var t = pc(1, e.dims.length + 1);\n    if (!p(e.dims.slice().sort(), t)) throw new Error(\"Invalid permutation `dims`: \" + JSON.stringify(e.dims) + \" `dims` must contain consecutive integers starting from 1.\");\n    this.dims = e.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new ch({\n      ndim: this.dims.length + 1\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ah(e)).slice();\n    return this.dims.forEach((n, s) => {\n      t[s + 1] = e[n];\n    }), t;\n  }\n\n  call(e, t) {\n    return $n(rh(e), this.dimsIncludingBatch);\n  }\n\n  getConfig() {\n    var e = {\n      dims: this.dims\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nXp.className = \"Permute\", qn(Xp);\n\nclass Yp extends gh {\n  constructor(e) {\n    super(null == e ? {} : e), this.supportsMasking = !0, this.maskValue = null != e ? null == e.maskValue ? 0 : e.maskValue : 0;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      maskValue: this.maskValue\n    };\n    return Object.assign(t, e), t;\n  }\n\n  computeMask(e, t) {\n    var n = rh(e);\n    return ls(ba(n, this.maskValue), -1);\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e),\n          s = ls(ba(n, this.maskValue), -1, !0);\n      return ss(n, pn(s, n.dtype));\n    });\n  }\n\n}\n\nYp.className = \"Masking\", qn(Yp);\n\nclass Jp extends gh {\n  constructor(e) {\n    if (super(e), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = \"randomUniform\", null == e.batchInputShape && null == e.inputShape) {\n      var _t215 = null;\n      null != e.batchSize && (_t215 = e.batchSize), this.batchInputShape = null == e.inputLength ? [_t215, null] : [_t215].concat($u(e.inputLength));\n    }\n\n    this.inputDim = e.inputDim, Mu(this.inputDim, \"inputDim\"), this.outputDim = e.outputDim, Mu(this.outputDim, \"outputDim\"), this.embeddingsInitializer = Jc(e.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = Qd(e.embeddingsRegularizer), this.activityRegularizer = Qd(e.activityRegularizer), this.embeddingsConstraint = Ku(e.embeddingsConstraint), this.maskZero = e.maskZero, this.supportsMasking = e.maskZero, this.inputLength = e.inputLength;\n  }\n\n  build(e) {\n    this.embeddings = this.addWeight(\"embeddings\", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, !0, this.embeddingsConstraint), this.built = !0;\n  }\n\n  warnOnIncompatibleInputShape(e) {}\n\n  computeMask(e, t) {\n    return Yn(() => this.maskZero ? (e = rh(e), ba(e, pr(e))) : null);\n  }\n\n  computeOutputShape(e) {\n    if (e = ah(e), null == this.inputLength) return [...e, this.outputDim];\n    var t = $u(this.inputLength);\n    if (t.length !== e.length - 1) throw new bu(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received input shape has shape \").concat(e));\n    {\n      var _n126 = 0;\n\n      for (var _s113 = 0; _s113 < t.length; ++_s113) {\n        var _r77 = t[_s113],\n            _a61 = e[_s113 + 1];\n        if (null != _r77 && null != _a61 && _r77 !== _a61) throw new bu(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received input shape has shape \").concat(e));\n        null == _r77 && (t[_n126] = _a61), _n126++;\n      }\n    }\n    return [e[0], ...t, this.outputDim];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n      \"int32\" !== n.dtype && (n = fc(n, \"int32\"));\n      var s = $c(this.embeddings.read(), Es(n, [n.size]));\n      return Es(s, ah(this.computeOutputShape(n.shape)));\n    });\n  }\n\n  getConfig() {\n    var e = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: Yc(this.embeddingsInitializer),\n      embeddingsRegularizer: Jd(this.embeddingsRegularizer),\n      activityRegularizer: Jd(this.activityRegularizer),\n      embeddingsConstraint: ju(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nJp.className = \"Embedding\", qn(Jp);\n\nclass Zp extends gh {\n  constructor(e) {\n    super(e || {}), this.supportsMasking = !0;\n  }\n\n  mergeFunction(e) {\n    throw new xu();\n  }\n\n  computeElementwiseOpOutputShape(e, t) {\n    if (null == e || null == t) return null;\n    if (e.length < t.length) return this.computeElementwiseOpOutputShape(t, e);\n    if (0 === t.length) return e;\n    var n = e.slice(0, e.length - t.length);\n\n    for (var _s114 = 0; _s114 < t.length; ++_s114) {\n      var _r78 = e[e.length - t.length + _s114],\n          _a62 = t[_s114];\n      if (null == _r78 || null == _a62 || _r78 < 0 || _a62 < 0) n.push(null);else if (1 === _r78) n.push(_a62);else if (1 === _a62) n.push(_r78);else {\n        if (_r78 !== _a62) throw new bu(\"Operands could not be broadcast together with shapes \" + JSON.stringify(e) + \" \" + JSON.stringify(t));\n        n.push(_r78);\n      }\n    }\n\n    return n;\n  }\n\n  build(e) {\n    if (Array.isArray(e) && !Array.isArray(e[0]) && (e = [ah(e)]), (e = e).length < 2) throw new bu(\"A merge layer should be called on an Array of at least 2 inputs. Got \".concat(e.length, \" input(s).\"));\n    var t = [];\n\n    for (var _n127 of e) {\n      null != _n127 && null !== _n127[0] && t.push(_n127[0]);\n    }\n\n    if (t = Fu(t), t.length > 1) throw new bu(\"Can not merge tensors with different batch sizes. Got tensors with shapes: \".concat(JSON.stringify(e), \".\"));\n    var n = null == e[0] ? null : e[0].slice(1);\n\n    for (var _t216 = 1; _t216 < e.length; ++_t216) {\n      var _s115 = null == e[_t216] ? null : e[_t216].slice(1);\n\n      n = this.computeElementwiseOpOutputShape(n, _s115);\n    }\n\n    var s = e.map(e => e.length);\n    this.reshapeRequired = -1 !== e.indexOf(null) || 1 !== Fu(s).length;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (e = e, this.reshapeRequired) {\n        var _t217 = [],\n            _n128 = e.map(e => e.rank);\n\n        if (-1 === _n128.indexOf(null)) {\n          var _s116 = dc(_n128);\n\n          for (var _n129 of e) {\n            var _e226 = _n129.rank;\n\n            for (var _t218 = 0; _t218 < _s116 - _e226; ++_t218) {\n              _n129 = gc(_n129, 1);\n            }\n\n            _t217.push(_n129);\n          }\n\n          return this.mergeFunction(_t217);\n        }\n\n        {\n          var _n130 = !1;\n\n          for (var _s118 of e) {\n            var _e227 = _s118.rank;\n\n            if (null == _e227) {\n              var _e228 = _s118.shape,\n                  _r80 = _e228[0],\n                  _a63 = _e228.slice(1).concat([_r80]);\n\n              var _i35 = Es(_s118, [_r80].concat(cc(_e228.slice(1))));\n\n              _i35 = $n(_i35, [1, 0]), _i35 = Es(_i35, _a63), _t217.push(_i35), _n130 = !0;\n            } else if (_e227 > 1) {\n              var _r81 = pc(1, _e227).concat([0]);\n\n              _t217.push($n(_s118, _r81)), _n130 = !0;\n            } else _t217.push(_s118);\n          }\n\n          var _s117 = this.mergeFunction(_t217);\n\n          var _r79 = _s117.rank;\n          if (_n130) if (null == _r79) {\n            var _e229 = _s117.shape,\n                _t219 = _e229[_e229.length - 1],\n                _n131 = [_t219].concat(_e229.slice(0, _e229.length - 1));\n\n            _s117 = Es($n(Es(_s117, [-1, _t219]), [1, 0]), _n131);\n          } else if (_r79 > 1) {\n            var _e230 = [_r79 - 1].concat(pc(0, _r79 - 1));\n\n            _s117 = $n(_s117, _e230);\n          }\n          return _s117;\n        }\n      }\n\n      return this.mergeFunction(e);\n    });\n  }\n\n  computeOutputShape(e) {\n    var t;\n    t = null == (e = e)[0] ? null : e[0].slice(1);\n\n    for (var _n132 = 1; _n132 < e.length; ++_n132) {\n      var _s119 = null == e[_n132] ? null : e[_n132].slice(1);\n\n      t = this.computeElementwiseOpOutputShape(t, _s119);\n    }\n\n    var n = [];\n\n    for (var _t220 of e) {\n      null != _t220 && null !== _t220[0] && n.push(_t220[0]);\n    }\n\n    return n = Fu(n), t = 1 === n.length ? n.concat(t) : [null].concat(t), t;\n  }\n\n  computeMask(e, t) {\n    return Yn(() => {\n      if (null == t) return null;\n      if (!Array.isArray(t)) throw new bu(\"`mask` should be an Array\");\n      if (!Array.isArray(e)) throw new bu(\"`inputs` should be an Array\");\n      if (t.length !== e.length) throw new bu(\"The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (\".concat(e.length, \" vs \").concat(t.length, \")\"));\n      if (t.every(e => null == e)) return null;\n      var n = (t = t.map(e => null == e ? e : yr(e, 0)))[0];\n\n      for (var _e231 = 1; _e231 < t.length - 1; ++_e231) {\n        n = ta(n, t[_e231]);\n      }\n\n      return n;\n    });\n  }\n\n}\n\nclass Qp extends Zp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Yn(() => {\n      var t = e[0].clone();\n\n      for (var _n133 = 1; _n133 < e.length; ++_n133) {\n        t = es(t, e[_n133]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nQp.className = \"Add\", qn(Qp);\n\nclass ef extends Zp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Yn(() => {\n      var t = e[0].clone();\n\n      for (var _n134 = 1; _n134 < e.length; ++_n134) {\n        t = ss(t, e[_n134]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nef.className = \"Multiply\", qn(ef);\n\nclass tf extends Zp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Yn(() => {\n      var t = e[0].clone();\n\n      for (var _n135 = 1; _n135 < e.length; ++_n135) {\n        t = es(t, e[_n135]);\n      }\n\n      return ss(1 / e.length, t);\n    });\n  }\n\n}\n\ntf.className = \"Average\", qn(tf);\n\nclass nf extends Zp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Yn(() => {\n      var t = e[0];\n\n      for (var _n136 = 1; _n136 < e.length; ++_n136) {\n        t = oa(t, e[_n136]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nnf.className = \"Maximum\", qn(nf);\n\nclass sf extends Zp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Yn(() => {\n      var t = e[0];\n\n      for (var _n137 = 1; _n137 < e.length; ++_n137) {\n        t = da(t, e[_n137]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nsf.className = \"Minimum\", qn(sf);\n\nclass rf extends Zp {\n  constructor(e) {\n    super(e), this.DEFAULT_AXIS = -1, null == e && (e = {}), this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis, this.supportsMasking = !0, this.reshapeRequired = !1;\n  }\n\n  build(e) {\n    if (!Array.isArray(e) || !Array.isArray(e[0]) || 1 === e.length) throw new bu(\"A `Concatenate` layer should be called on a list of at least 2 inputs\");\n    e = e;\n    var t = !0;\n\n    for (var _n138 of e) {\n      if (null != _n138) {\n        t = !1;\n        break;\n      }\n    }\n\n    if (t) return;\n    var n = [];\n\n    for (var _t221 = 0; _t221 < e.length; ++_t221) {\n      var _s120 = e[_t221].slice();\n\n      _s120.splice(this.axis, 1);\n\n      var _r82 = !1;\n\n      for (var _e232 of n) {\n        if (p(_e232, _s120)) {\n          _r82 = !0;\n          break;\n        }\n      }\n\n      _r82 || n.push(_s120);\n    }\n\n    if (n.length > 1) throw new bu(\"A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: \" + JSON.stringify(e));\n  }\n\n  mergeFunction(e) {\n    return Yn(() => yc(e, this.axis));\n  }\n\n  computeOutputShape(e) {\n    if (!Array.isArray(e) || !Array.isArray(e[0])) throw new bu(\"A `Concatenate` layer should be called on a list of inputs.\");\n    var t = e,\n        n = t[0].slice(),\n        s = this.axis < 0 ? n.length + this.axis : this.axis;\n\n    for (var _e233 of t.slice(1)) {\n      if (null == n[s] || null == _e233[s]) {\n        n[s] = null;\n        break;\n      }\n\n      n[s] += _e233[s];\n    }\n\n    return n;\n  }\n\n  computeMask(e, t) {\n    if (null == t) return null;\n    if (!Array.isArray(t)) throw new bu(\"`mask` should be an array for Concatenate\");\n    if (!Array.isArray(e)) throw new bu(\"`inputs` should be an array for Concatenate\");\n    if (t.length !== e.length) throw new bu(\"Mismatch in the length of mask (\".concat(t.length, \") and the legnth of inputs (\").concat(e.length, \")\"));\n    return Yn(() => {\n      var n = !0;\n      if (t.forEach(e => {\n        null == e || (n = !1);\n      }), n) return null;\n      var s = [];\n\n      for (var _n139 = 0; _n139 < e.length; ++_n139) {\n        s.push(null == t[_n139] ? pn(xa(e[_n139]), \"bool\") : t[_n139].rank < e[_n139].rank ? yr(t[_n139], -1) : t[_n139]);\n      }\n\n      var r = Fs(s, this.axis);\n      return os(r, -1, !1);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction af(e, t) {\n  for (; e < 0;) {\n    e += t;\n  }\n\n  return e;\n}\n\nrf.className = \"Concatenate\", qn(rf);\n\nclass of extends Zp {\n  constructor(e) {\n    super(e), this.axes = e.axes, this.normalize = null != e.normalize && e.normalize, this.supportsMasking = !0, this.reshapeRequired = !1;\n  }\n\n  build(e) {\n    l(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => \"A `Dot` layer should be called on a list of exactly 2 inputs.\");\n    var t = e[0],\n        n = e[1];\n    if (t.length > 3 || n.length > 3) throw new xu(\"Dot layer does not support tensors of 4D or higher rank yet.\");\n    var s = this.interpretAxes(t, n);\n    if (t[s[0]] !== n[s[1]]) throw new bu(\"Dimension incompatibility: \".concat(t[s[0]], \" !== \").concat(n[s[1]]));\n  }\n\n  mergeFunction(e) {\n    if (2 !== e.length) throw new bu(\"A `Dot` layer must be called on exactly 2 inputs, but received \".concat(e.length, \" input(s).\"));\n    var t,\n        n = e[0],\n        s = e[1];\n    return t = Array.isArray(this.axes) ? this.axes.map((t, n) => af(t, e[n].shape.length)) : [af(this.axes, n.shape.length), af(this.axes, s.shape.length)], this.normalize && (n = Rh(n, t[0]), s = Rh(s, t[1])), function (e, t, n) {\n      if (e.shape.length > 3 || t.shape.length > 3) throw new xu(\"batchDot is not implemented for tensors of 4D or higher rank yet\");\n      if (l(e.shape.length >= 2, () => \"batchDot requires the rank of x to be >= 2, but got \".concat(e.shape.length)), l(e.shape.length >= 2, () => \"batchDot requires the rank of y to be >= 2, but got \".concat(t.shape.length)), \"number\" == typeof n && (n = [n, n]), \"complex64\" === e.dtype || \"complex64\" === t.dtype) throw new xu(\"batchDot is not implemented for complex64-type Tensors yet.\");\n      var s = e.shape.length,\n          r = t.shape.length;\n      null == n && (n = [s - 1, r - 2]);\n      var a = n;\n      return Yn(() => {\n        var n, i;\n\n        if (s > r) {\n          n = s - r;\n          var _e234 = [];\n\n          for (var _t222 = 0; _t222 < n; ++_t222) {\n            _e234.push(1);\n          }\n\n          t = Es(t, t.shape.concat(_e234));\n        } else if (r > s) {\n          n = r - s;\n          var _t223 = [];\n\n          for (var _e235 = 0; _e235 < n; ++_e235) {\n            _t223.push(1);\n          }\n\n          e = Es(e, e.shape.concat(_t223));\n        } else n = 0;\n\n        if (i = 2 === e.shape.length && 2 === t.shape.length ? a[0] === a[1] ? Gr(ss(e, t), a[0]) : Gr(ss($n(e, [1, 0]), t), a[1]) : vn(e, t, a[0] !== e.shape.length - 1, a[1] === t.shape.length - 1), n > 0) {\n          var _e236;\n\n          _e236 = s > r ? s + r - 3 : s - 1;\n          var _t224 = [];\n\n          for (var _s121 = _e236; _s121 < _e236 + n; ++_s121) {\n            _t224.push(_s121);\n          }\n\n          i = hi(i, _t224);\n        }\n\n        return 1 === i.shape.length && (i = yr(i, 1)), i;\n      });\n    }(n, s, t);\n  }\n\n  interpretAxes(e, t) {\n    var n;\n    return n = Array.isArray(this.axes) ? this.axes : [af(this.axes, e.length), af(this.axes, t.length)], n;\n  }\n\n  computeOutputShape(e) {\n    l(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => \"A `Dot` layer should be called on a list of exactly 2 inputs.\");\n    var t = e[0].slice(),\n        n = e[1].slice();\n    if (t.length > 3 || n.length > 3) throw new xu(\"Dot layer does not support tensors of 4D or higher rank yet.\");\n    var s = this.interpretAxes(t, n);\n    t.splice(s[0], 1), n.splice(s[1], 1), n.splice(0, 1);\n    var r = t.concat(n);\n    return 1 === r.length && r.push(1), r;\n  }\n\n  computeMask(e, t) {\n    return null;\n  }\n\n  getConfig() {\n    var e = {\n      axes: this.axes,\n      normalize: this.normalize\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nof.className = \"Dot\", qn(of);\n\nclass lf extends gh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.stddev = e.stddev;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      stddev: this.stddev\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n      return Ec(() => es(vc(n.shape, 0, this.stddev), n), () => n, t.training || !1);\n    });\n  }\n\n}\n\nlf.className = \"GaussianNoise\", qn(lf);\n\nclass uf extends gh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.rate = e.rate;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      rate: this.rate\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t);\n      var n = rh(e);\n      return this.rate > 0 && this.rate < 1 ? Ec(() => {\n        var e = Math.sqrt(this.rate / (1 - this.rate));\n        return ss(n, vc(n.shape, 1, e));\n      }, () => n, t.training || !1) : n;\n    });\n  }\n\n}\n\nuf.className = \"GaussianDropout\", qn(uf);\n\nclass cf extends gh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.rate = e.rate, this.noiseShape = e.noiseShape;\n  }\n\n  _getNoiseShape(e) {\n    return this.noiseShape || rh(e).shape;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      rate: this.rate\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      if (this.rate < 1 && this.rate > 0) {\n        var _n140 = this._getNoiseShape(e);\n\n        return Ec(() => {\n          var t = rh(e),\n              s = -1.7580993408473766;\n          var r = Sr(za(_n140), this.rate);\n          r = fc(r, \"float32\");\n          var a = ((1 - this.rate) * (1 + this.rate * s ** 2)) ** -.5,\n              i = -a * s * this.rate,\n              o = es(ss(t, r), ss(es(r, -1), s));\n          return es(ss(o, a), i);\n        }, () => rh(e), t.training || !1);\n      }\n\n      return e;\n    });\n  }\n\n}\n\nfunction hf(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : .001;\n  var i;\n  if (2 === e.rank) i = zs(e, t, n, s, r, a);else if (3 === e.rank) i = Bs(e, t, n, s, r, a);else {\n    if (4 !== e.rank) throw new xu(\"batchNormalization is not implemented for array of rank \".concat(e.rank, \" yet\"));\n    i = Ps(e, t, n, s, r, a);\n  }\n  return i;\n}\n\ncf.className = \"AlphaDropout\", qn(cf);\n\nclass df extends gh {\n  constructor(e) {\n    null == e && (e = {}), super(e), this.supportsMasking = !0, this.axis = null == e.axis ? -1 : e.axis, this.momentum = null == e.momentum ? .99 : e.momentum, this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = Jc(e.betaInitializer || \"zeros\"), this.gammaInitializer = Jc(e.gammaInitializer || \"ones\"), this.movingMeanInitializer = Jc(e.movingMeanInitializer || \"zeros\"), this.movingVarianceInitializer = Jc(e.movingVarianceInitializer || \"ones\"), this.betaConstraint = Ku(e.betaConstraint), this.gammaConstraint = Ku(e.gammaConstraint), this.betaRegularizer = Qd(e.betaRegularizer), this.gammaRegularizer = Qd(e.gammaRegularizer);\n  }\n\n  build(e) {\n    e = ah(e);\n    var t = this.axis >= 0 ? this.axis : this.axis + e.length,\n        n = e[t];\n    if (null == n) throw new bu(\"Axis \".concat(t, \" of input tensor should have a defined dimension but the layer received an input with shape \").concat(JSON.stringify(e), \".\"));\n    this.inputSpec = [new ch({\n      ndim: e.length,\n      axes: {\n        [t]: n\n      }\n    })];\n    var s = [n];\n    this.scale && (this.gamma = this.addWeight(\"gamma\", s, null, this.gammaInitializer, this.gammaRegularizer, !0, this.gammaConstraint)), this.center && (this.beta = this.addWeight(\"beta\", s, null, this.betaInitializer, this.betaRegularizer, !0, this.betaConstraint)), this.movingMean = this.addWeight(\"moving_mean\", s, null, this.movingMeanInitializer, null, !1), this.movingVariance = this.addWeight(\"moving_variance\", s, null, this.movingVarianceInitializer, null, !1), this.built = !0;\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var n = null != t.training && t.training,\n          s = rh(e),\n          r = s.shape,\n          a = r.length,\n          i = pc(0, a),\n          o = this.axis >= 0 ? this.axis : this.axis + a;\n      i.splice(o, 1);\n      var l = ku(1, a);\n      l[o] = r[o];\n      var u = i.slice();\n      u.sort();\n      var c = !p(u, pc(0, a).slice(0, a - 1));\n      if (!n) return (() => {\n        if (c) {\n          var _e237 = Es(this.movingMean.read(), l),\n              _t225 = Es(this.movingVariance.read(), l),\n              _n141 = this.center ? Es(this.beta.read(), l) : null,\n              _r83 = this.scale ? Es(this.gamma.read(), l) : null;\n\n          return hf(s, _e237, _t225, _n141, _r83, this.epsilon);\n        }\n\n        return hf(s, this.movingMean.read(), this.movingVariance.read(), null == this.beta ? null : this.beta.read(), null == this.gamma ? null : this.gamma.read(), this.epsilon);\n      })();\n\n      var [h, d, f] = function (e, t, n, s) {\n        var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n        return p(s.slice().sort(), pc(0, e.rank - 1)) ? function (e, t, n, s) {\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n          return Yn(() => {\n            var a = ma(e, s),\n                i = a.mean,\n                o = a.variance;\n            return [hf(e, i, o, n, t, r), i, o];\n          });\n        }(e, t, n, s, r) : function (e, t, n, s) {\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n          return Yn(() => {\n            var a = ma(e, s),\n                i = a.mean,\n                o = a.variance,\n                l = [];\n\n            for (var _t226 of pc(0, e.rank)) {\n              -1 !== s.indexOf(_t226) ? l.push(1) : l.push(e.shape[_t226]);\n            }\n\n            var u = Es(i, l),\n                c = Es(o, l),\n                h = null == t ? null : Es(t, l),\n                d = null == n ? null : Es(n, l);\n            return [hf(e, u, c, d, h, r), i, o];\n          });\n        }(e, t, n, s, r);\n      }(s, this.gamma.read(), this.beta.read(), i, this.epsilon),\n          g = (e, t, n) => {\n        Yn(() => {\n          var s = 1 - n,\n              r = e.read(),\n              a = ss(Vr(r, t), s);\n          e.write(Vr(r, a));\n        });\n      };\n\n      return (() => {\n        g(this.movingMean, d, this.momentum), g(this.movingVariance, f, this.momentum);\n      })(), h;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis,\n      momentum: this.momentum,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: Yc(this.betaInitializer),\n      gammaInitializer: Yc(this.gammaInitializer),\n      movingMeanInitializer: Yc(this.movingMeanInitializer),\n      movingVarianceInitializer: Yc(this.movingVarianceInitializer),\n      betaRegularizer: Jd(this.betaRegularizer),\n      gammaRegularizer: Jd(this.gammaRegularizer),\n      betaConstraint: ju(this.betaConstraint),\n      gammaConstraint: ju(this.gammaConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\ndf.className = \"BatchNormalization\", qn(df);\n\nclass pf extends gh {\n  constructor(e) {\n    if (null == e && (e = {}), super(e), this.axis = null == e.axis ? -1 : e.axis, \"number\" == typeof this.axis) {\n      if (!Number.isInteger(this.axis)) throw new Error(\"Expected axis to be an integer, but received \".concat(this.axis));\n    } else {\n      if (!Array.isArray(this.axis)) throw new Error(\"Expected axis to be an integer or an array of integers, but received \".concat(JSON.stringify(this.axis)));\n\n      for (var _e238 of this.axis) {\n        if (!Number.isInteger(_e238)) throw new Error(\"Expected axis to be an array of integers, but received \".concat(JSON.stringify(this.axis)));\n      }\n    }\n\n    this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = Jc(e.betaInitializer || \"zeros\"), this.gammaInitializer = Jc(e.gammaInitializer || \"ones\"), this.betaRegularizer = Qd(e.betaRegularizer), this.gammaRegularizer = Qd(e.gammaRegularizer), this.supportsMasking = !0;\n  }\n\n  build(e) {\n    var t = (e = ah(e)).length;\n    \"number\" == typeof this.axis && (this.axis = [this.axis]);\n\n    for (var _e239 = 0; _e239 < this.axis.length; ++_e239) {\n      this.axis[_e239] < 0 && (this.axis[_e239] += t);\n    }\n\n    for (var _e240 of this.axis) {\n      if (_e240 < 0 || _e240 >= t) throw new Error(\"Invalid axis: \".concat(_e240));\n    }\n\n    if (this.axis.length !== Fu(this.axis).length) throw new Error(\"Found duplicate axes in: \".concat(this.axis));\n    var n = this.axis.map(t => e[t]);\n    this.gamma = this.scale ? this.addWeight(\"gamma\", n, \"float32\", this.gammaInitializer, this.gammaRegularizer, !0) : null, this.beta = this.center ? this.addWeight(\"beta\", n, \"float32\", this.betaInitializer, this.betaRegularizer, !0) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    var n = rh(e),\n        s = n.shape,\n        r = s.length;\n    return Yn(() => {\n      var {\n        mean: e,\n        variance: t\n      } = ma(n, this.axis, !0);\n      var a = ku(1, r);\n\n      for (var _e241 of this.axis) {\n        a[_e241] = s[_e241];\n      }\n\n      var i = e => null != e && e.shape.length !== r && this.axis !== [r - 1] ? Es(e, a) : e;\n\n      var o = i(this.gamma.read()),\n          l = i(this.beta.read());\n      var u = [],\n          c = [];\n\n      for (var _e242 = 0; _e242 < r; ++_e242) {\n        -1 !== this.axis.indexOf(_e242) ? (u.push(s[_e242]), c.push(1)) : (u.push(1), c.push(s[_e242]));\n      }\n\n      return e = wr(e, u), t = wr(t, u), o = wr(o, c), l = wr(l, c), hf(n, e, t, l, o, this.epsilon);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: Yc(this.betaInitializer),\n      gammaInitializer: Yc(this.gammaInitializer),\n      betaRegularizer: Jd(this.betaRegularizer),\n      gammaRegularizer: Jd(this.gammaRegularizer)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\npf.className = \"LayerNormalization\", qn(pf);\n\nclass ff extends gh {\n  constructor(e) {\n    if (null == e && (e = {}), super(e), this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, null == e.padding) this.padding = [[1, 1], [1, 1]];else if (\"number\" == typeof e.padding) this.padding = [[e.padding, e.padding], [e.padding, e.padding]];else {\n      if (e.padding = e.padding, 2 !== e.padding.length) throw new bu(\"ZeroPadding2D expects padding to be a length-2 array, but received a length-\".concat(e.padding.length, \" array.\"));\n\n      var _t227, _n142;\n\n      if (\"number\" == typeof e.padding[0]) _t227 = [e.padding[0], e.padding[0]], _n142 = [e.padding[1], e.padding[1]];else {\n        if (e.padding = e.padding, 2 !== e.padding[0].length) throw new bu(\"ZeroPadding2D expects height padding to be a length-2 array, but received a length-\".concat(e.padding[0].length, \" array.\"));\n        if (_t227 = e.padding[0], 2 !== e.padding[1].length) throw new bu(\"ZeroPadding2D expects width padding to be a length-2 array, but received a length-\".concat(e.padding[1].length, \" array.\"));\n        _n142 = e.padding[1];\n      }\n      this.padding = [_t227, _n142];\n    }\n    this.inputSpec = [new ch({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t, n;\n    return e = ah(e), \"channelsFirst\" === this.dataFormat ? (t = null != e[2] && e[2] >= 0 ? e[2] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[3] && e[3] >= 0 ? e[3] + this.padding[1][0] + this.padding[1][1] : null, [e[0], e[1], t, n]) : (t = null != e[1] && e[1] >= 0 ? e[1] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[2] && e[2] >= 0 ? e[2] + this.padding[1][0] + this.padding[1][1] : null, [e[0], t, n, e[3]]);\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      return t = rh(e), n = this.padding, s = this.dataFormat, Yn(() => {\n        if (4 !== t.rank) throw new bu(\"temporalPadding expects input tensor to be 4-D, but received a \".concat(t.rank, \"-D tensor.\"));\n        if (null == n && (n = [[1, 1], [1, 1]]), 2 !== n.length || 2 !== n[0].length || 2 !== n[1].length) throw new bu(\"spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.\");\n        if (null == s && (s = \"channelsLast\"), \"channelsLast\" !== s && \"channelsFirst\" !== s) throw new bu(\"Unknown data format: \".concat(s, \". Supported data formats are 'channelsLast' and 'channelsFirst.\"));\n        var e;\n        return e = \"channelsFirst\" === s ? [[0, 0], [0, 0], n[0], n[1]] : [[0, 0], n[0], n[1], [0, 0]], ya(t, e);\n      });\n      var t, n, s;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      padding: this.padding,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction gf(e, t, n, s, r, a) {\n  return Yn(() => {\n    var i;\n    tc(r), sc(a), nc(s), null == n && (n = [1, 1]), null == s && (s = \"valid\"), null == r && (r = \"channelsLast\"), null == a && (a = \"max\"), e = up(e, r);\n    var o = \"same\" === s ? \"same\" : \"valid\";\n    return i = \"max\" === a ? aa(e, t, n, o) : Rs(e, t, n, o), \"channelsFirst\" === r && (i = $n(i, [0, 3, 1, 2])), i;\n  });\n}\n\nfunction mf(e, t, n, s, r, a) {\n  return Yn(() => {\n    var i;\n    tc(r), sc(a), nc(s), null == n && (n = [1, 1, 1]), null == s && (s = \"valid\"), null == r && (r = \"channelsLast\"), null == a && (a = \"max\"), e = cp(e, r);\n    var o = \"same\" === s ? \"same\" : \"valid\";\n    return i = \"max\" === a ? ia(e, t, n, o) : As(e, t, n, o), \"channelsFirst\" === r && (i = $n(i, [0, 4, 1, 2, 3])), i;\n  });\n}\n\nff.className = \"ZeroPadding2D\", qn(ff);\n\nclass bf extends gh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = 2), super(e), \"number\" == typeof e.poolSize) this.poolSize = [e.poolSize];else {\n      if (!Array.isArray(e.poolSize) || 1 !== e.poolSize.length || \"number\" != typeof e.poolSize[0]) throw new bu(\"poolSize for 1D convolutional layer must be a number or an Array of a single number, but received \".concat(JSON.stringify(e.poolSize)));\n      this.poolSize = e.poolSize;\n    }\n    if (Mu(this.poolSize, \"poolSize\"), null == e.strides) this.strides = this.poolSize;else if (\"number\" == typeof e.strides) this.strides = [e.strides];else {\n      if (!Array.isArray(e.strides) || 1 !== e.strides.length || \"number\" != typeof e.strides[0]) throw new bu(\"strides for 1D convolutional layer must be a number or an Array of a single number, but received \".concat(JSON.stringify(e.strides)));\n      this.strides = e.strides;\n    }\n    Mu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, nc(this.padding), this.inputSpec = [new ch({\n      ndim: 3\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t = op((e = ah(e))[1], this.poolSize[0], this.padding, this.strides[0]);\n    return [e[0], t, e[2]];\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      this.invokeCallHook(e, t), e = gc(rh(e), 2);\n      var n = this.poolingFunction(rh(e), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, \"channelsLast\");\n      return hi(n, [2]);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass xf extends bf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), gf(e, t, n, s, r, \"max\");\n  }\n\n}\n\nxf.className = \"MaxPooling1D\", qn(xf);\n\nclass yf extends bf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), gf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nyf.className = \"AveragePooling1D\", qn(yf);\n\nclass kf extends gh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = [2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {\n      if (2 !== e.strides.length) throw new bu(\"If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length \".concat(e.strides.length, \".\"));\n      this.strides = e.strides;\n    } else this.strides = [e.strides, e.strides];\n    Mu(this.poolSize, \"poolSize\"), Mu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, tc(this.dataFormat), nc(this.padding), this.inputSpec = [new ch({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    e = ah(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[2] : e[1],\n        n = \"channelsFirst\" === this.dataFormat ? e[3] : e[2];\n    return t = op(t, this.poolSize[0], this.padding, this.strides[0]), n = op(n, this.poolSize[1], this.padding, this.strides[1]), \"channelsFirst\" === this.dataFormat ? [e[0], e[1], t, n] : [e[0], t, n, e[3]];\n  }\n\n  call(e, t) {\n    return Yn(() => (this.invokeCallHook(e, t), this.poolingFunction(rh(e), this.poolSize, this.strides, this.padding, this.dataFormat)));\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass wf extends kf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), gf(e, t, n, s, r, \"max\");\n  }\n\n}\n\nwf.className = \"MaxPooling2D\", qn(wf);\n\nclass vf extends kf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), gf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nvf.className = \"AveragePooling2D\", qn(vf);\n\nclass If extends gh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = [2, 2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {\n      if (3 !== e.strides.length) throw new bu(\"If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length \".concat(e.strides.length, \".\"));\n      this.strides = e.strides;\n    } else this.strides = [e.strides, e.strides, e.strides];\n    Mu(this.poolSize, \"poolSize\"), Mu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, tc(this.dataFormat), nc(this.padding), this.inputSpec = [new ch({\n      ndim: 5\n    })];\n  }\n\n  computeOutputShape(e) {\n    e = ah(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[2] : e[1],\n        n = \"channelsFirst\" === this.dataFormat ? e[3] : e[2],\n        s = \"channelsFirst\" === this.dataFormat ? e[4] : e[3];\n    return t = op(t, this.poolSize[0], this.padding, this.strides[0]), n = op(n, this.poolSize[1], this.padding, this.strides[1]), s = op(s, this.poolSize[2], this.padding, this.strides[2]), \"channelsFirst\" === this.dataFormat ? [e[0], e[1], t, n, s] : [e[0], t, n, s, e[4]];\n  }\n\n  call(e, t) {\n    return Yn(() => (this.invokeCallHook(e, t), this.poolingFunction(rh(e), this.poolSize, this.strides, this.padding, this.dataFormat)));\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass $f extends If {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), mf(e, t, n, s, r, \"max\");\n  }\n\n}\n\n$f.className = \"MaxPooling3D\", qn($f);\n\nclass Nf extends If {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return tc(r), nc(s), mf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nNf.className = \"AveragePooling3D\", qn(Nf);\n\nclass Cf extends gh {\n  constructor(e) {\n    super(e), this.inputSpec = [new ch({\n      ndim: 3\n    })];\n  }\n\n  computeOutputShape(e) {\n    return [e[0], e[2]];\n  }\n\n  call(e, t) {\n    throw new xu();\n  }\n\n}\n\nclass Sf extends Cf {\n  constructor(e) {\n    super(e || {});\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      return la(t, 1);\n    });\n  }\n\n}\n\nSf.className = \"GlobalAveragePooling1D\", qn(Sf);\n\nclass Tf extends Cf {\n  constructor(e) {\n    super(e || {});\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      return Ur(t, 1);\n    });\n  }\n\n}\n\nTf.className = \"GlobalMaxPooling1D\", qn(Tf);\n\nclass Ef extends gh {\n  constructor(e) {\n    super(e), this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, tc(this.dataFormat), this.inputSpec = [new ch({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    return e = e, \"channelsLast\" === this.dataFormat ? [e[0], e[3]] : [e[0], e[1]];\n  }\n\n  call(e, t) {\n    throw new xu();\n  }\n\n  getConfig() {\n    var e = {\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass Rf extends Ef {\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      return la(t, \"channelsLast\" === this.dataFormat ? [1, 2] : [2, 3]);\n    });\n  }\n\n}\n\nRf.className = \"GlobalAveragePooling2D\", qn(Rf);\n\nclass Af extends Ef {\n  call(e, t) {\n    return Yn(() => {\n      var t = rh(e);\n      return Ur(t, \"channelsLast\" === this.dataFormat ? [1, 2] : [2, 3]);\n    });\n  }\n\n}\n\nAf.className = \"GlobalMaxPooling2D\", qn(Af);\n\nclass Ff extends gh {\n  constructor(e) {\n    super(e), this.layer = e.layer;\n  }\n\n  build(e) {\n    this.built = !0;\n  }\n\n  get trainable() {\n    return null != this.layer && this.layer.trainable;\n  }\n\n  set trainable(e) {\n    null != this.layer && (this.layer.trainable = e);\n  }\n\n  get trainableWeights() {\n    return this.layer.trainableWeights;\n  }\n\n  get nonTrainableWeights() {\n    return this.layer.nonTrainableWeights;\n  }\n\n  get updates() {\n    return this.layer._updates;\n  }\n\n  get losses() {\n    return this.layer.losses;\n  }\n\n  getWeights() {\n    return this.layer.getWeights();\n  }\n\n  setWeights(e) {\n    this.layer.setWeights(e);\n  }\n\n  getConfig() {\n    var e = {\n      layer: {\n        className: this.layer.getClassName(),\n        config: this.layer.getConfig()\n      }\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.layer && this.layer.setFastWeightInitDuringBuild(e);\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = Eh(t.layer, n);\n    delete t.layer;\n    var r = {\n      layer: s\n    };\n    return Object.assign(r, t), new e(r);\n  }\n\n}\n\nclass Df extends Ff {\n  constructor(e) {\n    super(e), this.supportsMasking = !0;\n  }\n\n  build(e) {\n    if ((e = ah(e)).length < 3) throw new bu(\"TimeDistributed layer expects an input shape >= 3D, but received input shape \".concat(JSON.stringify(e)));\n    this.inputSpec = [{\n      shape: e\n    }];\n    var t = [e[0]].concat(e.slice(2));\n    this.layer.built || (this.layer.build(t), this.layer.built = !0), super.build(e);\n  }\n\n  computeOutputShape(e) {\n    var t = [(e = ah(e))[0]].concat(e.slice(2)),\n        n = this.layer.computeOutputShape(t);\n    return [n[0], e[1]].concat(n.slice(1));\n  }\n\n  call(e, t) {\n    return Yn(() => Np((e, n) => [rh(this.layer.call(e, t)), []], e = rh(e), [], !1, null, null, !1, !0)[1]);\n  }\n\n}\n\nDf.className = \"TimeDistributed\", qn(Df);\n\nclass _f extends Ff {\n  constructor(e) {\n    super(e);\n    var t = e.layer.getConfig(),\n        n = {};\n    n.className = e.layer.getClassName(), n.config = t, this.forwardLayer = Eh(n), t.goBackwards = !0 !== t.goBackwards;\n    var s = {};\n    if (s.className = e.layer.getClassName(), s.config = t, this.backwardLayer = Eh(s), this.forwardLayer.name = \"forward_\" + this.forwardLayer.name, this.backwardLayer.name = \"backward_\" + this.backwardLayer.name, this.mergeMode = void 0 === e.mergeMode ? \"concat\" : e.mergeMode, _u(Qu, \"BidirectionalMergeMode\", this.mergeMode), e.weights) throw new xu(\"weights support is not implemented for Bidirectional layer yet.\");\n    this._stateful = e.layer.stateful, this.returnSequences = e.layer.returnSequences, this.returnState = e.layer.returnState, this.supportsMasking = !0, this._trainable = !0, this.inputSpec = e.layer.inputSpec, this.numConstants = null;\n  }\n\n  get trainable() {\n    return this._trainable;\n  }\n\n  set trainable(e) {\n    this._trainable = e, null != this.forwardLayer && (this.forwardLayer.trainable = e), null != this.backwardLayer && (this.backwardLayer.trainable = e);\n  }\n\n  getWeights() {\n    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());\n  }\n\n  setWeights(e) {\n    var t = Math.floor(e.length / 2);\n    this.forwardLayer.setWeights(e.slice(0, t)), this.backwardLayer.setWeights(e.slice(t));\n  }\n\n  computeOutputShape(e) {\n    var t,\n        n,\n        s,\n        r = this.forwardLayer.computeOutputShape(e);\n    return Array.isArray(r) && Array.isArray(r[0]) || (r = [r]), r = r, this.returnState ? (s = r.slice(1), t = r[0]) : t = r[0], t = t, \"concat\" === this.mergeMode ? (t[t.length - 1] *= 2, n = [t]) : n = null == this.mergeMode ? [t, t.slice()] : [t], this.returnState ? null == this.mergeMode ? n.concat(s).concat(s.slice()) : [t].concat(s).concat(s.slice()) : Iu(n);\n  }\n\n  apply(e, t) {\n    var n = null == t ? null : t.initialState,\n        s = null == t ? null : t.constants;\n    null == t && (t = {});\n    var r = $p(e, n, s, this.numConstants);\n    if (e = r.inputs, n = r.initialState, s = r.constants, Array.isArray(e) && (n = e.slice(1), e = e[0]), (null == n || 0 === n.length) && null == s) return super.apply(e, t);\n    var a = [],\n        i = [];\n\n    if (null != n) {\n      var _e243 = n.length;\n      if (_e243 % 2 > 0) throw new bu(\"When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.\");\n      t.initialState = n, a.push(...n);\n\n      var _s122 = n.map(e => new ch({\n        shape: e.shape\n      }));\n\n      this.forwardLayer.stateSpec = _s122.slice(0, _e243 / 2), this.backwardLayer.stateSpec = _s122.slice(_e243 / 2), i.push(..._s122);\n    }\n\n    if (null != s) throw new xu(\"Support for constants in Bidirectional layers is not implemented yet.\");\n    var o = a[0] instanceof hh;\n\n    for (var _e244 of a) {\n      if (_e244 instanceof hh !== o) throw new bu(\"The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors\");\n    }\n\n    if (o) {\n      var _n143 = [e].concat(a),\n          _s123 = this.inputSpec.concat(i),\n          _r84 = this.inputSpec;\n\n      this.inputSpec = _s123;\n\n      var _o29 = super.apply(_n143, t);\n\n      return this.inputSpec = _r84, _o29;\n    }\n\n    return super.apply(e, t);\n  }\n\n  call(e, t) {\n    return Yn(() => {\n      var n = t.initialState;\n      var s, r, a, i;\n      if (null == n) s = this.forwardLayer.call(e, t), r = this.backwardLayer.call(e, t);else {\n        var _a64 = n.slice(0, n.length / 2),\n            _i36 = n.slice(n.length / 2);\n\n        s = this.forwardLayer.call(e, Object.assign(t, {\n          initialState: _a64\n        })), r = this.backwardLayer.call(e, Object.assign(t, {\n          initialState: _i36\n        }));\n      }\n      return this.returnState && (Array.isArray(s) && (a = s.slice(1).concat(r.slice(1))), s = s[0], r = r[0]), this.returnSequences && (r = Ga(r, 1)), \"concat\" === this.mergeMode ? i = yc([s, r]) : \"sum\" === this.mergeMode ? i = es(s, r) : \"ave\" === this.mergeMode ? i = ss(.5, es(s, r)) : \"mul\" === this.mergeMode ? i = ss(s, r) : null == this.mergeMode && (i = [s, r]), this.returnState ? null == this.mergeMode ? i.concat(a) : [i].concat(a) : i;\n    });\n  }\n\n  resetStates(e) {\n    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();\n  }\n\n  build(e) {\n    ac(this.forwardLayer.name, () => {\n      this.forwardLayer.build(e);\n    }), ac(this.backwardLayer.name, () => {\n      this.backwardLayer.build(e);\n    }), this.built = !0;\n  }\n\n  computeMask(e, t) {\n    var n;\n\n    if (Array.isArray(t) && (t = t[0]), n = this.returnSequences ? null == this.mergeMode ? [t, t] : t : null == this.mergeMode ? [null, null] : null, this.returnState) {\n      var _e245 = this.forwardLayer.states.map(e => null);\n\n      return Array.isArray(n) ? n.concat(_e245).concat(_e245) : [n].concat(_e245).concat(_e245);\n    }\n\n    return n;\n  }\n\n  get trainableWeights() {\n    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);\n  }\n\n  get nonTrainableWeights() {\n    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.forwardLayer && this.forwardLayer.setFastWeightInitDuringBuild(e), null != this.backwardLayer && this.backwardLayer.setFastWeightInitDuringBuild(e);\n  }\n\n  getConfig() {\n    var e = {\n      mergeMode: this.mergeMode\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  static fromConfig(e, t) {\n    var n = Eh(t.layer);\n    if (delete t.layer, null != t.numConstants) throw new xu(\"Deserialization of a Bidirectional layer with numConstants present is not supported yet.\");\n    var s = t;\n    return s.layer = n, new e(s);\n  }\n\n}\n\nfunction Of(e) {\n  return new kp(e);\n}\n\nfunction Mf(e) {\n  return new Up(e);\n}\n\nfunction Lf(e) {\n  return new xf(e);\n}\n\nfunction zf(e, t) {\n  Array.isArray(e) || (e = [e]), e.forEach(e => {\n    null != e && l(\"complex64\" !== e.dtype, () => \"\".concat(t, \" does not support complex64 tensors in the CPU backend.\"));\n  });\n}\n\n_f.className = \"Bidirectional\", qn(_f), function (e) {\n  e[e.DT_INVALID = 0] = \"DT_INVALID\", e[e.DT_FLOAT = 1] = \"DT_FLOAT\", e[e.DT_DOUBLE = 2] = \"DT_DOUBLE\", e[e.DT_INT32 = 3] = \"DT_INT32\", e[e.DT_UINT8 = 4] = \"DT_UINT8\", e[e.DT_INT16 = 5] = \"DT_INT16\", e[e.DT_INT8 = 6] = \"DT_INT8\", e[e.DT_STRING = 7] = \"DT_STRING\", e[e.DT_COMPLEX64 = 8] = \"DT_COMPLEX64\", e[e.DT_INT64 = 9] = \"DT_INT64\", e[e.DT_BOOL = 10] = \"DT_BOOL\", e[e.DT_QINT8 = 11] = \"DT_QINT8\", e[e.DT_QUINT8 = 12] = \"DT_QUINT8\", e[e.DT_QINT32 = 13] = \"DT_QINT32\", e[e.DT_BFLOAT16 = 14] = \"DT_BFLOAT16\", e[e.DT_FLOAT_REF = 101] = \"DT_FLOAT_REF\", e[e.DT_DOUBLE_REF = 102] = \"DT_DOUBLE_REF\", e[e.DT_INT32_REF = 103] = \"DT_INT32_REF\", e[e.DT_UINT8_REF = 104] = \"DT_UINT8_REF\", e[e.DT_INT16_REF = 105] = \"DT_INT16_REF\", e[e.DT_INT8_REF = 106] = \"DT_INT8_REF\", e[e.DT_STRING_REF = 107] = \"DT_STRING_REF\", e[e.DT_COMPLEX64_REF = 108] = \"DT_COMPLEX64_REF\", e[e.DT_INT64_REF = 109] = \"DT_INT64_REF\", e[e.DT_BOOL_REF = 110] = \"DT_BOOL_REF\", e[e.DT_QINT8_REF = 111] = \"DT_QINT8_REF\", e[e.DT_QUINT8_REF = 112] = \"DT_QUINT8_REF\", e[e.DT_QINT32_REF = 113] = \"DT_QINT32_REF\", e[e.DT_BFLOAT16_REF = 114] = \"DT_BFLOAT16_REF\";\n}(Mp || (Mp = {})), function (e) {\n  var t;\n  (t = e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}))[t.LEGACY = 0] = \"LEGACY\", t[t.V1 = 1] = \"V1\", t[t.V2 = 2] = \"V2\";\n}(Lp || (Lp = {})), function (e) {\n  e[e.FAIL = 0] = \"FAIL\", e[e.SHORTEST = 1] = \"SHORTEST\", e[e.LONGEST = 2] = \"LONGEST\";\n}(zp || (zp = {}));\nvar Bf = Ii;\n\nclass Pf extends n {\n  constructor() {\n    super(), this.blockSize = 48, this.firstUse = !0, this.data = new t(this, Kn());\n  }\n\n  nextDataId() {\n    return Pf.nextDataId++;\n  }\n\n  write(e, t, n) {\n    this.firstUse && (this.firstUse = !1, V().get(\"IS_NODE\") && Oo(\"\\n============================\\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\\n============================\"));\n    var s = {\n      id: this.nextDataId()\n    };\n    return this.data.set(s, {\n      values: e,\n      dtype: n,\n      refCount: 1\n    }), s;\n  }\n\n  makeTensorInfo(e, t, n) {\n    var s;\n\n    if (\"string\" === t && null != n && n.length > 0 && C(n[0])) {\n      var _r85 = n.map(e => Ge(e));\n\n      s = this.write(_r85, e, t);\n    } else s = this.write(n, e, t);\n\n    return {\n      dataId: s,\n      shape: e,\n      dtype: t\n    };\n  }\n\n  refCount(e) {\n    return this.data.has(e) ? this.data.get(e).refCount : 0;\n  }\n\n  incRef(e) {\n    this.data.get(e).refCount++;\n  }\n\n  decRef(e) {\n    this.data.has(e) && this.data.get(e).refCount--;\n  }\n\n  move(e, t, n, s, r) {\n    this.data.set(e, {\n      values: t,\n      dtype: s,\n      refCount: r\n    });\n  }\n\n  numDataIds() {\n    return this.data.numDataIds();\n  }\n\n  read(e) {\n    var _this69 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this69.readSync(e);\n    })();\n  }\n\n  readSync(e) {\n    var {\n      dtype: t,\n      complexTensorInfos: n\n    } = this.data.get(e);\n    return \"complex64\" === t ? Mo(this.readSync(n.real.dataId), this.readSync(n.imag.dataId)) : this.data.get(e).values;\n  }\n\n  bufferSync(e) {\n    var t = this.readSync(e.dataId);\n    var n = t;\n    if (\"string\" === e.dtype) try {\n      n = t.map(e => He(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode encoded string bytes into utf-8\");\n    }\n    return dn(e.shape, e.dtype, n);\n  }\n\n  makeOutput(e, t, n) {\n    var s = this.write(e, t, n);\n    return Kn().makeTensorFromDataId(s, t, n, this);\n  }\n\n  disposeData(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n\n    if (this.data.has(e)) {\n      if (this.data.get(e).refCount--, !t && this.data.get(e).refCount > 0) return !1;\n      var {\n        complexTensorInfos: _n144\n      } = this.data.get(e);\n      null != _n144 && (this.disposeData(_n144.real.dataId, !0), this.disposeData(_n144.imag.dataId, !0)), this.data.delete(e);\n    }\n\n    return !0;\n  }\n\n  disposeIntermediateTensorInfo(e) {\n    this.disposeData(e.dataId);\n  }\n\n  time(e) {\n    return _asyncToGenerator(function* () {\n      var t = Ve();\n      return e(), {\n        kernelMs: Ve() - t\n      };\n    })();\n  }\n\n  memory() {\n    return {\n      unreliable: !0,\n      reasons: [\"The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less.\"]\n    };\n  }\n\n  where(e) {\n    zf([e], \"where\");\n    var t = this.readSync(e.dataId);\n    return Bf(e.shape, t);\n  }\n\n  dispose() {}\n\n  floatPrecision() {\n    return 32;\n  }\n\n  epsilon() {\n    return super.epsilon();\n  }\n\n}\n\nfunction Wf(e) {\n  var t = new Float32Array(e.length);\n\n  for (var _n145 = 0; _n145 < e.length; ++_n145) {\n    t[_n145] = Math.abs(e[_n145]);\n  }\n\n  return t;\n}\n\nPf.nextDataId = 0;\nvar Uf = {\n  kernelName: \"Abs\",\n  backendName: \"cpu\",\n  kernelFunc: e => {\n    var {\n      x: t\n    } = e.inputs,\n        n = e.backend;\n    zf(t, \"abs\");\n    var s = new Float32Array(d(t.shape));\n    return s = Wf(n.data.get(t.dataId).values), n.makeOutput(s, t.shape, \"float32\");\n  }\n};\n\nfunction Vf(e) {\n  return (t, n, s, r, a) => {\n    var i = cr(t, n),\n        o = i.length,\n        l = A(i),\n        u = w(a, d(i)),\n        c = t.length,\n        h = n.length,\n        p = A(t),\n        f = A(n),\n        g = lr(t, i),\n        m = lr(n, i);\n    if (g.length + m.length === 0) for (var _t228 = 0; _t228 < u.length; ++_t228) {\n      u[_t228] = e(s[_t228 % s.length], r[_t228 % r.length]);\n    } else {\n      var _loop25 = function _loop25(_t229) {\n        var n = B(_t229, o, l),\n            a = n.slice(-c);\n        g.forEach(e => a[e] = 0);\n        var i = z(a, c, p),\n            d = n.slice(-h);\n        m.forEach(e => d[e] = 0);\n        var b = z(d, h, f);\n        u[_t229] = e(s[i], r[b]);\n      };\n\n      for (var _t229 = 0; _t229 < u.length; ++_t229) {\n        _loop25(_t229);\n      }\n    }\n    return [u, i];\n  };\n}\n\nfunction Gf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    real: s,\n    imag: r\n  } = t,\n      a = n.data.get(s.dataId).values,\n      i = n.data.get(r.dataId).values,\n      o = n.makeTensorInfo(s.shape, \"complex64\");\n  return n.data.get(o.dataId).complexTensorInfos = {\n    real: n.makeTensorInfo(s.shape, \"float32\", a),\n    imag: n.makeTensorInfo(r.shape, \"float32\", i)\n  }, o;\n}\n\nvar Hf = {\n  kernelName: \"Complex\",\n  backendName: \"cpu\",\n  kernelFunc: Gf\n};\n\nfunction jf(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"float32\";\n  if (\"complex64\" === n) return Gf({\n    inputs: {\n      real: jf(e, t, \"float32\"),\n      imag: jf(e, t, \"float32\")\n    },\n    backend: e\n  });\n  var s = O(d(t), n);\n  return e.makeTensorInfo(t, n, s);\n}\n\nfunction qf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  return n.incRef(s.dataId), {\n    dataId: s.dataId,\n    shape: s.shape,\n    dtype: s.dtype\n  };\n}\n\nvar Kf = {\n  kernelName: \"Identity\",\n  backendName: \"cpu\",\n  kernelFunc: qf\n};\n\nfunction Xf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t,\n      r = n.data.get(s.dataId).complexTensorInfos.real,\n      a = n.data.get(r.dataId).values;\n  return n.makeTensorInfo(r.shape, r.dtype, a);\n}\n\nvar Yf = {\n  kernelName: \"Real\",\n  backendName: \"cpu\",\n  kernelFunc: Xf\n};\n\nfunction Jf(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    dtype: a\n  } = s;\n\n  if (\"complex64\" === a) {\n    if (\"complex64\" === r.dtype) return qf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n\n    var _e246 = jf(n, r.shape, r.dtype),\n        _t230 = Jf({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        dtype: \"float32\"\n      }\n    }),\n        _s124 = Gf({\n      inputs: {\n        real: _t230,\n        imag: _e246\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e246), n.disposeIntermediateTensorInfo(_t230), _s124;\n  }\n\n  if (\"complex64\" === r.dtype) {\n    var _e247 = Xf({\n      inputs: {\n        input: r\n      },\n      backend: n\n    }),\n        _t231 = Jf({\n      inputs: {\n        x: _e247\n      },\n      backend: n,\n      attrs: {\n        dtype: a\n      }\n    });\n\n    return n.disposeIntermediateTensorInfo(_e247), _t231;\n  }\n\n  if (!I(r.dtype, a)) {\n    var _e248 = qf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n\n    return {\n      dataId: _e248.dataId,\n      shape: _e248.shape,\n      dtype: a\n    };\n  }\n\n  if (\"int32\" === a) {\n    var _e249 = n.data.get(r.dataId).values,\n        _t232 = Int32Array.from(_e249);\n\n    return n.makeTensorInfo(r.shape, \"int32\", _t232);\n  }\n\n  if (\"bool\" === a) {\n    var _e250 = n.data.get(r.dataId).values,\n        _t233 = Ue([0], r.dtype),\n        [_s125, _a65] = Vf((e, t) => e !== t ? 1 : 0)(r.shape, [], _e250, _t233, \"bool\");\n\n    return n.makeTensorInfo(_a65, \"bool\", _s125);\n  }\n\n  throw new Error(\"Error in Cast: failed to cast \".concat(r.dtype, \" to \").concat(a));\n}\n\nvar Zf = {\n  kernelName: \"Cast\",\n  backendName: \"cpu\",\n  kernelFunc: Jf\n};\n\nfunction Qf(e, t, n, s) {\n  return null == n ? _ref9 => {\n    var {\n      inputs: n,\n      backend: r\n    } = _ref9;\n    var {\n      a,\n      b: i\n    } = n,\n        o = r;\n    zf([a, i], e);\n    var l = o.data.get(a.dataId).values,\n        u = o.data.get(i.dataId).values,\n        c = \"string\" === a.dtype ? tl(l) : l,\n        h = \"string\" === a.dtype ? tl(u) : u,\n        d = s || a.dtype,\n        [p, f] = t(a.shape, i.shape, c, h, d);\n    return o.makeTensorInfo(f, d, p);\n  } : _ref10 => {\n    var {\n      inputs: e,\n      backend: r\n    } = _ref10;\n    var {\n      a,\n      b: i\n    } = e,\n        o = r;\n\n    if (\"complex64\" === a.dtype || \"complex64\" === i.dtype) {\n      var _e251 = Jf({\n        inputs: {\n          x: a\n        },\n        backend: o,\n        attrs: {\n          dtype: \"complex64\"\n        }\n      }),\n          _t234 = o.data.get(_e251.dataId),\n          _s126 = _t234.complexTensorInfos.imag,\n          _r86 = o.data.get(_t234.complexTensorInfos.real.dataId).values,\n          _l19 = o.data.get(_s126.dataId).values,\n          _u11 = Jf({\n        inputs: {\n          x: i\n        },\n        backend: o,\n        attrs: {\n          dtype: \"complex64\"\n        }\n      }),\n          _c11 = o.data.get(_u11.dataId),\n          _h8 = _c11.complexTensorInfos.imag,\n          _d8 = o.data.get(_c11.complexTensorInfos.real.dataId).values,\n          _p7 = o.data.get(_h8.dataId).values,\n          [_f6, _g8, _m7] = n(a.shape, i.shape, _r86, _l19, _d8, _p7),\n          _b6 = o.makeTensorInfo(_m7, \"float32\", _f6),\n          _x50 = o.makeTensorInfo(_m7, \"float32\", _g8),\n          _y6 = Gf({\n        inputs: {\n          real: _b6,\n          imag: _x50\n        },\n        backend: o\n      });\n\n      return o.disposeIntermediateTensorInfo(_e251), o.disposeIntermediateTensorInfo(_u11), o.disposeIntermediateTensorInfo(_b6), o.disposeIntermediateTensorInfo(_x50), _y6;\n    }\n\n    {\n      var _e252 = o.data.get(a.dataId).values,\n          _n146 = o.data.get(i.dataId).values,\n          _r87 = s || a.dtype,\n          [_l20, _u12] = t(a.shape, i.shape, _e252, _n146, _r87);\n\n      return o.makeTensorInfo(_u12, _r87, _l20);\n    }\n  };\n}\n\nfunction eg(e) {\n  return (t, n, s, r, a, i) => {\n    var o = cr(t, n),\n        l = d(o),\n        u = o.length,\n        c = A(o),\n        h = w(\"float32\", l),\n        p = w(\"float32\", l),\n        f = lr(t, o),\n        g = lr(n, o),\n        m = Mo(s, r),\n        b = Mo(a, i),\n        x = t.length,\n        y = A(t),\n        k = n.length,\n        v = A(n);\n    if (f.length + g.length === 0) for (var _t235 = 0; _t235 < h.length; _t235++) {\n      var _n147 = _t235 % m.length,\n          _s127 = _t235 % b.length,\n          _r88 = e(m[2 * _n147], m[2 * _n147 + 1], b[2 * _s127], b[2 * _s127 + 1]);\n\n      h[_t235] = _r88.real, p[_t235] = _r88.imag;\n    } else {\n      var _loop26 = function _loop26(_t236) {\n        var n = B(_t236, u, c),\n            s = n.slice(-x);\n        f.forEach(e => s[e] = 0);\n        var r = z(s, x, y),\n            a = n.slice(-k);\n        g.forEach(e => a[e] = 0);\n        var i = z(a, k, v),\n            o = e(m[2 * r], m[2 * r + 1], b[2 * i], b[2 * i + 1]);\n        h[_t236] = o.real, p[_t236] = o.imag;\n      };\n\n      for (var _t236 = 0; _t236 < h.length; _t236++) {\n        _loop26(_t236);\n      }\n    }\n    return [h, p, o];\n  };\n}\n\nvar tg = Vf((e, t) => e + t),\n    ng = Qf(\"Add\", tg, eg((e, t, n, s) => ({\n  real: e + n,\n  imag: t + s\n}))),\n    sg = {\n  kernelName: \"Add\",\n  backendName: \"cpu\",\n  kernelFunc: ng\n};\n\nfunction rg(e, t, n, s, r) {\n  var a = d(s),\n      i = O(r, n);\n\n  for (var _n148 = 0; _n148 < e.length; _n148++) {\n    var _s128 = e[_n148];\n    if (_s128 < 0) throw new Error(\"Input x must be non-negative!\");\n    _s128 >= r || (i[_s128] += a > 0 ? t[_n148] : 1);\n  }\n\n  return i;\n}\n\nfunction ag(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = e.shape[0],\n      a = e.shape[1],\n      i = dn([r, n], t.dtype);\n\n  for (var _o30 = 0; _o30 < r; _o30++) {\n    for (var _r89 = 0; _r89 < a; _r89++) {\n      var _a66 = e.get(_o30, _r89);\n\n      if (_a66 < 0) throw new Error(\"Input x must be non-negative!\");\n      _a66 >= n || i.set(s ? 1 : t.size > 0 ? i.get(_o30, _a66) + t.get(_o30, _r89) : i.get(_o30, _a66) + 1, _o30, _a66);\n    }\n  }\n\n  return i;\n}\n\nfunction ig(e) {\n  return (t, n, s) => {\n    var r = w(n, t.length);\n\n    for (var _n149 = 0; _n149 < t.length; ++_n149) {\n      r[_n149] = e(t[_n149], s);\n    }\n\n    return r;\n  };\n}\n\nfunction og(e, t, n) {\n  return _ref11 => {\n    var {\n      inputs: s,\n      attrs: r,\n      backend: a\n    } = _ref11;\n    var {\n      x: i\n    } = s;\n    if (zf(i, e), \"string\" === i.dtype || \"string\" === n) throw new Error(\"unaryKernelFunc does not support string input/output\");\n    var o = a,\n        l = o.data.get(i.dataId).values,\n        u = d(i.shape),\n        c = n || i.dtype,\n        h = v(c, u);\n\n    for (var _e253 = 0; _e253 < u; ++_e253) {\n      h[_e253] = t(l[_e253], r);\n    }\n\n    return o.makeTensorInfo(i.shape, c, h);\n  };\n}\n\nfunction lg(e, t, n) {\n  return _ref12 => {\n    var {\n      inputs: s,\n      attrs: r,\n      backend: a\n    } = _ref12;\n    var {\n      x: i\n    } = s;\n    if (zf(i, e), \"string\" === i.dtype || \"string\" === n) throw new Error(\"unaryKernelFunc does not support string input/output\");\n    var o = a,\n        l = o.data.get(i.dataId).values,\n        u = n || i.dtype,\n        c = t(l, u, r);\n    return o.makeTensorInfo(i.shape, u, c);\n  };\n}\n\nvar ug = ig(e => Math.ceil(e)),\n    cg = {\n  kernelName: \"Ceil\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Ceil\", ug)\n};\n\nfunction hg(e, t, n, s) {\n  var r = v(n, d(t));\n\n  if (s && \"string\" !== n) {\n    var _t237 = 0;\n    e.forEach(e => {\n      var n = d(e.shape);\n      r.set(e.vals, _t237), _t237 += n;\n    });\n  } else {\n    var _s129 = 0;\n    e.forEach(e => {\n      var a = \"string\" === n ? tl(e.vals) : e.vals;\n      var i = 0;\n\n      for (var _n150 = 0; _n150 < e.shape[0]; ++_n150) {\n        var _o31 = _n150 * t[1] + _s129;\n\n        for (var _t238 = 0; _t238 < e.shape[1]; ++_t238) {\n          r[_o31 + _t238] = a[i++];\n        }\n      }\n\n      _s129 += e.shape[1];\n    });\n  }\n\n  return r;\n}\n\nvar dg = Vf((e, t) => e === t ? 1 : 0),\n    pg = Qf(\"Equal\", dg, null, \"bool\"),\n    fg = {\n  kernelName: \"Equal\",\n  backendName: \"cpu\",\n  kernelFunc: pg\n},\n    gg = ig(e => Math.exp(e)),\n    mg = lg(\"Exp\", gg),\n    bg = {\n  kernelName: \"Exp\",\n  backendName: \"cpu\",\n  kernelFunc: mg\n},\n    xg = ig(e => Math.expm1(e)),\n    yg = {\n  kernelName: \"Expm1\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Expm1\", xg)\n},\n    kg = ig(e => Math.floor(e)),\n    wg = {\n  kernelName: \"Floor\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Floor\", kg)\n};\n\nfunction vg(e, t, n, s, r, a, i, o, l) {\n  var u = dn([s, a], n);\n\n  for (var _n151 = 0; _n151 < s; _n151++) {\n    var _s130 = [];\n    var _c12 = 0;\n\n    for (var _t239 = 0; _t239 < r; _t239++) {\n      var _a67 = e[_n151 * r + _t239];\n      _c12 += _a67 * i[_t239], _s130.push(_a67);\n    }\n\n    if (_c12 < 0 || _c12 >= l / a) throw new Error(\"Invalid indices: \".concat(_s130, \" does not index into \").concat(o));\n\n    for (var _e254 = 0; _e254 < a; _e254++) {\n      u.values[_n151 * a + _e254] = t.get(...t.indexToLoc(_c12 * a + _e254));\n    }\n  }\n\n  return u;\n}\n\nfunction Ig(e, t, n) {\n  var s = dn(n, e.dtype);\n\n  for (var _n152 = 0; _n152 < s.size; ++_n152) {\n    var _r90 = s.indexToLoc(_n152).slice(),\n        _a68 = t.locToIndex([_r90[0], _r90[2]]);\n\n    _r90[2] = t.values[_a68];\n\n    var _i37 = e.locToIndex(_r90);\n\n    s.values[_n152] = e.values[_i37];\n  }\n\n  return s;\n}\n\nvar $g = Vf((e, t) => e > t ? 1 : 0),\n    Ng = {\n  kernelName: \"Greater\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Greater\", $g, null, \"bool\")\n},\n    Cg = Vf((e, t) => e >= t ? 1 : 0),\n    Sg = {\n  kernelName: \"GreaterEqual\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"GreaterEqual\", Cg, null, \"bool\")\n},\n    Tg = Vf((e, t) => e < t ? 1 : 0),\n    Eg = {\n  kernelName: \"Less\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Less\", Tg, null, \"bool\")\n},\n    Rg = Vf((e, t) => e <= t ? 1 : 0),\n    Ag = {\n  kernelName: \"LessEqual\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"LessEqual\", Rg, null, \"bool\")\n};\n\nfunction Fg(e, t, n) {\n  var s = (t - e) / (n - 1),\n      r = O(n, \"float32\");\n  r[0] = e;\n\n  for (var _e255 = 1; _e255 < r.length; _e255++) {\n    r[_e255] = r[_e255 - 1] + s;\n  }\n\n  return r;\n}\n\nvar Dg = ig(e => Math.log(e)),\n    _g = {\n  kernelName: \"Log\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Log\", Dg)\n};\n\nfunction Og(e, t, n, s) {\n  var r = w(s, d(n));\n\n  for (var _n153 = 0; _n153 < r.length; ++_n153) {\n    var _s131 = _n153 * t;\n\n    var _a69 = e[_s131];\n\n    for (var _n154 = 0; _n154 < t; ++_n154) {\n      var _t240 = e[_s131 + _n154];\n      (Number.isNaN(_t240) || _t240 > _a69) && (_a69 = _t240);\n    }\n\n    r[_n153] = _a69;\n  }\n\n  return r;\n}\n\nvar Mg = Vf((e, t) => Math.max(e, t)),\n    Lg = {\n  kernelName: \"Maximum\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Maximum\", Mg)\n},\n    zg = Vf((e, t) => Math.min(e, t)),\n    Bg = {\n  kernelName: \"Minimum\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Minimum\", zg)\n},\n    Pg = Vf((e, t) => e * t),\n    Wg = eg((e, t, n, s) => ({\n  real: e * n - t * s,\n  imag: e * s + t * n\n})),\n    Ug = Qf(\"Multiply\", Pg, Wg),\n    Vg = {\n  kernelName: \"Multiply\",\n  backendName: \"cpu\",\n  kernelFunc: Ug\n};\n\nfunction Gg(e, t, n) {\n  var s = We(-1, n);\n  return Pg([], t, s, e, n);\n}\n\nvar Hg = {\n  kernelName: \"Neg\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n    zf(s, \"neg\");\n    var r = n.data.get(s.dataId).values,\n        [a, i] = Gg(r, s.shape, s.dtype);\n    return n.makeTensorInfo(i, s.dtype, a);\n  }\n},\n    jg = Vf((e, t) => e !== t ? 1 : 0),\n    qg = {\n  kernelName: \"NotEqual\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"NotEqual\", jg, null, \"bool\")\n};\n\nfunction Kg(e, t, n, s, r) {\n  var a = t.length,\n      i = d(t),\n      o = A(t),\n      l = A(r),\n      u = w(n, d(r));\n\n  for (var _t241 = 0; _t241 < i; ++_t241) {\n    var _n155 = B(_t241, a, o),\n        _r91 = new Array(_n155.length);\n\n    for (var _e256 = 0; _e256 < _r91.length; _e256++) {\n      _r91[_e256] = _n155[s[_e256]];\n    }\n\n    u[z(_r91, a, l)] = e[_t241];\n  }\n\n  return u;\n}\n\nfunction Xg(e) {\n  var {\n    inputs: t,\n    attrs: n,\n    backend: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    perm: a\n  } = n;\n  zf(r, \"transpose\");\n  var i = new Array(r.shape.length);\n\n  for (var _e257 = 0; _e257 < i.length; _e257++) {\n    i[_e257] = r.shape[a[_e257]];\n  }\n\n  var o = Kg(s.data.get(r.dataId).values, r.shape, r.dtype, a, i);\n  return {\n    dataId: s.write(o, i, r.dtype),\n    shape: i,\n    dtype: r.dtype\n  };\n}\n\nvar Yg = {\n  kernelName: \"Transpose\",\n  backendName: \"cpu\",\n  kernelFunc: Xg\n};\n\nfunction Jg(e, t, n, s) {\n  var [r, a] = Kr(e, s),\n      i = dt(t, \"int32\"),\n      o = O(d(r), i),\n      l = d(a);\n\n  for (var _e258 = 0; _e258 < o.length; ++_e258) {\n    var _t242 = _e258 * l;\n\n    var _s132 = 1;\n\n    for (var _e259 = 0; _e259 < l; ++_e259) {\n      _s132 *= n[_t242 + _e259];\n    }\n\n    o[_e258] = _s132;\n  }\n\n  return {\n    outVals: o,\n    outShape: r,\n    outDtype: i\n  };\n}\n\nvar Zg = {\n  kernelName: \"Prod\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    zf(r, \"prod\");\n    var o = r.shape.length,\n        l = y(a, r.shape),\n        u = Jr(l, o);\n    var c = l,\n        h = r;\n    var d = [];\n    null != u && (h = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), d.push(h), c = Qr(c.length, o));\n    var p = n.data.get(h.dataId).values,\n        {\n      outVals: f,\n      outShape: g,\n      outDtype: m\n    } = Jg(h.shape, h.dtype, p, c);\n    var b = g;\n    return i && (b = Xr(g, l)), d.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(b, m, f);\n  }\n};\n\nfunction Qg(e, t, n, s) {\n  if (e === t || e < t && n < 0 || t < e && n > 1) return O(0, s);\n  var r = O(Math.abs(Math.ceil((t - e) / n)), s);\n  t < e && 1 === n && (n = -1), r[0] = e;\n\n  for (var _e260 = 1; _e260 < r.length; _e260++) {\n    r[_e260] = r[_e260 - 1] + n;\n  }\n\n  return r;\n}\n\nvar em = ig(e => 1 / Math.sqrt(e)),\n    tm = {\n  kernelName: \"Rsqrt\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Rsqrt\", em)\n};\n\nfunction nm(e, t, n, s, r) {\n  var a = Pn(s, t, n),\n      i = d(n),\n      o = A(s);\n\n  if (a) {\n    var _n156 = Wn(t, o);\n\n    return \"string\" === r ? e.slice(_n156, _n156 + i) : e.subarray(_n156, _n156 + i);\n  }\n\n  var l = dn(s, r, \"string\" === r ? tl(e) : e),\n      u = dn(n, r);\n\n  for (var _e261 = 0; _e261 < u.size; ++_e261) {\n    var _n157 = u.indexToLoc(_e261),\n        _s133 = _n157.map((e, n) => e + t[n]);\n\n    u.set(l.get(..._s133), ..._n157);\n  }\n\n  return \"string\" === r ? nl(u.values) : u.values;\n}\n\nfunction sm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    begin: a,\n    size: i\n  } = s;\n  zf(r, \"slice\");\n  var [o, l] = Un(r, a, i);\n  Tn(r, o, l);\n  var u = nm(n.data.get(r.dataId).values, o, l, r.shape, r.dtype);\n  return n.makeTensorInfo(l, r.dtype, u);\n}\n\nvar rm = {\n  kernelName: \"Slice\",\n  backendName: \"cpu\",\n  kernelFunc: sm\n};\n\nfunction am(e, t, n, s, r, a, i) {\n  var o = t[0],\n      l = a[0],\n      u = new Array(l),\n      c = new Array(o),\n      h = t[1];\n\n  if (0 === l) {\n    if (0 !== o) throw new Error(\"Received SparseTensor with denseShape[0] = 0 but\\n         indices.shape[0] = \".concat(o));\n    return [v(n, 0), [0, h], v(r, 0), u, c];\n  }\n\n  var d = !0,\n      p = 0;\n  var f = new Array(l).fill(0);\n\n  for (var _t243 = 0; _t243 < o; ++_t243) {\n    var _n158 = e[_t243 * h];\n    if (_n158 < 0) throw new Error(\"indices(\".concat(_t243, \", 0) is invalid: \").concat(_n158, \" < 0\"));\n    if (_n158 >= l) throw new Error(\"indices(\".concat(_t243, \", 0) is invalid: \").concat(_n158, \" >= \").concat(l));\n    ++f[_n158], d = d && _n158 >= p, p = _n158;\n  }\n\n  var g = !0;\n\n  for (var _e262 = 0; _e262 < l; ++_e262) {\n    var _t244 = 0 === f[_e262];\n\n    u[_e262] = _t244, g = g && !_t244, f[_e262] = Math.max(f[_e262], 1), _e262 > 0 && (f[_e262] += f[_e262 - 1]);\n  }\n\n  if (g && d) {\n    var _t245 = e,\n        _n159 = s;\n\n    for (var _e263 = 0; _e263 < o; ++_e263) {\n      c[_e263] = _e263;\n    }\n\n    return [_t245, [o, h], _n159, u, c];\n  }\n\n  {\n    var _t246 = f[l - 1],\n        _a70 = v(n, _t246 * h),\n        _d9 = v(r, _t246),\n        _p8 = new Array(l).fill(0);\n\n    for (var _t247 = 0; _t247 < o; ++_t247) {\n      var _n160 = e[_t247 * h],\n          _r92 = (0 === _n160 ? 0 : f[_n160 - 1]) + _p8[_n160];\n\n      _p8[_n160]++;\n\n      for (var _n161 = 0; _n161 < h; ++_n161) {\n        _a70[_r92 * h + _n161] = e[_t247 * h + _n161];\n      }\n\n      _d9[_r92] = s[_t247], c[_t247] = _r92;\n    }\n\n    for (var _e264 = 0; _e264 < l; ++_e264) {\n      if (0 === _p8[_e264]) {\n        var _t248 = 0 === _e264 ? 0 : f[_e264 - 1];\n\n        _a70[_t248 * h + 0] = _e264;\n\n        for (var _e265 = 1; _e265 < h; ++_e265) {\n          _a70[_t248 * h + _e265] = 0;\n        }\n\n        _d9[_t248] = i;\n      }\n    }\n\n    return [_a70, [_t246, h], _d9, u, c];\n  }\n}\n\nfunction im(e, t, n, s, r) {\n  var a = d(s),\n      i = t[0],\n      o = r.length,\n      l = [];\n  var u = 1,\n      c = -1;\n\n  for (var _e266 = 0; _e266 < o; ++_e266) {\n    var _t249 = r[_e266];\n\n    if (-1 === _t249) {\n      if (-1 !== c) throw new Error(\"only one output dimension may be -1, not both \".concat(c, \" and \").concat(_e266));\n      c = _e266, l.push(1);\n    } else {\n      if (_t249 < 0) throw new Error(\"size \".concat(_e266, \" must be non-negative, not \").concat(_t249));\n      u *= _t249, l.push(_t249);\n    }\n  }\n\n  if (-1 !== c) {\n    if (u <= 0) throw new Error(\"reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\");\n\n    var _e267 = Math.trunc(a / u);\n\n    if (u * _e267 !== a) throw new Error(\"Input to reshape is a SparseTensor with \".concat(a, \"\\n          dense values, but the requested shape requires a multiple of \").concat(u, \". inputShape=\").concat(s, \" outputShape= \").concat(l));\n    l[c] = _e267;\n  }\n\n  var h = d(l);\n  if (h !== a) throw new Error(\"Input to reshape is a tensor with \".concat(a, \" dense values, but the requested shape has \").concat(h, \". inputShape=\").concat(s, \" outputShape=\").concat(l));\n  var p = s.length,\n      f = [];\n\n  if (p > 0) {\n    f[p - 1] = 1;\n\n    for (var _e268 = p - 2; _e268 >= 0; --_e268) {\n      f[_e268] = f[_e268 + 1] * s[_e268 + 1];\n    }\n  }\n\n  var g = [];\n\n  if (o > 0) {\n    g[o - 1] = 1;\n\n    for (var _e269 = o - 2; _e269 >= 0; --_e269) {\n      g[_e269] = g[_e269 + 1] * l[_e269 + 1];\n    }\n  }\n\n  var m = v(n, i * o);\n\n  for (var _t250 = 0; _t250 < i; ++_t250) {\n    var _n162 = 0;\n\n    for (var _s134 = 0; _s134 < p; ++_s134) {\n      _n162 += e[_t250 * p + _s134] * f[_s134];\n    }\n\n    for (var _e270 = 0; _e270 < o; ++_e270) {\n      m[_t250 * o + _e270] = Math.trunc(_n162 / g[_e270]), _n162 %= g[_e270];\n    }\n  }\n\n  return [m, [i, o], l];\n}\n\nfunction om(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;\n  var o = s.length;\n  if (o !== r.length) throw new Error(\"segmentIds and indices should have same size.\");\n  var l = [t[0], e.length / t[0]],\n      u = l[1],\n      c = o > 0 ? r[o - 1] + 1 : 0;\n  if (c < 0) throw new Error(\"segment ids must be >= 0\");\n  var h = t.slice();\n  h[0] = c;\n  var d = v(n, h.reduce((e, t) => e * t, 1));\n  if (0 === o) return c > 0 && d.fill(i), [d, h];\n  if (c <= 0) throw new Error(\"segment ids must be >= 0\");\n  var p = 0,\n      f = 1,\n      g = 0,\n      m = r[p];\n\n  for (;;) {\n    var _t251 = 0;\n\n    if (f < o) {\n      if (_t251 = r[f], m === _t251) {\n        ++f;\n        continue;\n      }\n\n      if (m >= _t251) throw new Error(\"segment ids are not increasing\");\n    }\n\n    if (m < 0 || m >= c) throw new Error(\"Segment id \".concat(m, \" out of range [0, \").concat(c, \"), possibly because segmentIds input is not sorted.\"));\n    m > g && d.fill(i, g * u, m * u);\n\n    for (var _t252 = p; _t252 < f; ++_t252) {\n      var _n163 = s[_t252];\n      if (_n163 < 0 || _n163 >= l[0]) throw new Error(\"Bad: indices[\".concat(_t252, \"] == \").concat(s[_t252], \" out of range [0, \").concat(l[0], \")\"));\n\n      for (var _t253 = 0; _t253 < u; _t253++) {\n        d[m * u + _t253] += e[_n163 * u + _t253];\n      }\n    }\n\n    if (a) for (var _e271 = 0; _e271 < u; _e271++) {\n      d[m * u + _e271] /= f - p;\n    }\n    if (p = f, ++f, g = m + 1, m = _t251, f > o) break;\n  }\n\n  return g < c && d.fill(i, g * u, c * u), [d, h];\n}\n\nvar lm = Vf((e, t) => {\n  var n = e - t;\n  return n * n;\n}),\n    um = {\n  kernelName: \"SquaredDifference\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"SquaredDifference\", lm)\n};\n\nfunction cm(e, t, n, s) {\n  var r = dn(e, t.dtype);\n\n  for (var _e272 = 0; _e272 < r.size; _e272++) {\n    var _a71 = r.indexToLoc(_e272),\n        _i38 = new Array(_a71.length);\n\n    for (var _e273 = 0; _e273 < _i38.length; _e273++) {\n      _i38[_e273] = _a71[_e273] * n[_e273] + s[_e273];\n    }\n\n    r.set(t.get(..._i38), ..._a71);\n  }\n\n  return r;\n}\n\nclass hm {\n  constructor(e, t, n, s, r, a) {\n    this.separator = Ge(e), this.nGramWidths = t, this.leftPad = Ge(n), this.rightPad = Ge(s), this.padWidth = r, this.preserveShort = a;\n  }\n\n  getPadWidth(e) {\n    return Math.min(this.padWidth < 0 ? e - 1 : this.padWidth, e - 1);\n  }\n\n  getNumNGrams(e, t) {\n    var n = this.getPadWidth(t);\n    return Math.max(0, e + 2 * n - t + 1);\n  }\n\n  createNGrams(e, t, n, s, r, a) {\n    var _this70 = this;\n\n    var _loop27 = function _loop27(_i39) {\n      var o = _this70.getPadWidth(a),\n          l = Math.max(0, o - _i39),\n          u = Math.max(0, o - (r - (_i39 + 1))),\n          c = a - (l + u),\n          h = t + (l > 0 ? 0 : _i39 - o);\n\n      var d = 0;\n      d += l * _this70.leftPad.length;\n\n      for (var _t254 = 0; _t254 < c; ++_t254) {\n        d += e[h + _t254].length;\n      }\n\n      d += u * _this70.rightPad.length, d += (l + u + c - 1) * _this70.separator.length, n[s + _i39] = new Uint8Array(d);\n      var p = n[s + _i39];\n      var f = 0;\n\n      var g = e => e.forEach(e => p[f++] = e);\n\n      for (var _e274 = 0; _e274 < l; ++_e274) {\n        g(_this70.leftPad), g(_this70.separator);\n      }\n\n      for (var _t255 = 0; _t255 < c - 1; ++_t255) {\n        g(e[h + _t255]), g(_this70.separator);\n      }\n\n      if (c > 0) {\n        g(e[h + c - 1]);\n\n        for (var _e275 = 0; _e275 < u; ++_e275) {\n          g(_this70.separator), g(_this70.rightPad);\n        }\n      } else {\n        for (var _e276 = 0; _e276 < u - 1; ++_e276) {\n          g(_this70.rightPad), g(_this70.separator);\n        }\n\n        g(_this70.rightPad);\n      }\n    };\n\n    for (var _i39 = 0; _i39 < r; ++_i39) {\n      _loop27(_i39);\n    }\n  }\n\n  compute(e, t) {\n    var _this71 = this;\n\n    var n = e.length,\n        s = t.length;\n\n    if (s > 0) {\n      var _e277 = t[0];\n      if (0 !== _e277) throw new Error(\"First split value must be 0, got \".concat(_e277));\n\n      for (var _r93 = 1; _r93 < s; ++_r93) {\n        var _s135 = t[_r93] >= _e277;\n\n        if (_s135 = _s135 && t[_r93] <= n, !_s135) throw new Error(\"Invalid split value \".concat(t[_r93], \", must be in [\").concat(_e277, \", \").concat(n, \"]\"));\n        _e277 = t[_r93];\n      }\n\n      if (_e277 !== n) throw new Error(\"Last split value must be data size. Expected \".concat(n, \", got \").concat(_e277));\n    }\n\n    var r = s - 1,\n        a = v(\"int32\", s);\n\n    if (0 === n || 0 === s) {\n      var _e278 = new Array(n);\n\n      for (var _e279 = 0; _e279 <= r; ++_e279) {\n        a[_e279] = 0;\n      }\n\n      return [_e278, a];\n    }\n\n    a[0] = 0;\n\n    var _loop28 = function _loop28(_e280) {\n      var n = t[_e280] - t[_e280 - 1];\n      var s = 0;\n      _this71.nGramWidths.forEach(e => {\n        s += _this71.getNumNGrams(n, e);\n      }), _this71.preserveShort && n > 0 && 0 === s && (s = 1), a[_e280] = a[_e280 - 1] + s;\n    };\n\n    for (var _e280 = 1; _e280 <= r; ++_e280) {\n      _loop28(_e280);\n    }\n\n    var i = new Array(a[r]);\n\n    var _loop29 = function _loop29(_n164) {\n      var s = t[_n164];\n      var r = a[_n164];\n\n      if (_this71.nGramWidths.forEach(a => {\n        var o = _this71.getNumNGrams(t[_n164 + 1] - t[_n164], a);\n\n        _this71.createNGrams(e, s, i, r, o, a), r += o;\n      }), _this71.preserveShort && r === a[_n164]) {\n        var _a72 = t[_n164 + 1] - t[_n164];\n\n        if (0 === _a72) return \"continue\";\n\n        _this71.createNGrams(e, s, i, r, 1, _a72 + 2 * _this71.padWidth);\n      }\n    };\n\n    for (var _n164 = 0; _n164 < r; ++_n164) {\n      var _ret4 = _loop29(_n164);\n\n      if (_ret4 === \"continue\") continue;\n    }\n\n    return [i, a];\n  }\n\n}\n\nfunction dm(e, t, n, s, r, a, i, o) {\n  return new hm(n, s, r, a, i, o).compute(e, t);\n}\n\nfunction pm(e, t, n) {\n  if (!e.length) return [];\n\n  if (0 === t.length) {\n    var _t256 = new Array(e.length);\n\n    for (var _n165 = 0; _n165 < e.length; ++_n165) {\n      _t256[_n165] = e.subarray(_n165, _n165 + 1);\n    }\n\n    return _t256;\n  }\n\n  if (1 === t.length) {\n    var _s136 = t[0],\n        _r94 = [];\n\n    var _a73 = e.indexOf(_s136);\n\n    for (; -1 !== _a73;) {\n      var _t257 = e.subarray(0, _a73);\n\n      n && 0 === _t257.length || _r94.push(_t257), _a73 = (e = e.subarray(_a73 + 1)).indexOf(_s136);\n    }\n\n    return n && 0 === e.length || _r94.push(e), _r94;\n  }\n\n  var s = [];\n  var r = 0;\n\n  for (var _a74 = 0; _a74 < e.length + 1; _a74++) {\n    if (_a74 === e.length || -1 !== t.indexOf(e[_a74])) {\n      var _t258 = e.subarray(r, _a74);\n\n      n && 0 === _t258.length || s.push(_t258), r = _a74 + 1;\n    }\n  }\n\n  return s;\n}\n\nfunction fm(e, t, n) {\n  var s = e.length,\n      r = [];\n  var a = 0,\n      i = 0;\n  var o = new Array(s);\n\n  for (var _l21 = 0; _l21 < s; ++_l21) {\n    var _s137 = pm(e[_l21], t, n),\n        _u13 = _s137.length;\n\n    o[_l21] = _u13, a += _u13, i = Math.max(i, _u13), r.push(..._s137);\n  }\n\n  var l = v(\"int32\", 2 * a),\n      u = new Array(a),\n      c = [s, i];\n  var h = 0;\n\n  for (var _e281 = 0; _e281 < s; ++_e281) {\n    for (var _t259 = 0; _t259 < o[_e281]; ++_t259) {\n      l[2 * h] = _e281, l[2 * h + 1] = _t259, u[h] = r[h], ++h;\n    }\n  }\n\n  return [l, u, c];\n}\n\nfunction gm(e, t) {\n  var n = v(\"int32\", e.length);\n\n  for (var _s138 = 0; _s138 < e.length; ++_s138) {\n    n[_s138] = Pe(e[_s138]).modulo(t).getLowBitsUnsigned();\n  }\n\n  return n;\n}\n\nvar mm = Vf((e, t) => e - t),\n    bm = Qf(\"Sub\", mm, eg((e, t, n, s) => ({\n  real: e - n,\n  imag: t - s\n}))),\n    xm = {\n  kernelName: \"Sub\",\n  backendName: \"cpu\",\n  kernelFunc: bm\n};\n\nfunction ym(e, t) {\n  var n = new Array(e.rank);\n\n  for (var _s139 = 0; _s139 < n.length; _s139++) {\n    n[_s139] = e.shape[_s139] * t[_s139];\n  }\n\n  var s = dn(n, e.dtype);\n\n  for (var _t260 = 0; _t260 < s.values.length; ++_t260) {\n    var _n166 = s.indexToLoc(_t260),\n        _r95 = new Array(e.rank);\n\n    for (var _t261 = 0; _t261 < _r95.length; _t261++) {\n      _r95[_t261] = _n166[_t261] % e.shape[_t261];\n    }\n\n    var _a75 = e.locToIndex(_r95);\n\n    s.values[_t260] = e.values[_a75];\n  }\n\n  return s;\n}\n\nvar km = (e, t) => {\n  var n = t.value - e.value;\n  return 0 === n ? e.index - t.index : n;\n};\n\nfunction wm(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : e.length - 1;\n\n  for (; s > n;) {\n    if (s - n > 600) {\n      var _r97 = s - n + 1,\n          _a77 = t - n + 1,\n          _i41 = Math.log(_r97),\n          _o32 = .5 * Math.exp(2 * _i41 / 3),\n          _l22 = .5 * Math.sqrt(_i41 * _o32 * (_r97 - _o32) / _r97) * Math.sign(_a77 - _r97 / 2);\n\n      wm(e, t, Math.max(n, Math.floor(t - _a77 * _o32 / _r97 + _l22)), Math.min(s, Math.floor(t + (_r97 - _a77) * _o32 / _r97 + _l22)));\n    }\n\n    var _r96 = e[t];\n    var _a76 = n,\n        _i40 = s;\n\n    for (o(e, n, t), km(e[s], _r96) > 0 && o(e, n, s); _a76 < _i40;) {\n      for (o(e, _a76, _i40), _a76++, _i40--; km(e[_a76], _r96) < 0;) {\n        _a76 += 1;\n      }\n\n      for (; km(e[_i40], _r96) > 0;) {\n        _i40 -= 1;\n      }\n    }\n\n    0 === km(e[n], _r96) ? o(e, n, _i40) : (_i40 += 1, o(e, _i40, s)), _i40 <= t && (n = _i40 + 1), t <= _i40 && (s = _i40 - 1);\n  }\n}\n\nfunction vm(e, t, n, s, r) {\n  var a = t[t.length - 1],\n      [i, o] = [e.length / a, a],\n      l = w(n, i * s),\n      u = w(\"int32\", i * s);\n\n  var _loop30 = function _loop30(_t262) {\n    var n = _t262 * o,\n        a = e.subarray(n, n + o);\n    var i = new Array(a.length);\n    a.forEach((e, t) => i[t] = {\n      value: e,\n      index: t\n    }), s < i.length && (wm(i, s), i = i.slice(0, s)), r && i.sort(km);\n    var c = _t262 * s,\n        h = l.subarray(c, c + s),\n        d = u.subarray(c, c + s);\n\n    for (var _e282 = 0; _e282 < s; _e282++) {\n      h[_e282] = i[_e282].value, d[_e282] = i[_e282].index;\n    }\n  };\n\n  for (var _t262 = 0; _t262 < i; _t262++) {\n    _loop30(_t262);\n  }\n\n  var c = t.slice();\n  return c[c.length - 1] = s, [dn(c, n, l), dn(c, \"int32\", u)];\n}\n\nfunction Im(e, t, n, s) {\n  var r = y(t, n)[0],\n      a = [1, n[0], 1];\n\n  for (var _e283 = 0; _e283 < r; _e283++) {\n    a[0] *= n[_e283];\n  }\n\n  a[1] = n[r];\n\n  for (var _e284 = r + 1; _e284 < n.length; _e284++) {\n    a[2] *= n[_e284];\n  }\n\n  var i = {},\n      o = new Int32Array(n[r]),\n      l = new et(a, s, e),\n      u = [],\n      c = 1 === a[0] && 1 === a[2];\n\n  for (var _t263 = 0; _t263 < n[r]; _t263++) {\n    var _n167 = void 0;\n\n    if (c) _n167 = e[_t263].toString();else {\n      var _e285 = [];\n\n      for (var _n168 = 0; _n168 < a[0]; _n168++) {\n        for (var _s140 = 0; _s140 < a[2]; _s140++) {\n          _e285.push(l.get(_n168, _t263, _s140));\n        }\n      }\n\n      _n167 = _e285.join(\",\");\n    }\n    if (void 0 !== i[_n167]) o[_t263] = i[_n167];else {\n      var _e286 = Object.keys(i).length;\n      i[_n167] = _e286, o[_t263] = _e286, u.push(_t263);\n    }\n  }\n\n  var h = a.slice();\n  h[1] = Object.keys(i).length;\n  var d = new et(h, s);\n  u.forEach((e, t) => {\n    for (var _n169 = 0; _n169 < a[0]; _n169++) {\n      for (var _s141 = 0; _s141 < a[2]; _s141++) {\n        d.set(l.get(_n169, e, _s141), _n169, t, _s141);\n      }\n    }\n  });\n  var p = n.slice();\n  return p[r] = h[1], {\n    outputValues: d.values,\n    outputShape: p,\n    indices: o\n  };\n}\n\nvar $m = {\n  __proto__: null,\n  simpleAbsImpl: Wf,\n  addImpl: tg,\n  bincountImpl: rg,\n  bincountReduceImpl: ag,\n  ceilImpl: ug,\n  concatImpl: hg,\n  equalImpl: dg,\n  expImpl: gg,\n  expm1Impl: xg,\n  floorImpl: kg,\n  gatherNdImpl: vg,\n  gatherV2Impl: Ig,\n  greaterImpl: $g,\n  greaterEqualImpl: Cg,\n  lessImpl: Tg,\n  lessEqualImpl: Rg,\n  linSpaceImpl: Fg,\n  logImpl: Dg,\n  maxImpl: Og,\n  maximumImpl: Mg,\n  minimumImpl: zg,\n  multiplyImpl: Pg,\n  negImpl: Gg,\n  notEqualImpl: jg,\n  prodImpl: Jg,\n  rangeImpl: Qg,\n  rsqrtImpl: em,\n  sliceImpl: nm,\n  sparseFillEmptyRowsImpl: am,\n  sparseReshapeImpl: im,\n  sparseSegmentReductionImpl: om,\n  squaredDifferenceImpl: lm,\n  stridedSliceImpl: cm,\n  stringNGramsImpl: dm,\n  stringSplitImpl: fm,\n  stringToHashBucketFastImpl: gm,\n  subImpl: mm,\n  tileImpl: ym,\n  topKImpl: vm,\n  transposeImpl: Kg,\n  uniqueImpl: Im\n};\nQn(\"cpu\", () => new Pf(), 1);\nvar Nm = og(\"Elu\", e => e >= 0 ? e : Math.exp(e) - 1),\n    Cm = {\n  kernelName: \"Elu\",\n  backendName: \"cpu\",\n  kernelFunc: Nm\n};\n\nfunction Sm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    alpha: a\n  } = s;\n  zf([r], \"leakyRelu\");\n  var i = d(r.shape),\n      o = n.data.get(r.dataId).values,\n      l = w(\"float32\", i);\n\n  for (var _e287 = 0; _e287 < o.length; _e287++) {\n    l[_e287] = o[_e287] < 0 ? a * o[_e287] : o[_e287];\n  }\n\n  return n.makeTensorInfo(r.shape, \"float32\", l);\n}\n\nvar Tm = {\n  kernelName: \"LeakyRelu\",\n  backendName: \"cpu\",\n  kernelFunc: Sm\n},\n    Em = Vf((e, t) => e < 0 ? t * e : e);\n\nfunction Rm(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s,\n    alpha: r\n  } = t;\n  zf([s, r], \"prelu\");\n  var a = n.data.get(s.dataId).values,\n      i = n.data.get(r.dataId).values,\n      [o, l] = Em(s.shape, r.shape, a, i, s.dtype);\n  return n.makeTensorInfo(l, s.dtype, o);\n}\n\nvar Am = {\n  kernelName: \"Prelu\",\n  backendName: \"cpu\",\n  kernelFunc: Rm\n},\n    Fm = og(\"Relu\", e => Math.max(0, e)),\n    Dm = {\n  kernelName: \"Relu\",\n  backendName: \"cpu\",\n  kernelFunc: Fm\n},\n    _m = og(\"Relu6\", e => Math.min(Math.max(0, e), 6)),\n    Om = {\n  kernelName: \"Relu6\",\n  backendName: \"cpu\",\n  kernelFunc: _m\n},\n    Mm = og(\"Sigmoid\", e => 1 / (1 + Math.exp(-e))),\n    Lm = {\n  kernelName: \"Sigmoid\",\n  backendName: \"cpu\",\n  kernelFunc: Mm\n};\n\nfunction zm(e, t, n, s, r) {\n  if (\"linear\" === n) return qf({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"relu\" === n) return Fm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"elu\" === n) return Nm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"relu6\" === n) return _m({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"prelu\" === n) return Rm({\n    inputs: {\n      x: t,\n      alpha: s\n    },\n    backend: e\n  });\n  if (\"leakyrelu\" === n) return Sm({\n    inputs: {\n      x: t\n    },\n    backend: e,\n    attrs: {\n      alpha: r\n    }\n  });\n  if (\"sigmoid\" === n) return Mm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  throw new Error(\"Activation \".concat(n, \" has not been implemented for the CPU backend.\"));\n}\n\nfunction Bm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    shape: a\n  } = s,\n      i = d(r.shape),\n      o = x(a, i),\n      u = d(o);\n  l(i === u, () => \"The new shape (\".concat(o, \") has \").concat(u, \" elements and the old shape (\").concat(r.shape, \") has \").concat(i, \" elements. The new shape and old shape must have the same number of elements.\")), n.incRef(r.dataId);\n  var c = n.data.get(r.dataId);\n\n  if (null != c.complexTensorInfos) {\n    var _e288 = c.complexTensorInfos.imag;\n    c.complexTensorInfos.real.shape = o, _e288.shape = o;\n  }\n\n  return {\n    dataId: r.dataId,\n    shape: o,\n    dtype: r.dtype\n  };\n}\n\nvar Pm = {\n  kernelName: \"Reshape\",\n  backendName: \"cpu\",\n  kernelFunc: Bm\n};\n\nfunction Wm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    a: r,\n    b: a\n  } = t,\n      {\n    transposeA: i,\n    transposeB: o\n  } = s;\n  zf([r, a], \"matMul\");\n  var u = r.shape.length,\n      c = a.shape.length,\n      h = i ? r.shape[u - 2] : r.shape[u - 1],\n      p = o ? a.shape[c - 1] : a.shape[c - 2],\n      f = i ? r.shape[u - 1] : r.shape[u - 2],\n      g = o ? a.shape[c - 2] : a.shape[c - 1],\n      m = r.shape.slice(0, -2),\n      b = a.shape.slice(0, -2),\n      x = d(m),\n      y = d(b);\n  l(u >= 2 && c >= 2 && (x === y || 1 === x || 1 === y), () => \"Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (\".concat(m, \") and (\").concat(b, \").\"));\n  var k = (x > y ? r.shape.slice(0, -2) : a.shape.slice(0, -2)).concat([f, g]);\n  l(h === p, () => \"Error in matMul: inner shapes (\".concat(h, \") and (\").concat(p, \") of Tensors with shapes \").concat(r.shape, \" and \").concat(a.shape, \" and transposeA=\").concat(i, \" and transposeB=\").concat(o, \" must match.\"));\n  var w = o ? [y, g, p] : [y, p, g],\n      v = Bm({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: i ? [x, h, f] : [x, f, h]\n    }\n  }),\n      I = Bm({\n    inputs: {\n      x: a\n    },\n    backend: n,\n    attrs: {\n      shape: w\n    }\n  }),\n      $ = i ? v.shape[1] : v.shape[2],\n      N = i ? v.shape[2] : v.shape[1],\n      C = o ? I.shape[1] : I.shape[2],\n      S = Math.max(x, y),\n      T = n.data.get(v.dataId).values,\n      E = n.data.get(I.dataId).values,\n      R = A(v.shape),\n      F = A(I.shape),\n      [D, _, O] = i ? [R[0], 1, R[1]] : [R[0], R[1], 1],\n      [M, L, z] = o ? [1, F[1], F[0]] : [F[1], 1, F[0]],\n      B = N * C,\n      P = dn([S, N, C], v.dtype),\n      W = P.values,\n      U = n.blockSize;\n\n  for (var _e289 = 0; _e289 < S; _e289++) {\n    for (var _t264 = 0; _t264 < N; _t264 += U) {\n      for (var _n170 = 0; _n170 < C; _n170 += U) {\n        for (var _s142 = 0; _s142 < $; _s142 += U) {\n          var _r98 = Math.min(_t264 + U, N),\n              _a78 = Math.min(_n170 + U, C),\n              _i42 = Math.min(_s142 + U, $);\n\n          for (var _o33 = _t264; _o33 < _r98; _o33++) {\n            for (var _t265 = _n170; _t265 < _a78; _t265++) {\n              var _n171 = 0;\n\n              for (var _r99 = _s142; _r99 < _i42; _r99++) {\n                var _s143 = Math.min(_e289, x - 1) * D,\n                    _a79 = Math.min(_e289, y - 1) * z;\n\n                _n171 += T[_s143 + _o33 * _ + _r99 * O] * E[_r99 * M + _t265 * L + _a79];\n              }\n\n              W[_e289 * B + (_o33 * C + _t265)] += _n171;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.disposeIntermediateTensorInfo(v), n.disposeIntermediateTensorInfo(I), n.makeTensorInfo(k, P.dtype, P.values);\n}\n\nvar Um = {\n  kernelName: \"BatchMatMul\",\n  backendName: \"cpu\",\n  kernelFunc: Wm\n},\n    Vm = {\n  kernelName: \"_FusedMatMul\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      transposeA: l,\n      transposeB: u,\n      activation: c,\n      leakyreluAlpha: h\n    } = s;\n    var d, p, f;\n    var g = [];\n    d = Wm({\n      inputs: {\n        a: r,\n        b: a\n      },\n      attrs: {\n        transposeA: l,\n        transposeB: u\n      },\n      backend: n\n    }), i && (p = ng({\n      inputs: {\n        a: d,\n        b: i\n      },\n      backend: n\n    }), g.push(d), d = p), c && (f = zm(n, d, c, o, h), g.push(d), d = f);\n\n    for (var _e290 of g) {\n      n.disposeIntermediateTensorInfo(_e290);\n    }\n\n    return d;\n  }\n},\n    Gm = {\n  kernelName: \"Acos\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Acos\", e => Math.acos(e))\n},\n    Hm = {\n  kernelName: \"Acosh\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Acosh\", e => Math.acosh(e))\n},\n    jm = {\n  kernelName: \"AddN\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        s = t;\n    zf(t, \"addN\");\n    var r = s.map(e => n.data.get(e.dataId).values),\n        a = dn(s[0].shape, s[0].dtype),\n        i = a.values;\n\n    for (var _e291 = 0; _e291 < s.length; _e291++) {\n      var _t266 = r[_e291];\n\n      for (var _e292 = 0; _e292 < i.length; _e292++) {\n        i[_e292] += _t266[_e292];\n      }\n    }\n\n    return n.makeTensorInfo(a.shape, a.dtype, a.values);\n  }\n},\n    qm = {\n  kernelName: \"All\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    zf(r, \"all\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Jr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = Qr(l.length, r.shape.length)), Yr(\"all\", l, c.shape.length);\n    var [h, p] = Kr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e293 = 0; _e293 < g.length; ++_e293) {\n      var _t267 = _e293 * f;\n\n      var _n172 = m[_t267];\n\n      for (var _e294 = 0; _e294 < f; ++_e294) {\n        var _s144 = m[_t267 + _e294];\n        _n172 = _n172 && _s144;\n      }\n\n      g[_e293] = _n172;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e295 = Bm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Xr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e295;\n    }\n\n    return b;\n  }\n},\n    Km = {\n  kernelName: \"Any\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    zf(r, \"any\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Jr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = Qr(l.length, r.shape.length)), Yr(\"any\", l, c.shape.length);\n    var [h, p] = Kr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e296 = 0; _e296 < g.length; ++_e296) {\n      var _t268 = _e296 * f;\n\n      var _n173 = m[_t268];\n\n      for (var _e297 = 0; _e297 < f; ++_e297) {\n        var _s145 = m[_t268 + _e297];\n        _n173 = _n173 || _s145;\n      }\n\n      g[_e296] = _n173;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e298 = Bm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Xr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e298;\n    }\n\n    return b;\n  }\n},\n    Xm = {\n  kernelName: \"ArgMax\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    zf(r, \"argMax\");\n    var i = y(a, r.shape);\n    var o = Jr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = Qr(i.length, l.shape.length)), i = [i[0]], Yr(\"argMax\", i, l.shape.length);\n    var [c, h] = Kr(l.shape, i),\n        p = O(d(c), \"int32\"),\n        f = d(h),\n        g = n.data.get(l.dataId).values;\n\n    for (var _e299 = 0; _e299 < p.length; ++_e299) {\n      var _t269 = _e299 * f;\n\n      var _n174 = g[_t269],\n          _s146 = 0;\n\n      for (var _e300 = 0; _e300 < f; ++_e300) {\n        var _r100 = g[_t269 + _e300];\n        _r100 > _n174 && (_n174 = _r100, _s146 = _e300);\n      }\n\n      p[_e299] = _s146;\n    }\n\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, \"int32\", p);\n  }\n},\n    Ym = {\n  kernelName: \"ArgMin\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    zf(r, \"argMin\");\n    var i = y(a, r.shape);\n    var o = Jr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = Qr(i.length, l.shape.length)), i = [i[0]], Yr(\"argMin\", i, l.shape.length);\n    var [c, h] = Kr(l.shape, i),\n        p = O(d(c), \"int32\"),\n        f = d(h),\n        g = n.data.get(l.dataId).values;\n\n    for (var _e301 = 0; _e301 < p.length; ++_e301) {\n      var _t270 = _e301 * f;\n\n      var _n175 = g[_t270],\n          _s147 = 0;\n\n      for (var _e302 = 0; _e302 < f; ++_e302) {\n        var _r101 = g[_t270 + _e302];\n        _r101 < _n175 && (_n175 = _r101, _s147 = _e302);\n      }\n\n      p[_e301] = _s147;\n    }\n\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, \"int32\", p);\n  }\n},\n    Jm = {\n  kernelName: \"Asin\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Asin\", e => Math.asin(e))\n},\n    Zm = {\n  kernelName: \"Asinh\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Asinh\", e => Math.asinh(e))\n},\n    Qm = {\n  kernelName: \"Atan\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Atan\", e => Math.atan(e))\n},\n    eb = {\n  kernelName: \"Atan2\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Atan2\", Vf((e, t) => Math.atan2(e, t)))\n},\n    tb = {\n  kernelName: \"Atanh\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Atanh\", e => Math.atanh(e))\n};\n\nfunction nb(e, t, n, s, r, a) {\n  var i = r.strideHeight,\n      o = r.strideWidth,\n      l = r.dilationHeight,\n      u = r.dilationWidth,\n      c = r.effectiveFilterHeight,\n      h = r.effectiveFilterWidth,\n      d = r.padInfo.top,\n      p = r.padInfo.left,\n      f = \"max\" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n      g = dn(r.outShape, n),\n      m = g.values,\n      b = r.outShape[1] * r.outShape[2] * r.outShape[3],\n      x = r.outShape[2] * r.outShape[3],\n      y = r.outShape[3];\n\n  for (var _t271 = 0; _t271 < r.batchSize; ++_t271) {\n    var _n176 = _t271 * b,\n        _g9 = _t271 * s[0];\n\n    for (var _t272 = 0; _t272 < r.inChannels; ++_t272) {\n      for (var _b7 = 0; _b7 < r.outHeight; ++_b7) {\n        var _k4 = _b7 * i - d,\n            _w3 = Math.max(0, _k4),\n            _v3 = Math.min(r.inHeight, c + _k4),\n            _I2 = _n176 + _b7 * x;\n\n        for (var _n177 = 0; _n177 < r.outWidth; ++_n177) {\n          var _i43 = _n177 * o - p,\n              _c13 = Math.max(0, _i43),\n              _d10 = Math.min(r.inWidth, h + _i43);\n\n          var _b8 = f,\n              _x51 = 0,\n              _k5 = 0;\n\n          for (var _n178 = _w3; _n178 < _v3; _n178 += l) {\n            var _r102 = _g9 + _n178 * s[1];\n\n            for (var _n179 = _c13; _n179 < _d10; _n179 += u) {\n              var _i44 = e[_r102 + _n179 * s[2] + _t272];\n              \"max\" === a && _i44 > _b8 ? _b8 = _i44 : \"avg\" === a && (_x51 += _i44, _k5++);\n            }\n\n            if (isNaN(_b8)) break;\n          }\n\n          m[_I2 + _n177 * y + _t272] = \"avg\" === a ? _x51 / _k5 : _b8;\n        }\n      }\n    }\n  }\n\n  return g;\n}\n\nfunction sb(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = dn(s.outShape, \"int32\"),\n      o = s.strideHeight,\n      l = s.strideWidth,\n      u = s.dilationHeight,\n      c = s.dilationWidth,\n      h = s.effectiveFilterHeight,\n      d = s.effectiveFilterWidth,\n      p = s.padInfo.top,\n      f = s.padInfo.left,\n      g = dn(t, n, e);\n\n  for (var _e303 = 0; _e303 < s.batchSize; ++_e303) {\n    for (var _t273 = 0; _t273 < s.inChannels; ++_t273) {\n      for (var _n180 = 0; _n180 < s.outHeight; ++_n180) {\n        var _m8 = _n180 * o - p;\n\n        var _b9 = _m8;\n\n        for (; _b9 < 0;) {\n          _b9 += u;\n        }\n\n        var _x52 = Math.min(s.inHeight, h + _m8);\n\n        for (var _o34 = 0; _o34 < s.outWidth; ++_o34) {\n          var _h9 = _o34 * l - f;\n\n          var _p9 = _h9;\n\n          for (; _p9 < 0;) {\n            _p9 += c;\n          }\n\n          var _y7 = Math.min(s.inWidth, d + _h9);\n\n          var _k6 = Number.NEGATIVE_INFINITY,\n              _w4 = -1;\n\n          for (var _n181 = _b9; _n181 < _x52; _n181 += u) {\n            var _i45 = _n181 - _m8;\n\n            for (var _o35 = _p9; _o35 < _y7; _o35 += c) {\n              var _l23 = _o35 - _h9,\n                  _u14 = g.get(_e303, _n181, _o35, _t273);\n\n              _u14 > _k6 && (_k6 = _u14, _w4 = r ? a ? ((_e303 * s.inHeight + _n181) * s.inWidth + _o35) * s.inChannels + _t273 : (_n181 * s.inWidth + _o35) * s.inChannels + _t273 : _i45 * d + _l23);\n            }\n          }\n\n          i.set(_w4, _e303, _n180, _o34, _t273);\n        }\n      }\n    }\n  }\n\n  return i;\n}\n\nfunction rb(e, t, n, s, r, a) {\n  var i = r.strideDepth,\n      o = r.strideHeight,\n      l = r.strideWidth,\n      u = r.dilationDepth,\n      c = r.dilationHeight,\n      h = r.dilationWidth,\n      d = r.effectiveFilterDepth,\n      p = r.effectiveFilterHeight,\n      f = r.effectiveFilterWidth,\n      g = r.padInfo.front,\n      m = r.padInfo.top,\n      b = r.padInfo.left,\n      x = \"max\" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n      y = dn(r.outShape, n),\n      k = y.values,\n      w = r.outShape[1] * r.outShape[2] * r.outShape[3] * r.outShape[4],\n      v = r.outShape[2] * r.outShape[3] * r.outShape[4],\n      I = r.outShape[3] * r.outShape[4],\n      $ = r.outShape[4];\n\n  for (var _t274 = 0; _t274 < r.batchSize; ++_t274) {\n    var _n182 = _t274 * w,\n        _y8 = _t274 * s[0];\n\n    for (var _t275 = 0; _t275 < r.inChannels; ++_t275) {\n      for (var _w5 = 0; _w5 < r.outDepth; ++_w5) {\n        var _N2 = _w5 * i - g;\n\n        var _C2 = _N2;\n\n        for (; _C2 < 0;) {\n          _C2 += u;\n        }\n\n        var _S = Math.min(r.inDepth, d + _N2),\n            _T = _n182 + _w5 * v;\n\n        for (var _n183 = 0; _n183 < r.outHeight; ++_n183) {\n          var _i46 = _n183 * o - m;\n\n          var _d11 = _i46;\n\n          for (; _d11 < 0;) {\n            _d11 += c;\n          }\n\n          var _g10 = Math.min(r.inHeight, p + _i46),\n              _w6 = _T + _n183 * I;\n\n          for (var _n184 = 0; _n184 < r.outWidth; ++_n184) {\n            var _i47 = _n184 * l - b;\n\n            var _o36 = _i47;\n\n            for (; _o36 < 0;) {\n              _o36 += h;\n            }\n\n            var _p10 = Math.min(r.inWidth, f + _i47),\n                _m9 = _w6 + _n184 * $;\n\n            var _v4 = x,\n                _I3 = 0,\n                _N3 = 0;\n\n            for (var _n185 = _C2; _n185 < _S; _n185 += u) {\n              var _r103 = _y8 + _n185 * s[1];\n\n              for (var _n186 = _d11; _n186 < _g10; _n186 += c) {\n                var _i48 = _r103 + _n186 * s[2];\n\n                for (var _n187 = _o36; _n187 < _p10; _n187 += h) {\n                  var _r104 = e[_i48 + _n187 * s[3] + _t275];\n                  if (\"max\" === a && _r104 > _v4 ? _v4 = _r104 : \"avg\" === a && (_I3 += _r104, _N3++), isNaN(_v4)) break;\n                }\n\n                if (isNaN(_v4)) break;\n              }\n\n              if (isNaN(_v4)) break;\n            }\n\n            k[_m9 + _t275] = \"avg\" === a ? _I3 / _N3 : _v4;\n          }\n        }\n      }\n    }\n  }\n\n  return y;\n}\n\nvar ab = {\n  kernelName: \"AvgPool\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    zf(r, \"avgPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ss(i, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = bs(r.shape, a, i, 1, o, u);\n    var h;\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) h = qf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });else {\n      var _e304 = n.data.get(r.dataId).values,\n          _t276 = A(r.shape),\n          _s148 = nb(_e304, 0, r.dtype, _t276, c, \"avg\");\n\n      h = n.makeTensorInfo(c.outShape, r.dtype, _s148.values);\n    }\n    return h;\n  }\n},\n    ib = {\n  kernelName: \"AvgPool3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s;\n    zf(r, \"avgPool3d\");\n    var c = xs(r.shape, a, i, 1, o, l, u),\n        h = rb(n.data.get(r.dataId).values, 0, r.dtype, A(r.shape), c, \"avg\");\n    return n.makeTensorInfo(h.shape, \"float32\", h.values);\n  }\n},\n    ob = {\n  kernelName: \"AvgPool3DGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        {\n      filterSize: i,\n      strides: o,\n      pad: l,\n      dimRoundingMode: u\n    } = s;\n    zf([r, a], \"avgPool3DGrad\");\n    var c = xs(a.shape, i, o, 1, l, u),\n        h = c.strideDepth,\n        d = c.strideHeight,\n        p = c.strideWidth,\n        f = c.filterDepth,\n        g = c.filterHeight,\n        m = c.filterWidth,\n        b = c.dilationDepth,\n        x = c.dilationHeight,\n        y = c.dilationWidth,\n        k = c.effectiveFilterDepth,\n        w = c.effectiveFilterHeight,\n        v = c.effectiveFilterWidth,\n        I = k - 1 - c.padInfo.front,\n        $ = v - 1 - c.padInfo.left,\n        N = w - 1 - c.padInfo.top,\n        C = dn(a.shape, \"float32\"),\n        S = 1 / (f * g * m),\n        T = n.bufferSync(r);\n\n    for (var _e305 = 0; _e305 < c.batchSize; ++_e305) {\n      for (var _t277 = 0; _t277 < c.inChannels; ++_t277) {\n        for (var _n188 = 0; _n188 < c.inDepth; ++_n188) {\n          for (var _s149 = 0; _s149 < c.inHeight; ++_s149) {\n            for (var _r105 = 0; _r105 < c.inWidth; ++_r105) {\n              var _a80 = _n188 - I,\n                  _i49 = _s149 - N,\n                  _o37 = _r105 - $;\n\n              var _l24 = 0;\n\n              for (var _n189 = 0; _n189 < k; _n189 += b) {\n                var _s150 = (_a80 + _n189) / h;\n\n                if (!(_s150 < 0 || _s150 >= c.outDepth || Math.floor(_s150) !== _s150)) for (var _n190 = 0; _n190 < w; _n190 += x) {\n                  var _r106 = (_i49 + _n190) / d;\n\n                  if (!(_r106 < 0 || _r106 >= c.outHeight || Math.floor(_r106) !== _r106)) for (var _n191 = 0; _n191 < v; _n191 += y) {\n                    var _a81 = (_o37 + _n191) / p;\n\n                    _a81 < 0 || _a81 >= c.outWidth || Math.floor(_a81) !== _a81 || (_l24 += T.get(_e305, _s150, _r106, _a81, _t277));\n                  }\n                }\n              }\n\n              C.set(_l24 * S, _e305, _n188, _s149, _r105, _t277);\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(C.shape, C.dtype, C.values);\n  }\n},\n    lb = {\n  kernelName: \"AvgPoolGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a;\n    zf([r, a], \"avgPoolGrad\");\n    var {\n      filterSize: o,\n      strides: l,\n      pad: u\n    } = s,\n        c = bs(i.shape, o, l, 1, u),\n        h = c.strideHeight,\n        d = c.strideWidth,\n        p = c.filterHeight,\n        f = c.filterWidth,\n        g = c.dilationHeight,\n        m = c.dilationWidth,\n        b = c.effectiveFilterHeight,\n        x = c.effectiveFilterWidth,\n        y = x - 1 - c.padInfo.left,\n        k = b - 1 - c.padInfo.top,\n        w = dn(i.shape, \"float32\"),\n        v = 1 / (p * f),\n        I = n.data.get(r.dataId).values,\n        $ = dn(r.shape, \"float32\", I);\n\n    for (var _e306 = 0; _e306 < c.batchSize; ++_e306) {\n      for (var _t278 = 0; _t278 < c.inChannels; ++_t278) {\n        for (var _n192 = 0; _n192 < c.inHeight; ++_n192) {\n          for (var _s151 = 0; _s151 < c.inWidth; ++_s151) {\n            var _r107 = _n192 - k,\n                _a82 = _s151 - y;\n\n            var _i50 = 0;\n\n            for (var _n193 = 0; _n193 < b; _n193 += g) {\n              var _s152 = (_r107 + _n193) / h;\n\n              if (!(_s152 < 0 || _s152 >= c.outHeight || Math.floor(_s152) !== _s152)) for (var _n194 = 0; _n194 < x; _n194 += m) {\n                var _r108 = (_a82 + _n194) / d;\n\n                _r108 < 0 || _r108 >= c.outWidth || Math.floor(_r108) !== _r108 || (_i50 += $.get(_e306, _s152, _r108, _t278));\n              }\n            }\n\n            w.set(_i50 * v, _e306, _n192, _s151, _t278);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(w.shape, w.dtype, w.values);\n  }\n},\n    ub = {\n  kernelName: \"FusedBatchNorm\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      scale: a,\n      offset: i,\n      mean: o,\n      variance: u\n    } = t;\n    l(o.shape.length === u.shape.length, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == i || o.shape.length === i.shape.length, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == a || o.shape.length === a.shape.length, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\"), zf([r, o, u, a, i], \"batchNorm\");\n    var {\n      varianceEpsilon: c\n    } = s;\n    null == c && (c = .001);\n    var h = n.data.get(r.dataId).values,\n        d = n.data.get(o.dataId).values,\n        p = n.data.get(u.dataId).values,\n        f = a ? n.data.get(a.dataId).values : new Float32Array([1]),\n        g = i ? n.data.get(i.dataId).values : new Float32Array([0]),\n        m = new Float32Array(h.length),\n        b = g.length,\n        x = f.length,\n        y = p.length,\n        k = d.length;\n    var w = 0,\n        v = 0,\n        I = 0,\n        $ = 0;\n\n    for (var _e307 = 0; _e307 < h.length; ++_e307) {\n      m[_e307] = g[w++] + (h[_e307] - d[v++]) * f[I++] / Math.sqrt(p[$++] + c), w >= b && (w = 0), v >= k && (v = 0), I >= x && (I = 0), $ >= y && ($ = 0);\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, m);\n  }\n},\n    cb = {\n  kernelName: \"BatchToSpaceND\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      crops: i\n    } = s;\n    zf([r], \"batchToSpaceND\");\n\n    var o = a.reduce((e, t) => e * t),\n        l = Ro(r.shape, a, o),\n        u = Ao(l.length, a.length),\n        c = Fo(r.shape, a, o),\n        h = Do(i, a.length),\n        d = _o(c, i, a.length),\n        p = Bm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: l\n      }\n    }),\n        f = Xg({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }),\n        g = Bm({\n      inputs: {\n        x: f\n      },\n      backend: n,\n      attrs: {\n        shape: c\n      }\n    }),\n        m = sm({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        begin: h,\n        size: d\n      }\n    });\n\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n  }\n},\n    hb = {\n  kernelName: \"Bincount\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i\n    } = s,\n        o = rg(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);\n    return n.makeTensorInfo([i], a.dtype, o);\n  }\n},\n    db = {\n  kernelName: \"ClipByValue\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"ClipByValue\", (e, t) => e > t.clipValueMax ? t.clipValueMax : e < t.clipValueMin ? t.clipValueMin : e)\n},\n    pb = {\n  kernelName: \"ComplexAbs\",\n  backendName: \"cpu\",\n  kernelFunc: e => {\n    var {\n      x: t\n    } = e.inputs,\n        n = e.backend,\n        s = new Float32Array(d(t.shape)),\n        r = n.data.get(t.dataId),\n        a = r.complexTensorInfos.imag,\n        i = n.data.get(r.complexTensorInfos.real.dataId).values,\n        o = n.data.get(a.dataId).values;\n\n    for (var _e308 = 0; _e308 < i.length; _e308++) {\n      s[_e308] = Math.hypot(i[_e308], o[_e308]);\n    }\n\n    return n.makeOutput(s, t.shape, \"float32\");\n  }\n};\n\nfunction fb(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t,\n      r = n.data.get(s.dataId).complexTensorInfos.imag,\n      a = n.data.get(r.dataId).values;\n  return n.makeTensorInfo(r.shape, r.dtype, a);\n}\n\nvar gb = {\n  kernelName: \"Imag\",\n  backendName: \"cpu\",\n  kernelFunc: fb\n};\n\nfunction mb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s,\n      a = y(r, t[0].shape)[0];\n  var i = So(t.map(e => e.shape), a);\n  if (0 === d(i)) return n.makeTensorInfo(i, t[0].dtype, []);\n  var o = t.filter(e => d(e.shape) > 0);\n  if (1 === o.length) return qf({\n    inputs: {\n      x: o[0]\n    },\n    backend: n\n  });\n\n  if (Co(o.map(e => e.shape), a), \"complex64\" === o[0].dtype) {\n    var _e309 = o.map(e => Xf({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _t279 = o.map(e => fb({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _s153 = mb({\n      inputs: _e309,\n      backend: n,\n      attrs: {\n        axis: a\n      }\n    }),\n        _r109 = mb({\n      inputs: _t279,\n      backend: n,\n      attrs: {\n        axis: a\n      }\n    }),\n        _i51 = Gf({\n      inputs: {\n        real: _s153,\n        imag: _r109\n      },\n      backend: n\n    });\n\n    return _e309.forEach(e => n.disposeIntermediateTensorInfo(e)), _t279.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_s153), n.disposeIntermediateTensorInfo(_r109), _i51;\n  }\n\n  var l = o.map(e => {\n    var t = d(e.shape.slice(a));\n    return Bm({\n      inputs: {\n        x: e\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, t]\n      }\n    });\n  }),\n      u = l.map(e => ({\n    vals: n.data.get(e.dataId).values,\n    shape: e.shape\n  }));\n  i = So(l.map(e => e.shape), 1);\n  var c = hg(u, i, t[0].dtype, 1 === l[0].shape[0]),\n      h = So(o.map(e => e.shape), a),\n      p = n.makeTensorInfo(h, t[0].dtype, c);\n  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;\n}\n\nvar bb = {\n  kernelName: \"Concat\",\n  backendName: \"cpu\",\n  kernelFunc: mb\n};\n\nfunction xb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    filter: a\n  } = t,\n      {\n    strides: i,\n    pad: o,\n    dataFormat: l,\n    dilations: u,\n    dimRoundingMode: c\n  } = s;\n  zf([r, a], \"conv2d\");\n  var h = Ts(l),\n      d = ys(r.shape, a.shape, i, u, o, c, !1, h),\n      p = d.filterHeight,\n      f = d.filterWidth,\n      g = d.dilationHeight,\n      m = d.dilationWidth,\n      b = d.padInfo.left,\n      x = d.padInfo.top,\n      y = \"channelsLast\" === d.dataFormat,\n      k = new et(d.outShape, r.dtype),\n      w = A(r.shape),\n      v = A(a.shape),\n      I = w[0],\n      $ = y ? w[1] : w[2],\n      N = y ? w[2] : 1,\n      C = y ? 1 : w[1],\n      S = k.strides[0],\n      T = y ? k.strides[1] : k.strides[2],\n      E = y ? k.strides[2] : 1,\n      R = y ? 1 : k.strides[1],\n      F = n.data.get(r.dataId).values,\n      D = n.data.get(a.dataId).values,\n      _ = k.values;\n\n  for (var _e310 = 0; _e310 < d.batchSize; ++_e310) {\n    var _t280 = _e310 * I,\n        _n195 = _e310 * S;\n\n    for (var _e311 = 0; _e311 < d.outHeight; ++_e311) {\n      var _s154 = _n195 + _e311 * T,\n          _r110 = _e311 * d.strideHeight - x;\n\n      for (var _e312 = 0; _e312 < p; ++_e312) {\n        var _n196 = _r110 + _e312 * g;\n\n        if (_n196 < 0 || _n196 >= d.inHeight) continue;\n\n        var _a83 = _e312 * v[0],\n            _i52 = _t280 + _n196 * $;\n\n        for (var _e313 = 0; _e313 < d.outWidth; ++_e313) {\n          var _t281 = _s154 + _e313 * E,\n              _n197 = _e313 * d.strideWidth - b;\n\n          for (var _e314 = 0; _e314 < f; ++_e314) {\n            var _s155 = _n197 + _e314 * m;\n\n            if (_s155 < 0 || _s155 >= d.inWidth) continue;\n\n            var _r111 = _i52 + _s155 * N;\n\n            var _o38 = _a83 + _e314 * v[1];\n\n            for (var _e315 = 0; _e315 < d.inChannels; ++_e315) {\n              var _n198 = F[_r111 + _e315 * C];\n\n              for (var _e316 = 0; _e316 < d.outChannels; ++_e316) {\n                _[_t281 + _e316 * R] += _n198 * D[_o38 + _e316];\n              }\n\n              _o38 += d.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.makeTensorInfo(k.shape, k.dtype, _);\n}\n\nvar yb = {\n  kernelName: \"Conv2D\",\n  backendName: \"cpu\",\n  kernelFunc: xb\n},\n    kb = {\n  kernelName: \"Conv2DBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s;\n    zf([r, a], \"conv2dBackpropFilter\");\n    var h = Ts(l),\n        d = ys(r.shape, c, i, 1, o, u, !1, h),\n        {\n      strideHeight: p,\n      strideWidth: f,\n      filterHeight: g,\n      filterWidth: m\n    } = d,\n        b = \"channelsLast\" === d.dataFormat,\n        x = new et(d.filterShape, \"float32\"),\n        y = d.padInfo.left,\n        k = d.padInfo.top,\n        w = n.data.get(r.dataId).values,\n        v = n.data.get(a.dataId).values,\n        I = new et(r.shape, r.dtype, w),\n        $ = new et(a.shape, a.dtype, v);\n\n    for (var _e317 = 0; _e317 < g; ++_e317) {\n      var _t282 = Math.max(0, Math.ceil((k - _e317) / p)),\n          _n199 = Math.min(d.outHeight, (d.inHeight + k - _e317) / p);\n\n      for (var _s156 = 0; _s156 < m; ++_s156) {\n        var _r112 = Math.max(0, Math.ceil((y - _s156) / f)),\n            _a84 = Math.min(d.outWidth, (d.inWidth + y - _s156) / f);\n\n        for (var _i53 = 0; _i53 < d.inChannels; ++_i53) {\n          for (var _o39 = 0; _o39 < d.outChannels; ++_o39) {\n            var _l25 = 0;\n\n            for (var _u15 = 0; _u15 < d.batchSize; ++_u15) {\n              for (var _c14 = _t282; _c14 < _n199; ++_c14) {\n                var _t283 = _e317 + _c14 * p - k;\n\n                for (var _e318 = _r112; _e318 < _a84; ++_e318) {\n                  var _n200 = _s156 + _e318 * f - y;\n\n                  _l25 += b ? I.get(_u15, _t283, _n200, _i53) * $.get(_u15, _c14, _e318, _o39) : I.get(_u15, _i53, _t283, _n200) * $.get(_u15, _o39, _c14, _e318);\n                }\n              }\n            }\n\n            x.set(_l25, _e317, _s156, _i53, _o39);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(x.shape, x.dtype, x.values);\n  }\n},\n    wb = {\n  kernelName: \"Conv2DBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      inputShape: i,\n      strides: o,\n      pad: l,\n      dataFormat: u,\n      dimRoundingMode: c\n    } = s;\n    zf([r, a], \"conv2dBackpropInput\");\n    var h = A(a.shape),\n        d = A(r.shape);\n    var p = Ts(u);\n    var f = ys(i, a.shape, o, 1, l, c, !1, p),\n        g = new et(f.inShape, \"float32\"),\n        m = g.values,\n        b = n.data.get(r.dataId).values,\n        x = n.data.get(a.dataId).values,\n        [y, k, w] = h,\n        {\n      batchSize: v,\n      filterHeight: I,\n      filterWidth: $,\n      inChannels: N,\n      inHeight: C,\n      inWidth: S,\n      outChannels: T,\n      outHeight: E,\n      outWidth: R,\n      strideHeight: F,\n      strideWidth: D\n    } = f;\n    p = f.dataFormat;\n\n    var _ = I - 1 - f.padInfo.top,\n        O = $ - 1 - f.padInfo.left,\n        M = \"channelsLast\" === p,\n        L = g.strides[0],\n        z = M ? g.strides[1] : g.strides[2],\n        B = M ? g.strides[2] : 1,\n        P = M ? 1 : g.strides[1],\n        W = d[0],\n        U = M ? d[1] : d[2],\n        V = M ? d[2] : 1,\n        G = M ? 1 : d[1];\n\n    for (var _e319 = 0; _e319 < v; ++_e319) {\n      for (var _t284 = 0; _t284 < N; ++_t284) {\n        for (var _n201 = 0; _n201 < C; ++_n201) {\n          var _s157 = _n201 - _,\n              _r113 = Math.max(0, Math.ceil(_s157 / F)),\n              _a85 = Math.min(E, (I + _s157) / F);\n\n          for (var _i54 = 0; _i54 < S; ++_i54) {\n            var _o40 = _i54 - O,\n                _l26 = Math.max(0, Math.ceil(_o40 / D)),\n                _u16 = Math.min(R, ($ + _o40) / D);\n\n            var _c15 = 0;\n\n            for (var _n202 = _r113; _n202 < _a85; ++_n202) {\n              var _r114 = _n202 * F - _s157;\n\n              for (var _s158 = _l26; _s158 < _u16; ++_s158) {\n                var _a86 = W * _e319 + U * _n202 + V * _s158,\n                    _i55 = y * (I - 1 - _r114) + k * ($ - 1 - (_s158 * D - _o40)) + w * _t284;\n\n                for (var _e320 = 0; _e320 < T; ++_e320) {\n                  _c15 += b[_a86 + G * _e320] * x[_i55 + _e320];\n                }\n              }\n            }\n\n            m[L * _e319 + z * _n201 + B * _i54 + P * _t284] = _c15;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(g.shape, g.dtype, g.values);\n  }\n},\n    vb = {\n  kernelName: \"Conv3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s;\n    zf([r, a], \"conv3d\");\n    var u = ks(r.shape, a.shape, i, l, o),\n        {\n      filterDepth: c,\n      filterHeight: h,\n      filterWidth: d,\n      dilationDepth: p,\n      dilationHeight: f,\n      dilationWidth: g,\n      padInfo: m\n    } = u,\n        b = m.front,\n        x = m.left,\n        y = m.top,\n        k = new et(u.outShape, r.dtype),\n        w = n.data.get(r.dataId).values,\n        v = n.data.get(a.dataId).values,\n        I = k.values,\n        $ = A(r.shape),\n        N = A(a.shape);\n\n    for (var _e321 = 0; _e321 < u.batchSize; ++_e321) {\n      var _t285 = _e321 * $[0],\n          _n203 = _e321 * k.strides[0];\n\n      for (var _e322 = 0; _e322 < u.outDepth; ++_e322) {\n        var _s159 = _n203 + _e322 * k.strides[1],\n            _r115 = _e322 * u.strideDepth - b;\n\n        for (var _e323 = 0; _e323 < c; ++_e323) {\n          var _n204 = _r115 + _e323 * p;\n\n          if (_n204 < 0 || _n204 >= u.inDepth) continue;\n\n          var _a87 = _e323 * N[0],\n              _i56 = _t285 + _n204 * $[1];\n\n          for (var _e324 = 0; _e324 < u.outHeight; ++_e324) {\n            var _t286 = _s159 + _e324 * k.strides[2],\n                _n205 = _e324 * u.strideHeight - y;\n\n            for (var _e325 = 0; _e325 < h; ++_e325) {\n              var _s160 = _n205 + _e325 * f;\n\n              if (_s160 < 0 || _s160 >= u.inHeight) continue;\n\n              var _r116 = _a87 + _e325 * N[1],\n                  _o41 = _i56 + _s160 * $[2];\n\n              for (var _e326 = 0; _e326 < u.outWidth; ++_e326) {\n                var _n206 = _t286 + _e326 * u.outChannels,\n                    _s161 = _e326 * u.strideWidth - x;\n\n                for (var _e327 = 0; _e327 < d; ++_e327) {\n                  var _t287 = _s161 + _e327 * g;\n\n                  if (_t287 < 0 || _t287 >= u.inWidth) continue;\n\n                  var _a88 = _o41 + _t287 * u.inChannels;\n\n                  var _i57 = _r116 + _e327 * N[2];\n\n                  for (var _e328 = 0; _e328 < u.inChannels; ++_e328) {\n                    var _t288 = w[_a88 + _e328];\n\n                    for (var _e329 = 0; _e329 < u.outChannels; ++_e329) {\n                      I[_n206 + _e329] += _t288 * v[_i57 + _e329];\n                    }\n\n                    _i57 += u.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(k.shape, k.dtype, k.values);\n  }\n},\n    Ib = {\n  kernelName: \"Conv3DBackpropFilterV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      filterShape: l\n    } = s;\n    zf([r, a], \"conv3dBackpropFilterV2\");\n    var u = A(r.shape),\n        c = A(a.shape),\n        h = ks(r.shape, l, i, 1, o),\n        d = h.strideDepth,\n        p = h.strideHeight,\n        f = h.strideWidth,\n        g = h.filterDepth,\n        m = h.filterHeight,\n        b = h.filterWidth,\n        x = new et(h.filterShape, \"float32\"),\n        y = x.values,\n        [k, w, v, I] = x.strides,\n        $ = n.data.get(a.dataId).values,\n        [N, C, S, T] = c,\n        E = n.data.get(r.dataId).values,\n        [R, F, D, _] = u,\n        O = h.padInfo.front,\n        M = h.padInfo.left,\n        L = h.padInfo.top;\n\n    for (var _e330 = 0; _e330 < g; ++_e330) {\n      var _t289 = Math.max(0, Math.ceil((O - _e330) / d)),\n          _n207 = Math.min(h.outDepth, (h.inDepth + O - _e330) / d),\n          _s162 = _e330 * k;\n\n      for (var _r117 = 0; _r117 < m; ++_r117) {\n        var _a89 = Math.max(0, Math.ceil((L - _r117) / p)),\n            _i58 = Math.min(h.outHeight, (h.inHeight + L - _r117) / p),\n            _o42 = _r117 * w + _s162;\n\n        for (var _s163 = 0; _s163 < b; ++_s163) {\n          var _l27 = Math.max(0, Math.ceil((M - _s163) / f)),\n              _u17 = Math.min(h.outWidth, (h.inWidth + M - _s163) / f),\n              _c16 = _s163 * v + _o42;\n\n          for (var _o43 = 0; _o43 < h.inChannels; ++_o43) {\n            var _g11 = _o43 * I + _c16;\n\n            for (var _c17 = 0; _c17 < h.outChannels; ++_c17) {\n              var _m10 = 0;\n\n              for (var _g12 = 0; _g12 < h.batchSize; ++_g12) {\n                var _h10 = _g12 * R,\n                    _b10 = _g12 * N;\n\n                for (var _g13 = _t289; _g13 < _n207; ++_g13) {\n                  var _t290 = (_e330 + _g13 * d - O) * F + _h10,\n                      _n208 = _g13 * C + _b10;\n\n                  for (var _e331 = _a89; _e331 < _i58; ++_e331) {\n                    var _a90 = (_r117 + _e331 * p - L) * D + _t290,\n                        _i59 = _e331 * S + _n208;\n\n                    for (var _e332 = _l27; _e332 < _u17; ++_e332) {\n                      _m10 += E[(_s163 + _e332 * f - M) * _ + _a90 + _o43] * $[_e332 * T + _i59 + _c17];\n                    }\n                  }\n                }\n              }\n\n              y[_g11 + _c17] = _m10;\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(x.shape, x.dtype, x.values);\n  }\n},\n    $b = {\n  kernelName: \"Conv3DBackpropInputV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      pad: i,\n      strides: o,\n      inputShape: l\n    } = s;\n    zf([r], \"conv3dBackpropInputV2\");\n    var u = A(r.shape),\n        c = A(a.shape),\n        h = ks(l, a.shape, o, 1, i),\n        d = new et(h.inShape, \"float32\"),\n        p = d.values,\n        [f, g, m, b] = d.strides,\n        x = n.data.get(r.dataId).values,\n        [y, k, w, v] = u,\n        I = n.data.get(a.dataId).values,\n        [$, N, C, S] = c,\n        {\n      batchSize: T,\n      filterDepth: E,\n      filterHeight: R,\n      filterWidth: F,\n      inChannels: D,\n      inDepth: _,\n      inHeight: O,\n      inWidth: M,\n      outChannels: L,\n      outDepth: z,\n      outHeight: B,\n      outWidth: P,\n      strideDepth: W,\n      strideHeight: U,\n      strideWidth: V\n    } = h,\n        G = E - 1 - h.padInfo.front,\n        H = R - 1 - h.padInfo.top,\n        j = F - 1 - h.padInfo.left;\n\n    for (var _e333 = 0; _e333 < T; ++_e333) {\n      for (var _t291 = 0; _t291 < D; ++_t291) {\n        for (var _n209 = 0; _n209 < _; ++_n209) {\n          var _s164 = _n209 - G,\n              _r118 = Math.max(0, Math.ceil(_s164 / W)),\n              _a91 = Math.min(z, (E + _s164) / W);\n\n          for (var _i60 = 0; _i60 < O; ++_i60) {\n            var _o44 = _i60 - H,\n                _l28 = Math.max(0, Math.ceil(_o44 / U)),\n                _u18 = Math.min(B, (R + _o44) / U);\n\n            for (var _c18 = 0; _c18 < M; ++_c18) {\n              var _h11 = _c18 - j,\n                  _d12 = Math.max(0, Math.ceil(_h11 / V)),\n                  _T2 = Math.min(P, (F + _h11) / V);\n\n              var _A = 0;\n\n              for (var _n210 = _r118; _n210 < _a91; ++_n210) {\n                var _r119 = _n210 * W - _s164;\n\n                for (var _s165 = _l28; _s165 < _u18; ++_s165) {\n                  var _a92 = _s165 * U - _o44;\n\n                  for (var _i61 = _d12; _i61 < _T2; ++_i61) {\n                    var _o45 = y * _e333 + k * _n210 + w * _s165 + v * _i61,\n                        _l29 = $ * (E - 1 - _r119) + N * (R - 1 - _a92) + C * (F - 1 - (_i61 * V - _h11)) + S * _t291;\n\n                    for (var _e334 = 0; _e334 < L; ++_e334) {\n                      _A += x[_o45 + _e334] * I[_l29 + _e334];\n                    }\n                  }\n                }\n              }\n\n              p[f * _e333 + g * _n209 + m * _i60 + b * _c18 + _t291] = _A;\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(d.shape, d.dtype, d.values);\n  }\n},\n    Nb = {\n  kernelName: \"Cos\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Cos\", e => Math.cos(e))\n},\n    Cb = {\n  kernelName: \"Cosh\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Cosh\", e => Math.cosh(e))\n},\n    Sb = {\n  kernelName: \"CropAndResize\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      boxes: a,\n      boxInd: i\n    } = t,\n        {\n      cropSize: o,\n      method: l,\n      extrapolationValue: u\n    } = s,\n        [c, h, d, p] = r.shape,\n        f = a.shape[0],\n        [g, m] = o,\n        b = dn([f, g, m, p], \"float32\"),\n        x = n.data.get(a.dataId).values,\n        y = n.data.get(i.dataId).values,\n        k = n.data.get(r.dataId).values,\n        w = A(r.shape),\n        v = A(b.shape);\n\n    for (var _e335 = 0; _e335 < f; _e335++) {\n      var _t292 = 4 * _e335,\n          _n211 = x[_t292],\n          _s166 = x[_t292 + 1],\n          _r120 = x[_t292 + 2],\n          _a93 = x[_t292 + 3],\n          _i62 = y[_e335];\n\n      if (_i62 >= c) continue;\n\n      var _o46 = g > 1 ? (_r120 - _n211) * (h - 1) / (g - 1) : 0,\n          _f7 = m > 1 ? (_a93 - _s166) * (d - 1) / (m - 1) : 0;\n\n      for (var _t293 = 0; _t293 < g; _t293++) {\n        var _c19 = g > 1 ? _n211 * (h - 1) + _t293 * _o46 : .5 * (_n211 + _r120) * (h - 1);\n\n        if (_c19 < 0 || _c19 > h - 1) for (var _n212 = 0; _n212 < m; _n212++) {\n          for (var _s167 = 0; _s167 < p; _s167++) {\n            b.values[_s167 + _n212 * v[2] + _t293 * v[1] + _e335 * v[0]] = u;\n          }\n        } else if (\"bilinear\" === l) {\n          var _n213 = Math.floor(_c19),\n              _r121 = Math.ceil(_c19),\n              _o47 = _c19 - _n213;\n\n          for (var _l30 = 0; _l30 < m; _l30++) {\n            var _c20 = m > 1 ? _s166 * (d - 1) + _l30 * _f7 : .5 * (_s166 + _a93) * (d - 1);\n\n            if (_c20 < 0 || _c20 > d - 1) {\n              for (var _n214 = 0; _n214 < p; _n214++) {\n                b.values[_n214 + _l30 * v[2] + _t293 * v[1] + _e335 * v[0]] = u;\n              }\n\n              continue;\n            }\n\n            var _h12 = Math.floor(_c20),\n                _g14 = Math.ceil(_c20),\n                _x53 = _c20 - _h12;\n\n            for (var _s168 = 0; _s168 < p; _s168++) {\n              var _a94 = _s168 + _h12 * w[2] + _n213 * w[1] + _i62 * w[0];\n\n              var _u19 = k[_a94];\n              _a94 = _s168 + _g14 * w[2] + _n213 * w[1] + _i62 * w[0];\n              var _c21 = k[_a94];\n              _a94 = _s168 + _h12 * w[2] + _r121 * w[1] + _i62 * w[0];\n              var _d13 = k[_a94];\n              _a94 = _s168 + _g14 * w[2] + _r121 * w[1] + _i62 * w[0];\n\n              var _p11 = k[_a94],\n                  _f8 = _u19 + (_c21 - _u19) * _x53;\n\n              _a94 = _s168 + _l30 * v[2] + _t293 * v[1] + _e335 * v[0], b.values[_a94] = _f8 + (_d13 + (_p11 - _d13) * _x53 - _f8) * _o47;\n            }\n          }\n        } else for (var _n215 = 0; _n215 < m; ++_n215) {\n          var _r122 = m > 1 ? _s166 * (d - 1) + _n215 * _f7 : .5 * (_s166 + _a93) * (d - 1);\n\n          if (_r122 < 0 || _r122 > d - 1) {\n            for (var _s169 = 0; _s169 < p; _s169++) {\n              b.values[_s169 + _n215 * v[2] + _t293 * v[1] + _e335 * v[0]] = u;\n            }\n\n            continue;\n          }\n\n          var _o48 = Math.round(_r122),\n              _l31 = Math.round(_c19);\n\n          for (var _s170 = 0; _s170 < p; _s170++) {\n            b.values[_s170 + _n215 * v[2] + _t293 * v[1] + _e335 * v[0]] = k[_s170 + _o48 * w[2] + _l31 * w[1] + _i62 * w[0]];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(b.shape, b.dtype, b.values);\n  }\n},\n    Tb = {\n  kernelName: \"Cumsum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      exclusive: i,\n      reverse: o\n    } = s;\n    zf(r, \"cumsum\");\n    var l = Jr([a], r.shape.length);\n    var u = r;\n    null != l && (u = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: l\n      }\n    }));\n    var c = Qr(1, r.shape.length)[0];\n    if (c !== u.shape.length - 1) throw new Error(\"backend.cumsum in CPU expects an inner-most axis=\".concat(u.shape.length - 1, \" but got axis=\").concat(c));\n    var h = dt(u.dtype, \"int32\"),\n        p = O(d(u.shape), h),\n        f = n.data.get(u.dataId).values,\n        g = u.shape[u.shape.length - 1],\n        m = o ? (e, t) => e + g - t - 1 : (e, t) => e + t;\n\n    for (var _e336 = 0; _e336 < f.length; _e336 += g) {\n      for (var _t294 = 0; _t294 < g; _t294++) {\n        var _n216 = m(_e336, _t294);\n\n        if (0 === _t294) p[_n216] = i ? 0 : f[_n216];else {\n          var _s171 = m(_e336, _t294 - 1);\n\n          p[_n216] = i ? f[_s171] + p[_s171] : f[_n216] + p[_s171];\n        }\n      }\n    }\n\n    var b = n.makeTensorInfo(u.shape, h, p);\n\n    if (null != l) {\n      var _e337 = Xg({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          perm: Zr(l)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(u), _e337;\n    }\n\n    return b;\n  }\n},\n    Eb = {\n  kernelName: \"DenseBincount\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i,\n      binaryOutput: o\n    } = s;\n\n    if (1 === r.shape.length) {\n      var _e338 = rg(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);\n\n      return n.makeTensorInfo([i], a.dtype, _e338);\n    }\n\n    if (2 === r.shape.length) {\n      var _e339 = ag(n.bufferSync(r), n.bufferSync(a), i, o);\n\n      return n.makeTensorInfo(_e339.shape, a.dtype, _e339.values);\n    }\n\n    throw new Error(\"Error in denseBincount: input must be at most rank 2, but got rank\".concat(r.shape.length, \".\"));\n  }\n},\n    Rb = {\n  kernelName: \"DepthToSpace\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockSize: a,\n      dataFormat: i\n    } = s;\n    l(\"NHWC\" === i, () => \"Only NHWC dataFormat supported on CPU for depthToSpace. Got \".concat(i)), l(a > 1, () => \"blockSize should be > 1 for depthToSpace, but was: \".concat(a));\n    var o = r.shape[0],\n        u = r.shape[1],\n        c = r.shape[2],\n        h = r.shape[3],\n        d = u * a,\n        p = c * a,\n        f = h / (a * a),\n        g = n.data.get(r.dataId).values,\n        m = new Float32Array(o * d * p * f);\n    var b = 0;\n\n    for (var _e340 = 0; _e340 < o; ++_e340) {\n      for (var _t295 = 0; _t295 < d; ++_t295) {\n        var _n217 = Math.floor(_t295 / a),\n            _s172 = _t295 % a;\n\n        for (var _t296 = 0; _t296 < p; ++_t296) {\n          var _r123 = Math.floor(_t296 / a),\n              _i63 = (_s172 * a + _t296 % a) * f;\n\n          for (var _t297 = 0; _t297 < f; ++_t297) {\n            m[b++] = g[_t297 + _i63 + h * (_r123 + c * (_n217 + u * _e340))];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([o, d, p, f], r.dtype, m);\n  }\n};\n\nfunction Ab(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    filter: a\n  } = t,\n      {\n    strides: i,\n    pad: o,\n    dilations: u,\n    dimRoundingMode: c\n  } = s;\n  zf([r, a], \"depthwiseConv2DNative\");\n  var h = A(r.shape),\n      d = A(a.shape);\n  var p = u;\n  null == p && (p = [1, 1]), l(Ss(i, p), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '\").concat(p, \"'\"));\n  var f = ys(r.shape, a.shape, i, p, o, c, !0),\n      {\n    filterHeight: g,\n    filterWidth: m,\n    dilationHeight: b,\n    dilationWidth: x,\n    padInfo: y\n  } = f,\n      k = y.left,\n      w = y.top,\n      v = f.outChannels / f.inChannels,\n      I = new et(f.outShape, r.dtype),\n      $ = n.data.get(r.dataId).values,\n      N = n.data.get(a.dataId).values,\n      C = I.values;\n\n  for (var _e341 = 0; _e341 < f.batchSize; ++_e341) {\n    var _t298 = _e341 * h[0],\n        _n218 = _e341 * I.strides[0];\n\n    for (var _e342 = 0; _e342 < f.outHeight; ++_e342) {\n      var _s173 = _n218 + _e342 * I.strides[1],\n          _r124 = _e342 * f.strideHeight - w;\n\n      for (var _e343 = 0; _e343 < g; ++_e343) {\n        var _n219 = _r124 + _e343 * b;\n\n        if (_n219 < 0 || _n219 >= f.inHeight) continue;\n\n        var _a95 = _e343 * d[0],\n            _i64 = _t298 + _n219 * h[1];\n\n        for (var _e344 = 0; _e344 < f.outWidth; ++_e344) {\n          var _t299 = _s173 + _e344 * I.strides[2],\n              _n220 = _e344 * f.strideWidth - k;\n\n          for (var _e345 = 0; _e345 < m; ++_e345) {\n            var _s174 = _n220 + _e345 * x;\n\n            if (_s174 < 0 || _s174 >= f.inWidth) continue;\n\n            var _r125 = _i64 + _s174 * f.inChannels;\n\n            var _o49 = _t299,\n                _l32 = _a95 + _e345 * d[1];\n\n            for (var _e346 = 0; _e346 < f.inChannels; ++_e346) {\n              var _t300 = $[_r125 + _e346];\n\n              for (var _e347 = 0; _e347 < v; ++_e347) {\n                C[_o49 + _e347] += _t300 * N[_l32 + _e347];\n              }\n\n              _o49 += v, _l32 += v;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.makeTensorInfo(I.shape, I.dtype, I.values);\n}\n\nvar Fb = {\n  kernelName: \"DepthwiseConv2dNative\",\n  backendName: \"cpu\",\n  kernelFunc: Ab\n},\n    Db = {\n  kernelName: \"DepthwiseConv2dNativeBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s;\n    zf([r, a], \"depthwiseConv2dNativeBackpropFilter\");\n    var h = ys(r.shape, c, i, o, l, u, !0),\n        {\n      strideHeight: d,\n      strideWidth: p,\n      filterHeight: f,\n      filterWidth: g\n    } = h,\n        m = new et(h.filterShape, \"float32\"),\n        b = h.padInfo.left,\n        x = h.padInfo.top,\n        y = h.outChannels / h.inChannels,\n        k = n.data.get(r.dataId).values,\n        w = new et(r.shape, r.dtype, k),\n        v = n.data.get(a.dataId).values,\n        I = new et(a.shape, a.dtype, v);\n\n    for (var _e348 = 0; _e348 < f; ++_e348) {\n      var _t301 = Math.max(0, Math.ceil((x - _e348) / d)),\n          _n221 = Math.min(h.outHeight, (h.inHeight + x - _e348) / d);\n\n      for (var _s175 = 0; _s175 < g; ++_s175) {\n        var _r126 = Math.max(0, Math.ceil((b - _s175) / p)),\n            _a96 = Math.min(h.outWidth, (h.inWidth + b - _s175) / p);\n\n        for (var _i65 = 0; _i65 < h.outChannels; ++_i65) {\n          var _o50 = Math.trunc(_i65 / y),\n              _l33 = _i65 % y;\n\n          var _u20 = 0;\n\n          for (var _l34 = 0; _l34 < h.batchSize; ++_l34) {\n            for (var _c22 = _t301; _c22 < _n221; ++_c22) {\n              var _t302 = _e348 + _c22 * d - x;\n\n              for (var _e349 = _r126; _e349 < _a96; ++_e349) {\n                _u20 += w.get(_l34, _t302, _s175 + _e349 * p - b, _o50) * I.get(_l34, _c22, _e349, _i65);\n              }\n            }\n          }\n\n          m.set(_u20, _e348, _s175, _o50, _l33);\n        }\n      }\n    }\n\n    return n.makeTensorInfo(m.shape, m.dtype, m.values);\n  }\n},\n    _b = {\n  kernelName: \"DepthwiseConv2dNativeBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      inputShape: c\n    } = s;\n    zf([r, a], \"depthwiseConv2DNativeBackpropInput\");\n    var h = A(r.shape),\n        d = A(a.shape),\n        p = ys(c, a.shape, i, o, l, u, !0),\n        f = new et(p.inShape, \"float32\"),\n        g = f.values,\n        [m, b, x] = f.strides,\n        y = n.data.get(r.dataId).values,\n        [k, w, v] = h,\n        I = n.data.get(a.dataId).values,\n        [$, N, C] = d,\n        {\n      batchSize: S,\n      filterHeight: T,\n      filterWidth: E,\n      inChannels: R,\n      inHeight: F,\n      inWidth: D,\n      outChannels: _,\n      outHeight: O,\n      outWidth: M,\n      strideHeight: L,\n      strideWidth: z\n    } = p,\n        B = T - 1 - p.padInfo.top,\n        P = E - 1 - p.padInfo.left,\n        W = _ / R;\n\n    for (var _e350 = 0; _e350 < S; ++_e350) {\n      for (var _t303 = 0; _t303 < R; ++_t303) {\n        for (var _n222 = 0; _n222 < F; ++_n222) {\n          var _s176 = _n222 - B,\n              _r127 = Math.max(0, Math.ceil(_s176 / L)),\n              _a97 = Math.min(O, (T + _s176) / L);\n\n          for (var _i66 = 0; _i66 < D; ++_i66) {\n            var _o51 = _i66 - P,\n                _l35 = Math.max(0, Math.ceil(_o51 / z)),\n                _u21 = Math.min(M, (E + _o51) / z);\n\n            var _c23 = 0;\n\n            for (var _n223 = _r127; _n223 < _a97; ++_n223) {\n              var _r128 = _n223 * L - _s176;\n\n              for (var _s177 = _l35; _s177 < _u21; ++_s177) {\n                var _a98 = k * _e350 + w * _n223 + v * _s177,\n                    _i67 = $ * (T - 1 - _r128) + N * (E - 1 - (_s177 * z - _o51)) + C * _t303;\n\n                for (var _e351 = 0; _e351 < W; ++_e351) {\n                  _c23 += y[_a98 + (_t303 * W + _e351)] * I[_i67 + _e351];\n                }\n              }\n            }\n\n            g[m * _e350 + b * _n222 + x * _i66 + _t303] = _c23;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(f.shape, f.dtype, f.values);\n  }\n},\n    Ob = {\n  kernelName: \"Diag\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = d(s.shape),\n        a = n.data.get(s.dataId).values,\n        i = dn([r, r], s.dtype),\n        o = i.values;\n\n    for (var _e352 = 0; _e352 < a.length; _e352++) {\n      o[_e352 * r + _e352] = a[_e352];\n    }\n\n    var l = [...s.shape, ...s.shape];\n    return n.makeTensorInfo(l, i.dtype, i.values);\n  }\n},\n    Mb = {\n  kernelName: \"Dilation2D\",\n  backendName: \"cpu\",\n  kernelFunc: _ref13 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref13;\n    var {\n      x: s,\n      filter: r\n    } = e,\n        {\n      strides: a,\n      pad: i,\n      dilations: o\n    } = n,\n        l = t,\n        u = l.data.get(s.dataId).values,\n        c = s.shape.length,\n        h = l.data.get(r.dataId).values,\n        p = r.shape.length,\n        {\n      batchSize: f,\n      inHeight: g,\n      inWidth: m,\n      inChannels: b,\n      outHeight: x,\n      outWidth: y,\n      padInfo: k,\n      strideHeight: w,\n      strideWidth: I,\n      filterHeight: $,\n      filterWidth: N,\n      dilationHeight: C,\n      dilationWidth: S,\n      outShape: T\n    } = ms(s.shape, r.shape, a, i, \"NHWC\", o),\n        E = d(T),\n        R = T.length,\n        F = v(s.dtype, E);\n\n    for (var _e353 = 0; _e353 < f; ++_e353) {\n      for (var _t304 = 0; _t304 < x; ++_t304) {\n        var _n224 = _t304 * w - k.top;\n\n        for (var _a99 = 0; _a99 < y; ++_a99) {\n          var _i68 = _a99 * I - k.left;\n\n          for (var _o52 = 0; _o52 < b; ++_o52) {\n            var _l36 = Number.MIN_SAFE_INTEGER;\n\n            for (var _t305 = 0; _t305 < $; ++_t305) {\n              var _a100 = _n224 + _t305 * C;\n\n              if (_a100 >= 0 && _a100 < g) for (var _n225 = 0; _n225 < N; ++_n225) {\n                var _d14 = _i68 + _n225 * S;\n\n                if (_d14 >= 0 && _d14 < m) {\n                  var _i69 = z([_e353, _a100, _d14, _o52], c, A(s.shape)),\n                      _f9 = z([_t305, _n225, _o52], p, A(r.shape)),\n                      _g15 = u[_i69] + h[_f9];\n\n                  _g15 > _l36 && (_l36 = _g15);\n                }\n              }\n            }\n\n            F[z([_e353, _t304, _a99, _o52], R, A(T))] = _l36;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: l.write(Ue(F, s.dtype), T, s.dtype),\n      shape: T,\n      dtype: s.dtype\n    };\n  }\n},\n    Lb = {\n  kernelName: \"Dilation2DBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: _ref14 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref14;\n    var {\n      x: s,\n      filter: r,\n      dy: a\n    } = e,\n        {\n      strides: i,\n      pad: o,\n      dilations: u\n    } = n,\n        c = t,\n        h = D(s.shape, c.data.get(s.dataId).values),\n        d = D(r.shape, c.data.get(r.dataId).values),\n        {\n      batchSize: p,\n      inHeight: f,\n      inWidth: g,\n      inChannels: m,\n      outHeight: b,\n      outWidth: x,\n      padInfo: y,\n      strideHeight: k,\n      strideWidth: w,\n      filterHeight: v,\n      filterWidth: I,\n      dilationHeight: $,\n      dilationWidth: N,\n      outShape: C\n    } = ms(s.shape, r.shape, i, o, \"NHWC\", u);\n    l(a.rank === C.length, () => \"Error in Dilation2DBackpropFilter, dy must have the same rank as output \".concat(C.length, \", but got \").concat(a.rank));\n    var S = D(C, c.data.get(a.dataId).values),\n        T = M(r.shape, r.dtype);\n\n    for (var _e354 = 0; _e354 < p; ++_e354) {\n      for (var _t306 = 0; _t306 < b; ++_t306) {\n        var _n226 = _t306 * k - y.top;\n\n        for (var _s178 = 0; _s178 < x; ++_s178) {\n          var _r129 = _s178 * w - y.left;\n\n          for (var _a101 = 0; _a101 < m; ++_a101) {\n            var _i70 = Number.MIN_SAFE_INTEGER,\n                _o53 = 0,\n                _l37 = 0;\n\n            for (var _t307 = 0; _t307 < v; ++_t307) {\n              var _s179 = _n226 + _t307 * $;\n\n              if (_s179 >= 0 && _s179 < f) for (var _n227 = 0; _n227 < I; ++_n227) {\n                var _u22 = _r129 + _n227 * N;\n\n                if (_u22 >= 0 && _u22 < g) {\n                  var _r130 = h[_e354][_s179][_u22][_a101] + d[_t307][_n227][_a101];\n\n                  _r130 > _i70 && (_i70 = _r130, _o53 = _t307, _l37 = _n227);\n                }\n              }\n            }\n\n            T[_o53][_l37][_a101] += S[_e354][_t306][_s178][_a101];\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: c.write(Ue(T, s.dtype), r.shape, r.dtype),\n      shape: r.shape,\n      dtype: r.dtype\n    };\n  }\n},\n    zb = {\n  kernelName: \"Dilation2DBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: _ref15 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref15;\n    var {\n      x: s,\n      filter: r,\n      dy: a\n    } = e,\n        {\n      strides: i,\n      pad: o,\n      dilations: u\n    } = n,\n        c = t,\n        h = D(s.shape, c.data.get(s.dataId).values),\n        d = D(r.shape, c.data.get(r.dataId).values),\n        {\n      batchSize: p,\n      inHeight: f,\n      inWidth: g,\n      inChannels: m,\n      outHeight: b,\n      outWidth: x,\n      padInfo: y,\n      strideHeight: k,\n      strideWidth: w,\n      filterHeight: v,\n      filterWidth: I,\n      dilationHeight: $,\n      dilationWidth: N,\n      outShape: C\n    } = ms(s.shape, r.shape, i, o, \"NHWC\", u);\n    l(a.rank === C.length, () => \"Error in Dilation2DBackpropInput, dy must have the same rank as output \".concat(C.length, \", but got \").concat(a.rank));\n    var S = D(C, c.data.get(a.dataId).values),\n        T = M(s.shape, s.dtype);\n\n    for (var _e355 = 0; _e355 < p; ++_e355) {\n      for (var _t308 = 0; _t308 < b; ++_t308) {\n        var _n228 = _t308 * k - y.top;\n\n        for (var _s180 = 0; _s180 < x; ++_s180) {\n          var _r131 = _s180 * w - y.left;\n\n          for (var _a102 = 0; _a102 < m; ++_a102) {\n            var _i71 = Number.MIN_SAFE_INTEGER,\n                _o54 = _n228 < 0 ? 0 : _n228,\n                _l38 = _r131 < 0 ? 0 : _r131;\n\n            for (var _t309 = 0; _t309 < v; ++_t309) {\n              var _s181 = _n228 + _t309 * $;\n\n              if (_s181 >= 0 && _s181 < f) for (var _n229 = 0; _n229 < I; ++_n229) {\n                var _u23 = _r131 + _n229 * N;\n\n                if (_u23 >= 0 && _u23 < g) {\n                  var _r132 = h[_e355][_s181][_u23][_a102] + d[_t309][_n229][_a102];\n\n                  _r132 > _i71 && (_i71 = _r132, _o54 = _s181, _l38 = _u23);\n                }\n              }\n            }\n\n            T[_e355][_o54][_l38][_a102] += S[_e355][_t308][_s180][_a102];\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: c.write(Ue(T, s.dtype), s.shape, s.dtype),\n      shape: s.shape,\n      dtype: s.dtype\n    };\n  }\n};\n\nfunction Bb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    axis: a,\n    keepDims: i\n  } = s;\n  var o;\n  zf(r, \"sum\"), o = \"bool\" === r.dtype ? Jf({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      dtype: \"int32\"\n    }\n  }) : qf({\n    inputs: {\n      x: r\n    },\n    backend: n\n  });\n  var l = o.shape.length,\n      u = y(a, o.shape),\n      c = Jr(u, l);\n  var h = u,\n      p = o;\n  null != c && (p = Xg({\n    inputs: {\n      x: o\n    },\n    backend: n,\n    attrs: {\n      perm: c\n    }\n  }), h = Qr(h.length, l)), Yr(\"sum\", h, p.shape.length);\n  var [f, g] = Kr(p.shape, h);\n  var m = jf(n, f, dt(p.dtype, \"int32\"));\n  var b = d(g),\n      x = n.data.get(m.dataId).values,\n      k = n.data.get(p.dataId).values;\n\n  for (var _e356 = 0; _e356 < x.length; ++_e356) {\n    var _t310 = _e356 * b;\n\n    var _n230 = 0;\n\n    for (var _e357 = 0; _e357 < b; ++_e357) {\n      _n230 += k[_t310 + _e357];\n    }\n\n    x[_e356] = _n230;\n  }\n\n  if (i) {\n    var _e358 = m;\n    m = Bm({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Xr(m.shape, u)\n      }\n    }), n.disposeIntermediateTensorInfo(_e358);\n  }\n\n  return n.disposeIntermediateTensorInfo(o), null != c && n.disposeIntermediateTensorInfo(p), m;\n}\n\nvar Pb = {\n  kernelName: \"Sum\",\n  backendName: \"cpu\",\n  kernelFunc: Bb\n},\n    Wb = {\n  kernelName: \"Einsum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      equation: r\n    } = s,\n        a = t,\n        {\n      allDims: i,\n      summedDims: o,\n      idDims: l\n    } = Ho(r, a.length);\n    qo(i.length, l, a);\n    var {\n      path: u,\n      steps: c\n    } = Ko(o, l),\n        h = c.length;\n    var d = null,\n        f = i.length;\n    var g = [];\n\n    for (var _e359 = 0; _e359 < h; ++_e359) {\n      for (var _t311 of c[_e359]) {\n        var {\n          permutationIndices: _e360,\n          expandDims: _s182\n        } = jo(f, l[_t311]);\n\n        var _r133 = void 0;\n\n        Xo(_e360) ? _r133 = a[_t311] : (_r133 = Xg({\n          inputs: {\n            x: a[_t311]\n          },\n          backend: n,\n          attrs: {\n            perm: _e360\n          }\n        }), g.push(_r133));\n\n        var _i72 = _r133.shape.slice();\n\n        for (var _e361 = 0; _e361 < _s182.length; ++_e361) {\n          _i72.splice(_s182[_e361], 0, 1);\n        }\n\n        p(_r133.shape, _i72) || (_r133 = Bm({\n          inputs: {\n            x: _r133\n          },\n          backend: n,\n          attrs: {\n            shape: _i72\n          }\n        }), g.push(_r133)), null === d ? d = _r133 : (d = Ug({\n          inputs: {\n            a: _r133,\n            b: d\n          },\n          backend: n\n        }), g.push(d));\n      }\n\n      _e359 < h - 1 && (u[_e359] >= 0 && (d = Bb({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          axis: u[_e359] - (i.length - f),\n          keepDims: !1\n        }\n      }), g.push(d)), f--);\n    }\n\n    for (var _e362 of g) {\n      _e362 !== d && n.disposeIntermediateTensorInfo(_e362);\n    }\n\n    return d;\n  }\n},\n    Ub = {\n  kernelName: \"EluGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      dy: s,\n      y: r\n    } = t;\n    zf([s, r], \"eluGrad\");\n    var a = new Float32Array(d(r.shape)),\n        i = n.data.get(r.dataId).values,\n        o = n.data.get(s.dataId).values;\n\n    for (var _e363 = 0; _e363 < i.length; ++_e363) {\n      var _t312 = i[_e363];\n      a[_e363] = _t312 >= 1 ? o[_e363] : o[_e363] * (_t312 + 1);\n    }\n\n    return n.makeTensorInfo(r.shape, \"float32\", a);\n  }\n},\n    Vb = {\n  kernelName: \"Erf\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Erf\", e => {\n    var t = Math.sign(e),\n        n = Math.abs(e),\n        s = 1 / (1 + .3275911 * n);\n    return t * (1 - ((((1.061405429 * s - 1.453152027) * s + 1.421413741) * s - .284496736) * s + .254829592) * s * Math.exp(-n * n));\n  })\n};\n\nfunction Gb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    input: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = r.shape.length,\n      o = r.shape.slice();\n  var u = a;\n  return a < 0 && (l(-(i + 1) <= a, () => \"Axis must be in the interval [\".concat(-(i + 1), \", \").concat(i, \"]\")), u = i + a + 1), o.splice(u, 0, 1), Bm({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: o\n    }\n  });\n}\n\nvar Hb = {\n  kernelName: \"ExpandDims\",\n  backendName: \"cpu\",\n  kernelFunc: Gb\n},\n    jb = Qf(\"RealDiv\", Vf((e, t) => e / t)),\n    qb = {\n  kernelName: \"RealDiv\",\n  backendName: \"cpu\",\n  kernelFunc: jb\n};\n\nfunction Kb(e, t, n) {\n  var s = e.shape,\n      r = s[0],\n      a = s[1],\n      i = n.data.get(e.dataId),\n      o = i.complexTensorInfos.real,\n      l = i.complexTensorInfos.imag,\n      u = [r, a],\n      c = d(u),\n      h = w(\"float32\", c),\n      p = w(\"float32\", c);\n\n  for (var _e364 = 0; _e364 < r; _e364++) {\n    var _s183 = sm({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        begin: [_e364, 0],\n        size: [1, a]\n      }\n    }),\n        _r134 = sm({\n      inputs: {\n        x: l\n      },\n      backend: n,\n      attrs: {\n        begin: [_e364, 0],\n        size: [1, a]\n      }\n    }),\n        _i73 = Gf({\n      inputs: {\n        real: _s183,\n        imag: _r134\n      },\n      backend: n\n    }),\n        {\n      real: _u24,\n      imag: _c24\n    } = Xb(_i73, t, n),\n        _d15 = Mo(_u24, _c24);\n\n    for (var _t313 = 0; _t313 < a; _t313++) {\n      var _n231 = Po(_d15, _t313);\n\n      h[_e364 * a + _t313] = _n231.real, p[_e364 * a + _t313] = _n231.imag;\n    }\n\n    n.disposeIntermediateTensorInfo(_s183), n.disposeIntermediateTensorInfo(_r134), n.disposeIntermediateTensorInfo(_i73);\n  }\n\n  var f = n.makeTensorInfo(u, \"float32\", h),\n      g = n.makeTensorInfo(u, \"float32\", p),\n      m = Gf({\n    inputs: {\n      real: f,\n      imag: g\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n}\n\nfunction Xb(e, t, n) {\n  var s = d(e.shape),\n      r = n.data.get(e.dataId),\n      a = n.data.get(r.complexTensorInfos.real.dataId).values,\n      i = n.data.get(r.complexTensorInfos.imag.dataId).values;\n\n  if (0 == ((o = s) & o - 1)) {\n    var _r135 = Yb(a, i, s, t, n),\n        _o55 = [e.shape[0], e.shape[1]];\n\n    if (t) {\n      var _e365 = n.makeTensorInfo(_o55, \"float32\", _r135.real),\n          _t314 = n.makeTensorInfo(_o55, \"float32\", _r135.imag),\n          _a103 = n.makeTensorInfo([], \"float32\", We(s, \"float32\")),\n          _i74 = qf({\n        inputs: {\n          x: _a103\n        },\n        backend: n\n      }),\n          _l39 = qb.kernelFunc({\n        inputs: {\n          a: _e365,\n          b: _a103\n        },\n        backend: n\n      }),\n          _u25 = qb.kernelFunc({\n        inputs: {\n          a: _t314,\n          b: _i74\n        },\n        backend: n\n      }),\n          _c25 = n.data.get(_l39.dataId).values,\n          _h13 = n.data.get(_u25.dataId).values;\n\n      return n.disposeIntermediateTensorInfo(_e365), n.disposeIntermediateTensorInfo(_t314), n.disposeIntermediateTensorInfo(_a103), n.disposeIntermediateTensorInfo(_i74), n.disposeIntermediateTensorInfo(_l39), n.disposeIntermediateTensorInfo(_u25), {\n        real: _c25,\n        imag: _h13\n      };\n    }\n\n    return _r135;\n  }\n\n  return Lo(function (e, t, n) {\n    var s = new Float32Array(2 * t);\n\n    for (var _r136 = 0; _r136 < t; _r136++) {\n      var _a104 = 0,\n          _i75 = 0;\n\n      for (var _s184 = 0; _s184 < t; _s184++) {\n        var _o56 = Vo(_r136 * _s184, t, n),\n            _l40 = Po(e, _s184);\n\n        _a104 += _l40.real * _o56.real - _l40.imag * _o56.imag, _i75 += _l40.real * _o56.imag + _l40.imag * _o56.real;\n      }\n\n      n && (_a104 /= t, _i75 /= t), Wo(s, _a104, _i75, _r136);\n    }\n\n    return s;\n  }(Mo(a, i), s, t));\n  var o;\n}\n\nfunction Yb(e, t, n, s, r) {\n  if (1 === n) return {\n    real: e,\n    imag: t\n  };\n\n  var a = Mo(e, t),\n      i = n / 2,\n      o = zo(a),\n      l = o.real,\n      u = o.imag,\n      c = [l.length],\n      h = r.makeTensorInfo(c, \"float32\", l),\n      d = r.makeTensorInfo(c, \"float32\", u),\n      p = Gf({\n    inputs: {\n      real: h,\n      imag: d\n    },\n    backend: r\n  }),\n      f = Bo(a),\n      g = f.real,\n      m = f.imag,\n      b = [g.length],\n      x = r.makeTensorInfo(b, \"float32\", g),\n      y = r.makeTensorInfo(b, \"float32\", m),\n      k = Gf({\n    inputs: {\n      real: x,\n      imag: y\n    },\n    backend: r\n  }),\n      w = Yb(l, u, i, s, r),\n      v = w.real,\n      I = w.imag,\n      $ = [v.length],\n      N = r.makeTensorInfo($, \"float32\", v),\n      C = r.makeTensorInfo($, \"float32\", I),\n      S = Gf({\n    inputs: {\n      real: N,\n      imag: C\n    },\n    backend: r\n  }),\n      T = Yb(g, m, i, s, r),\n      E = T.real,\n      R = T.imag,\n      A = [E.length],\n      F = r.makeTensorInfo(A, \"float32\", E),\n      D = r.makeTensorInfo(A, \"float32\", R),\n      _ = Gf({\n    inputs: {\n      real: F,\n      imag: D\n    },\n    backend: r\n  }),\n      O = Uo(n, s),\n      M = [O.real.length],\n      L = r.makeTensorInfo(M, \"float32\", O.real),\n      z = r.makeTensorInfo(M, \"float32\", O.imag),\n      B = Gf({\n    inputs: {\n      real: L,\n      imag: z\n    },\n    backend: r\n  }),\n      P = Ug({\n    inputs: {\n      a: B,\n      b: _\n    },\n    backend: r\n  }),\n      W = ng({\n    inputs: {\n      a: S,\n      b: P\n    },\n    backend: r\n  }),\n      U = bm({\n    inputs: {\n      a: S,\n      b: P\n    },\n    backend: r\n  }),\n      V = Xf({\n    inputs: {\n      input: W\n    },\n    backend: r\n  }),\n      G = Xf({\n    inputs: {\n      input: U\n    },\n    backend: r\n  }),\n      H = fb({\n    inputs: {\n      input: W\n    },\n    backend: r\n  }),\n      j = fb({\n    inputs: {\n      input: U\n    },\n    backend: r\n  }),\n      q = mb({\n    inputs: [V, G],\n    backend: r,\n    attrs: {\n      axis: 0\n    }\n  }),\n      K = mb({\n    inputs: [H, j],\n    backend: r,\n    attrs: {\n      axis: 0\n    }\n  }),\n      X = r.data.get(q.dataId).values,\n      Y = r.data.get(K.dataId).values;\n\n  return r.disposeIntermediateTensorInfo(h), r.disposeIntermediateTensorInfo(d), r.disposeIntermediateTensorInfo(p), r.disposeIntermediateTensorInfo(x), r.disposeIntermediateTensorInfo(y), r.disposeIntermediateTensorInfo(k), r.disposeIntermediateTensorInfo(N), r.disposeIntermediateTensorInfo(C), r.disposeIntermediateTensorInfo(S), r.disposeIntermediateTensorInfo(F), r.disposeIntermediateTensorInfo(D), r.disposeIntermediateTensorInfo(_), r.disposeIntermediateTensorInfo(L), r.disposeIntermediateTensorInfo(z), r.disposeIntermediateTensorInfo(B), r.disposeIntermediateTensorInfo(P), r.disposeIntermediateTensorInfo(W), r.disposeIntermediateTensorInfo(U), r.disposeIntermediateTensorInfo(V), r.disposeIntermediateTensorInfo(H), r.disposeIntermediateTensorInfo(G), r.disposeIntermediateTensorInfo(j), r.disposeIntermediateTensorInfo(q), r.disposeIntermediateTensorInfo(K), {\n    real: X,\n    imag: Y\n  };\n}\n\nvar Jb = {\n  kernelName: \"FFT\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t,\n        r = d(s.shape),\n        a = s.shape[s.shape.length - 1],\n        i = Bm({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [r / a, a]\n      }\n    }),\n        o = Kb(i, !1, n),\n        l = Bm({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        shape: s.shape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(o), l;\n  }\n};\n\nfunction Zb(e) {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    shape: s,\n    value: r,\n    dtype: a\n  } = n,\n      i = a || T(r),\n      o = v(i, d(s));\n  return function (e, t, n) {\n    e.fill(t);\n  }(o, r), t.makeTensorInfo(s, i, o);\n}\n\nvar Qb = {\n  kernelName: \"Fill\",\n  backendName: \"cpu\",\n  kernelFunc: Zb\n},\n    ex = {\n  kernelName: \"FlipLeftRight\",\n  backendName: \"cpu\",\n  kernelFunc: _ref16 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref16;\n    var {\n      image: n\n    } = e,\n        s = t,\n        r = w(n.dtype, d(n.shape)),\n        [a, i, o, l] = n.shape,\n        u = s.data.get(n.dataId).values;\n\n    for (var _e366 = 0; _e366 < a; _e366++) {\n      var _t315 = _e366 * o * i * l;\n\n      for (var _e367 = 0; _e367 < i; _e367++) {\n        var _n232 = _e367 * (o * l);\n\n        for (var _e368 = 0; _e368 < o; _e368++) {\n          var _s185 = _e368 * l;\n\n          for (var _a105 = 0; _a105 < l; _a105++) {\n            var _i76 = Math.round(o - _e368 - 1),\n                _c26 = _t315 + _n232 + _s185 + _a105;\n\n            var _h14 = u[_c26];\n            _i76 >= 0 && _i76 < o && (_h14 = u[_t315 + _n232 + _i76 * l + _a105]), r[_c26] = _h14;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: s.write(r, n.shape, n.dtype),\n      shape: n.shape,\n      dtype: n.dtype\n    };\n  }\n},\n    tx = {\n  kernelName: \"FloorDiv\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"FloorDiv\", Vf((e, t) => Math.floor(e / t)), null, \"int32\")\n},\n    nx = {\n  kernelName: \"FusedConv2D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s;\n    var g = xb({\n      inputs: {\n        x: r,\n        filter: a\n      },\n      backend: n,\n      attrs: {\n        strides: l,\n        pad: u,\n        dataFormat: c,\n        dilations: h,\n        dimRoundingMode: d\n      }\n    });\n\n    if (i) {\n      var _e369 = g;\n      g = ng({\n        inputs: {\n          a: g,\n          b: i\n        },\n        backend: n\n      }), n.disposeIntermediateTensorInfo(_e369);\n    }\n\n    if (p) {\n      var _e370 = g;\n      g = zm(n, g, p, o, f), n.disposeIntermediateTensorInfo(_e370);\n    }\n\n    return g;\n  }\n},\n    sx = {\n  kernelName: \"FusedDepthwiseConv2D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s;\n    var g = Ab({\n      inputs: {\n        x: r,\n        filter: a\n      },\n      backend: n,\n      attrs: {\n        strides: l,\n        pad: u,\n        dataFormat: c,\n        dilations: h,\n        dimRoundingMode: d\n      }\n    });\n\n    if (i) {\n      var _e371 = g;\n      g = ng({\n        inputs: {\n          a: g,\n          b: i\n        },\n        backend: n\n      }), n.disposeIntermediateTensorInfo(_e371);\n    }\n\n    if (p) {\n      var _e372 = g;\n      g = zm(n, g, p, o, f), n.disposeIntermediateTensorInfo(_e372);\n    }\n\n    return g;\n  }\n},\n    rx = {\n  kernelName: \"GatherNd\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      params: s,\n      indices: r\n    } = t,\n        a = d(s.shape),\n        i = r.shape,\n        o = i[i.length - 1],\n        [l, u, c, h] = Nn(s, r);\n    if (0 === u) return n.makeTensorInfo(l, s.dtype, []);\n    var p = vg(n.data.get(r.dataId).values, n.bufferSync(s), s.dtype, u, o, c, h, s.shape, a);\n    return n.makeTensorInfo(l, s.dtype, p.values);\n  }\n},\n    ax = {\n  kernelName: \"GatherV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      indices: a\n    } = t,\n        {\n      axis: i,\n      batchDims: o\n    } = s;\n    zf([r, a], \"gatherV2\");\n    var l = o;\n    null == o && (l = 0);\n    var u = d(a.shape),\n        c = el(r, a, y(i, r.shape)[0], l),\n        h = Bm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [c.batchSize, c.outerSize, c.dimSize, c.sliceSize]\n      }\n    }),\n        p = Bm({\n      inputs: {\n        x: a\n      },\n      backend: n,\n      attrs: {\n        shape: [c.batchSize, u / c.batchSize]\n      }\n    }),\n        f = [c.batchSize, c.outerSize, u / c.batchSize, c.sliceSize],\n        g = n.bufferSync(p),\n        m = Ig(n.bufferSync(h), g, f);\n    return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(p), n.makeTensorInfo(c.outputShape, m.dtype, m.values);\n  }\n},\n    ix = {\n  kernelName: \"IFFT\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t,\n        r = d(s.shape),\n        a = s.shape[s.shape.length - 1],\n        i = Bm({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [r / a, a]\n      }\n    }),\n        o = Kb(i, !0, n),\n        l = Bm({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        shape: s.shape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(o), l;\n  }\n},\n    ox = {\n  kernelName: \"IsFinite\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"IsFinite\", e => Number.isFinite(e) ? 1 : 0, \"bool\")\n},\n    lx = {\n  kernelName: \"IsInf\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"IsInf\", e => Infinity === Math.abs(e) ? 1 : 0, \"bool\")\n},\n    ux = {\n  kernelName: \"IsNan\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"IsNan\", e => Number.isNaN(e) ? 1 : 0, \"bool\")\n},\n    cx = {\n  kernelName: \"LinSpace\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      num: a\n    } = n,\n        i = Fg(s, r, a);\n    return t.makeTensorInfo([i.length], \"float32\", i);\n  }\n},\n    hx = {\n  kernelName: \"Log1p\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Log1p\", e => Math.log1p(e))\n},\n    dx = {\n  kernelName: \"LogicalAnd\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"LogicalAnd\", Vf((e, t) => e && t), null, \"bool\")\n},\n    px = {\n  kernelName: \"LogicalNot\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"LogicalNot\", e => e ? 0 : 1, \"bool\")\n},\n    fx = {\n  kernelName: \"LogicalOr\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"LogicalOr\", Vf((e, t) => e || t), null, \"bool\")\n},\n    gx = {\n  kernelName: \"LRN\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = s;\n    zf(r, \"LRN\");\n    var u = r.shape[3],\n        c = u - 1,\n        h = n.data.get(r.dataId).values,\n        p = d(r.shape),\n        f = new Float32Array(p);\n\n    function g(e) {\n      var t = e % u;\n      var n = e - t + Math.max(0, t - a);\n      var s = e - t + Math.min(t + a, c);\n      var r = 0;\n\n      for (; n <= s; n++) {\n        var _e373 = h[n];\n        r += _e373 * _e373;\n      }\n\n      return r;\n    }\n\n    for (var _e374 = 0; _e374 < p; _e374++) {\n      var _t316 = g(_e374),\n          _n233 = h[_e374] * Math.pow(i + o * _t316, -l);\n\n      f[_e374] = _n233;\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, f);\n  }\n},\n    mx = {\n  kernelName: \"LRNGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      y: a,\n      dy: i\n    } = t,\n        {\n      depthRadius: o,\n      bias: l,\n      alpha: u,\n      beta: c\n    } = s;\n    zf(i, \"LRNGrad\");\n    var h = d(i.shape),\n        p = i.shape[3],\n        f = n.data.get(i.dataId).values,\n        g = n.data.get(r.dataId).values,\n        m = n.data.get(a.dataId).values,\n        b = new Float32Array(h),\n        x = h;\n\n    for (var _e375 = 0; _e375 < x; _e375++) {\n      var _t317 = _e375 % p,\n          _n234 = _e375 - _t317 + Math.max(0, _t317 - o),\n          _s186 = _e375 - _t317 + Math.min(p, _t317 + o + 1);\n\n      var _r137 = 0;\n\n      for (var _e376 = _n234; _e376 < _s186; _e376++) {\n        _r137 += Math.pow(g[_e376], 2);\n      }\n\n      _r137 = u * _r137 + l;\n\n      for (var _t318 = _n234; _t318 < _s186; _t318++) {\n        var _n235 = -2 * u * c * g[_t318] * m[_e375] / _r137;\n\n        _e375 === _t318 && (_n235 += Math.pow(_r137, -c)), _n235 *= f[_e375], b[_t318] += _n235;\n      }\n    }\n\n    return n.makeTensorInfo(i.shape, r.dtype, b);\n  }\n};\n\nfunction bx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reductionIndices: a,\n    keepDims: i\n  } = s,\n      o = n;\n  var l = r.shape;\n  var u = l.length,\n      c = y(a, l);\n  var h = c;\n  var p = Jr(h, u);\n  var f = o.data.get(r.dataId).values;\n\n  if (null != p) {\n    var _e377 = new Array(u);\n\n    for (var _t319 = 0; _t319 < _e377.length; _t319++) {\n      _e377[_t319] = l[p[_t319]];\n    }\n\n    f = Kg(f, l, r.dtype, p, _e377), h = Qr(h.length, u), l = _e377;\n  }\n\n  zf(r, \"max\"), Yr(\"max\", h, u);\n  var [g, m] = Kr(l, h),\n      b = Og(f, d(m), g, r.dtype),\n      x = o.write(b, g, r.dtype);\n  var k = g;\n  return i && (k = Xr(g, c)), {\n    dataId: x,\n    shape: k,\n    dtype: r.dtype\n  };\n}\n\nvar xx = {\n  kernelName: \"Max\",\n  backendName: \"cpu\",\n  kernelFunc: bx\n},\n    yx = {\n  kernelName: \"MaxPool\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    zf(r, \"maxPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ss(i, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = bs(r.shape, a, i, 1, o, u);\n    var h;\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) h = qf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });else {\n      var _e378 = n.data.get(r.dataId).values,\n          _t320 = A(r.shape),\n          _s187 = nb(_e378, 0, r.dtype, _t320, c, \"max\");\n\n      h = n.makeTensorInfo(c.outShape, r.dtype, _s187.values);\n    }\n    return h;\n  }\n},\n    kx = {\n  kernelName: \"MaxPool3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s;\n    zf(r, \"maxPool3d\");\n    var c = xs(r.shape, a, i, 1, o, l, u),\n        h = rb(n.data.get(r.dataId).values, 0, r.dtype, A(r.shape), c, \"max\");\n    return n.makeTensorInfo(h.shape, \"float32\", h.values);\n  }\n},\n    wx = {\n  kernelName: \"MaxPool3DGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        {\n      filterSize: i,\n      strides: o,\n      pad: l,\n      dimRoundingMode: u\n    } = s;\n    zf([r, a], \"maxPool3DGrad\");\n\n    var c = xs(a.shape, i, o, 1, l, u),\n        h = function (e, t) {\n      var n = dn(t.outShape, \"int32\"),\n          s = t.strideDepth,\n          r = t.strideHeight,\n          a = t.strideWidth,\n          i = t.dilationDepth,\n          o = t.dilationHeight,\n          l = t.dilationWidth,\n          u = t.effectiveFilterDepth,\n          c = t.effectiveFilterHeight,\n          h = t.effectiveFilterWidth,\n          d = t.padInfo.front,\n          p = t.padInfo.top,\n          f = t.padInfo.left;\n\n      for (var _g16 = 0; _g16 < t.batchSize; ++_g16) {\n        for (var _m11 = 0; _m11 < t.inChannels; ++_m11) {\n          for (var _b11 = 0; _b11 < t.outDepth; ++_b11) {\n            var _x54 = _b11 * s - d;\n\n            var _y9 = _x54;\n\n            for (; _y9 < 0;) {\n              _y9 += i;\n            }\n\n            var _k7 = Math.min(t.inDepth, u + _x54);\n\n            for (var _s188 = 0; _s188 < t.outHeight; ++_s188) {\n              var _u26 = _s188 * r - p;\n\n              var _d16 = _u26;\n\n              for (; _d16 < 0;) {\n                _d16 += o;\n              }\n\n              var _w7 = Math.min(t.inHeight, c + _u26);\n\n              for (var _r138 = 0; _r138 < t.outWidth; ++_r138) {\n                var _p12 = _r138 * a - f;\n\n                var _v5 = _p12;\n\n                for (; _v5 < 0;) {\n                  _v5 += l;\n                }\n\n                var _I4 = Math.min(t.inWidth, h + _p12);\n\n                var _$2 = Number.NEGATIVE_INFINITY,\n                    _N4 = -1;\n\n                for (var _t321 = _y9; _t321 < _k7; _t321 += i) {\n                  var _n236 = _t321 - _x54;\n\n                  for (var _s189 = _d16; _s189 < _w7; _s189 += o) {\n                    var _r139 = _s189 - _u26;\n\n                    for (var _a106 = _v5; _a106 < _I4; _a106 += l) {\n                      var _i77 = _a106 - _p12,\n                          _o57 = e.get(_g16, _t321, _s189, _a106, _m11);\n\n                      _o57 >= _$2 && (_$2 = _o57, _N4 = _n236 * c * h + _r139 * c + _i77);\n                    }\n                  }\n                }\n\n                n.set(_N4, _g16, _b11, _s188, _r138, _m11);\n              }\n            }\n          }\n        }\n      }\n\n      return n;\n    }(n.bufferSync(a), c),\n        d = c.strideDepth,\n        p = c.strideHeight,\n        f = c.strideWidth,\n        g = c.dilationDepth,\n        m = c.dilationHeight,\n        b = c.dilationWidth,\n        x = c.effectiveFilterDepth,\n        y = c.effectiveFilterHeight,\n        k = c.effectiveFilterWidth,\n        w = x - 1 - c.padInfo.front,\n        v = k - 1 - c.padInfo.left,\n        I = y - 1 - c.padInfo.top,\n        $ = dn(a.shape, \"float32\"),\n        N = n.bufferSync(r);\n\n    for (var _e379 = 0; _e379 < c.batchSize; ++_e379) {\n      for (var _t322 = 0; _t322 < c.inChannels; ++_t322) {\n        for (var _n237 = 0; _n237 < c.inDepth; ++_n237) {\n          for (var _s190 = 0; _s190 < c.inHeight; ++_s190) {\n            for (var _r140 = 0; _r140 < c.inWidth; ++_r140) {\n              var _a107 = _n237 - w,\n                  _i78 = _s190 - I,\n                  _o58 = _r140 - v;\n\n              var _l41 = 0;\n\n              for (var _n238 = 0; _n238 < x; _n238 += g) {\n                var _s191 = (_a107 + _n238) / d;\n\n                if (!(_s191 < 0 || _s191 >= c.outDepth || Math.floor(_s191) !== _s191)) for (var _r141 = 0; _r141 < y; _r141 += m) {\n                  var _a108 = (_i78 + _r141) / p;\n\n                  if (!(_a108 < 0 || _a108 >= c.outHeight || Math.floor(_a108) !== _a108)) for (var _i79 = 0; _i79 < k; _i79 += b) {\n                    var _u27 = (_o58 + _i79) / f;\n\n                    if (_u27 < 0 || _u27 >= c.outWidth || Math.floor(_u27) !== _u27) continue;\n\n                    var _d17 = x * y * k - 1 - h.get(_e379, _s191, _a108, _u27, _t322) === _n238 * y * k + _r141 * k + _i79 ? 1 : 0;\n\n                    0 !== _d17 && (_l41 += N.get(_e379, _s191, _a108, _u27, _t322) * _d17);\n                  }\n                }\n              }\n\n              $.set(_l41, _e379, _n237, _s190, _r140, _t322);\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo($.shape, $.dtype, $.values);\n  }\n},\n    vx = {\n  kernelName: \"MaxPoolGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a,\n      output: i\n    } = t,\n        o = a;\n    zf([a, i], \"maxPoolGrad\");\n    var {\n      filterSize: l,\n      strides: u,\n      pad: c,\n      dimRoundingMode: h\n    } = s,\n        d = bs(o.shape, l, u, 1, c, h),\n        p = n.data.get(o.dataId).values,\n        f = dn(d.outShape, o.dtype, sb(p, o.shape, o.dtype, d).values),\n        g = d.strideHeight,\n        m = d.strideWidth,\n        b = d.dilationHeight,\n        x = d.dilationWidth,\n        y = d.effectiveFilterHeight,\n        k = d.effectiveFilterWidth,\n        w = k - 1 - d.padInfo.left,\n        v = y - 1 - d.padInfo.top,\n        I = dn(o.shape, \"float32\"),\n        $ = n.data.get(r.dataId).values,\n        N = dn(r.shape, \"float32\", $);\n\n    for (var _e380 = 0; _e380 < d.batchSize; ++_e380) {\n      for (var _t323 = 0; _t323 < d.inChannels; ++_t323) {\n        for (var _n239 = 0; _n239 < d.inHeight; ++_n239) {\n          for (var _s192 = 0; _s192 < d.inWidth; ++_s192) {\n            var _r142 = _n239 - v,\n                _a109 = _s192 - w;\n\n            var _i80 = 0;\n\n            for (var _n240 = 0; _n240 < y; _n240 += b) {\n              var _s193 = (_r142 + _n240) / g;\n\n              if (!(_s193 < 0 || _s193 >= d.outHeight || Math.floor(_s193) !== _s193)) for (var _r143 = 0; _r143 < k; _r143 += x) {\n                var _o59 = (_a109 + _r143) / m;\n\n                if (_o59 < 0 || _o59 >= d.outWidth || Math.floor(_o59) !== _o59) continue;\n\n                var _l42 = y * k - 1 - f.get(_e380, _s193, _o59, _t323) === _n240 * k + _r143 ? 1 : 0;\n\n                0 !== _l42 && (_i80 += N.get(_e380, _s193, _o59, _t323) * _l42);\n              }\n            }\n\n            I.set(_i80, _e380, _n239, _s192, _t323);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(I.shape, I.dtype, I.values);\n  }\n},\n    Ix = {\n  kernelName: \"MaxPoolWithArgmax\",\n  backendName: \"cpu\",\n  kernelFunc: _ref17 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref17;\n    var {\n      x: s\n    } = e,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      includeBatchInIndex: o\n    } = t,\n        l = n;\n    zf(s, \"MaxPoolWithArgmax\");\n\n    var u = l.data.get(s.dataId).values,\n        c = bs(s.shape, r, a, [1, 1], i),\n        [h, d] = function (e, t, n, s, r) {\n      var a = nb(e, 0, n, A(t), r, \"max\"),\n          i = sb(e, t, n, r, !0, s);\n      return [a.values, i.values];\n    }(u, s.shape, s.dtype, o, c),\n        p = l.write(h, c.outShape, s.dtype),\n        f = l.write(d, c.outShape, s.dtype);\n\n    return [{\n      dataId: p,\n      shape: c.outShape,\n      dtype: s.dtype\n    }, {\n      dataId: f,\n      shape: c.outShape,\n      dtype: \"int32\"\n    }];\n  }\n},\n    $x = {\n  kernelName: \"Mean\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = y(a, r.shape),\n        l = d(Kr(r.shape, o)[1]),\n        u = [],\n        c = n.makeTensorInfo([], \"float32\", new Float32Array([l]));\n    u.push(c);\n    var h = Jf({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        dtype: \"float32\"\n      }\n    });\n    u.push(h);\n    var p = jb({\n      inputs: {\n        a: h,\n        b: c\n      },\n      backend: n\n    });\n    u.push(p);\n    var f = Bb({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        axis: a,\n        keepDims: i\n      }\n    });\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), f;\n  }\n},\n    Nx = {\n  kernelName: \"Min\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    zf(r, \"min\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Jr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Xg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = Qr(l.length, r.shape.length)), Yr(\"min\", l, c.shape.length);\n    var [h, p] = Kr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e381 = 0; _e381 < g.length; ++_e381) {\n      var _t324 = _e381 * f;\n\n      var _n241 = m[_t324];\n\n      for (var _e382 = 0; _e382 < f; ++_e382) {\n        var _s194 = m[_t324 + _e382];\n        (Number.isNaN(_s194) || _s194 < _n241) && (_n241 = _s194);\n      }\n\n      g[_e381] = _n241;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e383 = Bm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Xr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e383;\n    }\n\n    return b;\n  }\n},\n    Cx = {\n  kernelName: \"MirrorPad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      paddings: a,\n      mode: i\n    } = s;\n    zf(r, \"mirrorPad\");\n    var o = a.map((e, t) => e[0] + r.shape[t] + e[1]),\n        l = a.map(e => e[0]),\n        u = a.map((e, t) => e[0] + r.shape[t]),\n        c = \"reflect\" === i ? 0 : 1,\n        h = n.data.get(r.dataId).values,\n        p = r.shape.length,\n        f = A(r.shape),\n        g = d(o),\n        m = o.length,\n        b = A(o),\n        x = w(r.dtype, g);\n\n    for (var _e384 = 0; _e384 < g; _e384++) {\n      var _t325 = B(_e384, m, b);\n\n      for (var _e385 = 0; _e385 < m; _e385++) {\n        _t325[_e385] < l[_e385] ? _t325[_e385] = 2 * l[_e385] - _t325[_e385] - c : _t325[_e385] >= u[_e385] && (_t325[_e385] = 2 * (u[_e385] - 1) - _t325[_e385] + c);\n      }\n\n      _t325 = _t325.map((e, t) => e - l[t]);\n\n      var _n242 = z(_t325, p, f);\n\n      x[_e384] = h[_n242];\n    }\n\n    return {\n      dataId: n.write(x, o, r.dtype),\n      shape: o,\n      dtype: r.dtype\n    };\n  }\n},\n    Sx = {\n  kernelName: \"Mod\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Mod\", Vf((e, t) => {\n    var n = e % t;\n    return e < 0 && t < 0 || e >= 0 && t >= 0 ? n : (n + t) % t;\n  }))\n};\n\nfunction Tx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    logits: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = r.shape.length;\n  var o = a;\n  if (-1 === o && (o = i - 1), o !== i - 1) throw Error(\"Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(i, \" and dim was \").concat(o));\n  var l = y([o], r.shape),\n      u = bx({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      reductionIndices: l,\n      keepDims: !1\n    }\n  }),\n      c = Xr(u.shape, l),\n      h = Bm({\n    inputs: {\n      x: u\n    },\n    backend: n,\n    attrs: {\n      shape: c\n    }\n  }),\n      d = bm({\n    inputs: {\n      a: r,\n      b: h\n    },\n    backend: n\n  }),\n      p = mg({\n    inputs: {\n      x: d\n    },\n    backend: n\n  }),\n      f = Bb({\n    inputs: {\n      x: p\n    },\n    backend: n,\n    attrs: {\n      axis: l,\n      keepDims: !1\n    }\n  }),\n      g = Bm({\n    inputs: {\n      x: f\n    },\n    backend: n,\n    attrs: {\n      shape: c\n    }\n  }),\n      m = jb({\n    inputs: {\n      a: p,\n      b: g\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n}\n\nvar Ex = {\n  kernelName: \"Softmax\",\n  backendName: \"cpu\",\n  kernelFunc: Tx\n},\n    Rx = {\n  kernelName: \"Multinomial\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      logits: r\n    } = t,\n        {\n      numSamples: a,\n      seed: i,\n      normalized: o\n    } = s;\n    zf(r, \"multinomial\");\n    var l = o ? r : Tx({\n      inputs: {\n        logits: r\n      },\n      backend: n,\n      attrs: {\n        dim: -1\n      }\n    }),\n        u = l.shape[0],\n        c = l.shape[1],\n        h = n.data.get(l.dataId).values,\n        p = [u, a],\n        f = O(d(p), \"int32\");\n\n    for (var _e386 = 0; _e386 < u; ++_e386) {\n      var _t326 = _e386 * c,\n          _n243 = new Float32Array(c - 1);\n\n      _n243[0] = h[_t326];\n\n      for (var _e387 = 1; _e387 < _n243.length; ++_e387) {\n        _n243[_e387] = _n243[_e387 - 1] + h[_t326 + _e387];\n      }\n\n      var _s195 = _a.alea(i.toString()),\n          _r144 = _e386 * a;\n\n      for (var _e388 = 0; _e388 < a; ++_e388) {\n        var _t327 = _s195();\n\n        f[_r144 + _e388] = _n243.length;\n\n        for (var _s196 = 0; _s196 < _n243.length; _s196++) {\n          if (_t327 < _n243[_s196]) {\n            f[_r144 + _e388] = _s196;\n            break;\n          }\n        }\n      }\n    }\n\n    return o || n.disposeIntermediateTensorInfo(l), n.makeTensorInfo(p, \"int32\", f);\n  }\n},\n    Ax = ji,\n    Fx = {\n  kernelName: \"NonMaxSuppressionV3\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l\n    } = s;\n    zf(r, \"NonMaxSuppression\");\n    var u = n.data.get(r.dataId).values,\n        c = n.data.get(a.dataId).values,\n        {\n      selectedIndices: h\n    } = Ax(u, c, i, o, l);\n    return n.makeTensorInfo([h.length], \"int32\", new Int32Array(h));\n  }\n},\n    Dx = qi,\n    _x = {\n  kernelName: \"NonMaxSuppressionV4\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      padToMaxOutputSize: u\n    } = s;\n    zf(r, \"NonMaxSuppressionPadded\");\n    var c = n.data.get(r.dataId).values,\n        h = n.data.get(a.dataId).values,\n        {\n      selectedIndices: d,\n      validOutputs: p\n    } = Dx(c, h, i, o, l, u);\n    return [n.makeTensorInfo([d.length], \"int32\", new Int32Array(d)), n.makeTensorInfo([], \"int32\", new Int32Array([p]))];\n  }\n},\n    Ox = Ki,\n    Mx = {\n  kernelName: \"NonMaxSuppressionV5\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      softNmsSigma: u\n    } = s;\n    zf(r, \"NonMaxSuppressionWithScore\");\n    var c = n.data.get(r.dataId).values,\n        h = n.data.get(a.dataId).values,\n        d = i,\n        p = o,\n        f = l,\n        g = u,\n        {\n      selectedIndices: m,\n      selectedScores: b\n    } = Ox(c, h, d, p, f, g);\n    return [n.makeTensorInfo([m.length], \"int32\", new Int32Array(m)), n.makeTensorInfo([b.length], \"float32\", new Float32Array(b))];\n  }\n},\n    Lx = {\n  kernelName: \"OneHot\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r\n    } = t,\n        {\n      depth: a,\n      onValue: i,\n      offValue: o\n    } = s;\n    zf(r, \"oneHot\");\n    var l = d(r.shape),\n        u = new Float32Array(l * a);\n    u.fill(o);\n    var c = n.data.get(r.dataId).values;\n\n    for (var _e389 = 0; _e389 < l; ++_e389) {\n      c[_e389] >= 0 && c[_e389] < a && (u[_e389 * a + c[_e389]] = i);\n    }\n\n    return n.makeTensorInfo([...r.shape, a], \"int32\", u);\n  }\n};\n\nfunction zx(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  if (\"string\" === s.dtype) throw new Error(\"zerosLike is not supported for string tensors\");\n\n  if (\"complex64\" === s.dtype) {\n    var _e390 = Xf({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _t328 = zx({\n      inputs: {\n        x: _e390\n      },\n      backend: n\n    }),\n        _r145 = fb({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _a110 = zx({\n      inputs: {\n        x: _r145\n      },\n      backend: n\n    }),\n        _i81 = Gf({\n      inputs: {\n        real: _t328,\n        imag: _a110\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e390), n.disposeIntermediateTensorInfo(_t328), n.disposeIntermediateTensorInfo(_r145), n.disposeIntermediateTensorInfo(_a110), _i81;\n  }\n\n  return Zb({\n    backend: n,\n    attrs: {\n      shape: s.shape,\n      value: 0,\n      dtype: s.dtype\n    }\n  });\n}\n\nvar Bx = {\n  kernelName: \"ZerosLike\",\n  backendName: \"cpu\",\n  kernelFunc: zx\n},\n    Px = {\n  kernelName: \"OnesLike\",\n  backendName: \"cpu\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        {\n      x: r\n    } = n;\n    if (\"string\" === r.dtype) throw new Error(\"onesLike is not supported for string tensors\");\n\n    if (\"complex64\" === r.dtype) {\n      var _t329 = Xf({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _n244 = e({\n        inputs: {\n          x: _t329\n        },\n        backend: s\n      }),\n          _a111 = fb({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _i82 = zx({\n        inputs: {\n          x: _a111\n        },\n        backend: s\n      }),\n          _o60 = Gf({\n        inputs: {\n          real: _n244,\n          imag: _i82\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_t329), s.disposeIntermediateTensorInfo(_n244), s.disposeIntermediateTensorInfo(_a111), s.disposeIntermediateTensorInfo(_i82), _o60;\n    }\n\n    return Zb({\n      backend: s,\n      attrs: {\n        shape: r.shape,\n        value: 1,\n        dtype: r.dtype\n      }\n    });\n  }\n};\n\nfunction Wx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s;\n  if (1 === t.length) return Gb({\n    inputs: {\n      input: t[0]\n    },\n    backend: n,\n    attrs: {\n      dim: r\n    }\n  });\n  var a = t[0].shape,\n      i = t[0].dtype;\n  t.forEach(e => {\n    u(a, e.shape, \"All tensors passed to stack must have matching shapes\"), l(i === e.dtype, () => \"All tensors passed to stack must have matching dtypes\");\n  });\n  var o = [],\n      c = mb({\n    inputs: t.map(e => {\n      var t = Gb({\n        inputs: {\n          input: e\n        },\n        backend: n,\n        attrs: {\n          dim: r\n        }\n      });\n      return o.push(t), t;\n    }),\n    backend: n,\n    attrs: {\n      axis: r\n    }\n  });\n  return o.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n}\n\nvar Ux = {\n  kernelName: \"Pack\",\n  backendName: \"cpu\",\n  kernelFunc: Wx\n},\n    Vx = {\n  kernelName: \"PadV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      paddings: a,\n      constantValue: i\n    } = s;\n    zf(r, \"pad\");\n    var o = a.map((e, t) => e[0] + r.shape[t] + e[1]),\n        l = a.map(e => e[0]),\n        u = n.data.get(r.dataId).values,\n        c = d(r.shape),\n        h = r.shape.length,\n        p = A(r.shape),\n        f = d(o),\n        g = o.length,\n        m = A(o),\n        b = w(r.dtype, f);\n    0 !== i && b.fill(i);\n\n    for (var _e391 = 0; _e391 < c; _e391++) {\n      b[z(B(_e391, h, p).map((e, t) => e + l[t]), g, m)] = u[_e391];\n    }\n\n    return {\n      dataId: n.write(b, o, r.dtype),\n      shape: o,\n      dtype: r.dtype\n    };\n  }\n},\n    Gx = {\n  kernelName: \"Pow\",\n  backendName: \"cpu\",\n  kernelFunc: Qf(\"Pow\", Vf((e, t) => Math.pow(e, t)))\n},\n    Hx = {\n  kernelName: \"Range\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      dtype: a,\n      step: i\n    } = n,\n        o = Qg(s, r, i, a);\n    return t.makeTensorInfo([o.length], a, o);\n  }\n},\n    jx = {\n  kernelName: \"Reciprocal\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Reciprocal\", e => 1 / e)\n},\n    qx = {\n  kernelName: \"ResizeBilinear\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s;\n    zf(r, \"resizeBilinear\");\n    var l = A(r.shape),\n        [u, c] = o,\n        [h, p, f, g] = r.shape,\n        m = n.data.get(r.dataId).values,\n        b = new Float32Array(d([h, u, c, g])),\n        x = [a && u > 1 ? p - 1 : p, a && c > 1 ? f - 1 : f],\n        y = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c];\n    var k = 0;\n    var w = x[0] / y[0],\n        v = x[1] / y[1];\n\n    for (var _e392 = 0; _e392 < h; _e392++) {\n      for (var _t330 = 0; _t330 < u; _t330++) {\n        var _n245 = void 0;\n\n        _n245 = i ? w * (_t330 + .5) - .5 : w * _t330;\n\n        var _s197 = Math.max(0, Math.floor(_n245)),\n            _r146 = _n245 - _s197,\n            _a112 = Math.min(p - 1, Math.ceil(_n245)),\n            _o61 = _e392 * l[0] + _s197 * l[1],\n            _u28 = _e392 * l[0] + _a112 * l[1];\n\n        for (var _e393 = 0; _e393 < c; _e393++) {\n          var _t331 = void 0;\n\n          _t331 = i ? v * (_e393 + .5) - .5 : v * _e393;\n\n          var _n246 = Math.max(0, Math.floor(_t331)),\n              _s198 = _t331 - _n246,\n              _a113 = Math.min(f - 1, Math.ceil(_t331)),\n              _c27 = _o61 + _n246 * l[2],\n              _h15 = _u28 + _n246 * l[2],\n              _d18 = _o61 + _a113 * l[2],\n              _p13 = _u28 + _a113 * l[2];\n\n          for (var _e394 = 0; _e394 < g; _e394++) {\n            var _t332 = m[_c27 + _e394],\n                _n247 = m[_h15 + _e394],\n                _a114 = _t332 + (m[_d18 + _e394] - _t332) * _s198;\n\n            b[k++] = _a114 + (_n247 + (m[_p13 + _e394] - _n247) * _s198 - _a114) * _r146;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([h, u, c, g], \"float32\", b);\n  }\n},\n    Kx = {\n  kernelName: \"ResizeBilinearGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s;\n    zf([a, r], \"resizeBilinearGrad\");\n    var o = A(r.shape),\n        [l, u, c, h] = r.shape,\n        [, d, p] = a.shape,\n        f = new Float32Array(l * u * c * h),\n        g = [i && d > 1 ? u - 1 : u, i && p > 1 ? c - 1 : c],\n        m = [i && d > 1 ? d - 1 : d, i && p > 1 ? p - 1 : p],\n        b = g[0] / m[0],\n        x = g[1] / m[1],\n        y = n.data.get(a.dataId).values;\n    var k = 0;\n\n    for (var _e395 = 0; _e395 < l; _e395++) {\n      var _t333 = _e395 * o[0];\n\n      for (var _e396 = 0; _e396 < d; _e396++) {\n        var _n248 = _e396 * b,\n            _s199 = Math.floor(_n248),\n            _r147 = Math.min(Math.ceil(_n248), u - 1),\n            _a115 = _t333 + _s199 * o[1],\n            _i83 = _t333 + _r147 * o[1],\n            _l43 = _n248 - _s199,\n            _d19 = 1 - _l43;\n\n        for (var _e397 = 0; _e397 < p; _e397++) {\n          var _t334 = _e397 * x,\n              _n249 = Math.floor(_t334),\n              _s200 = Math.min(Math.ceil(_t334), c - 1),\n              _r148 = _t334 - _n249,\n              _u29 = 1 - _r148,\n              _p14 = _a115 + _n249 * o[2],\n              _g17 = _a115 + _s200 * o[2],\n              _m12 = _i83 + _n249 * o[2],\n              _b12 = _i83 + _s200 * o[2],\n              _w8 = _d19 * _u29,\n              _v6 = _d19 * _r148,\n              _I5 = _l43 * _u29,\n              _$3 = _l43 * _r148;\n\n          for (var _e398 = 0; _e398 < h; _e398++) {\n            var _t335 = y[k++];\n            f[_p14 + _e398] += _t335 * _w8, f[_g17 + _e398] += _t335 * _v6, f[_m12 + _e398] += _t335 * _I5, f[_b12 + _e398] += _t335 * _$3;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([l, c, u, h], \"float32\", f);\n  }\n},\n    Xx = {\n  kernelName: \"ResizeNearestNeighbor\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s;\n    zf(r, \"resizeNearestNeighbor\");\n    var l = A(r.shape),\n        [u, c] = o,\n        [h, d, p, f] = r.shape,\n        g = n.data.get(r.dataId).values,\n        m = new Float32Array(h * u * c * f),\n        b = [a && u > 1 ? d - 1 : d, a && c > 1 ? p - 1 : p],\n        x = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c],\n        y = b[0] / x[0],\n        k = b[1] / x[1];\n    var w = 0;\n\n    for (var _e399 = 0; _e399 < h; _e399++) {\n      var _t336 = _e399 * l[0];\n\n      for (var _e400 = 0; _e400 < u; _e400++) {\n        var _n250 = i ? y * (_e400 + .5) : y * _e400;\n\n        var _s201 = Math.min(d - 1, a ? Math.round(_n250) : Math.floor(_n250));\n\n        i && (_s201 = Math.max(0, _s201));\n\n        var _r149 = _t336 + _s201 * l[1];\n\n        for (var _e401 = 0; _e401 < c; _e401++) {\n          var _t337 = i ? k * (_e401 + .5) : k * _e401;\n\n          var _n251 = Math.min(p - 1, a ? Math.round(_t337) : Math.floor(_t337));\n\n          i && (_n251 = Math.max(0, _n251));\n\n          var _s202 = _r149 + _n251 * l[2];\n\n          for (var _e402 = 0; _e402 < f; _e402++) {\n            m[w++] = g[_s202 + _e402];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([h, u, c, f], r.dtype, m);\n  }\n},\n    Yx = {\n  kernelName: \"ResizeNearestNeighborGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s;\n    zf([a, r], \"resizeNearestNeighborGrad\");\n    var o = A(r.shape),\n        l = A(a.shape),\n        [u, c, h, d] = r.shape,\n        [, p, f] = a.shape,\n        g = new Float32Array(u * c * h * d),\n        m = n.data.get(a.dataId).values,\n        b = [i && p > 1 ? c - 1 : c, i && f > 1 ? h - 1 : h],\n        x = [i && p > 1 ? p - 1 : p, i && f > 1 ? f - 1 : f],\n        y = b[0] / x[0],\n        k = b[1] / x[1],\n        w = 1 / y,\n        v = 1 / k,\n        I = 2 * Math.ceil(w) + 2,\n        $ = 2 * Math.ceil(v) + 2;\n\n    for (var _e403 = 0; _e403 < u; _e403++) {\n      var _t338 = _e403 * o[0];\n\n      for (var _e404 = 0; _e404 < c; _e404++) {\n        var _n252 = _t338 + _e404 * o[1],\n            _s203 = Math.floor(_e404 * w),\n            _r150 = Math.floor(_s203 - I / 2);\n\n        for (var _s204 = 0; _s204 < h; _s204++) {\n          var _a116 = _n252 + _s204 * o[2],\n              _u30 = Math.floor(_s204 * v),\n              _b13 = Math.floor(_u30 - $ / 2);\n\n          for (var _n253 = 0; _n253 < d; _n253++) {\n            var _o62 = 0;\n\n            for (var _a117 = 0; _a117 < I; _a117++) {\n              var _u31 = _a117 + _r150;\n\n              if (_u31 < 0 || _u31 >= p) continue;\n\n              var _d20 = _t338 + _u31 * l[1],\n                  _g18 = _u31 * y;\n\n              if (_e404 === Math.min(c - 1, i ? Math.round(_g18) : Math.floor(_g18))) for (var _e405 = 0; _e405 < $; _e405++) {\n                var _t339 = _e405 + _b13;\n\n                if (_t339 < 0 || _t339 >= f) continue;\n\n                var _r151 = _d20 + _t339 * l[2],\n                    _a118 = _t339 * k;\n\n                _s204 === Math.min(h - 1, i ? Math.round(_a118) : Math.floor(_a118)) && (_o62 += m[_r151 + _n253]);\n              }\n            }\n\n            g[_a116 + _n253] = _o62;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, g);\n  }\n},\n    Jx = {\n  kernelName: \"Reverse\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      dims: a\n    } = s;\n    zf(r, \"reverse\");\n    var i = r.shape.length,\n        o = y(a, r.shape);\n    if (0 === i) return qf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var l = new et(r.shape, r.dtype),\n        u = n.bufferSync(r);\n\n    var _loop31 = function _loop31(_e406) {\n      var t = l.indexToLoc(_e406),\n          n = t.slice();\n      o.forEach(e => n[e] = r.shape[e] - 1 - n[e]), l.set(u.get(...n), ...t);\n    };\n\n    for (var _e406 = 0; _e406 < l.size; _e406++) {\n      _loop31(_e406);\n    }\n\n    return n.makeTensorInfo(l.shape, l.dtype, l.values);\n  }\n},\n    Zx = {\n  kernelName: \"RotateWithOffset\",\n  backendName: \"cpu\",\n  kernelFunc: _ref18 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref18;\n    var {\n      image: s\n    } = e,\n        {\n      radians: r,\n      fillValue: a,\n      center: i\n    } = t,\n        o = n,\n        l = w(s.dtype, d(s.shape)),\n        [u, c, h, p] = s.shape,\n        [f, g] = Eo(i, c, h),\n        m = Math.sin(r),\n        b = Math.cos(r),\n        x = o.data.get(s.dataId).values;\n\n    for (var _e407 = 0; _e407 < u; _e407++) {\n      var _t340 = _e407 * h * c * p;\n\n      for (var _e408 = 0; _e408 < c; _e408++) {\n        var _n254 = _e408 * (h * p);\n\n        for (var _s205 = 0; _s205 < h; _s205++) {\n          var _r152 = _s205 * p;\n\n          for (var _i84 = 0; _i84 < p; _i84++) {\n            var _o63 = [u, _e408, _s205, _i84],\n                _d21 = _o63[2],\n                _y10 = _o63[1];\n\n            var _k8 = (_d21 - f) * b - (_y10 - g) * m,\n                _w9 = (_d21 - f) * m + (_y10 - g) * b;\n\n            _k8 = Math.round(_k8 + f), _w9 = Math.round(_w9 + g);\n            var _v7 = a;\n            \"number\" != typeof a && (_v7 = 3 === _i84 ? 255 : a[_i84]), _k8 >= 0 && _k8 < h && _w9 >= 0 && _w9 < c && (_v7 = x[_t340 + _w9 * (h * p) + _k8 * p + _i84]), l[_t340 + _n254 + _r152 + _i84] = _v7;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: o.write(l, s.shape, s.dtype),\n      shape: s.shape,\n      dtype: s.dtype\n    };\n  }\n},\n    Qx = {\n  kernelName: \"Round\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Round\", e => {\n    var t = Math.floor(e);\n    return e - t < .5 ? Math.floor(e) : e - t > .5 ? Math.ceil(e) : t % 2 == 0 ? t : t + 1;\n  })\n};\n\nfunction ey(e, t, n, s, r, a, i, o, l, u) {\n  var c = [s / r, r],\n      h = e.values,\n      d = t.values;\n  if (0 === s) return dn(n, t.dtype);\n  var p = dn(c, t.dtype);\n  p.values.fill(l);\n\n  for (var _e409 = 0; _e409 < a; _e409++) {\n    var _a119 = [];\n    var _l44 = 0;\n\n    for (var _t341 = 0; _t341 < i; _t341++) {\n      var _n255 = h[_e409 * i + _t341];\n      _a119.push(_n255), _l44 += _n255 * o[_t341];\n    }\n\n    if (_l44 < 0 || _l44 >= s / r) throw new Error(\"Invalid indices: \".concat(_a119, \" does not index into \").concat(n));\n\n    for (var _n256 = 0; _n256 < r; _n256++) {\n      u ? p.values[_l44 * r + _n256] += d[_e409 * r + _n256] : p.values[_l44 * r + _n256] = 0 === t.rank ? d[0] : d[_e409 * r + _n256];\n    }\n  }\n\n  return p;\n}\n\nvar ty = {\n  kernelName: \"ScatterNd\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r,\n      updates: a\n    } = t,\n        {\n      shape: i\n    } = s,\n        {\n      sliceRank: o,\n      numUpdates: l,\n      sliceSize: u,\n      strides: c,\n      outputSize: h\n    } = Sn(0, r, i),\n        d = ey(n.bufferSync(r), n.bufferSync(a), i, h, u, l, o, c, 0, !0);\n    return n.makeTensorInfo(i, d.dtype, d.values);\n  }\n},\n    ny = {\n  kernelName: \"Select\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      condition: s,\n      t: r,\n      e: a\n    } = t;\n    zf([s, r, a], \"select\");\n    var i = s.shape.length,\n        o = n.data.get(s.dataId).values,\n        l = n.data.get(r.dataId).values,\n        u = n.data.get(a.dataId).values,\n        c = dt(r.dtype, a.dtype),\n        h = O(d(r.shape), c);\n    var p = 0;\n    var f = 0 === i || i > 1 || 1 === r.shape.length ? 1 : d(r.shape.slice(1));\n\n    for (var _e410 = 0; _e410 < o.length; _e410++) {\n      for (var _t342 = 0; _t342 < f; _t342++) {\n        h[p++] = 1 === o[_e410] ? l[_e410] : u[_e410];\n      }\n    }\n\n    return n.makeTensorInfo(r.shape, c, h);\n  }\n},\n    sy = {\n  kernelName: \"Selu\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Selu\", e => e >= 0 ? 1.0507009873554805 * e : 1.7580993408473768 * (Math.exp(e) - 1))\n},\n    ry = {\n  kernelName: \"Sign\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Sign\", e => e < 0 ? -1 : e > 0 ? 1 : 0)\n},\n    ay = {\n  kernelName: \"Sin\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Sin\", e => Math.sin(e))\n},\n    iy = {\n  kernelName: \"Sinh\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Sinh\", e => Math.sinh(e))\n},\n    oy = Math.log(1.1920928955078125e-7) + 2,\n    ly = {\n  kernelName: \"Softplus\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Softplus\", e => {\n    var t = e > -oy,\n        n = e < oy,\n        s = Math.exp(e);\n    var r;\n    return r = n ? s : t ? e : Math.log(1 + s), r;\n  })\n},\n    uy = {\n  kernelName: \"SpaceToBatchND\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      paddings: i\n    } = s;\n    zf([r], \"spaceToBatchND\");\n    var o = d(a),\n        l = [[0, 0]];\n    l.push(...i);\n\n    for (var _e411 = 1 + a.length; _e411 < r.shape.length; ++_e411) {\n      l.push([0, 0]);\n    }\n\n    var u = Vx.kernelFunc({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        paddings: l,\n        constantValue: 0\n      }\n    }),\n        c = Ro(u.shape, a, o, !1),\n        h = Ao(c.length, a.length, !1),\n        p = Fo(u.shape, a, o, !1),\n        f = Bm({\n      inputs: {\n        x: u\n      },\n      backend: n,\n      attrs: {\n        shape: c\n      }\n    }),\n        g = Xg({\n      inputs: {\n        x: f\n      },\n      backend: n,\n      attrs: {\n        perm: h\n      }\n    }),\n        m = Bm({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    });\n    return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n  }\n},\n    cy = {\n  kernelName: \"SparseFillEmptyRows\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      indices: s,\n      values: r,\n      denseShape: a,\n      defaultValue: i\n    } = t;\n    if (1 !== a.shape.length) throw new Error(\"Dense shape must be a vector, saw:\\n        \".concat(a.shape));\n    if (2 !== s.shape.length) throw new Error(\"Indices must be a matrix, saw:\\n        \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Values must be a vector, saw:\\n        \".concat(r.shape));\n    if (0 !== i.shape.length) throw new Error(\"Default value must be a scalar, saw:\\n        \".concat(i.shape));\n    var o = n.data.get(s.dataId).values,\n        l = n.data.get(r.dataId).values,\n        u = n.data.get(a.dataId).values,\n        c = n.data.get(i.dataId).values[0],\n        [h, d, p, f, g] = am(o, s.shape, s.dtype, l, r.dtype, u, c);\n    return [n.makeTensorInfo(d, s.dtype, h), n.makeTensorInfo([d[0]], r.dtype, p), n.makeTensorInfo([f.length], \"bool\", new Uint8Array(f.map(e => Number(e)))), n.makeTensorInfo([g.length], s.dtype, new Int32Array(g))];\n  }\n},\n    hy = {\n  kernelName: \"SparseReshape\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    } = t;\n    if (2 !== s.shape.length) throw new Error(\"Input indices should be a matrix but received shape\\n        \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Input shape should be a vector but received shape\\n        \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Target shape should be a vector but received shape \".concat(a.shape));\n    var i = Array.from(n.data.get(r.dataId).values),\n        o = n.data.get(s.dataId).values,\n        l = Array.from(n.data.get(a.dataId).values),\n        [u, c, h] = im(o, s.shape, s.dtype, i, l);\n    return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))];\n  }\n},\n    dy = {\n  kernelName: \"SparseSegmentMean\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n          \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n          \".concat(a.shape));\n    var i = n.data.get(s.dataId).values,\n        o = n.data.get(r.dataId).values,\n        l = n.data.get(a.dataId).values,\n        [u, c] = om(i, s.shape, s.dtype, o, l, !0);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    py = {\n  kernelName: \"SparseSegmentSum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n         \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n         \".concat(a.shape));\n    var i = n.data.get(s.dataId).values,\n        o = n.data.get(r.dataId).values,\n        l = n.data.get(a.dataId).values,\n        [u, c] = om(i, s.shape, s.dtype, o, l);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    fy = {\n  kernelName: \"SparseToDense\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      sparseIndices: r,\n      sparseValues: a,\n      defaultValue: i\n    } = t,\n        {\n      outputShape: o\n    } = s,\n        {\n      sliceRank: l,\n      numUpdates: u,\n      sliceSize: c,\n      strides: h,\n      outputSize: d\n    } = Sn(0, r, o),\n        p = ey(n.bufferSync(r), n.bufferSync(a), o, d, c, u, l, h, n.data.get(i.dataId).values[0], !1);\n    return n.makeTensorInfo(o, p.dtype, p.values);\n  }\n},\n    gy = {\n  kernelName: \"SplitV\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      numOrSizeSplits: a,\n      axis: i\n    } = s,\n        o = y(i, r.shape)[0],\n        l = Jo(r, a, o),\n        u = new Array(r.shape.length).fill(0),\n        c = r.shape.slice();\n    return l.map(e => {\n      var t = [...c];\n      t[o] = e;\n      var s = sm({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: u,\n          size: t\n        }\n      });\n      return u[o] += e, s;\n    });\n  }\n},\n    my = {\n  kernelName: \"Sqrt\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Sqrt\", e => Math.sqrt(e))\n},\n    by = {\n  kernelName: \"Square\",\n  backendName: \"cpu\",\n  kernelFunc: _ref19 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref19;\n    var {\n      x: n\n    } = e,\n        s = t;\n    zf(n, \"square\");\n    var r = s.data.get(n.dataId).values,\n        a = new Float32Array(r.length);\n\n    for (var _e412 = 0; _e412 < r.length; ++_e412) {\n      var _t343 = r[_e412];\n      a[_e412] = _t343 * _t343;\n    }\n\n    return {\n      dataId: s.write(a, n.shape, n.dtype),\n      shape: n.shape,\n      dtype: n.dtype\n    };\n  }\n},\n    xy = {\n  kernelName: \"Step\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Step\", (e, t) => {\n    var n = t;\n    return isNaN(e) ? NaN : e > 0 ? 1 : n.alpha;\n  })\n},\n    yy = {\n  kernelName: \"StridedSlice\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      begin: a,\n      end: i,\n      strides: o,\n      beginMask: l,\n      endMask: u,\n      ellipsisMask: c,\n      newAxisMask: h,\n      shrinkAxisMask: d\n    } = s;\n    zf(r, \"stridedSlice\");\n    var {\n      nonStrided: p,\n      $begin: f,\n      $strides: g,\n      size: m,\n      newShape: b,\n      outShape: x\n    } = Vn(r.shape, a, i, o, l, u, c, h, d),\n        y = Bm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: b\n      }\n    });\n    var k;\n\n    if (p) {\n      var _e413 = sm({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          begin: f,\n          size: m\n        }\n      });\n\n      k = Bm({\n        inputs: {\n          x: _e413\n        },\n        backend: n,\n        attrs: {\n          shape: x\n        }\n      }), n.disposeIntermediateTensorInfo(_e413);\n    } else if (x.some(e => 0 === e)) k = n.makeTensorInfo(x, r.dtype, []);else {\n      var _e414 = cm(x, n.bufferSync(y), g, f);\n\n      k = n.makeTensorInfo(_e414.shape, _e414.dtype, _e414.values);\n    }\n\n    var w = Bm({\n      inputs: {\n        x: k\n      },\n      backend: n,\n      attrs: {\n        shape: x\n      }\n    });\n    return n.disposeIntermediateTensorInfo(y), n.disposeIntermediateTensorInfo(k), w;\n  }\n},\n    ky = {\n  kernelName: \"StringNGrams\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      separator: r,\n      nGramWidths: a,\n      leftPad: i,\n      rightPad: o,\n      padWidth: l,\n      preserveShortSequences: u\n    } = s,\n        {\n      data: c,\n      dataSplits: h\n    } = t,\n        d = n.data.get(c.dataId).values,\n        p = n.data.get(h.dataId).values,\n        [f, g] = dm(d, p, r, a, i, o, l, u);\n    return [n.makeTensorInfo([f.length], \"string\", f), n.makeTensorInfo(h.shape, \"int32\", g)];\n  }\n},\n    wy = {\n  kernelName: \"StringSplit\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      skipEmpty: r\n    } = s,\n        {\n      input: a,\n      delimiter: i\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (1 !== a.shape.length) throw new Error(\"Input must be a vector, got shape: \".concat(a.shape));\n    if (0 !== i.shape.length) throw new Error(\"Delimiter must be a scalar, got shape: \".concat(i.shape));\n    var o = n.data.get(a.dataId).values,\n        l = n.data.get(i.dataId).values[0],\n        [u, c, h] = fm(o, l, r),\n        d = c.length;\n    return [n.makeTensorInfo([d, 2], \"int32\", u), n.makeTensorInfo([d], \"string\", c), n.makeTensorInfo([2], \"int32\", new Int32Array(h))];\n  }\n},\n    vy = {\n  kernelName: \"StringToHashBucketFast\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      numBuckets: r\n    } = s,\n        {\n      input: a\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (r <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    var i = gm(n.data.get(a.dataId).values, r);\n    return n.makeTensorInfo(a.shape, \"int32\", i);\n  }\n},\n    Iy = {\n  kernelName: \"Tan\",\n  backendName: \"cpu\",\n  kernelFunc: og(\"Tan\", e => Math.tan(e))\n},\n    $y = og(\"Tanh\", e => Math.tanh(e));\n\nfunction Ny(e, t, n) {\n  switch (n) {\n    case \"reflect\":\n      return function (e, t) {\n        var n = e;\n        if (n < 0) {\n          if (t <= 1) n = 0;else {\n            var _e415 = 2 * t;\n\n            n < _e415 && (n = _e415 * Math.trunc(-n / _e415) + n), n = n < -t ? n + _e415 : -n - 1;\n          }\n        } else if (n > t - 1) if (t <= 1) n = 0;else {\n          var _e416 = 2 * t;\n\n          n -= _e416 * Math.trunc(n / _e416), n >= t && (n = _e416 - n - 1);\n        }\n        return a(0, n, t - 1);\n      }(e, t);\n\n    case \"wrap\":\n      return function (e, t) {\n        var n = e;\n        return n < 0 ? t <= 1 ? n = 0 : n += t * (Math.trunc(-n / (t - 1)) + 1) : n > t - 1 && (t <= 1 ? n = 0 : n -= t * Math.trunc(n / (t - 1))), a(0, n, t - 1);\n      }(e, t);\n\n    case \"nearest\":\n      return function (e, t) {\n        return a(0, e, t - 1);\n      }(e, t);\n\n    case \"constant\":\n    default:\n      return function (e, t) {\n        return e;\n      }(e);\n  }\n}\n\nfunction Cy(e, t, n, s, r, a, i, o, l, u, c) {\n  return 0 <= o && o < t && 0 <= l && l < n ? e[i * s + o * r + l * a + u] : c;\n}\n\nfunction Sy(e, t, n, s, r, a, i, o, l, u, c) {\n  return Cy(e, t, n, s, r, a, i, Math.round(o), Math.round(l), u, c);\n}\n\nfunction Ty(e, t, n, s, r, a, i, o, l, u, c) {\n  var h = Math.floor(o),\n      d = Math.floor(l),\n      p = h + 1,\n      f = d + 1;\n  return (p - o) * ((f - l) * Cy(e, t, n, s, r, a, i, h, d, u, c) + (l - d) * Cy(e, t, n, s, r, a, i, h, f, u, c)) + (o - h) * ((f - l) * Cy(e, t, n, s, r, a, i, p, d, u, c) + (l - d) * Cy(e, t, n, s, r, a, i, p, f, u, c));\n}\n\nvar Ey = [Vm, Uf, Gm, Hm, sg, jm, qm, Km, Xm, Ym, Jm, Zm, Qm, eb, tb, ab, ib, ob, lb, Um, ub, cb, hb, Zf, cg, db, Hf, pb, bb, kb, wb, yb, Ib, $b, vb, Nb, Cb, Sb, Tb, Eb, Rb, Fb, Db, _b, Ob, Mb, zb, Lb, qb, Wb, Cm, Ub, fg, Vb, bg, Hb, yg, Jb, Qb, ex, wg, tx, nx, sx, rx, ax, Ng, Sg, Kf, ix, gb, ox, lx, ux, Tm, Eg, Ag, cx, _g, hx, dx, px, fx, gx, mx, Lg, yx, kx, wx, vx, Ix, xx, $x, Nx, Bg, Cx, Sx, Rx, Vg, Hg, Fx, _x, Mx, qg, Lx, Px, Ux, Vx, Gx, Am, Zg, Hx, Yf, jx, Dm, Om, Pm, qx, Kx, Xx, Yx, Jx, Zx, Qx, tm, ty, ny, sy, Lm, ry, ay, iy, rm, Ex, ly, uy, cy, hy, dy, py, fy, gy, my, by, um, xy, yy, ky, wy, vy, xm, Pb, Iy, {\n  kernelName: \"Tanh\",\n  backendName: \"cpu\",\n  kernelFunc: $y\n}, {\n  kernelName: \"Tile\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      reps: a\n    } = s;\n    zf(r, \"tile\");\n    var i = ym(n.bufferSync(r), a);\n    return n.makeTensorInfo(i.shape, i.dtype, i.values);\n  }\n}, {\n  kernelName: \"TopK\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      k: a,\n      sorted: i\n    } = s;\n    zf(r, \"topk\");\n    var o = n.data.get(r.dataId).values,\n        [l, u] = vm(o, r.shape, r.dtype, a, i);\n    return [n.makeTensorInfo(l.shape, l.dtype, l.values), n.makeTensorInfo(u.shape, u.dtype, u.values)];\n  }\n}, Yg, {\n  kernelName: \"Transform\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      image: r,\n      transforms: a\n    } = t,\n        {\n      interpolation: i,\n      fillMode: o,\n      fillValue: l,\n      outputShape: u\n    } = n,\n        [c, h, p, f] = r.shape,\n        [g, m] = null != u ? u : [h, p],\n        b = [c, g, m, f],\n        x = A(r.shape),\n        y = x[0],\n        k = x[1],\n        v = x[2],\n        I = w(r.dtype, d(b));\n    I.fill(l);\n    var $ = s.data.get(r.dataId).values,\n        N = s.data.get(a.dataId).values;\n\n    for (var _e417 = 0; _e417 < c; ++_e417) {\n      var _t344 = 1 === a.shape[0] ? N : N.subarray(8 * _e417, 8 * _e417 + 8);\n\n      for (var _n257 = 0; _n257 < g; ++_n257) {\n        for (var _s206 = 0; _s206 < m; ++_s206) {\n          for (var _r153 = 0; _r153 < f; ++_r153) {\n            var _a120 = void 0;\n\n            var _u32 = _t344[6] * _s206 + _t344[7] * _n257 + 1;\n\n            if (0 === _u32) continue;\n\n            var _c28 = (_t344[3] * _s206 + _t344[4] * _n257 + _t344[5]) / _u32,\n                _d22 = Ny((_t344[0] * _s206 + _t344[1] * _n257 + _t344[2]) / _u32, p, o),\n                _f10 = Ny(_c28, h, o);\n\n            switch (i) {\n              case \"nearest\":\n                _a120 = Sy($, h, p, y, k, v, _e417, _f10, _d22, _r153, l);\n                break;\n\n              case \"bilinear\":\n                _a120 = Ty($, h, p, y, k, v, _e417, _f10, _d22, _r153, l);\n                break;\n\n              default:\n                throw new Error(\"Error in Transform: Expect 'nearest' or 'bilinear', but got \".concat(i));\n            }\n\n            I[_e417 * y + _n257 * k + _s206 * v + _r153] = _a120;\n          }\n        }\n      }\n\n      return s.makeTensorInfo(b, r.dtype, I);\n    }\n\n    return {\n      dataId: s.write(I, b, r.dtype),\n      shape: r.shape,\n      dtype: r.dtype\n    };\n  }\n}, {\n  kernelName: \"Unique\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      axis: r\n    } = n,\n        {\n      x: a\n    } = t;\n    zf(a, \"unique\");\n    var i = s.data.get(a.dataId).values,\n        {\n      outputValues: o,\n      outputShape: l,\n      indices: u\n    } = Im(i, r, a.shape, a.dtype);\n    return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], \"int32\", u)];\n  }\n}, {\n  kernelName: \"Unpack\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      value: r\n    } = t;\n    var {\n      axis: a\n    } = s;\n    a < 0 && (a += r.shape.length);\n    var i = r.shape.length,\n        o = r.shape[a],\n        l = new Array(i - 1);\n    var u = 0;\n\n    for (var _e418 = 0; _e418 < i; _e418++) {\n      _e418 !== a && (l[u++] = r.shape[_e418]);\n    }\n\n    var c = new Array(i).fill(0),\n        h = r.shape.slice();\n    h[a] = 1;\n    var d = new Array(o);\n\n    for (var _e419 = 0; _e419 < d.length; _e419++) {\n      c[a] = _e419;\n\n      var _t345 = sm({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: c,\n          size: h\n        }\n      });\n\n      d[_e419] = Bm({\n        inputs: {\n          x: _t345\n        },\n        backend: n,\n        attrs: {\n          shape: l\n        }\n      }), n.disposeIntermediateTensorInfo(_t345);\n    }\n\n    return d;\n  }\n}, {\n  kernelName: \"UnsortedSegmentSum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      segmentIds: a\n    } = t,\n        {\n      numSegments: i\n    } = s;\n    zf(r, \"unsortedSegmentSum\");\n    var o = [],\n        l = [],\n        u = r.shape.length - a.shape.length;\n    var c = a;\n\n    for (var _e420 = 0; _e420 < u; ++_e420) {\n      var _t346 = Gb({\n        inputs: {\n          input: c\n        },\n        backend: n,\n        attrs: {\n          dim: _e420 + 1\n        }\n      });\n\n      c = _t346, l.push(_t346);\n    }\n\n    for (var _e421 = 0; _e421 < i; ++_e421) {\n      var _t347 = We(_e421, \"int32\"),\n          _s207 = n.makeTensorInfo([], \"int32\", _t347),\n          _a121 = pg({\n        inputs: {\n          a: _s207,\n          b: c\n        },\n        backend: n\n      }),\n          _i85 = Jf({\n        inputs: {\n          x: _a121\n        },\n        backend: n,\n        attrs: {\n          dtype: \"float32\"\n        }\n      }),\n          _u33 = Ug({\n        inputs: {\n          a: _i85,\n          b: r\n        },\n        backend: n\n      }),\n          _h16 = Bb({\n        inputs: {\n          x: _u33\n        },\n        backend: n,\n        attrs: {\n          axis: 0,\n          keepDims: !1\n        }\n      });\n\n      o.push(_h16), l.push(_s207), l.push(_a121), l.push(_i85), l.push(_u33), l.push(_h16);\n    }\n\n    var h = Wx({\n      inputs: o,\n      backend: n,\n      attrs: {\n        axis: 0\n      }\n    });\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), h;\n  }\n}, Bx];\n\nfor (var _e422 of Ey) {\n  Q(_e422);\n}\n\nvar Ry = {},\n    Ay = {\n  alpha: !1,\n  antialias: !1,\n  premultipliedAlpha: !1,\n  preserveDrawingBuffer: !1,\n  depth: !1,\n  stencil: !1,\n  failIfMajorPerformanceCaveat: !0\n};\n\nfunction Fy(e) {\n  if (!(e in Ry)) {\n    var _t348 = function (e) {\n      if (1 !== e && 2 !== e) throw new Error(\"Cannot get WebGL rendering context, WebGL is disabled.\");\n\n      var t = function (e) {\n        if (\"undefined\" != typeof OffscreenCanvas && 2 === e) return new OffscreenCanvas(300, 150);\n        if (\"undefined\" != typeof document) return document.createElement(\"canvas\");\n        throw new Error(\"Cannot create a canvas in this context\");\n      }(e);\n\n      return t.addEventListener(\"webglcontextlost\", t => {\n        t.preventDefault(), delete Ry[e];\n      }, !1), 1 === e ? t.getContext(\"webgl\", Ay) || t.getContext(\"experimental-webgl\", Ay) : t.getContext(\"webgl2\", Ay);\n    }(e);\n\n    if (null === _t348) return console.log(\"Could not get context for WebGL version\", e), null;\n    Ry[e] = _t348;\n  }\n\n  var t = Ry[e];\n  return t.isContextLost() ? (delete Ry[e], Fy(e)) : (t.disable(t.DEPTH_TEST), t.disable(t.STENCIL_TEST), t.disable(t.BLEND), t.disable(t.DITHER), t.disable(t.POLYGON_OFFSET_FILL), t.disable(t.SAMPLE_COVERAGE), t.enable(t.SCISSOR_TEST), t.enable(t.CULL_FACE), t.cullFace(t.BACK), Ry[e]);\n}\n\nvar Dy, _y, Oy;\n\nfunction My(e, t) {\n  return [t, e];\n}\n\nfunction Ly(e) {\n  var t = d(e);\n  return g(Math.ceil(t / 4));\n}\n\nfunction zy(e, t) {\n  return [Math.max(1, Math.ceil(t / 2)), Math.max(1, Math.ceil(e / 2))];\n}\n\nfunction By(e, t) {\n  var n = e;\n  var s, r, a, i, o, l, u, c, h, d;\n  return 2 === V().getNumber(\"WEBGL_VERSION\") ? (s = n.R32F, r = n.R16F, a = n.RGBA16F, i = n.RGBA32F, o = n.RED, u = 4, c = 1, h = n.HALF_FLOAT, d = n.FLOAT) : (s = e.RGBA, r = e.RGBA, a = e.RGBA, i = n.RGBA, o = e.RGBA, u = 4, c = 4, h = null != t ? t.HALF_FLOAT_OES : null, d = e.FLOAT), l = e.RGBA, {\n    internalFormatFloat: s,\n    internalFormatHalfFloat: r,\n    internalFormatPackedHalfFloat: a,\n    internalFormatPackedFloat: i,\n    textureFormatFloat: o,\n    downloadTextureFormat: l,\n    downloadUnpackNumChannels: u,\n    defaultNumChannels: c,\n    textureTypeHalfFloat: h,\n    textureTypeFloat: d\n  };\n}\n\nfunction Py(e, t) {\n  var n = t();\n  return V().getBool(\"DEBUG\") && function (e) {\n    var t = e.getError();\n    if (t !== e.NO_ERROR) throw new Error(\"WebGL Error: \" + function (e, t) {\n      switch (t) {\n        case e.NO_ERROR:\n          return \"NO_ERROR\";\n\n        case e.INVALID_ENUM:\n          return \"INVALID_ENUM\";\n\n        case e.INVALID_VALUE:\n          return \"INVALID_VALUE\";\n\n        case e.INVALID_OPERATION:\n          return \"INVALID_OPERATION\";\n\n        case e.INVALID_FRAMEBUFFER_OPERATION:\n          return \"INVALID_FRAMEBUFFER_OPERATION\";\n\n        case e.OUT_OF_MEMORY:\n          return \"OUT_OF_MEMORY\";\n\n        case e.CONTEXT_LOST_WEBGL:\n          return \"CONTEXT_LOST_WEBGL\";\n\n        default:\n          return \"Unknown error code \".concat(t);\n      }\n    }(e, t));\n  }(e), n;\n}\n\nfunction Wy(e) {\n  return !!(V().getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") || 0 === e || 5.96e-8 < Math.abs(e) && Math.abs(e) < 65504);\n}\n\nfunction Uy(e, t) {\n  return Xy(e, () => e.getExtension(t), 'Extension \"' + t + '\" not supported on this browser.');\n}\n\n!function (e) {\n  e[e.DENSE = 0] = \"DENSE\", e[e.SHARED_BATCH = 1] = \"SHARED_BATCH\";\n}(Dy || (Dy = {})), function (e) {\n  e[e.RENDER = 0] = \"RENDER\", e[e.UPLOAD = 1] = \"UPLOAD\", e[e.PIXELS = 2] = \"PIXELS\", e[e.DOWNLOAD = 3] = \"DOWNLOAD\";\n}(_y || (_y = {})), function (e) {\n  e[e.UNPACKED_FLOAT16 = 0] = \"UNPACKED_FLOAT16\", e[e.UNPACKED_FLOAT32 = 1] = \"UNPACKED_FLOAT32\", e[e.PACKED_4X1_UNSIGNED_BYTE = 2] = \"PACKED_4X1_UNSIGNED_BYTE\", e[e.PACKED_2X2_FLOAT32 = 3] = \"PACKED_2X2_FLOAT32\", e[e.PACKED_2X2_FLOAT16 = 4] = \"PACKED_2X2_FLOAT16\";\n}(Oy || (Oy = {}));\nvar Vy = /ERROR: [0-9]+:([0-9]+):/g;\n\nfunction Gy(e, t) {\n  if (Py(e, () => e.validateProgram(t)), !1 === e.getProgramParameter(t, e.VALIDATE_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error(\"Shader program validation failed.\");\n}\n\nfunction Hy(e, t, n, s, r, a, i) {\n  var o = e.getAttribLocation(t, n);\n  return -1 !== o && (Py(e, () => e.bindBuffer(e.ARRAY_BUFFER, s)), Py(e, () => e.vertexAttribPointer(o, r, e.FLOAT, !1, a, i)), Py(e, () => e.enableVertexAttribArray(o)), !0);\n}\n\nfunction jy(e, t, n) {\n  Py(e, () => e.bindFramebuffer(e.FRAMEBUFFER, n)), Py(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, t, 0));\n}\n\nfunction qy(e, t) {\n  Py(e, () => e.bindFramebuffer(e.FRAMEBUFFER, t)), Py(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, null, 0));\n}\n\nfunction Ky(e) {\n  var t = e.checkFramebufferStatus(e.FRAMEBUFFER);\n  if (t !== e.FRAMEBUFFER_COMPLETE) throw new Error(\"Error binding framebuffer: \" + function (e, t) {\n    switch (t) {\n      case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:\n        return \"FRAMEBUFFER_INCOMPLETE_ATTACHMENT\";\n\n      case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:\n        return \"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT\";\n\n      case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:\n        return \"FRAMEBUFFER_INCOMPLETE_DIMENSIONS\";\n\n      case e.FRAMEBUFFER_UNSUPPORTED:\n        return \"FRAMEBUFFER_UNSUPPORTED\";\n\n      default:\n        return \"unknown error \".concat(t);\n    }\n  }(e, t));\n}\n\nfunction Xy(e, t, n) {\n  var s = Py(e, () => t());\n  if (null == s) throw new Error(n);\n  return s;\n}\n\nfunction Yy(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 2;\n  return d(e.slice(0, e.length - t));\n}\n\nfunction Jy(e) {\n  if (0 === e.length) throw Error(\"Cannot get rows and columns of an empty shape array.\");\n  return [e.length > 1 ? e[e.length - 2] : 1, e[e.length - 1]];\n}\n\nfunction Zy(e) {\n  var t = [1, 1, 1];\n  return 0 === e.length || 1 === e.length && 1 === e[0] || (t = [Yy(e), ...Jy(e)]), t;\n}\n\nfunction Qy(e) {\n  return e % 2 == 0;\n}\n\nfunction ek(e, t) {\n  if (p(e = e.slice(-2), t = t.slice(-2))) return !0;\n  if (!e.length || !t.length) return !0;\n  if (0 === e[0] || 0 === e[1] || 0 === t[0] || 0 === t[1]) return !0;\n\n  if (e.length !== t.length) {\n    var _n258 = e.slice(-1)[0],\n        _s208 = t.slice(-1)[0];\n    if (_n258 === _s208) return !0;\n    if (Qy(_n258) && Qy(_s208) && (1 === e[0] || 1 === t[0])) return !0;\n  }\n\n  return e[1] === t[1] && Qy(e[0]) && Qy(t[0]);\n}\n\nvar tk, nk;\n\nfunction sk(e, t) {\n  return null != e.getExtension(t);\n}\n\nfunction rk(e) {\n  try {\n    if (null != Fy(e)) return !0;\n  } catch (e) {\n    return console.log(\"Error when getting WebGL context: \", e), !1;\n  }\n\n  return !1;\n}\n\nfunction ak(e) {\n  var t = By(e),\n      n = e.createTexture();\n  e.bindTexture(e.TEXTURE_2D, n), e.texImage2D(e.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);\n  var s = e.createFramebuffer();\n  e.bindFramebuffer(e.FRAMEBUFFER, s), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, n, 0);\n  var r = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;\n  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(n), e.deleteFramebuffer(s), r;\n}\n\nfunction ik(e, t) {\n  Array.isArray(e) || (e = [e]), e.forEach(e => {\n    null != e && l(\"complex64\" !== e.dtype, () => \"\".concat(t, \" does not support complex64 tensors in the WebGL backend.\"));\n  });\n}\n\nvar ok = V();\n\nfunction lk() {\n  var e, t, n, s, r, a, i, o, l, u;\n  return 2 === V().getNumber(\"WEBGL_VERSION\") ? (e = \"#version 300 es\", t = \"in\", n = \"out\", s = \"in\", r = \"texture\", a = \"outputColor\", i = \"out vec4 outputColor;\", o = \"\\n      bool isnan_custom(float val) {\\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\\n      }\\n\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan_custom(val.x),\\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\\n      }\\n\\n      #define isnan(value) isnan_custom(value)\\n    \", l = \"\", u = \"\\n      #define round(value) newRound(value)\\n      int newRound(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 newRound(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \") : (e = \"\", t = \"attribute\", n = \"varying\", s = \"varying\", r = \"texture2D\", a = \"gl_FragColor\", i = \"\", o = \"\\n      #define isnan(value) isnan_custom(value)\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\\n      }\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\\n      }\\n    \", l = \"\\n      uniform float INFINITY;\\n\\n      bool isinf(float val) {\\n        return abs(val) == INFINITY;\\n      }\\n      bvec4 isinf(vec4 val) {\\n        return equal(abs(val), vec4(INFINITY));\\n      }\\n    \", u = \"\\n      int round(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 round(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \"), {\n    version: e,\n    attribute: t,\n    varyingVs: n,\n    varyingFs: s,\n    texture2D: r,\n    output: a,\n    defineOutput: i,\n    defineSpecialNaN: o,\n    defineSpecialInf: l,\n    defineRound: u\n  };\n}\n\nfunction uk(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"index\";\n  var s = A(t);\n  return s.map((t, r) => \"int \".concat(e[r], \" = \").concat(n, \" / \").concat(t, \"; \").concat(r === s.length - 1 ? \"int \".concat(e[r + 1], \" = \").concat(n, \" - \").concat(e[r], \" * \").concat(t) : \"index -= \".concat(e[r], \" * \").concat(t), \";\")).join(\"\");\n}\n\nfunction ck(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"index\";\n  var s = A(t);\n  return s.map((t, r) => \"int \".concat(e[r], \" = \").concat(n, \" / outShapeStrides[\").concat(r, \"]; \").concat(r === s.length - 1 ? \"int \".concat(e[r + 1], \" = \").concat(n, \" - \").concat(e[r], \" * outShapeStrides[\").concat(r, \"]\") : \"index -= \".concat(e[r], \" * outShapeStrides[\").concat(r, \"]\"), \";\")).join(\"\");\n}\n\nfunction hk(e) {\n  var t = A(e).map(e => e.toString());\n  return \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * \".concat(t[0], \" + coords.y * \").concat(t[1], \" + coords.z;\\n  }\\n\");\n}\n\nok.registerFlag(\"HAS_WEBGL\", () => ok.getNumber(\"WEBGL_VERSION\") > 0), ok.registerFlag(\"WEBGL_VERSION\", () => rk(2) ? 2 : rk(1) ? 1 : 0), ok.registerFlag(\"WEBGL_CHECK_NUMERICAL_PROBLEMS\", () => !1), ok.registerFlag(\"WEBGL_BUFFER_SUPPORTED\", () => 2 === ok.get(\"WEBGL_VERSION\")), ok.registerFlag(\"WEBGL_CPU_FORWARD\", () => !0), ok.registerFlag(\"WEBGL_FORCE_F16_TEXTURES\", () => !1), ok.registerFlag(\"WEBGL_PACK\", () => ok.getBool(\"HAS_WEBGL\")), ok.registerFlag(\"WEBGL_PACK_NORMALIZATION\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_CLIP\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_DEPTHWISECONV\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_BINARY_OPERATIONS\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_UNARY_OPERATIONS\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_ARRAY_OPERATIONS\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_IMAGE_OPERATIONS\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_PACK_REDUCE\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_LAZILY_UNPACK\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_CONV_IM2COL\", () => ok.getBool(\"WEBGL_PACK\")), ok.registerFlag(\"WEBGL_MAX_TEXTURE_SIZE\", () => function (e) {\n  if (null == tk) {\n    var _t349 = Fy(e);\n\n    tk = _t349.getParameter(_t349.MAX_TEXTURE_SIZE);\n  }\n\n  return tk;\n}(ok.getNumber(\"WEBGL_VERSION\"))), ok.registerFlag(\"WEBGL_MAX_TEXTURES_IN_SHADER\", () => function (e) {\n  if (null == nk) {\n    var _t350 = Fy(e);\n\n    nk = _t350.getParameter(_t350.MAX_TEXTURE_IMAGE_UNITS);\n  }\n\n  return Math.min(16, nk);\n}(ok.getNumber(\"WEBGL_VERSION\"))), ok.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\", () => {\n  var e = ok.getNumber(\"WEBGL_VERSION\");\n  return 0 === e ? 0 : function (e) {\n    if (0 === e) return 0;\n    var t;\n    var n = Fy(e);\n    return t = sk(n, \"EXT_disjoint_timer_query_webgl2\") && 2 === e ? 2 : sk(n, \"EXT_disjoint_timer_query\") ? 1 : 0, t;\n  }(e);\n}), ok.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\", () => ok.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") > 0 && !It()), ok.registerFlag(\"WEBGL_RENDER_FLOAT32_CAPABLE\", () => function (e) {\n  if (0 === e) return !1;\n  var t = Fy(e);\n\n  if (1 === e) {\n    if (!sk(t, \"OES_texture_float\")) return !1;\n  } else if (!sk(t, \"EXT_color_buffer_float\")) return !1;\n\n  return ak(t);\n}(ok.getNumber(\"WEBGL_VERSION\"))), ok.registerFlag(\"WEBGL_RENDER_FLOAT32_ENABLED\", () => !ok.getBool(\"WEBGL_FORCE_F16_TEXTURES\") && ok.getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\")), ok.registerFlag(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\", () => function (e) {\n  if (0 === e) return !1;\n  var t = Fy(e);\n\n  if (1 !== e) {\n    if (sk(t, \"EXT_color_buffer_float\")) return ak(t);\n    var _e423 = \"EXT_color_buffer_half_float\";\n\n    if (sk(t, _e423)) {\n      var _n259 = t.getExtension(_e423);\n\n      return function (e, t) {\n        var n = By(e, t),\n            s = e.createTexture();\n        e.bindTexture(e.TEXTURE_2D, s), e.texImage2D(e.TEXTURE_2D, 0, n.internalFormatHalfFloat, 1, 1, 0, n.textureFormatFloat, n.textureTypeHalfFloat, null);\n        var r = e.createFramebuffer();\n        e.bindFramebuffer(e.FRAMEBUFFER, r), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, s, 0);\n        var a = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;\n        return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(s), e.deleteFramebuffer(r), a;\n      }(t, _n259);\n    }\n\n    return !1;\n  }\n\n  return !!sk(t, \"OES_texture_float\") && !!sk(t, \"WEBGL_color_buffer_float\") && ak(t);\n}(ok.getNumber(\"WEBGL_VERSION\"))), ok.registerFlag(\"WEBGL_FENCE_API_ENABLED\", () => {\n  return 2 === (e = ok.getNumber(\"WEBGL_VERSION\")) && null != Fy(e).fenceSync;\n  var e;\n}), ok.registerFlag(\"WEBGL_SIZE_UPLOAD_UNIFORM\", () => ok.getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") ? 4 : 0), ok.registerFlag(\"WEBGL_DELETE_TEXTURE_THRESHOLD\", () => -1, e => {\n  if (e < 0 && -1 !== e) throw new Error(\"WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got \".concat(e, \".\"));\n}), ok.registerFlag(\"WEBGL_FLUSH_THRESHOLD\", () => It() && ok.getBool(\"IS_CHROME\") ? 1 : -1, e => {\n  if (e < 0 && -1 !== e) throw new Error(\"WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got \".concat(e, \".\"));\n}), ok.registerFlag(\"CPU_HANDOFF_SIZE_THRESHOLD\", () => 128), ok.registerFlag(\"WEBGL_USE_SHAPES_UNIFORMS\", () => !1), ok.registerFlag(\"TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD\", () => 1e5), ok.registerFlag(\"TOPK_K_CPU_HANDOFF_THRESHOLD\", () => 128);\nvar dk = \"\\n  const float FLOAT_MAX = 1.70141184e38;\\n  const float FLOAT_MIN = 1.17549435e-38;\\n\\n  lowp vec4 encode_float(highp float v) {\\n    if (isnan(v)) {\\n      return vec4(255, 255, 255, 255);\\n    }\\n\\n    highp float av = abs(v);\\n\\n    if(av < FLOAT_MIN) {\\n      return vec4(0.0, 0.0, 0.0, 0.0);\\n    } else if(v > FLOAT_MAX) {\\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n    } else if(v < -FLOAT_MAX) {\\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n    }\\n\\n    highp vec4 c = vec4(0,0,0,0);\\n\\n    highp float e = floor(log2(av));\\n    highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n    c[2] = floor(128.0 * m);\\n    m -= c[2] / 128.0;\\n    c[1] = floor(32768.0 * m);\\n    m -= c[1] / 32768.0;\\n    c[0] = floor(8388608.0 * m);\\n\\n    highp float ebias = e + 127.0;\\n    c[3] = floor(ebias / 2.0);\\n    ebias -= c[3] * 2.0;\\n    c[2] += floor(ebias) * 128.0;\\n\\n    c[3] += 128.0 * step(0.0, -v);\\n\\n    return c / 255.0;\\n  }\\n\";\n\nclass pk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0, this.outPackingScheme = Dy.DENSE;\n    var t = Ly(e),\n        n = lk();\n    this.outputShape = e, this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \".concat(uk([\"r\", \"c\", \"d\"], e), \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\").concat(t[0], \", \").concat(t[1], \"));\\n        int index = 4 * (resTexRC.x * \").concat(t[1], \" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getA(rc.x, rc.y, rc.z);\\n        }\\n\\n        \").concat(n.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nclass fk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outPackingScheme = Dy.DENSE;\n    var t = Ly(e),\n        n = lk();\n    this.outputShape = e, this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \".concat(uk([\"r\", \"c\", \"d\"], e), \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\").concat(t[0], \", \").concat(t[1], \"));\\n        int index = 4 * (resTexRC.x * \").concat(t[1], \" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\\n        }\\n\\n        \").concat(n.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nclass gk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.outTexUsage = _y.DOWNLOAD;\n    var t = lk();\n    this.outputShape = e, this.userCode = \"\\n      \".concat(dk, \"\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        \").concat(t.output, \" = encode_float(x);\\n      }\\n    \");\n  }\n\n}\n\nclass mk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !1, this.outTexUsage = _y.DOWNLOAD;\n    var t = lk();\n    this.outputShape = e, this.userCode = \"\\n      \".concat(dk, \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\\n        \").concat(t.output, \" = encode_float(x);\\n      }\\n    \");\n  }\n\n}\n\nclass bk {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    this.variableNames = [\"A\"];\n    var s = lk(),\n        [r, a] = t;\n    this.outputShape = e;\n    var i = \"result\";\n    n && (i = \"floor(result * 255. + 0.5)\"), this.userCode = \"\\n      \".concat(hk(e), \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        int flatIndex = getFlatIndex(coords);\\n        int offset = imod(flatIndex, 4);\\n\\n        flatIndex = idiv(flatIndex, 4, 1.);\\n\\n        int r = flatIndex / \").concat(a, \";\\n        int c = imod(flatIndex, \").concat(a, \");\\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(\").concat(a, \".0, \").concat(r, \".0);\\n        vec4 values = \").concat(s.texture2D, \"(A, uv);\\n\\n        float result;\\n\\n        if(offset == 0) {\\n          result = values[0];\\n        } else if(offset == 1) {\\n          result = values[1];\\n        } else if(offset == 2) {\\n          result = values[2];\\n        } else {\\n          result = values[3];\\n        }\\n\\n        \").concat(s.output, \" = vec4(\").concat(i, \", 0., 0., 0.);\\n      }\\n    \");\n  }\n\n}\n\nclass xk {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0;\n    var s = lk(),\n        [r, a] = t;\n    this.outputShape = e;\n    var i = \"\",\n        o = \"result\";\n    n && (o = \"floor(result * 255. + 0.5)\");\n\n    for (var _t351 = 0; _t351 <= 1; _t351++) {\n      for (var _n260 = 0; _n260 <= 1; _n260++) {\n        var _o64 = 2 * _t351 + _n260;\n\n        i += \"\\n          localCoords = coords;\\n          if(localCoords[2] + \".concat(_n260, \" < \").concat(e[2], \") {\\n            localCoords[2] += \").concat(_n260, \";\\n            if(localCoords[1] + \").concat(_t351, \" < \").concat(e[1], \") {\\n              localCoords[1] += \").concat(_t351, \";\\n\\n              flatIndex = getFlatIndex(localCoords);\\n              offset = imod(flatIndex, 4);\\n\\n              flatIndex = idiv(flatIndex, 4, 1.);\\n\\n              r = flatIndex / \").concat(a, \";\\n              c = imod(flatIndex, \").concat(a, \");\\n              uv = (vec2(c, r) + halfCR) / vec2(\").concat(a, \".0, \").concat(r, \".0);\\n              values = \").concat(s.texture2D, \"(A, uv);\\n\\n              if(offset == 0) {\\n                result[\").concat(_o64, \"] = values[0];\\n              } else if(offset == 1) {\\n                result[\").concat(_o64, \"] = values[1];\\n              } else if(offset == 2) {\\n                result[\").concat(_o64, \"] = values[2];\\n              } else {\\n                result[\").concat(_o64, \"] = values[3];\\n              }\\n            }\\n          }\\n        \");\n      }\n    }\n\n    this.userCode = \"\\n      \".concat(hk(e), \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n        int flatIndex, r, c, offset;\\n        ivec3 localCoords;\\n        vec2 uv;\\n        vec4 values;\\n\\n        \").concat(i, \"\\n\\n        \").concat(s.output, \" = \").concat(o, \";\\n      }\\n    \");\n  }\n\n}\n\nfunction yk(e, t, n, s, r, a) {\n  !function (e, t) {\n    var n = V().getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");\n    if (e <= 0 || t <= 0) throw new Error(\"Requested texture size [\".concat(e, \"x\").concat(t, \"] is invalid.\"));\n    if (e > n || t > n) throw new Error(\"Requested texture size [\".concat(e, \"x\").concat(t, \"] greater than WebGL maximum on this browser / GPU [\").concat(n, \"x\").concat(n, \"].\"));\n  }(t, n);\n\n  var i = function (e) {\n    return Xy(e, () => e.createTexture(), \"Unable to create WebGLTexture.\");\n  }(e),\n      o = e.TEXTURE_2D;\n\n  return Py(e, () => e.bindTexture(o, i)), Py(e, () => e.texParameteri(o, e.TEXTURE_WRAP_S, e.CLAMP_TO_EDGE)), Py(e, () => e.texParameteri(o, e.TEXTURE_WRAP_T, e.CLAMP_TO_EDGE)), Py(e, () => e.texParameteri(o, e.TEXTURE_MIN_FILTER, e.NEAREST)), Py(e, () => e.texParameteri(o, e.TEXTURE_MAG_FILTER, e.NEAREST)), Py(e, () => e.texImage2D(o, 0, s, t, n, 0, r, a, null)), Py(e, () => e.bindTexture(e.TEXTURE_2D, null)), i;\n}\n\nfunction kk(e) {\n  return e.internalFormatFloat;\n}\n\nfunction wk(e) {\n  return e.internalFormatHalfFloat;\n}\n\nfunction vk(e) {\n  return e.downloadTextureFormat;\n}\n\nfunction Ik(e) {\n  return e.internalFormatPackedFloat;\n}\n\nfunction $k(e) {\n  return e.internalFormatPackedHalfFloat;\n}\n\nclass Nk {\n  constructor(e) {\n    this.outputTexture = null, this.program = null, this.disposed = !1, this.vertexAttrsAreBound = !1, this.itemsToPoll = [];\n    var t = V().getNumber(\"WEBGL_VERSION\");\n    null != e ? (this.gl = e, function (e, t) {\n      Ry[e] = t;\n    }(t, e)) : this.gl = Fy(t);\n    var n = \"WEBGL_color_buffer_float\";\n    var s = \"EXT_color_buffer_half_float\";\n\n    if (1 === V().getNumber(\"WEBGL_VERSION\")) {\n      var _e424 = \"OES_texture_half_float\";\n      if (this.textureFloatExtension = Uy(this.gl, \"OES_texture_float\"), sk(this.gl, _e424)) this.textureHalfFloatExtension = Uy(this.gl, _e424);else if (V().get(\"WEBGL_FORCE_F16_TEXTURES\")) throw new Error(\"GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.\");\n      if (this.colorBufferFloatExtension = this.gl.getExtension(n), sk(this.gl, s)) this.colorBufferHalfFloatExtension = Uy(this.gl, s);else if (V().get(\"WEBGL_FORCE_F16_TEXTURES\")) throw new Error(\"GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.\");\n    } else if (n = \"EXT_color_buffer_float\", sk(this.gl, n)) this.colorBufferFloatExtension = this.gl.getExtension(n);else {\n      if (!sk(this.gl, s)) throw new Error(\"GL context does not support color renderable floats\");\n      this.colorBufferHalfFloatExtension = this.gl.getExtension(s);\n    }\n\n    this.vertexBuffer = function (e) {\n      return function (e, t) {\n        var n = Xy(e, () => e.createBuffer(), \"Unable to create WebGLBuffer\");\n        return Py(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), Py(e, () => e.bufferData(e.ARRAY_BUFFER, t, e.STATIC_DRAW)), n;\n      }(e, new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]));\n    }(this.gl), this.indexBuffer = function (e) {\n      return function (e, t) {\n        var n = Xy(e, () => e.createBuffer(), \"Unable to create WebGLBuffer\");\n        return Py(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, n)), Py(e, () => e.bufferData(e.ELEMENT_ARRAY_BUFFER, t, e.STATIC_DRAW)), n;\n      }(e, new Uint16Array([0, 1, 2, 2, 1, 3]));\n    }(this.gl), this.framebuffer = function (e) {\n      return Xy(e, () => e.createFramebuffer(), \"Unable to create WebGLFramebuffer.\");\n    }(this.gl), this.textureConfig = By(this.gl, this.textureHalfFloatExtension);\n  }\n\n  get debug() {\n    return V().getBool(\"DEBUG\");\n  }\n\n  dispose() {\n    if (this.disposed) return;\n    null != this.program && console.warn(\"Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.\"), null != this.outputTexture && console.warn(\"Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.\");\n    var e = this.gl;\n    Py(e, () => e.finish()), Py(e, () => e.bindFramebuffer(e.FRAMEBUFFER, null)), Py(e, () => e.deleteFramebuffer(this.framebuffer)), Py(e, () => e.bindBuffer(e.ARRAY_BUFFER, null)), Py(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, null)), Py(e, () => e.deleteBuffer(this.indexBuffer)), this.disposed = !0;\n  }\n\n  createFloat32MatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = My(t, n);\n      return yk(e, r, a, kk(s), s.textureFormatFloat, e.FLOAT);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createFloat16MatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = My(t, n);\n      return yk(e, r, a, wk(s), s.textureFormatFloat, s.textureTypeHalfFloat);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createUnsignedBytesMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = My(t, n);\n      return yk(e, r, a, vk(s), e.RGBA, e.UNSIGNED_BYTE);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  uploadPixelDataToTexture(e, t) {\n    this.throwIfDisposed(), function (e, t, n) {\n      Py(e, () => e.bindTexture(e.TEXTURE_2D, t)), n.data instanceof Uint8Array ? Py(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, n.width, n.height, 0, e.RGBA, e.UNSIGNED_BYTE, n.data)) : Py(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, e.RGBA, e.UNSIGNED_BYTE, n)), Py(e, () => e.bindTexture(e.TEXTURE_2D, null));\n    }(this.gl, e, t);\n  }\n\n  uploadDenseMatrixToTexture(e, t, n, s) {\n    this.throwIfDisposed(), function (e, t, n, s, r, a) {\n      var i, o, l;\n      Py(e, () => e.bindTexture(e.TEXTURE_2D, t)), r instanceof Uint8Array ? (i = new Uint8Array(n * s * 4), o = e.UNSIGNED_BYTE, l = e.RGBA) : (i = new Float32Array(n * s * 4), o = e.FLOAT, l = a.internalFormatPackedFloat), i.set(r), Py(e, () => e.texImage2D(e.TEXTURE_2D, 0, l, n, s, 0, e.RGBA, o, i)), Py(e, () => e.bindTexture(e.TEXTURE_2D, null));\n    }(this.gl, e, t, n, s, this.textureConfig);\n  }\n\n  createFloat16PackedMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = zy(t, n);\n      return yk(e, r, a, $k(s), e.RGBA, s.textureTypeHalfFloat);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createPackedMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = zy(t, n);\n      return yk(e, r, a, Ik(s), e.RGBA, e.FLOAT);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  deleteMatrixTexture(e) {\n    this.throwIfDisposed(), this.outputTexture === e && (qy(this.gl, this.framebuffer), this.outputTexture = null), Py(this.gl, () => this.gl.deleteTexture(e));\n  }\n\n  downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n) {\n    return this.downloadMatrixDriver(e, () => function (e, t, n, s) {\n      var [r, a] = My(t, n),\n          i = new Uint8Array(t * n * 4);\n      return Py(e, () => e.readPixels(0, 0, r, a, s.downloadTextureFormat, e.UNSIGNED_BYTE, i)), new Float32Array(i.buffer);\n    }(this.gl, t, n, this.textureConfig));\n  }\n\n  downloadPackedMatrixFromBuffer(e, t, n, s, r, a) {\n    return function (e, t, n, s, r, a, i, o) {\n      var l = e,\n          u = new Float32Array(function (e, t) {\n        var [n, s] = zy(e, t);\n        return n * s * 4;\n      }(a, i));\n      return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, u), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), u;\n    }(this.gl, e, 0, 0, 0, r, a);\n  }\n\n  downloadFloat32MatrixFromBuffer(e, t) {\n    return function (e, t, n) {\n      var s = e,\n          r = new Float32Array(n);\n      return s.bindBuffer(s.PIXEL_PACK_BUFFER, t), s.getBufferSubData(s.PIXEL_PACK_BUFFER, 0, r), s.bindBuffer(s.PIXEL_PACK_BUFFER, null), r;\n    }(this.gl, e, t);\n  }\n\n  createBufferFromTexture(e, t, n) {\n    this.bindTextureToFrameBuffer(e);\n\n    var s = function (e, t, n, s) {\n      var r = e.createBuffer();\n      Py(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, r));\n      var a = 16 * t * n;\n      return Py(e, () => e.bufferData(e.PIXEL_PACK_BUFFER, a, e.STREAM_READ)), Py(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, 0)), Py(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, null)), r;\n    }(this.gl, t, n);\n\n    return this.unbindTextureToFrameBuffer(), s;\n  }\n\n  createAndWaitForFence() {\n    var e = this.createFence(this.gl);\n    return this.pollFence(e);\n  }\n\n  createFence(e) {\n    var t, n;\n\n    if (V().getBool(\"WEBGL_FENCE_API_ENABLED\")) {\n      var _s209 = e,\n          _r154 = _s209.fenceSync(_s209.SYNC_GPU_COMMANDS_COMPLETE, 0);\n\n      e.flush(), n = () => {\n        var e = _s209.clientWaitSync(_r154, 0, 0);\n\n        return e === _s209.ALREADY_SIGNALED || e === _s209.CONDITION_SATISFIED;\n      }, t = _r154;\n    } else V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") > 0 ? (t = this.beginQuery(), this.endQuery(), n = () => this.isQueryAvailable(t, V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))) : n = () => !0;\n\n    return {\n      query: t,\n      isFencePassed: n\n    };\n  }\n\n  downloadMatrixFromPackedTexture(e, t, n) {\n    return this.downloadMatrixDriver(e, () => function (e, t, n) {\n      var s = new Float32Array(t * n * 4);\n      return Py(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, s)), s;\n    }(this.gl, t, n));\n  }\n\n  createProgram(e) {\n    this.throwIfDisposed();\n\n    var t = this.gl,\n        n = function (e, t) {\n      var n = Xy(e, () => e.createShader(e.FRAGMENT_SHADER), \"Unable to create fragment WebGLShader.\");\n      if (Py(e, () => e.shaderSource(n, t)), Py(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw function (e, t) {\n        var n = Vy.exec(t);\n        if (null == n) return console.log(\"Couldn't parse line number in error: \".concat(t)), void console.log(e);\n        var s = +n[1],\n            r = e.split(\"\\n\"),\n            a = r.length.toString().length + 2,\n            i = r.map((e, t) => m((t + 1).toString(), a) + e);\n        var o = 0;\n\n        for (var _e425 = 0; _e425 < i.length; _e425++) {\n          o = Math.max(i[_e425].length, o);\n        }\n\n        var l = i.slice(0, s - 1),\n            u = i.slice(s - 1, s),\n            c = i.slice(s);\n        console.log(l.join(\"\\n\")), console.log(t.split(\"\\n\")[0]), console.log(\"%c \".concat(m(u[0], o)), \"border:1px solid red; background-color:#e3d2d2; color:#a61717\"), console.log(c.join(\"\\n\"));\n      }(t, e.getShaderInfoLog(n)), new Error(\"Failed to compile fragment shader.\");\n      return n;\n    }(t, e);\n\n    null == this.vertexShader && (this.vertexShader = function (e) {\n      var t = lk();\n      return function (e, t) {\n        var n = Xy(e, () => e.createShader(e.VERTEX_SHADER), \"Unable to create vertex WebGLShader.\");\n        if (Py(e, () => e.shaderSource(n, t)), Py(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw console.log(e.getShaderInfoLog(n)), new Error(\"Failed to compile vertex shader.\");\n        return n;\n      }(e, \"\".concat(t.version, \"\\n    precision highp float;\\n    \").concat(t.attribute, \" vec3 clipSpacePos;\\n    \").concat(t.attribute, \" vec2 uv;\\n    \").concat(t.varyingVs, \" vec2 resultUV;\\n\\n    void main() {\\n      gl_Position = vec4(clipSpacePos, 1);\\n      resultUV = uv;\\n    }\"));\n    }(t));\n\n    var s = function (e) {\n      return Xy(e, () => e.createProgram(), \"Unable to create WebGLProgram.\");\n    }(t);\n\n    return Py(t, () => t.attachShader(s, this.vertexShader)), Py(t, () => t.attachShader(s, n)), function (e, t) {\n      if (Py(e, () => e.linkProgram(t)), !1 === e.getProgramParameter(t, e.LINK_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error(\"Failed to link vertex and fragment shaders.\");\n    }(t, s), this.debug && Gy(t, s), this.vertexAttrsAreBound || (this.setProgram(s), this.vertexAttrsAreBound = function (e, t, n) {\n      return Py(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), Hy(e, t, \"clipSpacePos\", n, 3, 20, 0) && Hy(e, t, \"uv\", n, 2, 20, 12);\n    }(t, this.program, this.vertexBuffer)), s;\n  }\n\n  deleteProgram(e) {\n    this.throwIfDisposed(), e === this.program && (this.program = null), null != e && Py(this.gl, () => this.gl.deleteProgram(e));\n  }\n\n  setProgram(e) {\n    this.throwIfDisposed(), this.program = e, null != this.program && this.debug && Gy(this.gl, this.program), Py(this.gl, () => this.gl.useProgram(e));\n  }\n\n  getUniformLocation(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    return this.throwIfDisposed(), n ? function (e, t, n) {\n      return Xy(e, () => e.getUniformLocation(t, n), 'uniform \"' + n + '\" not present in program.');\n    }(this.gl, e, t) : function (e, t, n) {\n      return e.getUniformLocation(t, n);\n    }(this.gl, e, t);\n  }\n\n  getAttributeLocation(e, t) {\n    return this.throwIfDisposed(), Py(this.gl, () => this.gl.getAttribLocation(e, t));\n  }\n\n  getUniformLocationNoThrow(e, t) {\n    return this.throwIfDisposed(), this.gl.getUniformLocation(e, t);\n  }\n\n  setInputMatrixTexture(e, t, n) {\n    this.throwIfDisposed(), this.throwIfNoProgram(), function (e, t, n, s) {\n      Py(e, () => function (e, t, n) {\n        !function (e, t) {\n          var n = e.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1,\n              s = t + e.TEXTURE0;\n          if (s < e.TEXTURE0 || s > n) throw new Error(\"textureUnit must be in [gl.TEXTURE0, gl.TEXTURE\".concat(n, \"].\"));\n        }(e, n), Py(e, () => e.activeTexture(e.TEXTURE0 + n)), Py(e, () => e.bindTexture(e.TEXTURE_2D, t));\n      }(e, t, s)), Py(e, () => e.uniform1i(n, s));\n    }(this.gl, e, t, n);\n  }\n\n  setOutputMatrixTexture(e, t, n) {\n    this.setOutputMatrixTextureDriver(e, n, t);\n  }\n\n  setOutputPackedMatrixTexture(e, t, n) {\n    this.throwIfDisposed();\n    var [s, r] = zy(t, n);\n    this.setOutputMatrixTextureDriver(e, s, r);\n  }\n\n  setOutputMatrixWriteRegion(e, t, n, s) {\n    this.setOutputMatrixWriteRegionDriver(n, e, s, t);\n  }\n\n  setOutputPackedMatrixWriteRegion(e, t, n, s) {\n    throw new Error(\"setOutputPackedMatrixWriteRegion not implemented.\");\n  }\n\n  debugValidate() {\n    null != this.program && Gy(this.gl, this.program), Ky(this.gl);\n  }\n\n  executeProgram() {\n    this.throwIfDisposed(), this.throwIfNoProgram();\n    var e = this.gl;\n    this.debug && this.debugValidate(), Py(e, () => e.drawElements(e.TRIANGLES, 6, e.UNSIGNED_SHORT, 0));\n  }\n\n  blockUntilAllProgramsCompleted() {\n    this.throwIfDisposed(), Py(this.gl, () => this.gl.finish());\n  }\n\n  getQueryTimerExtension() {\n    return null == this.disjointQueryTimerExtension && (this.disjointQueryTimerExtension = Uy(this.gl, 2 === V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") ? \"EXT_disjoint_timer_query_webgl2\" : \"EXT_disjoint_timer_query\")), this.disjointQueryTimerExtension;\n  }\n\n  getQueryTimerExtensionWebGL2() {\n    return this.getQueryTimerExtension();\n  }\n\n  getQueryTimerExtensionWebGL1() {\n    return this.getQueryTimerExtension();\n  }\n\n  beginQuery() {\n    if (2 === V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")) {\n      var _e426 = this.gl,\n          _t352 = this.getQueryTimerExtensionWebGL2(),\n          _n261 = _e426.createQuery();\n\n      return _e426.beginQuery(_t352.TIME_ELAPSED_EXT, _n261), _n261;\n    }\n\n    var e = this.getQueryTimerExtensionWebGL1(),\n        t = e.createQueryEXT();\n    return e.beginQueryEXT(e.TIME_ELAPSED_EXT, t), t;\n  }\n\n  endQuery() {\n    if (2 === V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")) {\n      var _e427 = this.gl,\n          _t353 = this.getQueryTimerExtensionWebGL2();\n\n      return void _e427.endQuery(_t353.TIME_ELAPSED_EXT);\n    }\n\n    var e = this.getQueryTimerExtensionWebGL1();\n    e.endQueryEXT(e.TIME_ELAPSED_EXT);\n  }\n\n  waitForQueryAndGetTime(e) {\n    var _this72 = this;\n\n    return _asyncToGenerator(function* () {\n      return yield b(() => _this72.disposed || _this72.isQueryAvailable(e, V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))), _this72.getQueryTime(e, V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"));\n    })();\n  }\n\n  getQueryTime(e, t) {\n    if (0 === t) return null;\n\n    if (2 === t) {\n      var _t354 = this.gl;\n      return _t354.getQueryParameter(e, _t354.QUERY_RESULT) / 1e6;\n    }\n\n    {\n      var _t355 = this.getQueryTimerExtensionWebGL1();\n\n      return _t355.getQueryObjectEXT(e, _t355.QUERY_RESULT_EXT) / 1e6;\n    }\n  }\n\n  isQueryAvailable(e, t) {\n    if (0 === t) return !0;\n\n    if (2 === t) {\n      var _t356 = this.gl,\n          _n262 = this.getQueryTimerExtensionWebGL2(),\n          _s210 = _t356.getQueryParameter(e, _t356.QUERY_RESULT_AVAILABLE);\n\n      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_n262.GPU_DISJOINT_EXT)), _s210 && !this.disjoint;\n    }\n\n    {\n      var _t357 = this.getQueryTimerExtensionWebGL1(),\n          _n263 = _t357.getQueryObjectEXT(e, _t357.QUERY_RESULT_AVAILABLE_EXT);\n\n      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_t357.GPU_DISJOINT_EXT)), _n263 && !this.disjoint;\n    }\n  }\n\n  pollFence(e) {\n    return new Promise(t => {\n      this.addItemToPoll(() => e.isFencePassed(), () => t());\n    });\n  }\n\n  pollItems() {\n    var e = function (e) {\n      var t = 0;\n\n      for (; t < e.length && e[t](); ++t) {\n        ;\n      }\n\n      return t - 1;\n    }(this.itemsToPoll.map(e => e.isDoneFn));\n\n    for (var _t358 = 0; _t358 <= e; ++_t358) {\n      var {\n        resolveFn: _e428\n      } = this.itemsToPoll[_t358];\n\n      _e428();\n    }\n\n    this.itemsToPoll = this.itemsToPoll.slice(e + 1);\n  }\n\n  addItemToPoll(e, t) {\n    this.itemsToPoll.push({\n      isDoneFn: e,\n      resolveFn: t\n    }), this.itemsToPoll.length > 1 || b(() => (this.pollItems(), 0 === this.itemsToPoll.length));\n  }\n\n  bindTextureToFrameBuffer(e) {\n    this.throwIfDisposed(), jy(this.gl, e, this.framebuffer), this.debug && Ky(this.gl);\n  }\n\n  unbindTextureToFrameBuffer() {\n    null != this.outputTexture ? (jy(this.gl, this.outputTexture, this.framebuffer), this.debug && Ky(this.gl)) : qy(this.gl, this.framebuffer);\n  }\n\n  downloadMatrixDriver(e, t) {\n    this.bindTextureToFrameBuffer(e);\n    var n = t();\n    return this.unbindTextureToFrameBuffer(), n;\n  }\n\n  setOutputMatrixTextureDriver(e, t, n) {\n    this.throwIfDisposed();\n    var s = this.gl;\n    jy(s, e, this.framebuffer), this.debug && Ky(s), this.outputTexture = e, Py(s, () => s.viewport(0, 0, t, n)), Py(s, () => s.scissor(0, 0, t, n));\n  }\n\n  setOutputMatrixWriteRegionDriver(e, t, n, s) {\n    this.throwIfDisposed(), Py(this.gl, () => this.gl.scissor(e, t, n, s));\n  }\n\n  throwIfDisposed() {\n    if (this.disposed) throw new Error(\"Attempted to use disposed GPGPUContext.\");\n  }\n\n  throwIfNoProgram() {\n    if (null == this.program) throw new Error(\"No GPU program is currently set.\");\n  }\n\n}\n\nvar {\n  getBroadcastDims: Ck\n} = sl;\n\nfunction Sk(e, t, n) {\n  var s = [];\n\n  if (e.forEach(e => {\n    var t = d(e.shapeInfo.logicalShape);\n\n    if (e.shapeInfo.isUniform ? s.push(\"uniform float \".concat(e.name).concat(t > 1 ? \"[\".concat(t, \"]\") : \"\", \";\")) : (s.push(\"uniform sampler2D \".concat(e.name, \";\")), s.push(\"uniform int offset\".concat(e.name, \";\"))), n.enableShapeUniforms) {\n      var {\n        uniformShape: _t359\n      } = Lk(n.packedInputs, e.shapeInfo.logicalShape, e.shapeInfo.texShape);\n\n      switch (_t359.length) {\n        case 1:\n          s.push(\"uniform int \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 2:\n          s.push(\"uniform ivec2 \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 3:\n          s.push(\"uniform ivec3 \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 4:\n          s.push(\"uniform ivec4 \".concat(e.name, \"Shape;\"));\n      }\n\n      s.push(\"uniform ivec2 \".concat(e.name, \"TexShape;\"));\n    }\n  }), n.enableShapeUniforms) {\n    switch (t.logicalShape.length) {\n      case 1:\n        s.push(\"uniform int outShape;\");\n        break;\n\n      case 2:\n        s.push(\"uniform ivec2 outShape;\"), s.push(\"uniform int outShapeStrides;\");\n        break;\n\n      case 3:\n        s.push(\"uniform ivec3 outShape;\"), s.push(\"uniform ivec2 outShapeStrides;\");\n        break;\n\n      case 4:\n        s.push(\"uniform ivec4 outShape;\"), s.push(\"uniform ivec3 outShapeStrides;\");\n    }\n\n    s.push(\"uniform ivec2 outTexShape;\");\n  }\n\n  n.customUniforms && n.customUniforms.forEach(e => {\n    s.push(\"uniform \".concat(e.type, \" \").concat(e.name).concat(e.arrayIndex ? \"[\".concat(e.arrayIndex, \"]\") : \"\", \";\"));\n  });\n\n  var r = s.join(\"\\n\"),\n      a = e.map(e => function (e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = \"\";\n    return r += n ? Ek(e, s) : Tk(e, s), e.shapeInfo.logicalShape.length <= t.logicalShape.length && (r += n ? function (e, t) {\n      var n = e.name,\n          s = n.charAt(0).toUpperCase() + n.slice(1),\n          r = \"get\" + s + \"AtOutCoords\",\n          a = e.shapeInfo.logicalShape.length,\n          i = t.logicalShape.length,\n          o = Ck(e.shapeInfo.logicalShape, t.logicalShape),\n          l = Mk(i),\n          u = i - a;\n      var c;\n      var h = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n      c = 0 === a ? \"\" : i < 2 && o.length >= 1 ? \"coords = 0;\" : o.map(e => \"coords.\".concat(h[e + u], \" = 0;\")).join(\"\\n\");\n      var p = \"\";\n      p = i < 2 && a > 0 ? \"coords\" : e.shapeInfo.logicalShape.map((e, t) => \"coords.\".concat(h[t + u])).join(\", \");\n      var f = \"return outputValue;\";\n      var g = 1 === d(e.shapeInfo.logicalShape),\n          m = 1 === d(t.logicalShape);\n\n      if (1 !== a || g || m) {\n        if (g && !m) f = 1 === i ? \"\\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\\n      \" : \"\\n        return vec4(outputValue.x);\\n      \";else if (o.length) {\n          var _e429 = a - 2,\n              _t360 = a - 1;\n\n          o.indexOf(_e429) > -1 && o.indexOf(_t360) > -1 ? f = \"return vec4(outputValue.x);\" : o.indexOf(_e429) > -1 ? f = \"return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);\" : o.indexOf(_t360) > -1 && (f = \"return vec4(outputValue.xx, outputValue.zz);\");\n        }\n      } else f = \"\\n      return vec4(outputValue.xy, outputValue.xy);\\n    \";\n\n      return \"\\n    vec4 \".concat(r, \"() {\\n      \").concat(l, \" coords = getOutputCoords();\\n      \").concat(c, \"\\n      vec4 outputValue = get\").concat(s, \"(\").concat(p, \");\\n      \").concat(f, \"\\n    }\\n  \");\n    }(e, t) : function (e, t) {\n      var n = e.name,\n          s = n.charAt(0).toUpperCase() + n.slice(1),\n          r = \"get\" + s + \"AtOutCoords\",\n          a = e.shapeInfo.logicalShape.length,\n          i = t.logicalShape.length;\n      if (!e.shapeInfo.isUniform && a === i && null == e.shapeInfo.flatOffset && p(e.shapeInfo.texShape, t.texShape)) return \"\\n      float \".concat(r, \"() {\\n        return sampleTexture(\").concat(n, \", resultUV);\\n      }\\n    \");\n      var o = Mk(i),\n          l = Ck(e.shapeInfo.logicalShape, t.logicalShape),\n          u = i - a;\n      var c;\n      var h = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n      c = 0 === a ? \"\" : i < 2 && l.length >= 1 ? \"coords = 0;\" : l.map(e => \"coords.\".concat(h[e + u], \" = 0;\")).join(\"\\n\");\n      var d = \"\";\n      return d = i < 2 && a > 0 ? \"coords\" : e.shapeInfo.logicalShape.map((e, t) => \"coords.\".concat(h[t + u])).join(\", \"), \"\\n    float \".concat(r, \"() {\\n      \").concat(o, \" coords = getOutputCoords();\\n      \").concat(c, \"\\n      return get\").concat(s, \"(\").concat(d, \");\\n    }\\n  \");\n    }(e, t)), r;\n  }(e, t, n.packedInputs, n.enableShapeUniforms)).join(\"\\n\"),\n      i = t.texShape,\n      o = lk(),\n      l = function (e) {\n    return \"\\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n      return \".concat(e.texture2D, \"(textureSampler, uv).r;\\n    }\\n  \");\n  }(o);\n\n  var u,\n      c,\n      h = function (e) {\n    return \"\".concat(e.version, \"\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    \").concat(e.varyingFs, \" vec2 resultUV;\\n    \").concat(e.defineOutput, \"\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    uniform float NAN;\\n    \").concat(e.defineSpecialNaN, \"\\n    \").concat(e.defineSpecialInf, \"\\n    \").concat(e.defineRound, \"\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    int idiv(int a, int b, float sign) {\\n      int res = a / b;\\n      int mod = imod(a, b);\\n      if (sign < 0. && mod != 0) {\\n        res -= 1;\\n      }\\n      return res;\\n    }\\n\\n    //Based on the work of Dave Hoskins\\n    //https://www.shadertoy.com/view/4djSRW\\n    #define HASHSCALE1 443.8975\\n    float random(float seed){\\n      vec2 p = resultUV * seed;\\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\\n      p3 += dot(p3, p3.yzx + 19.19);\\n      return fract((p3.x + p3.y) * p3.z);\\n    }\\n\\n    \").concat(Rk, \"\\n    \").concat(Ak, \"\\n    \").concat(Fk, \"\\n  \");\n  }(o);\n\n  return t.isPacked ? (u = function (e, t, n) {\n    switch (e.length) {\n      case 0:\n        return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n\n      case 1:\n        return function (e, t, n) {\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];\n          return 1 === s[0] ? n ? \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * \".concat(s[1], \".0);\\n      }\\n    \") : 1 === s[1] ? n ? \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * \".concat(s[0], \".0);\\n      }\\n    \") : n ? \"\\n    int getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\\n    }\\n  \" : \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      return 2 * (resTexRC.x * \").concat(s[1], \" + resTexRC.y);\\n    }\\n  \");\n        }(0, t, n);\n\n      case 2:\n        return function (e, t, n) {\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];\n          if (p(e, t)) return n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        return 2 * ivec2(resultUV.yx * vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      }\\n    \");\n          var r = Math.ceil(e[1] / 2);\n          return n ? \"\\n    ivec2 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \" : \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 3:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n\\n      int b = index / texelsInBatch;\\n      index -= b * texelsInBatch;\\n\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \";\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],\n              r = Math.ceil(e[2] / 2),\n              a = r * Math.ceil(e[1] / 2);\n          return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n\\n      int b = index / \").concat(a, \";\\n      index -= b * \").concat(a, \";\\n\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      default:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n\\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\\n      int texelsInBatchN = texelsInBatch * outShape[1];\\n\\n      int b2 = index / texelsInBatchN;\\n      index -= b2 * texelsInBatchN;\\n\\n      int b = index / texelsInBatch;\\n      index -= b * texelsInBatch;\\n\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec4(b2, b, r, c);\\n    }\\n  \";\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],\n              r = Math.ceil(e[e.length - 1] / 2),\n              a = r * Math.ceil(e[e.length - 2] / 2);\n          var i = a,\n              o = \"\",\n              l = \"b, r, c\";\n\n          for (var _t361 = 2; _t361 < e.length - 1; _t361++) {\n            i *= e[e.length - _t361 - 1], o = \"\\n      int b\".concat(_t361, \" = index / \").concat(i, \";\\n      index -= b\").concat(_t361, \" * \").concat(i, \";\\n    \") + o, l = \"b\".concat(_t361, \", \") + l;\n          }\n\n          return \"\\n    ivec\".concat(e.length, \" getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\").concat(s[0], \", \").concat(s[1], \"));\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n\\n      \").concat(o, \"\\n\\n      int b = index / \").concat(a, \";\\n      index -= b * \").concat(a, \";\\n\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec\").concat(e.length, \"(\").concat(l, \");\\n    }\\n  \");\n        }(e, t, n);\n    }\n  }(t.logicalShape, i, n.enableShapeUniforms), c = function (e) {\n    return \"\\n    void setOutput(vec4 val) {\\n      \".concat(e.output, \" = val;\\n    }\\n  \");\n  }(o)) : (u = function (e, t, n) {\n    switch (e.length) {\n      case 0:\n        return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n\n      case 1:\n        return function (e, t, n) {\n          return 1 === t[0] ? n ? \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * float(outTexShape[1]));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * \".concat(t[1], \".0);\\n      }\\n    \") : 1 === t[1] ? n ? \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * float(outTexShape[0]));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * \".concat(t[0], \".0);\\n      }\\n    \") : n ? \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(outTexShape[0], outTexShape[1]));\\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\\n    }\\n  \" : \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      return resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n    }\\n  \");\n        }(0, t, n);\n\n      case 2:\n        return function (e, t, n) {\n          return p(e, t) ? n ? \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      }\\n    \") : 1 === e[1] ? n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(outTexShape[0], outTexShape[1]));\\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n        int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \") : 1 === e[0] ? n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(outTexShape[0], outTexShape[1]));\\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n        int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \") : n ? \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(outTexShape[0], outTexShape[1]));\\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n      int r = index / outShape[1];\\n      int c = index - r * outShape[1];\\n      return ivec2(r, c);\\n    }\\n  \" : \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      int r = index / \").concat(e[1], \";\\n      int c = index - r * \").concat(e[1], \";\\n      return ivec2(r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 3:\n        return function (e, t, n) {\n          if (n) return \"\\n  ivec3 getOutputCoords() {\\n    ivec2 resTexRC = ivec2(resultUV.yx *\\n                           vec2(outTexShape[0], outTexShape[1]));\\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n    \".concat(ck([\"r\", \"c\", \"d\"], e), \"\\n    return ivec3(r, c, d);\\n  }\\n\");\n          var s = uk([\"r\", \"c\", \"d\"], e);\n          return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      \").concat(s, \"\\n      return ivec3(r, c, d);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 4:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(outTexShape[0], outTexShape[1]));\\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n      \".concat(ck([\"r\", \"c\", \"d\", \"d2\"], e), \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \");\n          var s = uk([\"r\", \"c\", \"d\", \"d2\"], e);\n          return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      \").concat(s, \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 5:\n        return function (e, t) {\n          var n = uk([\"r\", \"c\", \"d\", \"d2\", \"d3\"], e);\n          return \"\\n    ivec5 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(\".concat(t[0], \",\\n                             \").concat(t[1], \"));\\n\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n\\n      \").concat(n, \"\\n\\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\\n      return outShape;\\n    }\\n  \");\n        }(e, t);\n\n      case 6:\n        return function (e, t) {\n          var n = uk([\"r\", \"c\", \"d\", \"d2\", \"d3\", \"d4\"], e);\n          return \"\\n    ivec6 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n\\n      \").concat(n, \"\\n\\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\\n      return result;\\n    }\\n  \");\n        }(e, t);\n\n      default:\n        throw new Error(\"\".concat(e.length, \"-D output sampling is not yet supported\"));\n    }\n  }(t.logicalShape, i, n.enableShapeUniforms), c = function (e) {\n    return \"\\n    void setOutput(float val) {\\n      \".concat(e.output, \" = vec4(val, 0, 0, 0);\\n    }\\n  \");\n  }(o)), n.packedInputs && (h += Dk), [h, l, c, r, u, a, n.userCode].join(\"\\n\");\n}\n\nfunction Tk(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  var n = e.shapeInfo.logicalShape;\n\n  switch (n.length) {\n    case 0:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1);\n        if (e.shapeInfo.isUniform) return \"float \".concat(s, \"() {return \").concat(n, \";}\");\n        var [r, a] = e.shapeInfo.texShape;\n        if (1 === r && 1 === a) return \"\\n      float \".concat(s, \"() {\\n        return sampleTexture(\").concat(n, \", halfCR);\\n      }\\n    \");\n\n        var i = _k(n);\n\n        if (t) return \"\\n    float \".concat(s, \"() {\\n      vec2 uv = uvFromFlat(\").concat(n, \"TexShape[0], \").concat(n, \"TexShape[1], \").concat(i, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n        var [o, l] = e.shapeInfo.texShape;\n        return \"\\n    float \".concat(s, \"() {\\n      vec2 uv = uvFromFlat(\").concat(o, \", \").concat(l, \", \").concat(i, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 1:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1);\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int index) {\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n        var r = e.shapeInfo.texShape,\n            a = r[0],\n            i = r[1];\n        if (1 === i && 1 === a) return \"\\n      float \".concat(s, \"(int index) {\\n        return sampleTexture(\").concat(n, \", halfCR);\\n      }\\n    \");\n\n        var o = _k(n);\n\n        return 1 === i ? t ? \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \").concat(o, \") + 0.5) / float(\").concat(n, \"TexShape[0]));\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \").concat(o, \") + 0.5) / \").concat(a, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : 1 === a ? t ? \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2((float(index + \").concat(o, \") + 0.5) / float(\").concat(n, \"TexShape[1]), 0.5);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2((float(index + \").concat(o, \") + 0.5) / \").concat(i, \".0, 0.5);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : t ? \"\\n    float \".concat(s, \"(int index) {\\n      vec2 uv = uvFromFlat(\").concat(n, \"TexShape[0], \").concat(n, \"TexShape[1], index + \").concat(o, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \") : \"\\n    float \".concat(s, \"(int index) {\\n      vec2 uv = uvFromFlat(\").concat(a, \", \").concat(i, \", index + \").concat(o, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 2:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape;\n        if (null != a && p(n, a)) return t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(a[1], \".0, \").concat(a[0], \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n        var {\n          newShape: i,\n          keptDims: o\n        } = k(n);\n\n        if (i.length < n.length) {\n          var _n264 = [\"row\", \"col\"];\n          return \"\\n      \".concat(Tk(zk(e, i), t), \"\\n      float \").concat(r, \"(int row, int col) {\\n        return \").concat(r, \"(\").concat(Bk(_n264, o), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col) {\\n        int index = round(dot(vec2(row, col), vec2(\").concat(n[1], \", 1)));\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n\n        var l = a[0],\n            u = a[1],\n            c = _k(s);\n\n        return 1 === u ? t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(s, \"Shape[1], 1, 1));\\n        vec2 uv = vec2(0.5, (index + 0.5) / float(\").concat(s, \"TexShape[0]));\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(n[1], \", 1, 1));\\n      vec2 uv = vec2(0.5, (index + 0.5) / \").concat(l, \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : 1 === l ? t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(s, \"Shape[1], 1, 1));\\n        vec2 uv = vec2((index + 0.5) / float(\").concat(s, \"TexShape[1]), 0.5);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(n[1], \", 1, 1));\\n      vec2 uv = vec2((index + 0.5) / \").concat(u, \".0, 0.5);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \").concat(s, \"Shape[1] + col + \").concat(c, \";\\n        vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n  float \".concat(r, \"(int row, int col) {\\n    // Explicitly use integer operations as dot() only works on floats.\\n    int index = row * \").concat(n[1], \" + col + \").concat(c, \";\\n    vec2 uv = uvFromFlat(\").concat(l, \", \").concat(u, \", index);\\n    return sampleTexture(\").concat(s, \", uv);\\n  }\\n\");\n      }(e, t);\n\n    case 3:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = n[1] * n[2],\n            i = n[2],\n            {\n          newShape: o,\n          keptDims: l\n        } = k(n);\n\n        if (o.length < n.length) {\n          var _n265 = [\"row\", \"col\", \"depth\"];\n          return \"\\n        \".concat(Tk(zk(e, o), t), \"\\n        float \").concat(r, \"(int row, int col, int depth) {\\n          return \").concat(r, \"(\").concat(Bk(_n265, l), \");\\n        }\\n      \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        int index = round(dot(vec3(row, col, depth),\\n                          vec3(\").concat(a, \", \").concat(i, \", 1)));\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n        var u = e.shapeInfo.texShape,\n            c = u[0],\n            h = u[1],\n            d = e.shapeInfo.flatOffset;\n        if (h === a && null == d) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        int stride1 = \").concat(s, \"Shape[2];\\n        float texR = float(row);\\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n        float \".concat(r, \"(int row, int col, int depth) {\\n          float texR = float(row);\\n          float texC = dot(vec2(col, depth), vec2(\").concat(i, \", 1));\\n          vec2 uv = (vec2(texC, texR) + halfCR) /\\n                     vec2(\").concat(h, \".0, \").concat(c, \".0);\\n          return sampleTexture(\").concat(s, \", uv);\\n        }\\n      \");\n        if (h === i && null == d) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        float texR = dot(vec2(row, col), vec2(\").concat(s, \"Shape[1], 1));\\n        float texC = float(depth);\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col, int depth) {\\n      float texR = dot(vec2(row, col), vec2(\").concat(n[1], \", 1));\\n      float texC = float(depth);\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(h, \".0, \").concat(c, \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n\n        var p = _k(s);\n\n        return t ? \"\\n    float \".concat(r, \"(int row, int col, int depth) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int stride0 = \").concat(s, \"Shape[1] * \").concat(s, \"Shape[2];\\n      int stride1 = \").concat(s, \"Shape[2];\\n      int index = row * \").concat(a, \" + col * \").concat(i, \" + depth + \").concat(p, \";\\n      vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \").concat(a, \" + col * \").concat(i, \" + depth + \").concat(p, \";\\n        vec2 uv = uvFromFlat(\").concat(c, \", \").concat(h, \", index);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n  \");\n      }(e, t);\n\n    case 4:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = n[3],\n            i = n[2] * a,\n            o = n[1] * i,\n            {\n          newShape: l,\n          keptDims: u\n        } = k(n);\n\n        if (l.length < n.length) {\n          var _n266 = [\"row\", \"col\", \"depth\", \"depth2\"];\n          return \"\\n      \".concat(Tk(zk(e, l), t), \"\\n      float \").concat(r, \"(int row, int col, int depth, int depth2) {\\n        return \").concat(r, \"(\").concat(Bk(_n266, u), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        int index = round(dot(vec4(row, col, depth, depth2),\\n                          vec4(\").concat(o, \", \").concat(i, \", \").concat(a, \", 1)));\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n        var c = e.shapeInfo.flatOffset,\n            h = e.shapeInfo.texShape,\n            d = h[0],\n            p = h[1],\n            f = \"int stride2 = \".concat(s, \"Shape[3];\"),\n            g = \"int stride1 = \".concat(s, \"Shape[2] * stride2;\"),\n            m = \"int stride0 = \".concat(s, \"Shape[1] * stride1;\");\n        if (p === o && null == c) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        \").concat(f, \"\\n        \").concat(g, \"\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(stride1, stride2, 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(\").concat(i, \", \").concat(a, \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \");\n        if (p === a && null == c) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\").concat(s, \"Shape[1] * \").concat(s, \"Shape[2], \").concat(s, \"Shape[2], 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\").concat(n[1] * n[2], \", \").concat(n[2], \", 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \");\n\n        var b = _k(s);\n\n        return t ? \"\\n    float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      \").concat(f, \"\\n      \").concat(g, \"\\n      \").concat(m, \"\\n      int index = row * stride0 + col * stride1 +\\n          depth * stride2 + depth2;\\n      vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index + \").concat(b, \");\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : \"\\n    float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(o, \" + col * \").concat(i, \" +\\n          depth * \").concat(a, \" + depth2;\\n      vec2 uv = uvFromFlat(\").concat(d, \", \").concat(p, \", index + \").concat(b, \");\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 5:\n      return function (e) {\n        var t = e.shapeInfo.logicalShape,\n            n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = t[4],\n            a = t[3] * r,\n            i = t[2] * a,\n            o = t[1] * i,\n            {\n          newShape: l,\n          keptDims: u\n        } = k(t);\n\n        if (l.length < t.length) {\n          var _t362 = [\"row\", \"col\", \"depth\", \"depth2\", \"depth3\"];\n          return \"\\n      \".concat(Tk(zk(e, l)), \"\\n      float \").concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        return \").concat(s, \"(\").concat(Bk(_t362, u), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        float index = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(o, \", \").concat(i, \", \").concat(a, \", \").concat(r, \")) +\\n          depth3;\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n        var c = e.shapeInfo.flatOffset,\n            h = e.shapeInfo.texShape,\n            d = h[0],\n            p = h[1];\n        return p === o && null == c ? \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n                         vec4(\").concat(i, \", \").concat(a, \", \").concat(r, \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : p === r && null == c ? \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        float texR = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(t[1] * t[2] * t[3], \",\\n               \").concat(t[2] * t[3], \", \").concat(t[3], \", 1));\\n        int texC = depth3;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(o, \" + col * \").concat(i, \" + depth * \").concat(a, \" +\\n          depth2 * \").concat(r, \" + depth3 + \").concat(_k(n), \";\\n      vec2 uv = uvFromFlat(\").concat(d, \", \").concat(p, \", index);\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e);\n\n    case 6:\n      return function (e) {\n        var t = e.shapeInfo.logicalShape,\n            n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            {\n          newShape: r,\n          keptDims: a\n        } = k(t);\n\n        if (r.length < t.length) {\n          var _t363 = [\"row\", \"col\", \"depth\", \"depth2\", \"depth3\", \"depth4\"];\n          return \"\\n      \".concat(Tk(zk(e, r)), \"\\n      float \").concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        return \").concat(s, \"(\").concat(Bk(_t363, a), \");\\n      }\\n    \");\n        }\n\n        var i = t[5],\n            o = t[4] * i,\n            l = t[3] * o,\n            u = t[2] * l,\n            c = t[1] * u;\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n        int index = round(dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(c, \", \").concat(u, \", \").concat(l, \", \").concat(o, \")) +\\n          dot(\\n            vec2(depth3, depth4),\\n            vec2(\").concat(i, \", 1)));\\n        \").concat(Ok(e), \"\\n      }\\n    \");\n        var h = e.shapeInfo.flatOffset,\n            d = e.shapeInfo.texShape,\n            p = d[0],\n            f = d[1];\n        return f === c && null == h ? \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n          vec4(\").concat(u, \", \").concat(l, \", \").concat(o, \", \").concat(i, \")) +\\n               float(depth4);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(f, \".0, \").concat(p, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : f === i && null == h ? \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        float texR = dot(vec4(row, col, depth, depth2),\\n          vec4(\").concat(t[1] * t[2] * t[3] * t[4], \",\\n               \").concat(t[2] * t[3] * t[4], \",\\n               \").concat(t[3] * t[4], \",\\n               \").concat(t[4], \")) + float(depth3);\\n        int texC = depth4;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(f, \".0, \").concat(p, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(s, \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(c, \" + col * \").concat(u, \" + depth * \").concat(l, \" +\\n          depth2 * \").concat(o, \" + depth3 * \").concat(i, \" + depth4 + \").concat(_k(n), \";\\n      vec2 uv = uvFromFlat(\").concat(p, \", \").concat(f, \", index);\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e);\n\n    default:\n      throw new Error(\"\".concat(n.length, \"-D input sampling is not yet supported\"));\n  }\n}\n\nfunction Ek(e, t) {\n  switch (e.shapeInfo.logicalShape.length) {\n    case 0:\n      return function (e) {\n        var t = e.name;\n        return \"\\n    vec4 \".concat(\"get\" + t.charAt(0).toUpperCase() + t.slice(1), \"() {\\n      return \").concat(lk().texture2D, \"(\").concat(t, \", halfCR);\\n    }\\n  \");\n      }(e);\n\n    case 1:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = e.shapeInfo.texShape,\n            a = lk();\n        if (t) return \"\\n    vec4 \".concat(s, \"(int index) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(n, \"TexShape[0]) / 2.0), ceil(float(\").concat(n, \"TexShape[1]) / 2.0));\\n      vec2 uv = packedUVfrom1D(\\n        packedTexShape[0], packedTexShape[1], index);\\n      return \").concat(a.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n        var i = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)];\n        return \"\\n    vec4 \".concat(s, \"(int index) {\\n      vec2 uv = packedUVfrom1D(\\n        \").concat(i[0], \", \").concat(i[1], \", index);\\n      return \").concat(a.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 2:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape,\n            i = a[0],\n            o = a[1],\n            l = lk();\n        if (null != a && p(n, a)) return t ? \"\\n      vec4 \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n\\n        return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      vec4 \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(o, \".0, \").concat(i, \".0);\\n\\n        return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n      }\\n    \");\n        if (t) return \"\\n    vec4 \".concat(r, \"(int row, int col) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(s, \"TexShape[0]) / 2.0), ceil(float(\").concat(s, \"TexShape[1]) / 2.0));\\n      int valuesPerRow = int(ceil(float(\").concat(s, \"Shape[1]) / 2.0));\\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\\n      return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n        var u = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];\n        return \"\\n    vec4 \".concat(r, \"(int row, int col) {\\n      vec2 uv = packedUVfrom2D(\").concat(Math.ceil(n[1] / 2), \", \").concat(u[0], \", \").concat(u[1], \", row, col);\\n      return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 3:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape,\n            i = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];\n\n        if (1 === n[0]) {\n          var _s211 = [1, 2],\n              _a122 = [\"b\", \"row\", \"col\"];\n          return \"\\n        \".concat(Ek(zk(e, n.slice(1)), t), \"\\n        vec4 \").concat(r, \"(int b, int row, int col) {\\n          return \").concat(r, \"(\").concat(Bk(_a122, _s211), \");\\n        }\\n      \");\n        }\n\n        var o = lk();\n        if (t) return \"\\n    vec4 \".concat(r, \"(int b, int row, int col) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(s, \"TexShape[0]) / 2.0), ceil(float(\").concat(s, \"TexShape[1]) / 2.0));\\n      int valuesPerRow = int(ceil(float(\").concat(s, \"Shape[2]) / 2.0));\\n      int texelsInBatch = valuesPerRow * int(ceil(float(\").concat(s, \"Shape[1]) / 2.0));\\n      vec2 uv = packedUVfrom3D(\\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\\n      return \").concat(o.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n        var l = i[0],\n            u = i[1],\n            c = Math.ceil(n[2] / 2);\n        return \"\\n    vec4 \".concat(r, \"(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        \").concat(l, \", \").concat(u, \", \").concat(c * Math.ceil(n[1] / 2), \", \").concat(c, \", b, row, col);\\n      return \").concat(o.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    default:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = lk();\n        if (t) return \"\\n    vec4 \".concat(s, \"(int b2, int b, int row, int col) {\\n      int valuesPerRow = int(ceil(float(\").concat(n, \"Shape[3]) / 2.0));\\n      int texelsInBatch = valuesPerRow * int(ceil(float(\").concat(n, \"Shape[2]) / 2.0));\\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\\n      texelsInBatch *= \").concat(n, \"Shape[1];\\n      index = b2 * texelsInBatch + index;\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(n, \"TexShape[0]) / 2.0), ceil(float(\").concat(n, \"TexShape[1]) / 2.0));\\n      int texR = index / packedTexShape[1];\\n      int texC = index - texR * packedTexShape[1];\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return \").concat(r.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n        var a = e.shapeInfo.logicalShape,\n            i = a.length,\n            o = e.shapeInfo.texShape,\n            l = [Math.ceil(o[0] / 2), Math.ceil(o[1] / 2)],\n            u = l[0],\n            c = l[1],\n            h = Math.ceil(a[i - 1] / 2);\n        var d = h * Math.ceil(a[i - 2] / 2),\n            p = \"int b, int row, int col\",\n            f = \"b * \".concat(d, \" + (row / 2) * \").concat(h, \" + (col / 2)\");\n\n        for (var _e430 = 2; _e430 < i - 1; _e430++) {\n          p = \"int b\".concat(_e430, \", \") + p, d *= a[i - _e430 - 1], f = \"b\".concat(_e430, \" * \").concat(d, \" + \") + f;\n        }\n\n        return \"\\n    vec4 \".concat(s, \"(\").concat(p, \") {\\n      int index = \").concat(f, \";\\n      int texR = index / \").concat(c, \";\\n      int texC = index - texR * \").concat(c, \";\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(c, \", \").concat(u, \");\\n      return \").concat(r.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n  }\n}\n\nvar Rk = \"\\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n  int texelIndex = index / 2;\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    Ak = \"\\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\\n  int texNumC, int row, int col) {\\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    Fk = \"\\nvec2 packedUVfrom3D(int texNumR, int texNumC,\\n    int texelsInBatch, int texelsInLogicalRow, int b,\\n    int row, int col) {\\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    Dk = \"\\n  float getChannel(vec4 frag, vec2 innerDims) {\\n    vec2 modCoord = mod(innerDims, 2.);\\n    return modCoord.x == 0. ?\\n      (modCoord.y == 0. ? frag.r : frag.g) :\\n      (modCoord.y == 0. ? frag.b : frag.a);\\n  }\\n  float getChannel(vec4 frag, int dim) {\\n    float modCoord = mod(float(dim), 2.);\\n    return modCoord == 0. ? frag.r : frag.g;\\n  }\\n\";\n\nfunction _k(e) {\n  return \"offset\".concat(e);\n}\n\nfunction Ok(e) {\n  var t = e.name,\n      n = d(e.shapeInfo.logicalShape);\n  return n < 2 ? \"return \".concat(t, \";\") : \"\\n    for (int i = 0; i < \".concat(n, \"; i++) {\\n      if (i == index) {\\n        return \").concat(t, \"[i];\\n      }\\n    }\\n  \");\n}\n\nfunction Mk(e) {\n  if (e <= 1) return \"int\";\n  if (2 === e) return \"ivec2\";\n  if (3 === e) return \"ivec3\";\n  if (4 === e) return \"ivec4\";\n  if (5 === e) return \"ivec5\";\n  if (6 === e) return \"ivec6\";\n  throw Error(\"GPU for rank \".concat(e, \" is not yet supported\"));\n}\n\nfunction Lk(e, t, n) {\n  var {\n    newShape: s\n  } = k(t),\n      r = t.length,\n      a = e && 3 === r && 1 === t[0],\n      i = a ? t.slice(1) : s,\n      o = !e && r > 1 && !p(t, n) && s.length < r || a;\n  return {\n    useSqueezeShape: o,\n    uniformShape: o ? i : t\n  };\n}\n\nfunction zk(e, t) {\n  var n = JSON.parse(JSON.stringify(e));\n  return n.shapeInfo.logicalShape = t, n;\n}\n\nfunction Bk(e, t) {\n  return t.map(t => e[t]).join(\", \");\n}\n\nfunction Pk(e, t) {\n  if (e.length !== t.length) throw Error(\"Binary was compiled with \".concat(e.length, \" inputs, but was executed with \").concat(t.length, \" inputs\"));\n  e.forEach((e, n) => {\n    var s = e.logicalShape,\n        r = t[n],\n        a = r.shape;\n    if (!p(s, a)) throw Error(\"Binary was compiled with different shapes than the current args. Shapes \".concat(s, \" and \").concat(a, \" must match\"));\n    if (e.isUniform && r.isUniform) return;\n    var i = e.texShape,\n        o = r.isUniform ? null : r.texData.texShape;\n    if (!p(i, o)) throw Error(\"Binary was compiled with different texture shapes than the current args. Shape \".concat(i, \" and \").concat(o, \" must match\"));\n  });\n}\n\nfunction Wk(e) {\n  return V().getBool(\"WEBGL_USE_SHAPES_UNIFORMS\") && e <= 4;\n}\n\nvar {\n  addImpl: Uk,\n  bincountImpl: Vk,\n  bincountReduceImpl: Gk,\n  ceilImpl: Hk,\n  concatImpl: jk,\n  equalImpl: qk,\n  expImpl: Kk,\n  expm1Impl: Xk,\n  floorImpl: Yk,\n  gatherNdImpl: Jk,\n  gatherV2Impl: Zk,\n  greaterImpl: Qk,\n  greaterEqualImpl: ew,\n  lessImpl: tw,\n  lessEqualImpl: nw,\n  linSpaceImpl: sw,\n  logImpl: rw,\n  maxImpl: aw,\n  maximumImpl: iw,\n  minimumImpl: ow,\n  multiplyImpl: lw,\n  negImpl: uw,\n  notEqualImpl: cw,\n  prodImpl: hw,\n  rangeImpl: dw,\n  rsqrtImpl: pw,\n  simpleAbsImpl: fw,\n  sliceImpl: gw,\n  sparseFillEmptyRowsImpl: mw,\n  sparseReshapeImpl: bw,\n  sparseSegmentReductionImpl: xw,\n  stridedSliceImpl: yw,\n  stringNGramsImpl: kw,\n  stringSplitImpl: ww,\n  stringToHashBucketFastImpl: vw,\n  subImpl: Iw,\n  tileImpl: $w,\n  topKImpl: Nw,\n  transposeImpl: Cw,\n  uniqueImpl: Sw\n} = $m;\n\nfunction Tw(e, t) {\n  return [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, t).map(t => \"\".concat(e, \".\").concat(t));\n}\n\nfunction Ew(e, t) {\n  return 1 === t ? [e] : Tw(e, t);\n}\n\nclass Rw {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0, this.outputShape = e;\n    var t = e.length;\n    if (0 === t) this.userCode = \"\\n        void main() {\\n          setOutput(vec4(getA(), 0., 0., 0.));\\n        }\\n      \";else {\n      var _n267 = Ew(\"rc\", t),\n          _s212 = Mk(t),\n          _r155 = function (e, t, n) {\n        if (1 === e) return \"rc > \".concat(t[0]);\n        var s = \"\";\n\n        for (var _r156 = e - 2; _r156 < e; _r156++) {\n          s += \"\".concat(n[_r156], \" >= \").concat(t[_r156]), _r156 < e - 1 && (s += \"||\");\n        }\n\n        return s;\n      }(t, e, _n267),\n          _a123 = function (e, t, n, s) {\n        if (1 === e) return \"\";\n        var r = s.slice(-2);\n        return \"\\n    int r = \".concat(r[0], \";\\n    int c = \").concat(r[1], \";\\n    int rp1 = r + 1;\\n    int cp1 = c + 1;\\n\\n    bool cEdge = cp1 >= \").concat(t, \";\\n    bool rEdge = rp1 >= \").concat(n, \";\\n  \");\n      }(t, e[e.length - 1], e[e.length - 2], _n267),\n          _i86 = function (e, t) {\n        var n = e.length,\n            s = function (e, t) {\n          var n = [];\n\n          for (var _s213 = 0; _s213 <= 1; _s213++) {\n            for (var _r157 = 0; _r157 <= 1; _r157++) {\n              var _a124 = \"\".concat(0 === _s213 ? \"r\" : \"rp1\", \", \").concat(0 === _r157 ? \"c\" : \"cp1\");\n\n              for (var _n268 = 2; _n268 < e; _n268++) {\n                _a124 = \"\".concat(t[t.length - 1 - _n268], \",\") + _a124;\n              }\n\n              n.push(_a124);\n            }\n          }\n\n          return n;\n        }(n, t);\n\n        return 1 === n ? \"getA(rc),\\n            rc + 1 >= \".concat(e[0], \" ? 0. : getA(rc + 1),\\n            0, 0\") : \"getA(\".concat(s[0], \"),\\n          cEdge ? 0. : getA(\").concat(s[1], \"),\\n          rEdge ? 0. : getA(\").concat(s[2], \"),\\n          rEdge || cEdge ? 0. : getA(\").concat(s[3], \")\");\n      }(e, _n267);\n\n      this.userCode = \"\\n        void main() {\\n          \".concat(_s212, \" rc = getOutputCoords();\\n\\n          if(\").concat(_r155, \") {\\n            setOutput(vec4(0));\\n          } else {\\n            \").concat(_a123, \"\\n\\n            setOutput(vec4(\").concat(_i86, \"));\\n          }\\n        }\\n      \");\n    }\n  }\n\n}\n\nclass Aw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;\n    var n = \"\";\n\n    for (var _e431 = 0; _e431 < 4; _e431++) {\n      var _t364 = \"thisRC = rc;\";\n      _e431 % 2 == 1 && (_t364 += \"thisRC.z += 1;\"), _e431 > 1 && (_t364 += \"thisRC.y += 1;\"), n += \"\\n        \".concat(_t364, \"\\n        \").concat(_e431 > 0 ? \"if(thisRC.y < rows && thisRC.z < cols){\" : \"\", \"\\n          int flatIndex = getFlatIndex(thisRC);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[\").concat(_e431, \"] =\\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\\n        \").concat(_e431 > 0 ? \"}\" : \"\", \"\\n      \");\n    }\n\n    var s;\n    this.userCode = \"\\n      \".concat((s = t, \"\\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      \".concat(uk([\"r\", \"c\", \"d\"], s), \"\\n      return ivec3(r, c, d);\\n    }\\n  \")), \"\\n      \").concat(hk(e), \"\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n\\n        ivec3 thisRC;\\n        int rows = \").concat(e[1], \";\\n        int cols = \").concat(e[2], \";\\n\\n        \").concat(n, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass Fw {\n  constructor(e) {\n    this.gpgpu = e, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.logEnabled = !1, this.usedTextures = {};\n  }\n\n  acquireTexture(e, t, n) {\n    var s = _w(t, n),\n        r = Ow(e, s, n);\n\n    r in this.freeTextures || (this.freeTextures[r] = []), r in this.usedTextures || (this.usedTextures[r] = []);\n    var a = Dw(e, s, this.gpgpu.gl, this.gpgpu.textureConfig, n);\n\n    if (this.freeTextures[r].length > 0) {\n      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= a, this.log();\n\n      var _e432 = this.freeTextures[r].shift();\n\n      return this.usedTextures[r].push(_e432), _e432;\n    }\n\n    var i;\n    return s === Oy.PACKED_2X2_FLOAT32 ? i = this.gpgpu.createPackedMatrixTexture(e[0], e[1]) : s === Oy.PACKED_2X2_FLOAT16 ? i = this.gpgpu.createFloat16PackedMatrixTexture(e[0], e[1]) : s === Oy.UNPACKED_FLOAT32 ? i = this.gpgpu.createFloat32MatrixTexture(e[0], e[1]) : s === Oy.UNPACKED_FLOAT16 ? i = this.gpgpu.createFloat16MatrixTexture(e[0], e[1]) : s === Oy.PACKED_4X1_UNSIGNED_BYTE && (i = this.gpgpu.createUnsignedBytesMatrixTexture(e[0], e[1])), this.usedTextures[r].push(i), this.numUsedTextures++, this._numBytesAllocated += a, this.log(), i;\n  }\n\n  releaseTexture(e, t, n, s) {\n    if (null == this.freeTextures) return;\n\n    var r = _w(n, s),\n        a = Ow(t, r, s);\n\n    a in this.freeTextures || (this.freeTextures[a] = []);\n    var i = Dw(t, r, this.gpgpu.gl, this.gpgpu.textureConfig, s),\n        o = V().get(\"WEBGL_DELETE_TEXTURE_THRESHOLD\");\n    -1 !== o && this._numBytesAllocated > o ? (this.gpgpu.deleteMatrixTexture(e), this._numBytesAllocated -= i) : (this.freeTextures[a].push(e), this.numFreeTextures++, this._numBytesFree += i), this.numUsedTextures--;\n    var l = this.usedTextures[a],\n        u = l.indexOf(e);\n    if (u < 0) throw new Error(\"Cannot release a texture that was never provided by this texture manager\");\n    l.splice(u, 1), this.log();\n  }\n\n  log() {\n    if (!this.logEnabled) return;\n    console.log(\"Free/Used\", \"\".concat(this.numFreeTextures, \" / \").concat(this.numUsedTextures), \"(\".concat(this.numFreeTextures + this.numUsedTextures, \")\"));\n    var e = this._numBytesFree / this._numBytesAllocated;\n    console.log(\"Bytes allocated: \".concat(this._numBytesAllocated)), console.log(\"Bytes unused: \".concat(this._numBytesFree, \" (\").concat(Math.round(100 * e), \"%)\"));\n  }\n\n  get numBytesAllocated() {\n    return this._numBytesAllocated;\n  }\n\n  get numBytesFree() {\n    return this._numBytesFree;\n  }\n\n  getNumUsedTextures() {\n    return this.numUsedTextures;\n  }\n\n  getNumFreeTextures() {\n    return this.numFreeTextures;\n  }\n\n  dispose() {\n    if (null != this.freeTextures) {\n      for (var _e433 in this.freeTextures) {\n        this.freeTextures[_e433].forEach(e => {\n          this.gpgpu.deleteMatrixTexture(e);\n        });\n      }\n\n      for (var _e434 in this.usedTextures) {\n        this.usedTextures[_e434].forEach(e => {\n          this.gpgpu.deleteMatrixTexture(e);\n        });\n      }\n\n      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;\n    }\n  }\n\n}\n\nfunction Dw(e, t, n, s, r) {\n  var a = function (e, t) {\n    switch (e) {\n      case Oy.PACKED_2X2_FLOAT32:\n        return Ik(t);\n\n      case Oy.PACKED_2X2_FLOAT16:\n        return $k(t);\n\n      case Oy.UNPACKED_FLOAT32:\n        return kk(t);\n\n      case Oy.UNPACKED_FLOAT16:\n        return wk(t);\n\n      case Oy.PACKED_4X1_UNSIGNED_BYTE:\n        return vk(t);\n\n      default:\n        throw new Error(\"Unknown physical texture type \".concat(e));\n    }\n  }(t, s);\n\n  var i;\n\n  if (r) {\n    var [_t365, _n269] = zy(e[0], e[1]);\n    i = _t365 * _n269;\n  } else {\n    var [_t366, _n270] = My(e[0], e[1]);\n    i = _t366 * _n270;\n  }\n\n  return i * function (e, t) {\n    if (t === e.R32F) return 4;\n    if (t === e.R16F) return 2;\n    if (t === e.RGBA32F) return 16;\n    if (t === e.RGBA) return 16;\n    if (t === e.RGBA16F) return 8;\n    throw new Error(\"Unknown internal format \".concat(t));\n  }(n, a);\n}\n\nfunction _w(e, t) {\n  if (e === _y.UPLOAD) return Oy.PACKED_2X2_FLOAT32;\n  if (e === _y.RENDER || null == e) return function (e) {\n    return V().getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") ? e ? Oy.PACKED_2X2_FLOAT32 : Oy.UNPACKED_FLOAT32 : e ? Oy.PACKED_2X2_FLOAT16 : Oy.UNPACKED_FLOAT16;\n  }(t);\n  if (e === _y.DOWNLOAD || e === _y.PIXELS) return Oy.PACKED_4X1_UNSIGNED_BYTE;\n  throw new Error(\"Unknown logical texture type \".concat(e));\n}\n\nfunction Ow(e, t, n) {\n  return \"\".concat(e[0], \"_\").concat(e[1], \"_\").concat(t, \"_\").concat(n);\n}\n\nclass Mw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.outputShape = e, this.enableShapeUniforms = Wk(this.outputShape.length), this.userCode = \"\\n      float unaryOperation(float x) {\\n        \".concat(t, \"\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        float y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \");\n  }\n\n}\n\nvar Lw = \"return x;\";\n\nclass zw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.enableShapeUniforms = Wk(this.outputShape.length), this.userCode = \"\\n      vec4 unaryOperation(vec4 x) {\\n        \".concat(t, \"\\n      }\\n\\n      void main() {\\n        vec4 x = getAAtOutCoords();\\n        vec4 y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \");\n  }\n\n}\n\nclass Bw {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !1, this.outputShape = e;\n\n    var t = e.length,\n        n = Ew(\"rc\", t),\n        s = Mk(t),\n        r = function (e, t) {\n      if (1 === e) return \"rc\";\n      var n = \"\";\n\n      for (var _s214 = 0; _s214 < e; _s214++) {\n        n += t[_s214], _s214 < e - 1 && (n += \",\");\n      }\n\n      return n;\n    }(t, n),\n        a = n.slice(-2),\n        i = t <= 1 ? \"rc\" : \"vec2(\".concat(a.join(\",\"), \")\");\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(s, \" rc = getOutputCoords();\\n        vec4 packedInput = getA(\").concat(r, \");\\n\\n        setOutput(getChannel(packedInput, \").concat(i, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar Pw = Ii,\n    Ww = {},\n    Uw = V().getNumber(\"CPU_HANDOFF_SIZE_THRESHOLD\");\n\nclass Vw extends n {\n  constructor(e) {\n    if (super(), this.pendingRead = new WeakMap(), this.pendingDisposal = new WeakSet(), this.dataRefCount = new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = !1, this.pendingDeletes = 0, this.disposed = !1, !V().getBool(\"HAS_WEBGL\")) throw new Error(\"WebGL is not supported on this device\");\n\n    if (null == e) {\n      var _e435 = Fy(V().getNumber(\"WEBGL_VERSION\"));\n\n      this.binaryCache = ((n = V().getNumber(\"WEBGL_VERSION\")) in Ww || (Ww[n] = {}), Ww[n]), this.gpgpu = new Nk(_e435), this.canvas = _e435.canvas, this.gpgpuCreatedLocally = !0;\n    } else this.gpgpu = e, this.binaryCache = {}, this.gpgpuCreatedLocally = !1, this.canvas = e.gl.canvas;\n\n    var n;\n    this.textureManager = new Fw(this.gpgpu), this.numMBBeforeWarning = null == V().global.screen ? 1024 : V().global.screen.height * V().global.screen.width * window.devicePixelRatio * 600 / 1024 / 1024, this.texData = new t(this, Kn());\n  }\n\n  nextDataId() {\n    return Vw.nextDataId++;\n  }\n\n  numDataIds() {\n    return this.texData.numDataIds() - this.pendingDeletes;\n  }\n\n  write(e, t, n) {\n    if ((V().getBool(\"WEBGL_CHECK_NUMERICAL_PROBLEMS\") || V().getBool(\"DEBUG\")) && this.checkNumericalProblems(e), \"complex64\" === n && null != e) throw new Error(\"Cannot write to a complex64 dtype. Please use tf.complex(real, imag).\");\n    var s = {\n      id: this.nextDataId()\n    };\n    return this.texData.set(s, {\n      shape: t,\n      dtype: n,\n      values: e,\n      usage: _y.UPLOAD,\n      refCount: 1\n    }), s;\n  }\n\n  refCount(e) {\n    return this.texData.has(e) ? this.texData.get(e).refCount : 0;\n  }\n\n  incRef(e) {\n    this.texData.get(e).refCount++;\n  }\n\n  decRef(e) {\n    this.texData.has(e) && this.texData.get(e).refCount--;\n  }\n\n  move(e, t, n, s, r) {\n    if (V().getBool(\"DEBUG\") && this.checkNumericalProblems(t), \"complex64\" === s) throw new Error(\"Cannot write to a complex64 dtype. Please use tf.complex(real, imag).\");\n    this.texData.set(e, {\n      shape: n,\n      dtype: s,\n      values: t,\n      usage: _y.UPLOAD,\n      refCount: r\n    });\n  }\n\n  disposeIntermediateTensorInfo(e) {\n    this.disposeData(e.dataId);\n  }\n\n  readSync(e) {\n    var t = this.texData.get(e),\n        {\n      values: n,\n      dtype: s,\n      complexTensorInfos: r,\n      slice: a,\n      shape: i,\n      isPacked: o\n    } = t;\n\n    if (null != a) {\n      var _t367;\n\n      _t367 = o ? new zw(i, Lw) : new Mw(i, Lw);\n\n      var _n271 = this.runWebGLProgram(_t367, [{\n        dataId: e,\n        shape: i,\n        dtype: s\n      }], s),\n          _r158 = this.readSync(_n271.dataId);\n\n      return this.disposeIntermediateTensorInfo(_n271), _r158;\n    }\n\n    if (null != n) return this.convertAndCacheOnCPU(e);\n    if (\"string\" === s) return n;\n    var l = null != this.activeTimers;\n    var u, c;\n    return l && (u = Ve()), c = \"complex64\" === s ? Mo(this.readSync(r.real.dataId), this.readSync(r.imag.dataId)) : this.getValuesFromTexture(e), l && (this.downloadWaitMs += Ve() - u), this.convertAndCacheOnCPU(e, c);\n  }\n\n  read(e) {\n    var _this73 = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this73.pendingRead.has(e)) {\n        var _t368 = _this73.pendingRead.get(e);\n\n        return new Promise(e => _t368.push(e));\n      }\n\n      var t = _this73.texData.get(e),\n          {\n        values: n,\n        shape: s,\n        slice: r,\n        dtype: a,\n        complexTensorInfos: i,\n        isPacked: o\n      } = t;\n\n      if (null != r) {\n        var _t369;\n\n        _t369 = o ? new zw(s, Lw) : new Mw(s, Lw);\n\n        var _n272 = _this73.runWebGLProgram(_t369, [{\n          dataId: e,\n          shape: s,\n          dtype: a\n        }], a),\n            _r159 = _this73.read(_n272.dataId);\n\n        return _this73.disposeIntermediateTensorInfo(_n272), _r159;\n      }\n\n      if (null != n) return _this73.convertAndCacheOnCPU(e);\n      if (!V().getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\") && 2 === V().getNumber(\"WEBGL_VERSION\")) throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.\");\n      var l,\n          u,\n          c = null;\n\n      if (\"complex64\" !== a && V().get(\"WEBGL_BUFFER_SUPPORTED\")) {\n        l = _this73.decode(e);\n\n        var _t370 = _this73.texData.get(l.dataId);\n\n        c = _this73.gpgpu.createBufferFromTexture(_t370.texture, ...Ly(s));\n      }\n\n      if (_this73.pendingRead.set(e, []), \"complex64\" !== a && (yield _this73.gpgpu.createAndWaitForFence()), \"complex64\" === a) {\n        var _e436 = yield Promise.all([_this73.read(i.real.dataId), _this73.read(i.imag.dataId)]);\n\n        u = Mo(_e436[0], _e436[1]);\n      } else if (null == c) u = _this73.getValuesFromTexture(e);else {\n        var _e437 = d(s);\n\n        u = _this73.gpgpu.downloadFloat32MatrixFromBuffer(c, _e437);\n      }\n\n      if (null != l && _this73.disposeIntermediateTensorInfo(l), null != c) {\n        var _e438 = _this73.gpgpu.gl;\n        Py(_e438, () => _e438.deleteBuffer(c));\n      }\n\n      var h = _this73.convertAndCacheOnCPU(e, u),\n          p = _this73.pendingRead.get(e);\n\n      return _this73.pendingRead.delete(e), p.forEach(e => e(h)), _this73.pendingDisposal.has(e) && (_this73.pendingDisposal.delete(e), _this73.disposeData(e) && Kn().removeDataId(e, _this73), _this73.pendingDeletes--), h;\n    })();\n  }\n\n  bufferSync(e) {\n    var t = this.readSync(e.dataId);\n    var n = t;\n    if (\"string\" === e.dtype) try {\n      n = t.map(e => He(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode encoded string bytes into utf-8\");\n    }\n    return dn(e.shape, e.dtype, n);\n  }\n\n  checkNumericalProblems(e) {\n    if (null != e) for (var _t371 = 0; _t371 < e.length; _t371++) {\n      var _n273 = e[_t371];\n\n      if (!Wy(_n273)) {\n        if (V().getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\")) throw Error(\"The value \".concat(_n273, \" cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'\"));\n        throw Error(\"The value \".concat(_n273, \" cannot be represented on this device.\"));\n      }\n    }\n  }\n\n  getValuesFromTexture(e) {\n    var {\n      shape: t,\n      dtype: n,\n      isPacked: s\n    } = this.texData.get(e),\n        r = d(t);\n\n    if (V().getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\")) {\n      var _n274 = this.decode(e),\n          _s215 = this.texData.get(_n274.dataId),\n          _a125 = this.gpgpu.downloadMatrixFromPackedTexture(_s215.texture, ...Ly(t)).subarray(0, r);\n\n      return this.disposeIntermediateTensorInfo(_n274), _a125;\n    }\n\n    var a = V().getBool(\"WEBGL_PACK\") && !0 === s,\n        i = a ? Zy(t) : t,\n        o = a ? new mk(i) : new gk(i),\n        l = this.runWebGLProgram(o, [{\n      shape: i,\n      dtype: n,\n      dataId: e\n    }], \"float32\"),\n        u = this.texData.get(l.dataId),\n        c = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture, u.texShape[0], u.texShape[1]).subarray(0, r);\n    return this.disposeIntermediateTensorInfo(l), c;\n  }\n\n  timerAvailable() {\n    return V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0;\n  }\n\n  time(e) {\n    var _this74 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = _this74.activeTimers,\n          n = [];\n      var s = !1;\n      null == _this74.programTimersStack ? (_this74.programTimersStack = n, s = !0) : _this74.activeTimers.push(n), _this74.activeTimers = n, e();\n      var r = h(_this74.activeTimers.map(e => e.query)).filter(e => null != e),\n          a = h(_this74.activeTimers.map(e => e.name)).filter(e => null != e);\n      _this74.activeTimers = t, s && (_this74.programTimersStack = null);\n      var i = {\n        uploadWaitMs: _this74.uploadWaitMs,\n        downloadWaitMs: _this74.downloadWaitMs,\n        kernelMs: null,\n        wallMs: null\n      };\n\n      if (V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0) {\n        var _e439 = yield Promise.all(r);\n\n        i.kernelMs = function (e) {\n          var t = 0;\n\n          for (var _n275 = 0; _n275 < e.length; _n275++) {\n            t += e[_n275];\n          }\n\n          return t;\n        }(_e439), i.getExtraProfileInfo = () => _e439.map((e, t) => ({\n          name: a[t],\n          ms: e\n        })).map(e => \"\".concat(e.name, \": \").concat(e.ms)).join(\", \");\n      } else i.kernelMs = {\n        error: \"WebGL query timers are not supported in this environment.\"\n      };\n\n      return _this74.uploadWaitMs = 0, _this74.downloadWaitMs = 0, i;\n    })();\n  }\n\n  memory() {\n    return {\n      unreliable: !1,\n      numBytesInGPU: this.numBytesInGPU,\n      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,\n      numBytesInGPUFree: this.textureManager.numBytesFree\n    };\n  }\n\n  startTimer() {\n    return V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? this.gpgpu.beginQuery() : {\n      startMs: Ve(),\n      endMs: null\n    };\n  }\n\n  endTimer(e) {\n    return V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? (this.gpgpu.endQuery(), e) : (e.endMs = Ve(), e);\n  }\n\n  getQueryTime(e) {\n    var _this75 = this;\n\n    return _asyncToGenerator(function* () {\n      return V().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? _this75.gpgpu.waitForQueryAndGetTime(e) : e.endMs - e.startMs;\n    })();\n  }\n\n  disposeData(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    if (this.pendingDisposal.has(e)) return !1;\n    if (!this.texData.has(e)) return !0;\n    if (t ? this.texData.get(e).refCount = 0 : this.texData.get(e).refCount--, !t && this.texData.get(e).refCount > 0) return !1;\n    if (this.pendingRead.has(e)) return this.pendingDisposal.add(e), this.pendingDeletes++, !1;\n    this.releaseGPUData(e);\n    var {\n      complexTensorInfos: n\n    } = this.texData.get(e);\n    return null != n && (this.disposeData(n.real.dataId, t), this.disposeData(n.imag.dataId, t)), this.texData.delete(e), !0;\n  }\n\n  releaseGPUData(e) {\n    var {\n      texture: t,\n      dtype: n,\n      texShape: s,\n      usage: r,\n      isPacked: a,\n      slice: i\n    } = this.texData.get(e),\n        o = i && i.origDataId || e,\n        l = this.dataRefCount.get(o);\n    l > 1 ? this.dataRefCount.set(o, l - 1) : (this.dataRefCount.delete(o), null != t && (this.numBytesInGPU -= this.computeBytes(s, n), this.textureManager.releaseTexture(t, s, r, a)));\n    var u = this.texData.get(e);\n    u.texture = null, u.texShape = null, u.isPacked = !1, u.slice = null;\n  }\n\n  getTexture(e) {\n    return this.uploadToGPU(e), this.texData.get(e).texture;\n  }\n\n  getDataInfo(e) {\n    return this.texData.get(e);\n  }\n\n  shouldExecuteOnCPU(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : Uw;\n    return V().getBool(\"WEBGL_CPU_FORWARD\") && e.every(e => null == this.texData.get(e.dataId).texture && d(e.shape) < t);\n  }\n\n  getGPGPUContext() {\n    return this.gpgpu;\n  }\n\n  where(e) {\n    Oo(\"tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead\");\n    var t = e.dataSync();\n    return Pw(e.shape, t);\n  }\n\n  packedUnaryOp(e, t, n) {\n    var s = new zw(e.shape, t),\n        r = this.compileAndRun(s, [e], n);\n    return Kn().makeTensorFromDataId(r.dataId, r.shape, r.dtype);\n  }\n\n  abs(e) {\n    if (this.shouldExecuteOnCPU([e]) && \"complex64\" !== e.dtype) {\n      var _t372 = fw(this.texData.get(e.dataId).values);\n\n      return this.makeOutput(e.shape, e.dtype, _t372);\n    }\n\n    if (V().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\")) return this.packedUnaryOp(e, \"return abs(x);\", e.dtype);\n    var t = new Mw(e.shape, \"return abs(x);\"),\n        n = this.compileAndRun(t, [e]);\n    return Kn().makeTensorFromDataId(n.dataId, n.shape, n.dtype);\n  }\n\n  makeTensorInfo(e, t, n) {\n    var s;\n\n    if (\"string\" === t && null != n && n.length > 0 && C(n[0])) {\n      var _r160 = n.map(e => Ge(e));\n\n      s = this.write(_r160, e, t);\n    } else s = this.write(n, e, t);\n\n    return this.texData.get(s).usage = null, {\n      dataId: s,\n      shape: e,\n      dtype: t\n    };\n  }\n\n  makeOutput(e, t, n) {\n    var {\n      dataId: s\n    } = this.makeTensorInfo(e, t, n);\n    return Kn().makeTensorFromDataId(s, e, t, this);\n  }\n\n  unpackTensor(e) {\n    var t = new Bw(e.shape);\n    return this.runWebGLProgram(t, [e], e.dtype);\n  }\n\n  packTensor(e) {\n    var t = new Rw(e.shape);\n    return this.runWebGLProgram(t, [e], e.dtype, null, !0);\n  }\n\n  packedReshape(e, t) {\n    var n = [Yy(e.shape), ...Jy(e.shape)],\n        s = {\n      dtype: e.dtype,\n      shape: n,\n      dataId: e.dataId\n    },\n        r = [Yy(t), ...Jy(t)],\n        a = new Aw(r, n),\n        i = this.runWebGLProgram(a, [s], e.dtype, null, !0);\n    return {\n      dataId: i.dataId,\n      shape: t,\n      dtype: i.dtype\n    };\n  }\n\n  decode(e) {\n    var t = this.texData.get(e),\n        {\n      isPacked: n,\n      shape: s,\n      dtype: r\n    } = t,\n        a = Zy(s);\n    var i;\n    return i = n ? new fk(a) : new pk(a), {\n      dtype: r,\n      shape: s,\n      dataId: this.runWebGLProgram(i, [{\n        shape: a,\n        dtype: r,\n        dataId: e\n      }], r, null, !0).dataId\n    };\n  }\n\n  runWebGLProgram(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    var a = this.makeTensorInfo(e.outputShape, n),\n        i = this.texData.get(a.dataId);\n\n    if (e.packedOutput && (i.isPacked = !0), e.outPackingScheme === Dy.DENSE) {\n      var _t373 = Ly(e.outputShape);\n\n      i.texShape = _t373.map(e => 2 * e);\n    }\n\n    if (null != e.outTexUsage && (i.usage = e.outTexUsage), 0 === d(a.shape)) return i.values = w(a.dtype, 0), a;\n    var o = [],\n        l = t.map(t => {\n      if (\"complex64\" === t.dtype) throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.\");\n      var n = this.texData.get(t.dataId);\n\n      if (null == n.texture) {\n        if (!e.packedInputs && d(t.shape) <= V().getNumber(\"WEBGL_SIZE_UPLOAD_UNIFORM\")) return {\n          shape: t.shape,\n          texData: null,\n          isUniform: !0,\n          uniformValues: n.values\n        };\n        e.packedInputs && (n.isPacked = !0, n.shape = t.shape);\n      } else if (!!n.isPacked != !!e.packedInputs) t = n.isPacked ? this.unpackTensor(t) : this.packTensor(t), o.push(t), n = this.texData.get(t.dataId);else if (n.isPacked && !ek(n.shape, t.shape)) {\n        var _e440 = t,\n            _s216 = t.shape;\n        t.shape = n.shape, t = this.packedReshape(t, _s216), o.push(t), n = this.texData.get(t.dataId), _e440.shape = _s216;\n      }\n\n      return this.uploadToGPU(t.dataId), {\n        shape: t.shape,\n        texData: n,\n        isUniform: !1\n      };\n    });\n    this.uploadToGPU(a.dataId);\n\n    var u = {\n      shape: a.shape,\n      texData: i,\n      isUniform: !1\n    },\n        c = function (e, t, n) {\n      var s = \"\";\n      t.concat(n).forEach(t => {\n        var r = null != t.texData && null != t.texData.slice && t.texData.slice.flatOffset > 0;\n\n        if (e.enableShapeUniforms && !t.isUniform) {\n          var _a126 = t.texData.texShape,\n              {\n            useSqueezeShape: _i87,\n            uniformShape: _o65\n          } = Lk(e.packedInputs, t.shape, _a126);\n          var _l45 = \"\",\n              _u34 = \"\",\n              _c29 = \"\";\n\n          if (1 === _o65.length && e.packedInputs) {\n            var _e441 = [Math.ceil(_a126[0] / 2), Math.ceil(_a126[1] / 2)];\n            _l45 = \"\".concat(_e441[0] > 1, \"_\").concat(_e441[1] > 1);\n          } else if (2 !== _o65.length || e.packedInputs) {\n            if (_o65.length > 2 && !e.packedInputs) {\n              var _e442 = A(_o65);\n\n              _c29 = \"\".concat(_e442[0] === _a126[1], \"_\").concat(_e442[_e442.length - 1] === _a126[1]);\n            }\n          } else _u34 = \"\".concat(_o65[0] > 1, \"_\").concat(_o65[1] > 1);\n\n          var _h17 = t.shape.length,\n              _f11 = 2 === _h17 && p(t.shape, _a126),\n              _g19 = 1 === d(t.shape),\n              _m13 = lr(t.shape, n.shape),\n              _b14 = !e.packedInputs && _h17 === n.shape.length && p(_a126, n.texData.texShape);\n\n          s += \"\".concat(_h17, \"_\").concat(_b14, \"_\").concat(_i87, \"_\").concat(_o65.length, \"_\").concat(_g19, \"_\").concat(_m13, \"_\").concat(_f11, \"_\").concat(_l45, \"_\").concat(_u34, \"_\").concat(_c29, \"_\").concat(e.packedInputs || _h17 > 2 ? \"\" : \"\".concat(_a126[0] > 1, \"_\").concat(_a126[1] > 1), \"_\").concat(r);\n        } else s += \"\".concat(t.shape, \"_\").concat(t.isUniform ? \"uniform\" : t.texData.texShape, \"_\").concat(r);\n      });\n      var r = e.constructor.name;\n      return r += \"_\" + s + \"_\" + e.userCode + \"\".concat(V().getNumber(\"WEBGL_VERSION\")), r;\n    }(e, l, u),\n        h = this.getAndSaveBinary(c, () => function (e, t, n, s) {\n      var r = n.map((e, n) => {\n        var s = {\n          logicalShape: e.shape,\n          texShape: e.isUniform ? null : e.texData.texShape,\n          isUniform: e.isUniform,\n          isPacked: !e.isUniform && e.texData.isPacked,\n          flatOffset: null\n        };\n        return null != e.texData && null != e.texData.slice && e.texData.slice.flatOffset > 0 && (s.flatOffset = e.texData.slice.flatOffset), {\n          name: t.variableNames[n],\n          shapeInfo: s\n        };\n      }),\n          a = r.map(e => e.shapeInfo),\n          i = {\n        logicalShape: s.shape,\n        texShape: s.texData.texShape,\n        isUniform: !1,\n        isPacked: s.texData.isPacked,\n        flatOffset: null\n      },\n          o = Sk(r, i, t),\n          l = e.createProgram(o);\n      var u = null;\n      var c = e.getUniformLocation(l, \"NAN\", !1);\n      1 === V().getNumber(\"WEBGL_VERSION\") && (u = e.getUniformLocation(l, \"INFINITY\", !1));\n      var h = !1,\n          d = {},\n          p = {},\n          f = {};\n\n      for (var _n276 = 0; _n276 < t.variableNames.length; _n276++) {\n        var _s217 = t.variableNames[_n276];\n        d[_s217] = e.getUniformLocation(l, _s217, h), d[\"offset\".concat(_s217)] = e.getUniformLocation(l, \"offset\".concat(_s217), h), t.enableShapeUniforms && (p[\"\".concat(_s217, \"Shape\")] = e.getUniformLocation(l, \"\".concat(_s217, \"Shape\"), h), f[\"\".concat(_s217, \"TexShape\")] = e.getUniformLocation(l, \"\".concat(_s217, \"TexShape\"), h));\n      }\n\n      var g, m, b;\n      t.enableShapeUniforms && (g = e.getUniformLocation(l, \"outShape\", h), b = e.getUniformLocation(l, \"outShapeStrides\", h), m = e.getUniformLocation(l, \"outTexShape\", h));\n      var x = [];\n      return t.customUniforms && t.customUniforms.forEach((t, n) => {\n        x[n] = e.getUniformLocation(l, t.name, h);\n      }), {\n        program: t,\n        source: o,\n        webGLProgram: l,\n        uniformLocations: d,\n        customUniformLocations: x,\n        inShapeInfos: a,\n        outShapeInfo: i,\n        infLoc: u,\n        nanLoc: c,\n        inShapesLocations: p,\n        inTexShapesLocations: f,\n        outShapeLocation: g,\n        outShapeStridesLocation: b,\n        outTexShapeLocation: m\n      };\n    }(this.gpgpu, e, l, u)),\n        f = null != this.activeTimers;\n\n    var g;\n    f && (g = this.startTimer()), function (e, t, n, s, r) {\n      t.program.enableShapeUniforms || (Pk(t.inShapeInfos, n), Pk([t.outShapeInfo], [s]));\n      var a = s.texData.texture,\n          i = s.texData.texShape;\n      s.texData.isPacked ? e.setOutputPackedMatrixTexture(a, i[0], i[1]) : e.setOutputMatrixTexture(a, i[0], i[1]), e.setProgram(t.webGLProgram), 1 === V().getNumber(\"WEBGL_VERSION\") && null !== t.infLoc && e.gl.uniform1f(t.infLoc, Infinity), null !== t.nanLoc && e.gl.uniform1f(t.nanLoc, NaN), n.forEach((n, s) => {\n        var r = t.program.variableNames[s],\n            a = t.uniformLocations[r],\n            i = t.uniformLocations[\"offset\".concat(r)],\n            o = t.inShapesLocations[\"\".concat(r, \"Shape\")],\n            l = t.inTexShapesLocations[\"\".concat(r, \"TexShape\")];\n\n        if (o) {\n          var {\n            uniformShape: _s218\n          } = Lk(t.program.packedInputs, n.shape, n.texData.texShape);\n\n          switch (_s218.length) {\n            case 1:\n              e.gl.uniform1iv(o, new Int32Array(_s218));\n              break;\n\n            case 2:\n              e.gl.uniform2iv(o, new Int32Array(_s218));\n              break;\n\n            case 3:\n              e.gl.uniform3iv(o, new Int32Array(_s218));\n              break;\n\n            case 4:\n              e.gl.uniform4iv(o, new Int32Array(_s218));\n          }\n        }\n\n        if (l && e.gl.uniform2i(l, n.texData.texShape[0], n.texData.texShape[1]), null != a) if (n.isUniform) {\n          if (d(n.shape) < 2) e.gl.uniform1f(a, n.uniformValues[0]);else {\n            var _t374 = n.uniformValues;\n            _t374 instanceof Float32Array || (_t374 = new Float32Array(_t374)), e.gl.uniform1fv(a, _t374);\n          }\n        } else null != n.texData.slice && null != i && e.gl.uniform1i(i, n.texData.slice.flatOffset), e.setInputMatrixTexture(n.texData.texture, a, s);\n      });\n      var o = t.outShapeLocation;\n      if (o) switch (s.shape.length) {\n        case 1:\n          e.gl.uniform1iv(o, new Int32Array(s.shape));\n          break;\n\n        case 2:\n          e.gl.uniform2iv(o, new Int32Array(s.shape));\n          break;\n\n        case 3:\n          e.gl.uniform3iv(o, new Int32Array(s.shape));\n          break;\n\n        case 4:\n          e.gl.uniform4iv(o, new Int32Array(s.shape));\n      }\n\n      if (t.outShapeStridesLocation) {\n        var _n277 = A(s.shape);\n\n        switch (s.shape.length) {\n          case 2:\n            e.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(_n277));\n            break;\n\n          case 3:\n            e.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(_n277));\n            break;\n\n          case 4:\n            e.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(_n277));\n        }\n      }\n\n      t.outTexShapeLocation && e.gl.uniform2i(t.outTexShapeLocation, s.texData.texShape[0], s.texData.texShape[1]), t.program.customUniforms && r && t.program.customUniforms.forEach((n, s) => {\n        var a = t.customUniformLocations[s],\n            i = r[s];\n        if (\"float\" === n.type) e.gl.uniform1fv(a, i);else if (\"vec2\" === n.type) e.gl.uniform2fv(a, i);else if (\"vec3\" === n.type) e.gl.uniform3fv(a, i);else if (\"vec4\" === n.type) e.gl.uniform4fv(a, i);else if (\"int\" === n.type) e.gl.uniform1iv(a, i);else if (\"ivec2\" === n.type) e.gl.uniform2iv(a, i);else if (\"ivec3\" === n.type) e.gl.uniform3iv(a, i);else {\n          if (\"ivec4\" !== n.type) throw Error(\"uniform type \".concat(n.type, \" is not supported yet.\"));\n          e.gl.uniform4iv(a, i);\n        }\n      }), e.executeProgram();\n    }(this.gpgpu, h, l, u, s), o.forEach(e => this.disposeIntermediateTensorInfo(e)), f && (g = this.endTimer(g), this.activeTimers.push({\n      name: e.constructor.name,\n      query: this.getQueryTime(g)\n    }));\n    var m = V().get(\"WEBGL_FLUSH_THRESHOLD\");\n\n    if (m > 0) {\n      var _e443 = Ve();\n\n      _e443 - this.lastGlFlushTime > m && (this.gpgpu.gl.flush(), this.lastGlFlushTime = _e443);\n    }\n\n    if (!V().getBool(\"WEBGL_LAZILY_UNPACK\") && i.isPacked && !1 === r) {\n      var _e444 = this.unpackTensor(a);\n\n      return this.disposeIntermediateTensorInfo(a), _e444;\n    }\n\n    return a;\n  }\n\n  compileAndRun(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    return this.runWebGLProgram(e, t, n = n || t[0].dtype, s, r);\n  }\n\n  getAndSaveBinary(e, t) {\n    return e in this.binaryCache || (this.binaryCache[e] = t()), this.binaryCache[e];\n  }\n\n  getTextureManager() {\n    return this.textureManager;\n  }\n\n  dispose() {\n    this.disposed || (V().getBool(\"IS_TEST\") || Object.keys(this.binaryCache).forEach(e => {\n      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];\n    }), this.textureManager.dispose(), null != this.canvas && \"undefined\" != typeof HTMLCanvasElement && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = !0);\n  }\n\n  floatPrecision() {\n    return null == this.floatPrecisionValue && (this.floatPrecisionValue = Yn(() => {\n      if (!V().get(\"WEBGL_RENDER_FLOAT32_ENABLED\")) {\n        var _e445 = V().getBool(\"DEBUG\");\n\n        V().set(\"DEBUG\", !1);\n        var _t375 = this.abs(qa(1e-8)).dataSync()[0];\n        if (V().set(\"DEBUG\", _e445), _t375 > 0) return 32;\n      }\n\n      return 16;\n    })), this.floatPrecisionValue;\n  }\n\n  epsilon() {\n    return 32 === this.floatPrecision() ? 1e-7 : 1e-4;\n  }\n\n  uploadToGPU(e) {\n    var t = this.texData.get(e),\n        {\n      shape: n,\n      dtype: s,\n      values: r,\n      texture: a,\n      usage: o,\n      isPacked: l\n    } = t;\n    if (null != a) return;\n    var u = null != this.activeTimers;\n    var c;\n    u && (c = Ve());\n    var h = t.texShape;\n\n    if (null == h && (h = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n      var n = V().getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");\n\n      if (t && (n *= 2, 1 === (e = e.map((t, n) => n >= e.length - 2 ? i(e[n]) : e[n])).length && (e = [2, e[0]])), 2 !== e.length) {\n        var _t376 = k(e);\n\n        e = _t376.newShape;\n      }\n\n      var s = d(e);\n      if (e.length <= 1 && s <= n) return [1, s];\n      if (2 === e.length && e[0] <= n && e[1] <= n) return e;\n      if (3 === e.length && e[0] * e[1] <= n && e[2] <= n) return [e[0] * e[1], e[2]];\n      if (3 === e.length && e[0] <= n && e[1] * e[2] <= n) return [e[0], e[1] * e[2]];\n      if (4 === e.length && e[0] * e[1] * e[2] <= n && e[3] <= n) return [e[0] * e[1] * e[2], e[3]];\n      if (4 === e.length && e[0] <= n && e[1] * e[2] * e[3] <= n) return [e[0], e[1] * e[2] * e[3]];\n\n      if (t) {\n        var _t377 = Yy(e);\n\n        var _n278 = 2,\n            _r161 = 2;\n        return e.length && ([_n278, _r161] = Jy(e)), s = _t377 * (_n278 / 2) * (_r161 / 2), g(s).map(e => 2 * e);\n      }\n\n      return g(s);\n    }(n, l), t.texShape = h), null != r) {\n      var _e446 = Zy(n);\n\n      var _a127,\n          _i88 = h[1],\n          _o66 = h[0];\n\n      var _d23 = r instanceof Uint8Array;\n\n      l ? ([_i88, _o66] = zy(h[0], h[1]), _a127 = new xk(_e446, [_o66, _i88], _d23)) : _a127 = new bk(_e446, [_o66, _i88], _d23);\n\n      var _p15 = this.makeTensorInfo([_o66, _i88], s);\n\n      this.texData.get(_p15.dataId).usage = _d23 ? _y.PIXELS : _y.UPLOAD, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(_p15.dataId), _i88, _o66, r);\n\n      var _f12 = this.runWebGLProgram(_a127, [_p15], s, null, !0),\n          _g20 = this.texData.get(_f12.dataId);\n\n      t.texture = _g20.texture, t.texShape = _g20.texShape, t.isPacked = _g20.isPacked, t.usage = _g20.usage, this.disposeIntermediateTensorInfo(_p15), this.texData.delete(_f12.dataId), t.values = null, u && (this.uploadWaitMs += Ve() - c);\n    } else {\n      var _e447 = this.acquireTexture(h, o, s, l);\n\n      t.texture = _e447;\n    }\n  }\n\n  convertAndCacheOnCPU(e, t) {\n    var n = this.texData.get(e),\n        {\n      dtype: s\n    } = n;\n    return this.releaseGPUData(e), null != t && (n.values = function (e, t) {\n      if (\"float32\" === t || \"complex64\" === t) return e;\n\n      if (\"int32\" === t || \"bool\" === t) {\n        var _n279 = \"int32\" === t ? new Int32Array(e.length) : new Uint8Array(e.length);\n\n        for (var _t378 = 0; _t378 < _n279.length; ++_t378) {\n          _n279[_t378] = Math.round(e[_t378]);\n        }\n\n        return _n279;\n      }\n\n      throw new Error(\"Unknown dtype \".concat(t));\n    }(t, s)), n.values;\n  }\n\n  acquireTexture(e, t, n, s) {\n    if (this.numBytesInGPU += this.computeBytes(e, n), !this.warnedAboutMemory && this.numBytesInGPU > 1024 * this.numMBBeforeWarning * 1024) {\n      var _e448 = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n\n      this.warnedAboutMemory = !0, console.warn(\"High memory usage in GPU: \".concat(_e448, \" MB, most likely due to a memory leak\"));\n    }\n\n    return this.textureManager.acquireTexture(e, t, s);\n  }\n\n  computeBytes(e, t) {\n    return e[0] * e[1] * N(t);\n  }\n\n}\n\nVw.nextDataId = 0, $t() && Qn(\"webgl\", () => new Vw(), 2);\n\nclass Gw {\n  constructor(e, t, n) {\n    this.variableNames = [\"A\", \"B\"], this.outputShape = cr(t, n), this.enableShapeUniforms = Wk(this.outputShape.length), this.userCode = \"\\n      float binaryOperation(float a, float b) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \");\n  }\n\n}\n\nclass Hw {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    this.variableNames = [\"A\", \"B\"], this.supportsBroadcasting = !0, this.packedInputs = !0, this.packedOutput = !0, this.outputShape = cr(t, n);\n    var r = this.outputShape.length;\n    this.enableShapeUniforms = Wk(r);\n    var a = \"\";\n    if (s) if (0 === r || 1 === d(this.outputShape)) a = \"\\n          result.y = 0.;\\n          result.z = 0.;\\n          result.w = 0.;\\n        \";else if (a = \"\\n          \".concat(Mk(r), \" coords = getOutputCoords();\\n        \"), 1 === r) a += this.enableShapeUniforms ? \"\\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \" : \"\\n            result.y = (coords + 1) >= \".concat(this.outputShape[0], \" ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \");else {\n      var _e449 = Ew(\"coords\", r);\n\n      a += this.enableShapeUniforms ? \"\\n            bool nextRowOutOfBounds =\\n              (\".concat(_e449[r - 2], \" + 1) >= outShape[\").concat(r, \" - 2];\\n            bool nextColOutOfBounds =\\n              (\").concat(_e449[r - 1], \" + 1) >= outShape[\").concat(r, \" - 1];\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \") : \"\\n            bool nextRowOutOfBounds =\\n              (\".concat(_e449[r - 2], \" + 1) >= \").concat(this.outputShape[r - 2], \";\\n            bool nextColOutOfBounds =\\n              (\").concat(_e449[r - 1], \" + 1) >= \").concat(this.outputShape[r - 1], \";\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \");\n    }\n    this.userCode = \"\\n      vec4 binaryOperation(vec4 a, vec4 b) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n\\n        vec4 result = binaryOperation(a, b);\\n        \").concat(a, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction jw(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  return n.incRef(s.dataId), {\n    dataId: s.dataId,\n    shape: s.shape,\n    dtype: s.dtype\n  };\n}\n\nvar qw = {\n  kernelName: \"Identity\",\n  backendName: \"webgl\",\n  kernelFunc: jw\n};\n\nfunction Kw(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    real: s,\n    imag: r\n  } = t,\n      a = n.makeTensorInfo(s.shape, \"complex64\"),\n      i = n.texData.get(a.dataId),\n      o = jw({\n    inputs: {\n      x: s\n    },\n    backend: n\n  }),\n      l = jw({\n    inputs: {\n      x: r\n    },\n    backend: n\n  });\n  return i.complexTensorInfos = {\n    real: o,\n    imag: l\n  }, a;\n}\n\nvar Xw = {\n  kernelName: \"Complex\",\n  backendName: \"webgl\",\n  kernelFunc: Kw\n},\n    Yw = \"return (a < 0.) ? b * a : a;\",\n    Jw = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\",\n    Zw = {\n  kernelName: \"LeakyRelu\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      alpha: a\n    } = s,\n        i = n.makeTensorInfo([], \"float32\", We(a, \"float32\")),\n        o = V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Hw(Jw, r.shape, i.shape) : new Gw(Yw, r.shape, i.shape),\n        l = n.runWebGLProgram(o, [r, i], r.dtype);\n    return n.disposeIntermediateTensorInfo(i), l;\n  }\n},\n    Qw = \"return (a < 0.) ? b * a : a;\",\n    ev = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\",\n    tv = {\n  kernelName: \"Prelu\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s,\n      alpha: r\n    } = t,\n        a = V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Hw(ev, s.shape, r.shape) : new Gw(Qw, s.shape, r.shape);\n    return n.runWebGLProgram(a, [s, r], s.dtype);\n  }\n};\n\nfunction nv(_ref20) {\n  var {\n    opSnippet: e,\n    packedOpSnippet: t,\n    cpuKernelImpl: n,\n    dtype: s\n  } = _ref20;\n  return _ref21 => {\n    var {\n      inputs: r,\n      backend: a\n    } = _ref21;\n    var {\n      x: i\n    } = r,\n        o = a,\n        l = s || i.dtype;\n\n    if (o.shouldExecuteOnCPU([i]) && null != n) {\n      var _e450 = o.texData.get(i.dataId),\n          _t379 = n(_e450.values, l);\n\n      return o.makeTensorInfo(i.shape, l, _t379);\n    }\n\n    var u;\n    return u = V().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") && null != t ? new zw(i.shape, t) : new Mw(i.shape, e), o.runWebGLProgram(u, [i], l);\n  };\n}\n\nfunction sv(_ref22) {\n  var {\n    opSnippet: e,\n    packedOpSnippet: t,\n    checkOutOfBounds: n = !1,\n    supportsComplex: s = !1,\n    cpuKernelImpl: r,\n    dtype: a\n  } = _ref22;\n  return _ref23 => {\n    var {\n      inputs: i,\n      backend: o\n    } = _ref23;\n    var {\n      a: l,\n      b: u\n    } = i,\n        c = o;\n\n    if (s && \"complex64\" === l.dtype) {\n      var _t380 = c.texData.get(l.dataId),\n          _n280 = c.texData.get(u.dataId),\n          [_s219, _r162] = [[_t380.complexTensorInfos.real, _n280.complexTensorInfos.real], [_t380.complexTensorInfos.imag, _n280.complexTensorInfos.imag]].map(t => {\n        var [n, s] = t,\n            r = {\n          dataId: n.dataId,\n          dtype: n.dtype,\n          shape: l.shape\n        },\n            a = {\n          dataId: s.dataId,\n          dtype: s.dtype,\n          shape: u.shape\n        },\n            i = new Gw(e, l.shape, u.shape);\n        return c.runWebGLProgram(i, [r, a], dt(n.dtype, s.dtype));\n      }),\n          _a128 = Kw({\n        inputs: {\n          real: _s219,\n          imag: _r162\n        },\n        backend: c\n      });\n\n      return c.disposeIntermediateTensorInfo(_s219), c.disposeIntermediateTensorInfo(_r162), _a128;\n    }\n\n    var h = a || dt(l.dtype, u.dtype);\n\n    if ((\"string\" === l.dtype || \"string\" === u.dtype || c.shouldExecuteOnCPU([l, u])) && null != r) {\n      var _e451 = c.texData.get(l.dataId).values,\n          _t381 = c.texData.get(u.dataId).values,\n          _n281 = \"string\" === l.dtype ? tl(_e451) : _e451,\n          _s220 = \"string\" === l.dtype ? tl(_t381) : _t381,\n          [_a129, _i89] = r(l.shape, u.shape, _n281, _s220, h),\n          _o67 = c.makeTensorInfo(_i89, h);\n\n      return c.texData.get(_o67.dataId).values = _a129, _o67;\n    }\n\n    var d;\n    return d = V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") && null != t ? new Hw(t, l.shape, u.shape, n) : new Gw(e, l.shape, u.shape), c.runWebGLProgram(d, [l, u], h);\n  };\n}\n\nfunction rv(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  if (\"linear\" === e) return \"return x;\";\n  if (\"relu\" === e) return t ? \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\" : \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : x;\\n\";\n  if (\"elu\" === e) return t ? \"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\" : \"return (x >= 0.0) ? x : (exp(x) - 1.0);\";\n  if (\"relu6\" === e) return t ? \"\\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\" : \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : min(6.0, x);\\n\";\n  if (\"prelu\" === e) return t ? ev : Qw;\n  if (\"leakyrelu\" === e) return t ? Jw : Yw;\n  if (\"sigmoid\" === e) return \"return 1.0 / (1.0 + exp(-1.0 * x));\";\n  throw new Error(\"Activation \".concat(e, \" has not been implemented for the WebGL backend.\"));\n}\n\nclass av {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;\n    this.variableNames = [\"matrixA\", \"matrixB\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = n;\n    var u = Math.ceil((s ? e[1] : e[2]) / 2),\n        c = s ? \"i * 2, rc.y\" : \"rc.y, i * 2\",\n        h = r ? \"rc.z, i * 2\" : \"i * 2, rc.z\",\n        d = s ? [\"a.xxyy\", \"a.zzww\"] : [\"a.xxzz\", \"a.yyww\"],\n        p = r ? [\"b.xzxz\", \"b.ywyw\"] : [\"b.xyxy\", \"b.zwzw\"];\n    var f = \"\",\n        g = \"\";\n    i && (f = o ? \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(i, \"\\n        }\") : l ? \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(i, \"\\n        }\") : \"vec4 activation(vec4 x) {\\n          \".concat(i, \"\\n        }\"), g = \"result = activation(result);\");\n    var m = a ? \"result += getBiasAtOutCoords();\" : \"\";\n    a && this.variableNames.push(\"bias\"), o && this.variableNames.push(\"preluActivationWeights\"), l && this.variableNames.push(\"leakyreluAlpha\");\n    var b = \"rc.x\",\n        x = \"rc.x\";\n    e[0] < t[0] ? b = \"int(min(float(rc.x), \".concat(e[0] - 1, \".))\") : t[0] < e[0] && (x = \"int(min(float(rc.x), \".concat(t[0] - 1, \".))\")), this.userCode = \"\\n      \".concat(f, \"\\n\\n      const float sharedDimension = \").concat(u, \".0;\\n\\n      vec4 dot2x2ARowBCol(ivec3 rc) {\\n        vec4 result = vec4(0);\\n        for (int i = 0; i < \").concat(u, \"; i++) {\\n          int batchA = \").concat(b, \";\\n          int batchB = \").concat(x, \";\\n          vec4 a = getMatrixA(batchA, \").concat(c, \");\\n          vec4 b = getMatrixB(batchB, \").concat(h, \");\\n\\n          // These swizzled products need to be separately added.\\n          // See: https://github.com/tensorflow/tfjs/issues/1735\\n          result += (\").concat(d[0], \" * \").concat(p[0], \");\\n          result += (\").concat(d[1], \" * \").concat(p[1], \");\\n        }\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n        vec4 result = dot2x2ARowBCol(rc);\\n\\n        \").concat(m, \"\\n\\n        \").concat(g, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass iv {\n  constructor(e, t, n) {\n    this.variableNames = [\"AReal\", \"AImag\", \"BReal\", \"BImag\"], this.outputShape = cr(t, n), this.userCode = \"\\n      float binaryOpComplex(\\n          float areal, float aimag, float breal, float bimag) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        float areal = getARealAtOutCoords();\\n        float aimag = getAImagAtOutCoords();\\n        float breal = getBRealAtOutCoords();\\n        float bimag = getBImagAtOutCoords();\\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\\n      }\\n    \");\n  }\n\n}\n\nvar ov = \"return a * b;\";\n\nfunction lv(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    a: s,\n    b: r\n  } = t,\n      a = dt(s.dtype, r.dtype);\n\n  if (\"complex64\" === s.dtype) {\n    var _e452 = n.texData.get(s.dataId),\n        _t382 = n.texData.get(r.dataId),\n        _a130 = new iv(\"return areal * breal - aimag * bimag;\", s.shape, r.shape),\n        _i90 = new iv(\"return areal * bimag + aimag * breal;\", s.shape, r.shape),\n        _o68 = [{\n      dataId: _e452.complexTensorInfos.real.dataId,\n      dtype: _e452.complexTensorInfos.real.dtype,\n      shape: s.shape\n    }, {\n      dataId: _e452.complexTensorInfos.imag.dataId,\n      dtype: _e452.complexTensorInfos.imag.dtype,\n      shape: s.shape\n    }, {\n      dataId: _t382.complexTensorInfos.real.dataId,\n      dtype: _t382.complexTensorInfos.real.dtype,\n      shape: r.shape\n    }, {\n      dataId: _t382.complexTensorInfos.imag.dataId,\n      dtype: _t382.complexTensorInfos.imag.dtype,\n      shape: r.shape\n    }],\n        _l46 = n.runWebGLProgram(_a130, _o68, \"float32\"),\n        _u35 = n.runWebGLProgram(_i90, _o68, \"float32\"),\n        _c30 = Kw({\n      inputs: {\n        real: _l46,\n        imag: _u35\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_l46), n.disposeIntermediateTensorInfo(_u35), _c30;\n  }\n\n  if (n.shouldExecuteOnCPU([s, r])) {\n    var _e453 = n.texData.get(s.dataId),\n        _t383 = n.texData.get(r.dataId),\n        [_i91, _o69] = lw(s.shape, r.shape, _e453.values, _t383.values, a),\n        _l47 = n.makeTensorInfo(_o69, a);\n\n    return n.texData.get(_l47.dataId).values = _i91, _l47;\n  }\n\n  var i;\n  return i = V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Hw(ov, s.shape, r.shape) : new Gw(ov, s.shape, r.shape), n.runWebGLProgram(i, [s, r], a);\n}\n\nvar uv = {\n  kernelName: \"Multiply\",\n  backendName: \"webgl\",\n  kernelFunc: lv\n};\n\nfunction cv(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    shape: a\n  } = s,\n      i = n,\n      o = d(r.shape),\n      u = x(a, o),\n      c = d(u);\n  l(o === c, () => \"The new shape (\".concat(u, \") has \").concat(c, \" elements and the old shape (\").concat(r.shape, \") has \").concat(o, \" elements. The new shape and old shape must have the same number of elements.\"));\n  var h = i.texData.get(r.dataId);\n  return !h.isPacked || ek(r.shape, u) || null !== h.texture && ek(h.shape, u) ? (i.incRef(r.dataId), {\n    dataId: r.dataId,\n    shape: u,\n    dtype: r.dtype\n  }) : function (e, t, n) {\n    var s = [Yy(e.shape), ...Jy(e.shape)],\n        r = {\n      dtype: e.dtype,\n      shape: s,\n      dataId: e.dataId\n    },\n        a = [Yy(t), ...Jy(t)],\n        i = new Aw(a, s),\n        o = n.runWebGLProgram(i, [r], e.dtype, null, !0);\n    return {\n      dataId: o.dataId,\n      shape: t,\n      dtype: o.dtype\n    };\n  }(r, u, i);\n}\n\nvar hv = {\n  kernelName: \"Reshape\",\n  backendName: \"webgl\",\n  kernelFunc: cv\n};\n\nclass dv {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var {\n      windowSize: n,\n      batchSize: s,\n      inSize: r,\n      outSize: a\n    } = e;\n    this.outputShape = [s, a];\n    var i = 4 * Math.floor(n / 4),\n        o = n % 4;\n    var l = \"sumValue += dot(values, ones);\";\n\n    if (null != t) {\n      var _e454 = 1 / t;\n\n      l = \"sumValue += dot(values * \".concat(f(_e454) ? _e454.toPrecision(2) : _e454, \", ones);\");\n    }\n\n    var u = \"\";\n    r % n > 0 && (u = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return 0.0;\\n        }\\n      \")), this.userCode = \"\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \".concat(u, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \").concat(n, \";\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(i, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \").concat(l, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(i, \";\\n        if (\").concat(1 === o, \") {\\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\\n\\n          \").concat(l, \"\\n        } else if (\").concat(2 === o, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1), 0.0, 0.0);\\n\\n          \").concat(l, \"\\n        } else if (\").concat(3 === o, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2), 0.0);\\n\\n          \").concat(l, \"\\n        }\\n        setOutput(sumValue);\\n      }\\n    \");\n  }\n\n}\n\nclass pv {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var {\n      windowSize: n,\n      batchSize: s,\n      inSize: r,\n      outSize: a\n    } = e;\n    this.outputShape = [s, a];\n    var i = \"0.0\",\n        o = \"\";\n    \"prod\" === t ? i = \"1.0\" : \"min\" === t ? (i = \"1.0 / 1e-20\", o = \"min\") : \"max\" === t && (i = \"-1.0 / 1e-20\", o = \"max\");\n    var l = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"sum\" === t ? l = \"sumValue\" : \"prod\" === t ? l = \"prodValue\" : \"all\" === t ? l = \"allValue\" : \"any\" === t && (l = \"anyValue\");\n    var u = 4 * Math.floor(n / 4),\n        c = n % 4;\n    var h = \"\\n      if (\".concat(\"sum\" === t, \") {\\n        sumValue += dot(values, ones);\\n      } else if (\").concat(\"prod\" === t, \") {\\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\\n        prodValue *= tmp[0] * tmp[1];\\n      } else {\\n        minMaxValue = \").concat(o, \"(values, minMaxValue);\\n        if (\").concat(\"min\" === t, \" || \").concat(\"max\" === t, \") {\\n          minMaxValue = \").concat(o, \"(values, minMaxValue);\\n          bvec4 isNaN = isnan(values);\\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\\n            minMaxValue = vec4(NAN);\\n          }\\n        }\\n      }\\n    \"),\n        d = \"vec4\";\n    \"all\" === t ? (i = \"1.0\", h = \"\\n        bool reducedAllValue = all(values);\\n        float floatedReducedAllValue = float(reducedAllValue);\\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\\n      \", d = \"bvec4\") : \"any\" === t && (i = \"0.0\", h = \"\\n        bool reducedAnyValue = any(values);\\n        float floatedReducedAnyValue = float(reducedAnyValue);\\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\\n      \", d = \"bvec4\");\n    var p = \"\";\n    r % n > 0 && (p = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return initializationValue;\\n        }\\n      \")), this.userCode = \"\\n      const float initializationValue = \".concat(i, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \").concat(p, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \").concat(n, \";\\n\\n        vec4 minMaxValue = vec4(\").concat(i, \");\\n        float prodValue = 1.0;\\n        float sumValue = 0.0;\\n        float allValue = 1.0;\\n        float anyValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(u, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \").concat(h, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(u, \";\\n        if (\").concat(1 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        } else if (\").concat(2 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        } else if (\").concat(3 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        }\\n        setOutput(\").concat(l, \");\\n      }\\n    \");\n  }\n\n}\n\nfunction fv(e, t, n, s) {\n  var r = function (e) {\n    var t = [];\n\n    for (; 0 === t.length || 1 !== t[t.length - 1].outSize;) {\n      var _n282 = t.length ? t[t.length - 1].outSize : e[1],\n          _s221 = To(_n282);\n\n      t.push({\n        inSize: _n282,\n        windowSize: _s221,\n        outSize: Math.ceil(_n282 / _s221)\n      });\n    }\n\n    return t;\n  }(e.shape);\n\n  var a = e;\n\n  for (var _i92 = 0; _i92 < r.length; _i92++) {\n    var {\n      inSize: _o70,\n      windowSize: _l48,\n      outSize: _u36\n    } = r[_i92];\n\n    var _c31 = void 0,\n        _h18 = void 0;\n\n    _c31 = \"mean\" === n ? 0 === _i92 ? new dv({\n      windowSize: _l48,\n      inSize: _o70,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }, _o70) : new dv({\n      windowSize: _l48,\n      inSize: _o70,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }) : new pv({\n      windowSize: _l48,\n      inSize: _o70,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }, n), _h18 = a, a = s.runWebGLProgram(_c31, [a], t), _h18.dataId !== e.dataId && s.disposeIntermediateTensorInfo(_h18);\n  }\n\n  return a;\n}\n\nclass gv {\n  constructor(e, t) {\n    this.variableNames = [\"A\"];\n    var n = new Array(e.length);\n\n    for (var _s222 = 0; _s222 < n.length; _s222++) {\n      n[_s222] = e[t[_s222]];\n    }\n\n    this.outputShape = n, this.rank = n.length;\n\n    var s = Mk(this.rank),\n        r = function (e) {\n      var t = e.length;\n      if (t > 6) throw Error(\"Transpose for rank \".concat(t, \" is not yet supported\"));\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\", \"resRC.u\", \"resRC.v\"],\n          s = new Array(t);\n\n      for (var _t384 = 0; _t384 < e.length; _t384++) {\n        s[e[_t384]] = n[_t384];\n      }\n\n      return s.join();\n    }(t);\n\n    this.userCode = \"\\n    void main() {\\n      \".concat(s, \" resRC = getOutputCoords();\\n      setOutput(getA(\").concat(r, \"));\\n    }\\n    \");\n  }\n\n}\n\nclass mv {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0;\n    var n = new Array(e.length);\n\n    for (var _s223 = 0; _s223 < n.length; _s223++) {\n      n[_s223] = e[t[_s223]];\n    }\n\n    if (this.outputShape = n, this.rank = n.length, this.rank > 6) throw Error(\"Packed transpose for rank \".concat(this.rank, \" is not yet supported.\"));\n    var s = Mk(this.rank),\n        r = Tw(\"rc\", this.rank),\n        a = new Array(this.rank);\n\n    for (var _e455 = 0; _e455 < t.length; _e455++) {\n      a[t[_e455]] = r[_e455];\n    }\n\n    var i = \"vec2(\".concat(a.slice(-2).join(), \")\"),\n        o = \"++\".concat(r[this.rank - 1], \" < \").concat(n[this.rank - 1]),\n        l = \"getChannel(getA(\".concat(a.join(), \"), \").concat(i, \")\");\n    this.userCode = \"\\n    void main() {\\n      \".concat(s, \" rc = getOutputCoords();\\n      vec4 result = vec4(0.);\\n      result[0] = \").concat(l, \";\\n      if(\").concat(o, \") {\\n        result[1] = \").concat(l, \";\\n      }\\n      --\").concat(r[this.rank - 1], \";\\n      if(++\").concat(r[this.rank - 2], \" < \").concat(n[this.rank - 2], \") {\\n        result[2] = \").concat(l, \";\\n        if(\").concat(o, \") {\\n          result[3] = \").concat(l, \";\\n        }\\n      }\\n      setOutput(result);\\n    }\\n    \");\n  }\n\n}\n\nfunction bv(e, t, n) {\n  var s = V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new mv(e.shape, t) : new gv(e.shape, t);\n  return n.runWebGLProgram(s, [e], e.dtype);\n}\n\nfunction xv(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    axis: a,\n    keepDims: i\n  } = s;\n  return function (e, t, n, s) {\n    var r = e.shape.length,\n        a = y(t, e.shape);\n    var i = a;\n    var o = Jr(i, r),\n        l = null != o;\n    var u = e;\n    l && (u = bv(e, o, s), i = Qr(i.length, r)), Yr(\"sum\", i, r);\n    var [c, h] = Kr(u.shape, i);\n    var p = c;\n    n && (p = Xr(c, a));\n    var f = d(h),\n        g = cv({\n      inputs: {\n        x: u\n      },\n      attrs: {\n        shape: [d(e.shape) / f, f]\n      },\n      backend: s\n    }),\n        m = fv(g, pt(e.dtype), \"sum\", s),\n        b = cv({\n      inputs: {\n        x: m\n      },\n      attrs: {\n        shape: p\n      },\n      backend: s\n    });\n    return s.disposeIntermediateTensorInfo(g), s.disposeIntermediateTensorInfo(m), l && s.disposeIntermediateTensorInfo(u), b;\n  }(r, a, i, n);\n}\n\nvar yv = {\n  kernelName: \"Sum\",\n  backendName: \"webgl\",\n  kernelFunc: xv\n};\n\nfunction kv(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    perm: a\n  } = s,\n      i = n,\n      o = new Array(r.shape.length);\n\n  for (var _e456 = 0; _e456 < o.length; _e456++) {\n    o[_e456] = r.shape[a[_e456]];\n  }\n\n  var l;\n\n  if (i.shouldExecuteOnCPU([r])) {\n    var _e457 = i.texData.get(r.dataId),\n        _t385 = Cw(_e457.values, r.shape, r.dtype, a, o);\n\n    l = i.makeTensorInfo(o, r.dtype), i.texData.get(l.dataId).values = _t385;\n  } else l = bv(r, a, i);\n\n  return l;\n}\n\nvar wv = {\n  kernelName: \"Transpose\",\n  backendName: \"webgl\",\n  kernelFunc: kv\n};\n\nfunction vv(_ref24) {\n  var {\n    a: e,\n    b: t,\n    transposeA: n,\n    transposeB: s,\n    backend: r,\n    bias: a = null,\n    preluActivationWeights: i = null,\n    leakyreluAlpha: o = 0,\n    activation: u = null\n  } = _ref24;\n  var c = e.shape.length,\n      h = t.shape.length,\n      p = n ? e.shape[c - 2] : e.shape[c - 1],\n      f = s ? t.shape[h - 1] : t.shape[h - 2],\n      g = n ? e.shape[c - 1] : e.shape[c - 2],\n      m = s ? t.shape[h - 2] : t.shape[h - 1],\n      b = e.shape.slice(0, -2),\n      x = t.shape.slice(0, -2),\n      y = d(b),\n      k = d(x);\n  l(c >= 2 && h >= 2 && (y === k || 1 === y || 1 === k), () => \"Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (\".concat(b, \") and (\").concat(x, \").\"));\n  var w = (y > k ? e.shape.slice(0, -2) : t.shape.slice(0, -2)).concat([g, m]);\n  l(p === f, () => \"Error in matMul: inner shapes (\".concat(p, \") and (\").concat(f, \") of Tensors with shapes \").concat(e.shape, \" and \").concat(t.shape, \" and transposeA=\").concat(n, \" and transposeB=\").concat(s, \" must match.\"));\n  var v = n ? [y, p, g] : [y, g, p],\n      I = s ? [k, m, f] : [k, f, m],\n      $ = cv({\n    inputs: {\n      x: e\n    },\n    backend: r,\n    attrs: {\n      shape: v\n    }\n  }),\n      N = cv({\n    inputs: {\n      x: t\n    },\n    backend: r,\n    attrs: {\n      shape: I\n    }\n  }),\n      C = [$, N],\n      S = Math.max(y, k),\n      T = n ? $.shape[1] : $.shape[2],\n      E = null != a,\n      R = null != i,\n      A = \"leakyrelu\" === u,\n      F = null != u ? rv(u, !0) : null;\n  var D;\n\n  if ((1 === g || 1 === m) && T > 1e3 && !1 === (E || R || A || null != F)) {\n    var _e458 = $,\n        _t386 = N;\n    n && (_e458 = kv({\n      inputs: {\n        x: $\n      },\n      backend: r,\n      attrs: {\n        perm: [0, 2, 1]\n      }\n    }), C.push(_e458)), s && (_t386 = kv({\n      inputs: {\n        x: N\n      },\n      backend: r,\n      attrs: {\n        perm: [0, 2, 1]\n      }\n    }), C.push(_t386));\n\n    var _a131 = 1 === m;\n\n    var _i93 = _e458;\n    1 !== m && (_i93 = cv({\n      inputs: {\n        x: _e458\n      },\n      backend: r,\n      attrs: {\n        shape: [S, T, 1]\n      }\n    }), C.push(_i93));\n\n    var _o71 = 1 === m ? 2 : 1;\n\n    var _l49 = _t386;\n    _a131 && (_l49 = cv({\n      inputs: {\n        x: _t386\n      },\n      backend: r,\n      attrs: {\n        shape: [S, 1, T]\n      }\n    }), C.push(_l49));\n\n    var _u37 = lv({\n      inputs: {\n        a: _i93,\n        b: _l49\n      },\n      backend: r\n    });\n\n    D = xv({\n      inputs: {\n        x: _u37\n      },\n      backend: r,\n      attrs: {\n        axis: _o71,\n        keepDims: !0\n      }\n    }), C.push(_u37);\n  } else {\n    var _l50 = dt(e.dtype, t.dtype),\n        _u38 = new av(v, I, [S, g, m], n, s, E, F, R, A),\n        _c32 = [$, N];\n\n    if (null != a && _c32.push(a), R && _c32.push(i), A) {\n      var _e459 = r.makeTensorInfo([], \"float32\", We(o, \"float32\"));\n\n      _c32.push(_e459), C.push(_e459);\n    }\n\n    D = r.runWebGLProgram(_u38, _c32, _l50);\n  }\n\n  var _ = cv({\n    inputs: {\n      x: D\n    },\n    backend: r,\n    attrs: {\n      shape: w\n    }\n  });\n\n  C.push(D);\n\n  for (var _e460 of C) {\n    r.disposeIntermediateTensorInfo(_e460);\n  }\n\n  return _;\n}\n\nvar Iv = {\n  kernelName: \"_FusedMatMul\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      transposeA: l,\n      transposeB: u,\n      activation: c,\n      leakyreluAlpha: h\n    } = s;\n    return vv({\n      a: r,\n      b: a,\n      transposeA: l,\n      transposeB: u,\n      backend: n,\n      bias: i,\n      preluActivationWeights: o,\n      leakyreluAlpha: h,\n      activation: c\n    });\n  }\n},\n    $v = \"return abs(x);\",\n    Nv = {\n  kernelName: \"Abs\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n\n    if (n.shouldExecuteOnCPU([s]) && \"complex64\" !== s.dtype) {\n      var _e461 = n.texData.get(s.dataId),\n          _t387 = fw(_e461.values);\n\n      return n.makeTensorInfo(s.shape, s.dtype, _t387);\n    }\n\n    var r;\n    return r = V().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") ? new zw(s.shape, $v) : new Mw(s.shape, $v), n.runWebGLProgram(r, [s], s.dtype);\n  }\n},\n    Cv = {\n  kernelName: \"Acos\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return acos(x);\\n\"\n  })\n},\n    Sv = {\n  kernelName: \"Acosh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (x < 1.0) return NAN;\\nreturn log(x + sqrt(x * x - 1.0));\"\n  })\n},\n    Tv = \"return a + b;\",\n    Ev = {\n  kernelName: \"Add\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: Tv,\n    packedOpSnippet: Tv,\n    supportsComplex: !0,\n    cpuKernelImpl: Uk\n  })\n};\n\nclass Rv {\n  constructor(e, t) {\n    this.outputShape = [], this.outputShape = e, this.variableNames = t.map((e, t) => \"T\".concat(t));\n    var n = [];\n    this.variableNames.forEach(e => {\n      n.push(\"float v\".concat(e, \" = get\").concat(e, \"AtOutCoords();\"));\n    });\n    var s = this.variableNames.map(e => \"v\".concat(e)).join(\" + \");\n    this.userCode = \"\\n      void main() {\\n        \".concat(n.join(\"\\n        \"), \"\\n\\n        float result = \").concat(s, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass Av {\n  constructor(e, t) {\n    this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.variableNames = t.map((e, t) => \"T\".concat(t));\n    var n = [];\n    this.variableNames.forEach(e => {\n      n.push(\"vec4 v\".concat(e, \" = get\").concat(e, \"AtOutCoords();\"));\n    });\n    var s = this.variableNames.map(e => \"v\".concat(e)).join(\" + \");\n    this.userCode = \"\\n      void main() {\\n        \".concat(n.join(\"\\n        \"), \"\\n\\n        vec4 result = \").concat(s, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar Fv = {\n  kernelName: \"AddN\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        r = n;\n    if (1 === r.length) return jw({\n      inputs: {\n        x: r[0]\n      },\n      backend: s\n    });\n\n    if (r.length > V().get(\"WEBGL_MAX_TEXTURES_IN_SHADER\")) {\n      var _t388 = Math.floor(r.length / 2),\n          _n283 = e({\n        inputs: r.slice(0, _t388),\n        backend: s\n      }),\n          _a132 = e({\n        inputs: r.slice(_t388),\n        backend: s\n      });\n\n      return e({\n        inputs: [_n283, _a132],\n        backend: s\n      });\n    }\n\n    var a = r.map(e => e.dtype).reduce((e, t) => dt(e, t)),\n        i = r.map(e => e.shape),\n        o = V().getBool(\"WEBGL_PACK\") ? new Av(r[0].shape, i) : new Rv(r[0].shape, i);\n    return s.runWebGLProgram(o, r, a);\n  }\n},\n    Dv = {\n  kernelName: \"All\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Jr(u, o);\n    var h = r;\n    null != c && (h = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = Qr(u.length, o)), Yr(\"all\", u, o);\n    var [p, f] = Kr(h.shape, u),\n        g = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = fv(g, g.dtype, \"all\", n);\n    var b;\n    return b = cv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Xr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n},\n    _v = {\n  kernelName: \"Any\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Jr(u, o);\n    var h = r;\n    null != c && (h = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = Qr(u.length, o)), Yr(\"any\", u, o);\n    var [p, f] = Kr(h.shape, u),\n        g = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = fv(g, g.dtype, \"any\", n);\n    var b;\n    return b = cv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Xr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n};\n\nclass Ov {\n  constructor(e, t, n) {\n    this.variableNames = [\"A\"];\n    var {\n      windowSize: s,\n      batchSize: r,\n      outSize: a\n    } = e;\n    n || this.variableNames.push(\"bestIndicesA\"), this.outputShape = [r, a], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \".concat(s, \";\\n\\n        int bestIndex = inOffset;\\n        float bestValue = getA(batch, bestIndex);\\n\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          int inIdx = \").concat(n ? \"inOffset + i;\" : \"round(getBestIndicesA(batch, inOffset + i));\", \";\\n          float candidate = getA(batch, inIdx);\\n          if (candidate \").concat(\"max\" === t ? \">\" : \"<\", \" bestValue) {\\n            bestValue = candidate;\\n            bestIndex = inIdx;\\n          }\\n        }\\n        setOutput(float(bestIndex));\\n      }\\n    \");\n  }\n\n}\n\nclass Mv {\n  constructor(e, t, n, s) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, l(e.length > 2, () => \"Packed arg\".concat(n.charAt(0).toUpperCase() + n.slice(1), \" supports only inputs with rank above 2.\"));\n    var r = Math.ceil(e[e.length - 1] / t);\n    this.outputShape = e.slice(0, -1), r > 1 && this.outputShape.push(r), s || this.variableNames.push(\"bestIndicesA\");\n    var a = this.outputShape,\n        i = a.length,\n        o = Mk(i),\n        u = Ew(\"coords\", i);\n    var c, h;\n\n    if (1 === r) {\n      h = i + 1;\n\n      var _e462 = Mk(h);\n\n      c = \"\\n        \".concat(_e462, \" sourceLocR = \").concat(_e462, \"(\").concat(u.join(), \", 0);\\n        ++\").concat(u[i - 1], \";\\n        \").concat(_e462, \" sourceLocG = \").concat(_e462, \"(\").concat(u.join(), \", 0);\\n        ++\").concat(u[i - 2], \";\\n        \").concat(_e462, \" sourceLocA = \").concat(_e462, \"(\").concat(u.join(), \", 0);\\n        --\").concat(u[i - 1], \";\\n        \").concat(_e462, \" sourceLocB = \").concat(_e462, \"(\").concat(u.join(), \", 0);\\n        --\").concat(u[i - 2], \";\");\n    } else h = i, c = \"\\n        \".concat(o, \" sourceLocR = coords;\\n        ++\").concat(u[i - 1], \";\\n        \").concat(o, \" sourceLocG = coords;\\n        ++\").concat(u[i - 2], \";\\n        \").concat(o, \" sourceLocA = coords;\\n        --\").concat(u[i - 1], \";\\n        \").concat(o, \" sourceLocB = coords;\\n        --\").concat(u[i - 2], \";\");\n\n    var d = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, h),\n        p = \".\" + d[h - 1],\n        f = d.map(e => \"int \" + e),\n        g = Ew(\"sourceLocR\", h - 1).concat(\"inIdx.r\"),\n        m = Ew(\"sourceLocG\", h - 1).concat(\"inIdx.g\"),\n        b = Ew(\"sourceLocB\", h - 1).concat(\"inIdx.b\"),\n        x = Ew(\"sourceLocA\", h - 1).concat(\"inIdx.a\"),\n        y = \"max\" === n ? \"greaterThan\" : \"lessThan\",\n        k = s ? \"\" : \"\\n          inIdx = round(vec4(getBestIndicesAChannel(\".concat(g.join(), \"),\\n                             getBestIndicesAChannel(\").concat(m.join(), \"),\\n                             getBestIndicesAChannel(\").concat(b.join(), \"),\\n                             getBestIndicesAChannel(\").concat(x.join(), \")));\"),\n        w = \"vec4(\\n            getAChannel(\".concat(g.join(), \"),\\n            hasNextCol ? getAChannel(\").concat(m.join(), \") : 0.,\\n            hasNextRow ? getAChannel(\").concat(b.join(), \") : 0.,\\n            hasNextRow && hasNextCol ? getAChannel(\").concat(x.join(), \") : 0.)\"),\n        v = s ? \"\" : \"\\n      float getBestIndicesAChannel(\".concat(f.join(), \") {\\n        return getChannel(getBestIndicesA(\").concat(d.join(), \"),\\n                                          vec2(\").concat(d.slice(-2).join(), \"));\\n      }\");\n    this.userCode = \"\\n      float getAChannel(\".concat(f.join(), \") {\\n        return getChannel(getA(\").concat(d.join(), \"),\\n                               vec2(\").concat(d.slice(-2).join(), \"));\\n      }\\n      \").concat(v, \"\\n      void main() {\\n        \").concat(o, \" coords = getOutputCoords();\\n        bool hasNextCol = \").concat(u[i - 1], \" < \").concat(a[i - 1] - 1, \";\\n        bool hasNextRow = \").concat(u[i - 2], \" < \").concat(a[i - 2] - 1, \";\\n        \").concat(c, \"\\n        ivec4 srcIdx = ivec4(sourceLocR\").concat(p, \", sourceLocG\").concat(p, \",\\n          sourceLocB\").concat(p, \", sourceLocA\").concat(p, \") * \").concat(t, \";\\n        ivec4 inIdx = srcIdx;\\n        vec4 bestIndex = vec4(inIdx);\\n        vec4 bestValue = \").concat(w, \";\\n\\n        for (int i = 0; i < \").concat(t, \"; i++) {\\n          inIdx = srcIdx;\\n          \").concat(k, \"\\n          vec4 candidate = \").concat(w, \";\\n          bvec4 nan = isnan(candidate);\\n          bvec4 replace = bvec4(\\n            vec4(\").concat(y, \"(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\\n\\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\\n                           replace.y  ? candidate.y : bestValue.y,\\n                           replace.z  ? candidate.z : bestValue.z,\\n                           replace.w  ? candidate.w : bestValue.w);\\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\\n          srcIdx++;\\n        }\\n        setOutput(bestIndex);\\n      }\\n    \");\n  }\n\n}\n\nfunction Lv(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n  var r = t.shape[0],\n      a = t.shape[1];\n  null != s && (r = s.shape[0], a = s.shape[1]);\n  var i = To(a),\n      o = {\n    windowSize: i,\n    inSize: a,\n    batchSize: r,\n    outSize: Math.ceil(a / i)\n  },\n      l = new Ov(o, n, null == s),\n      u = [t];\n  null != s && u.push(s);\n  var c = e.runWebGLProgram(l, u, \"int32\");\n  if (1 === c.shape[1]) return c;\n  var h = Lv(e, t, n, c);\n  return e.disposeIntermediateTensorInfo(c), h;\n}\n\nfunction zv(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n  var r = null != s ? s.shape : t.shape,\n      a = To(r[r.length - 1]),\n      i = new Mv(r, a, n, null == s),\n      o = e.runWebGLProgram(i, null == s ? [t] : [t, s], \"int32\");\n\n  if (o.shape.length === t.shape.length) {\n    var _s224 = zv(e, t, n, o);\n\n    return e.disposeIntermediateTensorInfo(o), _s224;\n  }\n\n  return o;\n}\n\nfunction Bv(e, t, n, s) {\n  var r = [n];\n\n  if (Yr(\"arg\" + s.charAt(0).toUpperCase() + s.slice(1), r, t.shape.length), !V().getBool(\"WEBGL_PACK_REDUCE\") || t.shape.length <= 2) {\n    var _n284 = [],\n        [_a133, _i94] = Kr(t.shape, r),\n        _o72 = d(_i94),\n        _l51 = cv({\n      inputs: {\n        x: t\n      },\n      backend: e,\n      attrs: {\n        shape: [-1, _o72]\n      }\n    });\n\n    _n284.push(_l51);\n\n    var _u39 = Lv(e, _l51, s);\n\n    _n284.push(_u39);\n\n    var _c33 = cv({\n      inputs: {\n        x: _u39\n      },\n      backend: e,\n      attrs: {\n        shape: _a133\n      }\n    });\n\n    return _n284.forEach(t => e.disposeIntermediateTensorInfo(t)), _c33;\n  }\n\n  return zv(e, t, s);\n}\n\nvar Pv = {\n  kernelName: \"ArgMax\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    var i = y(a, r.shape);\n    var o = Jr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = Qr(i.length, l.shape.length)), Yr(\"argMax\", [i[0]], l.shape.length);\n    var c = Bv(n, l, i[0], \"max\");\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n},\n    Wv = {\n  kernelName: \"ArgMin\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    var i = y(a, r.shape);\n    var o = Jr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = Qr(i.length, l.shape.length)), Yr(\"argMin\", [i[0]], l.shape.length);\n    var c = Bv(n, l, i[0], \"min\");\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n},\n    Uv = {\n  kernelName: \"Asin\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return asin(x);\\n\"\n  })\n},\n    Vv = {\n  kernelName: \"Asinh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;return log(x + sqrt(x * x + 1.0));\"\n  })\n},\n    Gv = {\n  kernelName: \"Atan\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return atan(x);\\n\"\n  })\n},\n    Hv = {\n  kernelName: \"Atan2\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return atan(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = atan(a, b);\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    jv = {\n  kernelName: \"Atanh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if ((x < -1.0) || (x > 1.0)) return NAN;\\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;\"\n  })\n};\n\nclass qv {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (this.variableNames = [\"x\"], \"avg\" === t && n) throw new Error(\"Cannot compute positions for average pool.\");\n    var a = e.filterWidth,\n        i = e.strideHeight,\n        o = e.strideWidth,\n        l = e.dilationHeight,\n        u = e.dilationWidth,\n        c = e.effectiveFilterHeight,\n        h = e.effectiveFilterWidth,\n        d = e.padInfo.top,\n        p = e.padInfo.left;\n    this.outputShape = e.outShape;\n    var f = \"avg\" === t;\n    var g = \"0.0\";\n    if (f || (g = \"-1.0 / 1e-20\"), n) return void (this.userCode = \"\\n        const ivec2 strides = ivec2(\".concat(i, \", \").concat(o, \");\\n        const ivec2 pads = ivec2(\").concat(d, \", \").concat(p, \");\\n\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int batch = coords[0];\\n          int d = coords[3];\\n\\n          ivec2 xRCCorner = coords.yz * strides - pads;\\n          int xRCorner = xRCCorner.x;\\n          int xCCorner = xRCCorner.y;\\n\\n          // max/min x(?, ?, d) to get y(yR, yC, d).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n          float avgValue = 0.0;\\n\\n          for (int wR = 0; wR < \").concat(c, \";\\n              wR += \").concat(l, \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(h, \";\\n                wC += \").concat(u, \") {\\n              int xC = xCCorner + wC;\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              float value = getX(batch, xR, xC, d);\\n\\n              // If a min / max value has already been found, use it. If not,\\n              // use the current value.\\n              float currMinMaxValue = mix(\\n                  value, minMaxValue, minMaxValueFound);\\n              if (value >= currMinMaxValue) {\\n                minMaxValue = value;\\n                minMaxValueFound = 1.0;\\n                minMaxPosition = \").concat(s ? r ? \"((batch  * \".concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + d\") : \"(xR * \".concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + d\") : \"wR * \".concat(h, \" + wC\"), \";\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \"));\n    var m = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"avg\" === t && (m = \"avgValue / count\");\n    var b = 4 * Math.floor(a / 4),\n        x = a % 4,\n        y = \"\\n      if (\".concat(f, \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \");\n    this.userCode = \"\\n      const ivec2 strides = ivec2(\".concat(i, \", \").concat(o, \");\\n      const ivec2 pads = ivec2(\").concat(d, \", \").concat(p, \");\\n      const float initializationValue = \").concat(g, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xR, int xC, int d) {\\n        if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xR, xC, d);\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // max/min x(?, ?, d) to get y(yR, yC, d).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\").concat(g, \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wR = 0; wR < \").concat(c, \";\\n            wR += \").concat(l, \") {\\n          int xR = xRCorner + wR;\\n\\n          if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(b, \"; wC += 4) {\\n            int xC = xCCorner + wC * \").concat(u, \";\\n\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              getValue(batch, xR, xC + 2 * \").concat(u, \", d),\\n              getValue(batch, xR, xC + 3 * \").concat(u, \", d)\\n            );\\n\\n            \").concat(y, \"\\n          }\\n\\n          int xC = xCCorner + \").concat(b, \";\\n          if (\").concat(1 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              initializationValue,\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          } else if (\").concat(2 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          } else if (\").concat(3 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              getValue(batch, xR, xC + 2 * \").concat(u, \", d),\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          }\\n        }\\n        setOutput(\").concat(m, \");\\n      }\\n    \");\n  }\n\n}\n\nclass Kv {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (this.variableNames = [\"x\"], \"avg\" === t && n) throw new Error(\"Cannot compute positions for average pool.\");\n    var a = e.filterWidth,\n        i = e.strideDepth,\n        o = e.strideHeight,\n        l = e.strideWidth,\n        u = e.dilationDepth,\n        c = e.dilationHeight,\n        h = e.dilationWidth,\n        d = e.effectiveFilterDepth,\n        p = e.effectiveFilterHeight,\n        f = e.effectiveFilterWidth,\n        g = e.padInfo.front,\n        m = e.padInfo.top,\n        b = e.padInfo.left;\n    this.outputShape = e.outShape;\n    var x = \"avg\" === t;\n    var y = \"0.0\";\n    if (x || (y = \"-1.0 / 1e-20\"), n) return void (this.userCode = \"\\n        const ivec3 strides =\\n            ivec3(\".concat(i, \", \").concat(o, \", \").concat(l, \");\\n        const ivec3 pads = ivec3(\").concat(g, \", \").concat(m, \", \").concat(b, \");\\n\\n        void main() {\\n          ivec5 coords = getOutputCoords();\\n          int batch = coords.x;\\n          int ch = coords.u;\\n\\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n          int xDCorner = xCorner.x;\\n          int xRCorner = xCorner.y;\\n          int xCCorner = xCorner.z;\\n\\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n\\n          for (int wD = 0; wD < \").concat(d, \";\\n              wD += \").concat(u, \") {\\n            int xD = xDCorner + wD;\\n\\n            if (xD < 0 || xD >= \").concat(e.inDepth, \") {\\n              continue;\\n            }\\n\\n            for (int wR = 0; wR < \").concat(p, \";\\n                wR += \").concat(c, \") {\\n              int xR = xRCorner + wR;\\n\\n              if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n                continue;\\n              }\\n\\n              for (int wC = 0; wC < \").concat(f, \";\\n                  wC += \").concat(h, \") {\\n                int xC = xCCorner + wC;\\n\\n                if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                  continue;\\n                }\\n\\n                float value = getX(batch, xD, xR, xC, ch);\\n\\n                // If a min / max value has already been found, use it. If not,\\n                // use the current value.\\n                float currMinMaxValue = mix(\\n                    value, minMaxValue, minMaxValueFound);\\n                if (value >= currMinMaxValue) {\\n                  minMaxValue = value;\\n                  minMaxValueFound = 1.0;\\n                  minMaxPosition = \").concat(s ? r ? \"(((batch * \".concat(e.inDepth, \" + xD) * \").concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + ch\") : \"((xD * \".concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + ch\") : \"wD * \".concat(p, \" * \").concat(f, \" +\\n                      wR * \").concat(f, \" + wC\"), \";\\n                }\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \"));\n    var k = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"avg\" === t && (k = \"avgValue / count\");\n    var w = 4 * Math.floor(a / 4),\n        v = a % 4,\n        I = \"\\n      if (\".concat(x, \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \");\n    this.userCode = \"\\n      const ivec3 strides =\\n        ivec3(\".concat(i, \", \").concat(o, \", \").concat(l, \");\\n      const ivec3 pads = ivec3(\").concat(g, \", \").concat(m, \", \").concat(b, \");\\n      const float initializationValue = \").concat(y, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\\n        if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xD, xR, xC, ch);\\n      }\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xDCorner = xCorner.x;\\n        int xRCorner = xCorner.y;\\n        int xCCorner = xCorner.z;\\n\\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\").concat(y, \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(d, \";\\n            wD += \").concat(u, \") {\\n          int xD = xDCorner + wD;\\n\\n          if (xD < 0 || xD >= \").concat(e.inDepth, \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \").concat(p, \";\\n            wR += \").concat(c, \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(w, \"; wC += 4) {\\n              int xC = xCCorner + wC * \").concat(h, \";\\n\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 3 * \").concat(h, \", ch)\\n              );\\n\\n              \").concat(I, \"\\n            }\\n\\n            int xC = xCCorner + \").concat(w, \";\\n            if (\").concat(1 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                initializationValue,\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            } else if (\").concat(2 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            } else if (\").concat(3 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \").concat(h, \", ch),\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            }\\n          }\\n          setOutput(\").concat(k, \");\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar Xv = {\n  kernelName: \"AvgPool\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    ik(r, \"avgPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ss(i, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = bs(r.shape, a, i, 1, o, u);\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) return jw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var h = new qv(c, \"avg\", !1);\n    return n.runWebGLProgram(h, [r], \"float32\");\n  }\n},\n    Yv = {\n  kernelName: \"AvgPool3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s,\n        c = xs(r.shape, a, i, [1, 1, 1], o, l, u),\n        h = new Kv(c, \"avg\", !1);\n    return n.runWebGLProgram(h, [r], \"float32\");\n  }\n};\n\nclass Jv {\n  constructor(e) {\n    this.variableNames = [\"dy\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterHeight,\n        n = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n      const float avgMultiplier = float(\").concat(1 / (e.filterHeight * e.filterWidth), \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \";\\n            wR += \").concat(e.dilationHeight, \") {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \").concat(n, \";\\n            wC+= \").concat(e.dilationWidth, \") {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n\\n            dotProd += dyValue * avgMultiplier;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass Zv {\n  constructor(e) {\n    this.variableNames = [\"dy\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterDepth,\n        n = e.effectiveFilterHeight,\n        s = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n      const float avgMultiplier = float(\").concat(1 / (e.filterDepth * e.filterHeight * e.filterWidth), \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(t, \";\\n            wD += \").concat(e.dilationDepth, \") {\\n          float dyD = float(dyDCorner + wD) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyD < 0.0 || dyD >= \").concat(e.outDepth, \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \").concat(n, \";\\n              wR += \").concat(e.dilationHeight, \") {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \").concat(s, \";\\n                wC += \").concat(e.dilationWidth, \") {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n\\n              dotProd += dyValue * avgMultiplier;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar Qv = {\n  kernelName: \"AvgPool3DGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a,\n        {\n      filterSize: o,\n      strides: l,\n      pad: u,\n      dimRoundingMode: c\n    } = s,\n        h = xs(i.shape, o, l, [1, 1, 1], u, c),\n        d = new Zv(h);\n    return n.runWebGLProgram(d, [r], i.dtype);\n  }\n},\n    eI = {\n  kernelName: \"AvgPoolGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a;\n    ik([r, a], \"avgPoolGrad\");\n    var {\n      filterSize: o,\n      strides: l,\n      pad: u\n    } = s,\n        c = bs(i.shape, o, l, 1, u),\n        h = new Jv(c);\n    return n.runWebGLProgram(h, [r], i.dtype);\n  }\n},\n    tI = {\n  kernelName: \"BatchMatMul\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a\n    } = t,\n        {\n      transposeA: i,\n      transposeB: o\n    } = s;\n    return vv({\n      a: r,\n      b: a,\n      transposeA: i,\n      transposeB: o,\n      backend: n\n    });\n  }\n};\n\nclass nI {\n  constructor(e, t, n, s, r, a) {\n    this.outputShape = [], this.variableNames = [\"x\", \"mean\", \"variance\"], cr(e, t), cr(e, n);\n    var i = \"0.0\";\n    null != s && (cr(e, s), this.variableNames.push(\"offset\"), i = \"getOffsetAtOutCoords()\");\n    var o = \"1.0\";\n    null != r && (cr(e, r), this.variableNames.push(\"scale\"), o = \"getScaleAtOutCoords()\"), this.outputShape = e, this.userCode = \"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \".concat(i, \";\\n        float scale = \").concat(o, \";\\n        float inv = scale * inversesqrt(variance + float(\").concat(a, \"));\\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\\n      }\\n    \");\n  }\n\n}\n\nclass sI {\n  constructor(e, t, n, s, r, a) {\n    this.packedInputs = !0, this.packedOutput = !0, this.variableNames = [\"x\", \"mean\", \"variance\"], cr(e, t), cr(e, n);\n    var i = \"vec4(0.0)\";\n    null != s && (cr(e, s), this.variableNames.push(\"offset\"), i = \"getOffsetAtOutCoords()\");\n    var o = \"vec4(1.0)\";\n    null != r && (cr(e, r), this.variableNames.push(\"scale\"), o = \"getScaleAtOutCoords()\"), this.outputShape = e, this.userCode = \"\\n      void main() {\\n        vec4 offset = \".concat(i, \";\\n        vec4 scale = \").concat(o, \";\\n\\n        vec4 x = getXAtOutCoords();\\n        vec4 mean = getMeanAtOutCoords();\\n        vec4 variance = getVarianceAtOutCoords();\\n\\n        vec4 inv = scale * inversesqrt(variance + vec4(\").concat(a, \"));\\n\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \");\n  }\n\n}\n\nvar rI = {\n  kernelName: \"FusedBatchNorm\",\n  backendName: \"webgl\",\n  kernelFunc: _ref25 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref25;\n    var {\n      x: s,\n      mean: r,\n      variance: a,\n      offset: i,\n      scale: o\n    } = e;\n    l(r.shape.length === a.shape.length, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == i || r.shape.length === i.shape.length, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == o || r.shape.length === o.shape.length, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\");\n    var {\n      varianceEpsilon: u\n    } = n;\n    null == u && (u = .001);\n    var c = [s, r, a];\n    var h = null;\n    null != i && (h = i.shape, c.push(i));\n    var d = null;\n    null != o && (d = o.shape, c.push(o));\n    var p = V().getBool(\"WEBGL_PACK_NORMALIZATION\") ? new sI(s.shape, r.shape, a.shape, h, d, u) : new nI(s.shape, r.shape, a.shape, h, d, u);\n    return t.runWebGLProgram(p, c, c[0].dtype);\n  }\n};\n\nclass aI {\n  constructor(e) {\n    this.variableNames = [\"source\"], this.outputShape = e, this.rank = e.length;\n    var t = Mk(this.rank);\n    this.customUniforms = [{\n      name: \"start\",\n      arrayIndex: this.rank,\n      type: \"int\"\n    }];\n\n    var n = function (e) {\n      if (1 === e) return \"sourceLoc\";\n      if (e <= 6) return iI.slice(0, e).map(e => \"sourceLoc.\" + e).join(\",\");\n      throw Error(\"Slicing for rank \".concat(e, \" is not yet supported\"));\n    }(this.rank);\n\n    var s;\n    s = \"\\n        \".concat(t, \" sourceLoc;\\n        \").concat(t, \" coords = getOutputCoords();\\n        \").concat(e.map((e, t) => \"sourceLoc.\".concat(iI[t], \" = start[\").concat(t, \"] + coords.\").concat(iI[t], \";\")).join(\"\\n\"), \"\\n      \"), this.userCode = \"\\n      void main() {\\n        \".concat(s, \"\\n        setOutput(getSource(\").concat(n, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar iI = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n\nclass oI {\n  constructor(e) {\n    this.variableNames = [\"source\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.rank = e.length, this.customUniforms = [{\n      name: \"start\",\n      arrayIndex: this.rank,\n      type: \"int\"\n    }];\n    var t = Mk(this.rank),\n        n = Ew(\"coords\", this.rank),\n        s = Ew(\"sourceLoc\", this.rank),\n        r = 1 === this.rank ? \"sourceLoc\" : \"vec2(\".concat(s.slice(-2).join(), \")\"),\n        a = \"getChannel(getSource(\".concat(s.join(), \"), \").concat(r, \")\"),\n        i = \"\\n      result.x = \".concat(a, \";\\n      if (++\").concat(n[this.rank - 1], \" < \").concat(e[this.rank - 1], \") {\\n        ++\").concat(s[this.rank - 1], \";\\n        result.y = \").concat(a, \";\\n        --\").concat(s[this.rank - 1], \";\\n      }\\n    \"),\n        o = 1 === this.rank ? \"\" : \"\\n      --\".concat(n[this.rank - 1], \";\\n      if (++\").concat(n[this.rank - 2], \" < \").concat(e[this.rank - 2], \") {\\n        ++\").concat(s[this.rank - 2], \";\\n        result.z = \").concat(a, \";\\n        if (++\").concat(n[this.rank - 1], \" < \").concat(e[this.rank - 1], \") {\\n          ++\").concat(s[this.rank - 1], \";\\n          result.w = \").concat(a, \";\\n        }\\n      }\\n    \"),\n        l = this.rank <= 4 ? \"sourceLoc = coords +\\n            \".concat(t, \"(\").concat(e.map((e, t) => \"start[\".concat(t, \"]\")).join(), \");\") : e.map((e, t) => \"\".concat(s[t], \" = \").concat(n[t], \" + start[\").concat(t, \"];\")).join(\"\\n\");\n    this.userCode = \"\\n      void main() {\\n        \".concat(t, \" coords = getOutputCoords();\\n        \").concat(t, \" sourceLoc;\\n        \").concat(l, \"\\n        vec4 result = vec4(0.);\\n        \").concat(i, \"\\n        \").concat(o, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction lI(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    begin: a,\n    size: i\n  } = s,\n      [o, l] = Un(r, a, i);\n  if (Tn(r, o, l), 0 === d(l)) return n.makeTensorInfo(l, r.dtype, []);\n\n  if (n.shouldExecuteOnCPU([r]) || \"string\" === r.dtype) {\n    var _e463 = n.texData.get(r.dataId),\n        _t389 = gw(_e463.values, o, l, r.shape, r.dtype);\n\n    return n.makeTensorInfo(l, r.dtype, _t389);\n  }\n\n  var {\n    isPacked: u\n  } = n.texData.get(r.dataId),\n      c = Pn(r.shape, o, l);\n\n  if (u || !c) {\n    var _e464 = V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new oI(l) : new aI(l);\n\n    return n.runWebGLProgram(_e464, [r], r.dtype, [o]);\n  }\n\n  return n.uploadToGPU(r.dataId), function (e, t, n, s) {\n    var r = s.texData.get(e.dataId),\n        a = s.makeTensorInfo(n, e.dtype),\n        i = s.texData.get(a.dataId);\n    Object.assign(i, r), i.refCount = 1, i.shape = n, i.dtype = e.dtype;\n    var o = Wn(t, A(e.shape));\n    r.slice && (o += r.slice.flatOffset), i.slice = {\n      flatOffset: o,\n      origDataId: r.slice && r.slice.origDataId || e.dataId\n    };\n    var l = s.dataRefCount.get(i.slice.origDataId) || 1;\n    return s.dataRefCount.set(i.slice.origDataId, l + 1), a;\n  }(r, o, l, n);\n}\n\nvar uI = {\n  kernelName: \"Slice\",\n  backendName: \"webgl\",\n  kernelFunc: lI\n},\n    cI = {\n  kernelName: \"BatchToSpaceND\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      crops: i\n    } = s;\n    l(r.shape.length <= 4, () => \"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet\");\n\n    var o = a.reduce((e, t) => e * t),\n        u = Ro(r.shape, a, o),\n        c = Ao(u.length, a.length),\n        h = Fo(r.shape, a, o),\n        d = Do(i, a.length),\n        p = _o(h, i, a.length),\n        f = [],\n        g = cv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: u\n      }\n    }),\n        m = kv({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }),\n        b = cv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: h\n      }\n    }),\n        x = lI({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        begin: d,\n        size: p\n      }\n    });\n\n    return f.push(g), f.push(m), f.push(b), f.forEach(e => n.disposeIntermediateTensorInfo(e)), x;\n  }\n},\n    hI = {\n  kernelName: \"Bincount\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i\n    } = s,\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        u = Vk(o, l, a.dtype, a.shape, i);\n    return n.makeTensorInfo([i], a.dtype, u);\n  }\n},\n    dI = sv({\n  opSnippet: \"return float(a != b);\",\n  cpuKernelImpl: cw,\n  dtype: \"bool\"\n}),\n    pI = {\n  kernelName: \"NotEqual\",\n  backendName: \"webgl\",\n  kernelFunc: dI\n};\n\nfunction fI(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t;\n  return jw({\n    inputs: {\n      x: n.texData.get(s.dataId).complexTensorInfos.real\n    },\n    backend: n\n  });\n}\n\nvar gI = {\n  kernelName: \"Real\",\n  backendName: \"webgl\",\n  kernelFunc: fI\n},\n    mI = {\n  kernelName: \"Cast\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s,\n      attrs: r\n    } = t,\n        {\n      x: a\n    } = n,\n        {\n      dtype: i\n    } = r;\n\n    if (\"complex64\" === i) {\n      if (\"complex64\" === a.dtype) return jw({\n        inputs: {\n          x: a\n        },\n        backend: s\n      });\n\n      var _t390 = ua(a.shape),\n          _n285 = e({\n        inputs: {\n          x: a\n        },\n        backend: s,\n        attrs: {\n          dtype: \"float32\"\n        }\n      }),\n          _r163 = Kw({\n        inputs: {\n          real: _n285,\n          imag: _t390\n        },\n        backend: s\n      });\n\n      return _t390.dispose(), s.disposeIntermediateTensorInfo(_n285), _r163;\n    }\n\n    if (\"complex64\" === a.dtype) {\n      var _t391 = fI({\n        inputs: {\n          input: a\n        },\n        backend: s\n      }),\n          _n286 = e({\n        inputs: {\n          x: _t391\n        },\n        backend: s,\n        attrs: {\n          dtype: i\n        }\n      });\n\n      return s.disposeIntermediateTensorInfo(_t391), _n286;\n    }\n\n    if (!I(a.dtype, i)) {\n      var _e465 = jw({\n        inputs: {\n          x: a\n        },\n        backend: s\n      });\n\n      return {\n        dataId: _e465.dataId,\n        shape: _e465.shape,\n        dtype: i\n      };\n    }\n\n    if (\"int32\" === i) return function (e, t) {\n      var n = new Mw(e.shape, \"return float(int(x));\"),\n          s = t.runWebGLProgram(n, [e], \"int32\");\n      return {\n        dataId: s.dataId,\n        shape: s.shape,\n        dtype: s.dtype\n      };\n    }(a, s);\n\n    if (\"bool\" === i) {\n      var _e466 = s.makeTensorInfo([], \"bool\", w(\"bool\", 1)),\n          _t392 = dI({\n        inputs: {\n          a,\n          b: _e466\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_e466), _t392;\n    }\n\n    throw new Error(\"Error in Cast: failed to cast \".concat(a.dtype, \" to \").concat(i));\n  }\n},\n    bI = \"return ceil(x);\",\n    xI = {\n  kernelName: \"Ceil\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: bI,\n    packedOpSnippet: bI,\n    cpuKernelImpl: Hk\n  })\n};\n\nclass yI {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.customUniforms = [{\n      name: \"minVal\",\n      type: \"float\"\n    }, {\n      name: \"maxVal\",\n      type: \"float\"\n    }], this.outputShape = e, this.userCode = \"\\n\\n      void main() {\\n        float value = getAAtOutCoords();\\n        if (isnan(value)) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, minVal, maxVal));\\n      }\\n    \";\n  }\n\n}\n\nclass kI {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"minVal\",\n      type: \"float\"\n    }, {\n      name: \"maxVal\",\n      type: \"float\"\n    }], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        vec4 value = getAAtOutCoords();\\n\\n        if (any(isnan(value))) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\\n      }\\n    \";\n  }\n\n}\n\nvar wI = {\n  kernelName: \"ClipByValue\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      clipValueMin: a,\n      clipValueMax: i\n    } = s;\n    var o;\n    return o = V().getBool(\"WEBGL_PACK_CLIP\") ? new kI(r.shape) : new yI(r.shape), n.runWebGLProgram(o, [r], r.dtype, [[a], [i]]);\n  }\n};\n\nclass vI {\n  constructor(e) {\n    this.variableNames = [\"real\", \"imag\"], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        float re = abs(getRealAtOutCoords());\\n        float im = abs(getImagAtOutCoords());\\n        float mx = max(re, im);\\n\\n        // sadly the length function in glsl is not underflow-safe\\n        // (at least not on Intel GPUs). So the safe solution is\\n        // to ensure underflow-safety in all cases.\\n        setOutput(\\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\\n        );\\n      }\\n    \";\n  }\n\n}\n\nfunction II(e, t) {\n  return {\n    dataId: t.dataId,\n    dtype: t.dtype,\n    shape: e.shape\n  };\n}\n\nvar $I = {\n  kernelName: \"ComplexAbs\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = n.texData.get(s.dataId),\n        a = new vI(s.shape),\n        i = [II(s, r.complexTensorInfos.real), II(s, r.complexTensorInfos.imag)];\n    return n.runWebGLProgram(a, i, i[0].dtype);\n  }\n};\n\nclass NI {\n  constructor(e) {\n    this.outputShape = [], this.outputShape = So(e, 1), this.variableNames = e.map((e, t) => \"T\".concat(t));\n    var t = new Array(e.length - 1);\n    t[0] = e[0][1];\n\n    for (var _n287 = 1; _n287 < t.length; _n287++) {\n      t[_n287] = t[_n287 - 1] + e[_n287][1];\n    }\n\n    var n = [\"if (yC < \".concat(t[0], \") setOutput(getT0(yR, yC));\")];\n\n    for (var _e467 = 1; _e467 < t.length; _e467++) {\n      n.push(\"else if (yC < \".concat(t[_e467], \") setOutput(getT\").concat(_e467, \"(yR, yC-\").concat(t[_e467 - 1], \"));\"));\n    }\n\n    n.push(\"else setOutput(getT\".concat(t.length, \"(yR, yC-\").concat(t[t.length - 1], \"));\")), this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int yR = coords.x;\\n        int yC = coords.y;\\n\\n        \".concat(n.join(\"\\n        \"), \"\\n      }\\n    \");\n  }\n\n}\n\nclass CI {\n  constructor(e, t) {\n    this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [], this.outputShape = So(e, t);\n    var n = this.outputShape,\n        s = n.length,\n        r = Mk(s),\n        a = Ew(\"coords\", s),\n        i = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, s);\n    this.variableNames = e.map((e, t) => \"T\".concat(t));\n    var o = new Array(e.length - 1);\n    o[0] = e[0][t];\n\n    for (var _n288 = 1; _n288 < o.length; _n288++) {\n      o[_n288] = o[_n288 - 1] + e[_n288][t];\n    }\n\n    var l = i[t],\n        u = i.slice(-2),\n        c = i.join();\n    var h = \"if (\".concat(l, \" < \").concat(o[0], \") {\\n        return getChannel(\\n            getT0(\").concat(c, \"), vec2(\").concat(u.join(), \"));\\n        }\");\n\n    for (var _e468 = 1; _e468 < o.length; _e468++) {\n      var _t393 = o[_e468 - 1];\n      h += \"\\n        if (\".concat(l, \" < \").concat(o[_e468], \"  && \").concat(l, \" >= \").concat(o[_e468 - 1], \") {\\n          return getChannel(\\n            getT\").concat(_e468, \"(\").concat(SI(i, l, _t393), \"),\\n            vec2(\").concat(SI(u, l, _t393), \"));\\n        }\");\n    }\n\n    var d = o[o.length - 1];\n    h += \"\\n        return getChannel(\\n          getT\".concat(o.length, \"(\").concat(SI(i, l, d), \"),\\n          vec2(\").concat(SI(u, l, d), \"));\"), this.userCode = \"\\n      float getValue(\".concat(i.map(e => \"int \" + e), \") {\\n        \").concat(h, \"\\n      }\\n\\n      void main() {\\n        \").concat(r, \" coords = getOutputCoords();\\n        vec4 result = vec4(getValue(\").concat(a, \"), 0., 0., 0.);\\n\\n        \").concat(a[s - 1], \" = \").concat(a[s - 1], \" + 1;\\n        if (\").concat(a[s - 1], \" < \").concat(n[s - 1], \") {\\n          result.g = getValue(\").concat(a, \");\\n        }\\n\\n        \").concat(a[s - 2], \" = \").concat(a[s - 2], \" + 1;\\n        if (\").concat(a[s - 2], \" < \").concat(n[s - 2], \") {\\n          result.a = getValue(\").concat(a, \");\\n        }\\n\\n        \").concat(a[s - 1], \" = \").concat(a[s - 1], \" - 1;\\n        if (\").concat(a[s - 2], \" < \").concat(n[s - 2], \" &&\\n            \").concat(a[s - 1], \" < \").concat(n[s - 1], \") {\\n          result.b = getValue(\").concat(a, \");\\n        }\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction SI(e, t, n) {\n  var s = e.indexOf(t);\n  return e.map((e, t) => t === s ? \"\".concat(e, \" - \").concat(n) : e).join();\n}\n\nfunction TI(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t;\n  return jw({\n    inputs: {\n      x: n.texData.get(s.dataId).complexTensorInfos.imag\n    },\n    backend: n\n  });\n}\n\nvar EI = {\n  kernelName: \"Imag\",\n  backendName: \"webgl\",\n  kernelFunc: TI\n};\n\nfunction RI(e, t, n) {\n  var s = e[0].dtype;\n\n  if (\"complex64\" === s) {\n    var _s225 = e.map(e => fI({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _r164 = e.map(e => TI({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _a134 = RI(_s225, t, n),\n        _i95 = RI(_r164, t, n),\n        _o73 = Kw({\n      inputs: {\n        real: _a134,\n        imag: _i95\n      },\n      backend: n\n    });\n\n    return _s225.forEach(e => n.disposeIntermediateTensorInfo(e)), _r164.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_a134), n.disposeIntermediateTensorInfo(_i95), _o73;\n  }\n\n  var r = n.shouldExecuteOnCPU(e);\n\n  if (\"string\" === s && (r = !0), r) {\n    var _r165 = e.map(e => {\n      var s = d(e.shape.slice(t));\n      return cv({\n        inputs: {\n          x: e\n        },\n        backend: n,\n        attrs: {\n          shape: [-1, s]\n        }\n      });\n    }),\n        _a135 = _r165.map(e => ({\n      vals: n.readSync(e.dataId),\n      shape: e.shape\n    })),\n        _i96 = So(_r165.map(e => e.shape), 1),\n        _o74 = jk(_a135, _i96, s, 1 === _r165[0].shape[0]),\n        _l52 = So(e.map(e => e.shape), t),\n        _u40 = n.makeTensorInfo(_l52, s, _o74);\n\n    return _r165.forEach(e => n.disposeIntermediateTensorInfo(e)), _u40;\n  }\n\n  if (e.length > V().getNumber(\"WEBGL_MAX_TEXTURES_IN_SHADER\")) {\n    var _s226 = Math.floor(e.length / 2),\n        _r166 = RI(e.slice(0, _s226), t, n),\n        _a136 = RI(e.slice(_s226), t, n),\n        _i97 = RI([_r166, _a136], t, n);\n\n    return n.disposeIntermediateTensorInfo(_r166), n.disposeIntermediateTensorInfo(_a136), _i97;\n  }\n\n  if (V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") && e[0].shape.length > 1) {\n    var _r167 = new CI(e.map(e => e.shape), t);\n\n    return n.runWebGLProgram(_r167, e, s);\n  }\n\n  var {\n    tensors2D: a,\n    outShape: i\n  } = function (e, t, n) {\n    var s = So(e.map(e => e.shape), t);\n    return {\n      tensors2D: e.map(e => cv({\n        inputs: {\n          x: e\n        },\n        attrs: {\n          shape: [-1, d(e.shape.slice(t))]\n        },\n        backend: n\n      })),\n      outShape: s\n    };\n  }(e, t, n),\n      o = new NI(a.map(e => e.shape)),\n      l = n.runWebGLProgram(o, a, s);\n\n  a.forEach(e => n.disposeIntermediateTensorInfo(e));\n  var u = cv({\n    inputs: {\n      x: l\n    },\n    attrs: {\n      shape: i\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(l), u;\n}\n\nfunction AI(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s,\n      a = y(r, t[0].shape)[0],\n      i = So(t.map(e => e.shape), a);\n  if (0 === d(i)) return n.makeTensorInfo(i, t[0].dtype, []);\n  var o = t.filter(e => d(e.shape) > 0);\n  return 1 === o.length ? jw({\n    inputs: {\n      x: o[0]\n    },\n    backend: n\n  }) : (Co(o.map(e => e.shape), a), RI(o, a, n));\n}\n\nvar FI = {\n  kernelName: \"Concat\",\n  backendName: \"webgl\",\n  kernelFunc: AI\n};\n\nclass DI {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var a = e.padInfo.top,\n        i = e.padInfo.left,\n        o = e.strideHeight,\n        l = e.strideWidth,\n        u = e.dilationHeight,\n        c = e.dilationWidth,\n        h = e.filterHeight,\n        d = e.filterWidth,\n        p = 4 * Math.floor(e.inChannels / 4),\n        f = e.inChannels % 4,\n        g = \"channelsLast\" === e.dataFormat,\n        m = g ? 1 : 2,\n        b = g ? 2 : 3,\n        x = g ? 3 : 1;\n    var y = \"\",\n        k = \"\";\n    n && (y = s ? \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"float activation(float a) {\\n          float b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"\\n          float activation(float x) {\\n            \".concat(n, \"\\n          }\\n        \"), k = \"result = activation(result);\");\n    var w = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(y, \"\\n\\n      const ivec2 strides = ivec2(\").concat(o, \", \").concat(l, \");\\n      const ivec2 pads = ivec2(\").concat(a, \", \").concat(i, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d2 = coords[\").concat(x, \"];\\n\\n        ivec2 xRCCorner =\\n            ivec2(coords[\").concat(m, \"], coords[\").concat(b, \"]) * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(h, \"; wR++) {\\n          int xR = xRCorner + wR * \").concat(u, \";\\n\\n          if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(d, \"; wC++) {\\n            int xC = xCCorner + wC * \").concat(c, \";\\n\\n            if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n              continue;\\n            }\\n\\n            for (int d1 = 0; d1 < \").concat(p, \"; d1 += 4) {\\n              vec4 wValues = vec4(\\n                getW(wR, wC, d1, d2),\\n                getW(wR, wC, d1 + 1, d2),\\n                getW(wR, wC, d1 + 2, d2),\\n                getW(wR, wC, d1 + 3, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec4 xValues = vec4(\\n                  getX(batch, xR, xC, d1),\\n                  getX(batch, xR, xC, d1 + 1),\\n                  getX(batch, xR, xC, d1 + 2),\\n                  getX(batch, xR, xC, d1 + 3)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec4 xValues = vec4(\\n                  getX(batch, d1, xR, xC),\\n                  getX(batch, d1 + 1, xR, xC),\\n                  getX(batch, d1 + 2, xR, xC),\\n                  getX(batch, d1 + 3, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n\\n            if (\").concat(1 === f, \") {\\n\\n              if (\").concat(g, \") {\\n                dotProd +=\\n                    getX(batch, xR, xC, \").concat(p, \") *\\n                    getW(wR, wC, \").concat(p, \", d2);\\n              } else {\\n                dotProd +=\\n                    getX(batch, \").concat(p, \", xR, xC) *\\n                    getW(wR, wC, \").concat(p, \", d2);\\n              }\\n\\n            } else if (\").concat(2 === f, \") {\\n              vec2 wValues = vec2(\\n                getW(wR, wC, \").concat(p, \", d2),\\n                getW(wR, wC, \").concat(p, \" + 1, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xR, xC, \").concat(p, \"),\\n                  getX(batch, xR, xC, \").concat(p, \" + 1)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec2 xValues = vec2(\\n                  getX(batch, \").concat(p, \", xR, xC),\\n                  getX(batch, \").concat(p, \" + 1, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            } else if (\").concat(3 === f, \") {\\n              vec3 wValues = vec3(\\n                getW(wR, wC, \").concat(p, \", d2),\\n                getW(wR, wC, \").concat(p, \" + 1, d2),\\n                getW(wR, wC, \").concat(p, \" + 2, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xR, xC, \").concat(p, \"),\\n                  getX(batch, xR, xC, \").concat(p, \" + 1),\\n                  getX(batch, xR, xC, \").concat(p, \" + 2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec3 xValues = vec3(\\n                  getX(batch, \").concat(p, \", xR, xC),\\n                  getX(batch, \").concat(p, \" + 1, xR, xC),\\n                  getX(batch, \").concat(p, \" + 2, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            }\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \").concat(w, \"\\n        \").concat(k, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass _I {\n  constructor(e) {\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var t = e.padInfo.front,\n        n = e.padInfo.top,\n        s = e.padInfo.left,\n        r = e.strideDepth,\n        a = e.strideHeight,\n        i = e.strideWidth,\n        o = e.dilationDepth,\n        l = e.dilationHeight,\n        u = e.dilationWidth,\n        c = e.filterDepth,\n        h = e.filterHeight,\n        d = e.filterWidth,\n        p = 4 * Math.floor(e.inChannels / 4),\n        f = e.inChannels % 4;\n    this.userCode = \"\\n      const ivec3 strides = ivec3(\".concat(r, \", \").concat(a, \", \").concat(i, \");\\n      const ivec3 pads = ivec3(\").concat(t, \", \").concat(n, \", \").concat(s, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d2 = coords.u;\\n\\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xFCorner = xFRCCorner.x;\\n        int xRCorner = xFRCCorner.y;\\n        int xCCorner = xFRCCorner.z;\\n\\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\\n        // values in that axis.\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \").concat(c, \"; wF++) {\\n          int xF = xFCorner + wF * \").concat(o, \";\\n\\n          if (xF < 0 || xF >= \").concat(e.inDepth, \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \").concat(h, \"; wR++) {\\n            int xR = xRCorner + wR * \").concat(l, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(d, \"; wC++) {\\n              int xC = xCCorner + wC * \").concat(u, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              for (int d1 = 0; d1 < \").concat(p, \"; d1 += 4) {\\n                vec4 xValues = vec4(\\n                  getX(batch, xF, xR, xC, d1),\\n                  getX(batch, xF, xR, xC, d1 + 1),\\n                  getX(batch, xF, xR, xC, d1 + 2),\\n                  getX(batch, xF, xR, xC, d1 + 3)\\n                );\\n                vec4 wValues = vec4(\\n                  getW(wF, wR, wC, d1, d2),\\n                  getW(wF, wR, wC, d1 + 1, d2),\\n                  getW(wF, wR, wC, d1 + 2, d2),\\n                  getW(wF, wR, wC, d1 + 3, d2)\\n                );\\n\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n              if (\").concat(1 === f, \") {\\n                dotProd +=\\n                  getX(batch, xF, xR, xC, \").concat(p, \") *\\n                  getW(wF, wR, wC, \").concat(p, \", d2);\\n              } else if (\").concat(2 === f, \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xF, xR, xC, \").concat(p, \"),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 1)\\n                );\\n                vec2 wValues = vec2(\\n                  getW(wF, wR, wC, \").concat(p, \", d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 1, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else if (\").concat(3 === f, \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xF, xR, xC, \").concat(p, \"),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 1),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 2)\\n                );\\n                vec3 wValues = vec3(\\n                  getW(wF, wR, wC, \").concat(p, \", d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 1, d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 2, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass OI {\n  constructor(e, t, n) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;\n    var {\n      filterWidth: s,\n      inChannels: r,\n      strideWidth: a,\n      strideHeight: i,\n      padInfo: o,\n      outWidth: l,\n      dilationWidth: u,\n      dilationHeight: c,\n      dataFormat: h\n    } = n,\n        {\n      left: d,\n      top: p\n    } = o,\n        f = r * s,\n        g = lk(),\n        m = \"channelsLast\" === h,\n        b = m ? 0 : 1,\n        x = m ? 1 : 2;\n    var y = \"\";\n\n    for (var _n289 = 0; _n289 <= 1; _n289++) {\n      for (var _s227 = 0; _s227 <= 1; _s227++) {\n        y += \"\\n          blockIndex = rc.y + \".concat(_s227, \";\\n          pos = rc.x + \").concat(_n289, \";\\n\\n          if(blockIndex < \").concat(e[1], \" && pos < \").concat(e[0], \") {\\n            offsetY = int(blockIndex / (\").concat(l, \")) * \").concat(i, \" - \").concat(p, \";\\n            d0 = offsetY + \").concat(c, \" * (pos / \").concat(f, \");\\n\\n            if(d0 < \").concat(t[b], \" && d0 >= 0) {\\n\\n              offsetX = int(mod(float(blockIndex), \").concat(l, \".) * \").concat(a, \". - \").concat(d, \".);\\n              d1 = offsetX + \").concat(u, \" * (int(mod(float(pos), \").concat(f, \".) / \").concat(r, \".));\\n\\n              if(d1 < \").concat(t[x], \" && d1 >= 0) {\\n\\n                ch = int(mod(float(pos), \").concat(r, \".));\\n\\n                if (\").concat(m, \") {\\n                  innerDims = vec2(d1, ch);\\n                  result[\").concat(2 * _n289 + _s227, \"] = getChannel(\\n                    getA(d0, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                } else {\\n                  innerDims = vec2(d0, d1);\\n                  result[\").concat(2 * _n289 + _s227, \"] = getChannel(\\n                    getA(ch, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                }\\n              }\\n            }\\n          }\\n        \");\n      }\n    }\n\n    this.userCode = \"\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0);\\n\\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\\n        vec2 innerDims;\\n\\n        \".concat(y, \"\\n\\n        \").concat(g.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nfunction MI(_ref26) {\n  var {\n    x: e,\n    filter: t,\n    convInfo: n,\n    backend: s,\n    bias: r = null,\n    preluActivationWeights: a = null,\n    leakyreluAlpha: i = 0,\n    activation: o = null\n  } = _ref26;\n  var u = e.shape,\n      c = s.texData.get(e.dataId),\n      h = \"channelsLast\" === n.dataFormat;\n  var d;\n  var p = [],\n      f = u[2] % 2 != 0 && !!c.isPacked;\n\n  if ((1 != u[0] * u[1] * u[2] && 1 !== n.outChannels || !(n.inChannels > 1e3)) && V().getBool(\"WEBGL_LAZILY_UNPACK\") && V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") && f) {\n    var _f13 = {\n      dataId: e.dataId,\n      shape: [1, h ? u[0] * u[1] * (u[2] + 1) : u[0] * u[2] * (u[3] + 1), n.inChannels],\n      dtype: e.dtype\n    },\n        _g21 = c.shape;\n    c.shape = c.shape.slice(), c.shape[c.shape.length - 2]++, l(ek(c.shape, _f13.shape), () => \"packed reshape \".concat(c.shape, \" to \").concat(_f13.shape, \" isn't free\"));\n\n    var _m14 = cv({\n      inputs: {\n        x: t\n      },\n      backend: s,\n      attrs: {\n        shape: [1, n.inChannels, n.outChannels]\n      }\n    });\n\n    p.push(_m14);\n\n    var _b15 = vv({\n      a: _f13,\n      b: _m14,\n      backend: s,\n      transposeA: !1,\n      transposeB: !1,\n      bias: r,\n      activation: o,\n      preluActivationWeights: a,\n      leakyreluAlpha: i\n    }),\n        _x55 = s.texData.get(_b15.dataId);\n\n    l(_x55.isPacked, () => \"batchMatMul result is expected to be packed\"), c.shape = _g21, _x55.shape = n.outShape, d = jw({\n      inputs: {\n        x: _b15\n      },\n      backend: s\n    }), d.shape = n.outShape, p.push(_b15);\n  } else {\n    var _l53 = cv({\n      inputs: {\n        x: e\n      },\n      backend: s,\n      attrs: {\n        shape: [1, h ? u[0] * u[1] * u[2] : u[0] * u[2] * u[3], n.inChannels]\n      }\n    }),\n        _c34 = cv({\n      inputs: {\n        x: t\n      },\n      backend: s,\n      attrs: {\n        shape: [1, n.inChannels, n.outChannels]\n      }\n    }),\n        _f14 = vv({\n      a: _l53,\n      b: _c34,\n      transposeA: !1,\n      transposeB: !1,\n      backend: s,\n      bias: r,\n      activation: o,\n      preluActivationWeights: a,\n      leakyreluAlpha: i\n    });\n\n    d = cv({\n      inputs: {\n        x: _f14\n      },\n      backend: s,\n      attrs: {\n        shape: n.outShape\n      }\n    }), p.push(_l53), p.push(_c34), p.push(_f14);\n  }\n\n  for (var _e469 of p) {\n    s.disposeIntermediateTensorInfo(_e469);\n  }\n\n  return d;\n}\n\nfunction LI(_ref27) {\n  var {\n    x: e,\n    filter: t,\n    convInfo: n,\n    backend: s,\n    bias: r = null,\n    preluActivationWeights: a = null,\n    leakyreluAlpha: i = 0,\n    activation: o = null\n  } = _ref27;\n  var {\n    filterWidth: l,\n    filterHeight: u,\n    inChannels: c,\n    outWidth: h,\n    outHeight: p,\n    dataFormat: f\n  } = n,\n      g = \"channelsLast\" === f,\n      m = l * u * c,\n      b = p * h,\n      x = [m, b],\n      y = [],\n      k = cv({\n    inputs: {\n      x: e\n    },\n    backend: s,\n    attrs: {\n      shape: e.shape.slice(1)\n    }\n  }),\n      w = cv({\n    inputs: {\n      x: t\n    },\n    backend: s,\n    attrs: {\n      shape: [1, m, d(t.shape) / m]\n    }\n  });\n  y.push(k), y.push(w);\n  var v = new OI(x, k.shape, n),\n      I = s.runWebGLProgram(v, [k], \"float32\"),\n      $ = cv({\n    inputs: {\n      x: I\n    },\n    backend: s,\n    attrs: {\n      shape: [1, x[0], x[1]]\n    }\n  });\n  y.push(I), y.push($);\n  var N = null != r,\n      C = null != a,\n      S = \"leakyrelu\" === o,\n      T = o ? rv(o, !0) : null,\n      E = new av($.shape, w.shape, [1, b, n.outChannels], !0, !1, N, T, C, S),\n      R = [$, w];\n\n  if (r && R.push(r), C && R.push(a), S) {\n    var _e470 = s.makeTensorInfo([], \"float32\", We(i, \"float32\"));\n\n    R.push(_e470), y.push(_e470);\n  }\n\n  var A = s.runWebGLProgram(E, R, \"float32\"),\n      F = cv({\n    inputs: {\n      x: A\n    },\n    backend: s,\n    attrs: {\n      shape: g ? [1, p, h, n.outChannels] : [1, n.outChannels, p, h]\n    }\n  });\n  y.push(A);\n\n  for (var _e471 of y) {\n    s.disposeIntermediateTensorInfo(_e471);\n  }\n\n  return F;\n}\n\nvar zI = {\n  kernelName: \"Conv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dilations: u,\n      dimRoundingMode: c\n    } = s,\n        h = Ts(l),\n        d = ys(r.shape, a.shape, i, u, o, c, !1, h);\n    var p;\n    if (1 !== d.filterHeight || 1 !== d.filterWidth || 1 !== d.dilationHeight || 1 !== d.dilationWidth || 1 !== d.strideHeight || 1 !== d.strideWidth || \"SAME\" !== d.padInfo.type && \"VALID\" !== d.padInfo.type) {\n      if (V().getBool(\"WEBGL_CONV_IM2COL\") && 1 === r.shape[0]) p = LI({\n        x: r,\n        filter: a,\n        convInfo: d,\n        backend: n\n      });else {\n        var _e472 = new DI(d);\n\n        p = n.runWebGLProgram(_e472, [r, a], \"float32\");\n      }\n    } else p = MI({\n      x: r,\n      filter: a,\n      convInfo: d,\n      backend: n\n    });\n    var f = cv({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        shape: d.outShape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), f;\n  }\n};\n\nclass BI {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int d2 = coords.w;\\n\\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \".concat(e.batchSize, \"; b++) {\\n          for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n            int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n              int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              if (\").concat(\"channelsLast\" === e.dataFormat, \") {\\n                float dyValue = getDy(b, yR, yC, d2);\\n                float xValue = getX(b, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              } else {\\n                float dyValue = getDy(b, d2, yR, yC);\\n                float xValue = getX(b, d1, xR, xC);\\n                dotProd += (xValue * dyValue);\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass PI {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterHeight,\n        n = e.filterWidth,\n        s = \"channelsLast\" === e.dataFormat;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[\").concat(s ? 3 : 1, \"];\\n\\n        ivec2 dyCorner = ivec2(coords[\").concat(s ? 1 : 2, \"], coords[\").concat(s ? 2 : 3, \"]) - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \").concat(t, \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \").concat(n, \" - 1 - wC;\\n\\n            for (int d2 = 0; d2 < \").concat(e.outChannels, \"; d2++) {\\n\\n              if (\").concat(s, \") {\\n                float xValue = getDy(batch, idyR, idyC, d2);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              } else {\\n                float xValue = getDy(batch, d2, idyR, idyC);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass WI {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int wF = coords.x;\\n        int wR = coords.y;\\n        int wC = coords.z;\\n        int d1 = coords.w;\\n        int d2 = coords.u;\\n\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \".concat(e.batchSize, \"; b++) {\\n          for (int yF = 0; yF < \").concat(e.outDepth, \"; yF++) {\\n            int xF = wF + yF * \").concat(e.strideDepth, \" - \").concat(e.padInfo.front, \";\\n\\n            if (xF < 0 || xF >= \").concat(e.inDepth, \") {\\n              continue;\\n            }\\n\\n            for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n              int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n              if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n                continue;\\n              }\\n\\n              for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n                int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n                if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                  continue;\\n                }\\n\\n                float dyValue = getDy(b, yF, yR, yC, d2);\\n                float xValue = getX(b, xF, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass UI {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterDepth,\n        n = e.filterHeight,\n        s = e.filterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.u;\\n\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyFCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \").concat(t, \"; wF++) {\\n          float dyF = float(dyFCorner + wF) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyF < 0.0 || dyF >= \").concat(e.outDepth, \".0 || fract(dyF) > 0.0) {\\n            continue;\\n          }\\n          int idyF = int(dyF);\\n\\n          int wFPerm = \").concat(t, \" - 1 - wF;\\n\\n          for (int wR = 0; wR < \").concat(n, \"; wR++) {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n              fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            int wRPerm = \").concat(n, \" - 1 - wR;\\n\\n            for (int wC = 0; wC < \").concat(s, \"; wC++) {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              int wCPerm = \").concat(s, \" - 1 - wC;\\n\\n              for (int d2 = 0; d2 < \").concat(e.outChannels, \"; d2++) {\\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar VI = {\n  kernelName: \"Conv2DBackpropFilter\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s,\n        h = Ts(l),\n        d = ys(r.shape, c, i, 1, o, u, !1, h),\n        p = new BI(d);\n    return n.runWebGLProgram(p, [r, a], \"float32\");\n  }\n},\n    GI = {\n  kernelName: \"Conv2DBackpropInput\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      inputShape: i,\n      strides: o,\n      pad: l,\n      dataFormat: u,\n      dimRoundingMode: c\n    } = s,\n        h = Ts(u),\n        d = ys(i, a.shape, o, 1, l, c, !1, h),\n        p = new PI(d);\n    return n.runWebGLProgram(p, [r, a], \"float32\");\n  }\n},\n    HI = {\n  kernelName: \"Conv3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s,\n        u = ks(r.shape, a.shape, i, l, o),\n        c = new _I(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    jI = {\n  kernelName: \"Conv3DBackpropFilterV2\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      filterShape: l\n    } = s,\n        u = ks(r.shape, l, i, 1, o),\n        c = new WI(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    qI = {\n  kernelName: \"Conv3DBackpropInputV2\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      pad: i,\n      strides: o,\n      inputShape: l\n    } = s,\n        u = ks(l, a.shape, o, 1, i),\n        c = new UI(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    KI = {\n  kernelName: \"Cos\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return cos(x);\\n\"\n  })\n},\n    XI = {\n  kernelName: \"Cosh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  float e2x = exp(-x);\\n  return (e2x + 1.0 / e2x) / 2.0;\\n\"\n  })\n};\n\nclass YI {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"Image\", \"Boxes\", \"BoxInd\"], this.outputShape = [];\n    var [a, i, o, l] = e,\n        [u] = t,\n        [c, h] = n;\n    this.outputShape = [u, c, h, l];\n    var d = \"bilinear\" === s ? 1 : 0,\n        [p, f] = [i - 1 + \".0\", o - 1 + \".0\"],\n        [g, m, b] = c > 1 ? [\"\" + (i - 1) / (c - 1), \"(y2-y1) * height_ratio\", \"y1*\".concat(p, \" + float(y)*(height_scale)\")] : [\"0.0\", \"0.0\", \"0.5 * (y1+y2) * \".concat(p)],\n        [x, y, k] = h > 1 ? [\"\" + (o - 1) / (h - 1), \"(x2-x1) * width_ratio\", \"x1*\".concat(f, \" + float(x)*(width_scale)\")] : [\"0.0\", \"0.0\", \"0.5 * (x1+x2) * \".concat(f)];\n    this.userCode = \"\\n      const float height_ratio = float(\".concat(g, \");\\n      const float width_ratio = float(\").concat(x, \");\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int y = coords[1];\\n        int x = coords[2];\\n        int d = coords[3];\\n\\n        // get box vals\\n        float y1 = getBoxes(b,0);\\n        float x1 = getBoxes(b,1);\\n        float y2 = getBoxes(b,2);\\n        float x2 = getBoxes(b,3);\\n\\n        // get image in batch index\\n        int bInd = round(getBoxInd(b));\\n        if(bInd < 0 || bInd >= \").concat(a, \") {\\n          return;\\n        }\\n\\n        float height_scale = \").concat(m, \";\\n        float width_scale = \").concat(y, \";\\n\\n        float in_y = \").concat(b, \";\\n        if( in_y < 0.0 || in_y > \").concat(p, \" ) {\\n          setOutput(float(\").concat(r, \"));\\n          return;\\n        }\\n        float in_x = \").concat(k, \";\\n        if( in_x < 0.0 || in_x > \").concat(f, \" ) {\\n          setOutput(float(\").concat(r, \"));\\n          return;\\n        }\\n\\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\\n        if(\").concat(d, \" == 1) {\\n          // Compute the four integer indices.\\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\\n\\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\\n\\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\\n\\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\\n          float newValue = top + (bottom - top) * fracCR.y;\\n          setOutput(newValue);\\n        } else {\\n          // Compute the coordinators of nearest neighbor point.\\n          ivec2 sourceNearestCR = ivec2(floor(\\n            sourceFracIndexCR + vec2(0.5,0.5)));\\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\\n          setOutput(newValue);\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar JI = {\n  kernelName: \"CropAndResize\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      boxes: a,\n      boxInd: i\n    } = t,\n        {\n      cropSize: o,\n      method: l,\n      extrapolationValue: u\n    } = s,\n        c = new YI(r.shape, a.shape, o, l, u);\n    return n.runWebGLProgram(c, [r, a, i], \"float32\");\n  }\n};\n\nclass ZI {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.customUniforms = [{\n      name: \"index\",\n      type: \"float\"\n    }], this.outputShape = e;\n    var s = e.length,\n        r = t ? \"0.0\" : \"getX(\".concat(QI(s, \"coords\"), \")\"),\n        a = e[e.length - 1];\n    var i = \"\",\n        o = \"\";\n    t ? (i = n ? \"end != \" + (a - 1) : \"end != 0\", o = n ? \"end + 1\" : \"end - 1\") : (i = n ? \"end + pow2 < \".concat(a) : \"end >= pow2\", o = n ? \"end + pow2\" : \"end - pow2\"), this.userCode = \"\\n      void main() {\\n        \".concat(Mk(s), \" coords = getOutputCoords();\\n        int end = \").concat(e$(s, \"coords\"), \";\\n        float val = \").concat(r, \";\\n        int pow2 = int(pow(2.0, index));\\n        if (\").concat(i, \") {\\n          int idx = \").concat(o, \";\\n          \").concat(e$(s, \"coords\"), \" = idx;\\n          val += getX(\").concat(QI(s, \"coords\"), \");\\n        }\\n        setOutput(val);\\n      }\\n    \");\n  }\n\n}\n\nfunction QI(e, t) {\n  if (1 === e) return \"\".concat(t);\n  if (2 === e) return \"\".concat(t, \".x, \").concat(t, \".y\");\n  if (3 === e) return \"\".concat(t, \".x, \").concat(t, \".y, \").concat(t, \".z\");\n  if (4 === e) return \"\".concat(t, \".x, \").concat(t, \".y, \").concat(t, \".z, \").concat(t, \".w\");\n  throw Error(\"Cumulative sum for rank \".concat(e, \" is not yet supported\"));\n}\n\nfunction e$(e, t) {\n  if (1 === e) return \"\".concat(t);\n  if (2 === e) return \"\".concat(t, \".y\");\n  if (3 === e) return \"\".concat(t, \".z\");\n  if (4 === e) return \"\".concat(t, \".w\");\n  throw Error(\"Cumulative sum for rank \".concat(e, \" is not yet supported\"));\n}\n\nvar t$ = {\n  kernelName: \"Cumsum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      exclusive: i,\n      reverse: o\n    } = s,\n        l = r.shape.length,\n        u = Jr([a], l);\n    var c = r;\n    null != u && (c = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }));\n    var h = Qr(1, l)[0];\n    if (h !== l - 1) throw new Error(\"WebGL cumsum shader expects an inner-most axis=\".concat(r.shape.length - 1, \" but got axis=\").concat(a));\n    var d = c.shape[h];\n    var p = jw({\n      inputs: {\n        x: c\n      },\n      backend: n\n    });\n\n    for (var _e473 = 0; _e473 <= Math.ceil(Math.log2(d)) - 1; _e473++) {\n      var _t394 = new ZI(c.shape, !1, o),\n          _s228 = p;\n\n      p = n.runWebGLProgram(_t394, [p], p.dtype, [[_e473]]), n.disposeIntermediateTensorInfo(_s228);\n    }\n\n    if (i) {\n      var _e474 = new ZI(c.shape, i, o),\n          _t395 = p;\n\n      p = n.runWebGLProgram(_e474, [p], p.dtype), n.disposeIntermediateTensorInfo(_t395);\n    }\n\n    if (null != u) {\n      var _e475 = kv({\n        inputs: {\n          x: p\n        },\n        backend: n,\n        attrs: {\n          perm: Zr(u)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(c), _e475;\n    }\n\n    return p;\n  }\n},\n    n$ = {\n  kernelName: \"DenseBincount\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i,\n      binaryOutput: o\n    } = s;\n\n    if (1 === r.shape.length) {\n      var _e476 = n.readSync(r.dataId),\n          _t396 = n.readSync(a.dataId),\n          _s229 = Vk(_e476, _t396, a.dtype, a.shape, i);\n\n      return n.makeTensorInfo([i], a.dtype, _s229);\n    }\n\n    if (2 === r.shape.length) {\n      var _e477 = n.bufferSync(r),\n          _t397 = n.bufferSync(a),\n          _s230 = Gk(_e477, _t397, i, o);\n\n      return n.makeTensorInfo(_s230.shape, a.dtype, _s230.values);\n    }\n\n    throw new Error(\"Error in denseBincount: input must be at most rank 2, but got rank\".concat(r.shape.length, \".\"));\n  }\n};\n\nclass s$ {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = [], this.outputShape = e, this.blockSize = t, this.dataFormat = n, this.userCode = \"\\n    void main() {\\n      ivec4 coords = getOutputCoords();\\n      int b = coords[0];\\n      int h = \".concat(this.getHeightCoordString(), \";\\n      int w = \").concat(this.getWidthCoordString(), \";\\n      int d = \").concat(this.getDepthCoordString(), \";\\n\\n      int in_h = h / \").concat(t, \";\\n      int offset_h = imod(h, \").concat(t, \");\\n      int in_w = w / \").concat(t, \";\\n      int offset_w = imod(w, \").concat(t, \");\\n      int offset_d = (offset_h * \").concat(t, \" + offset_w) *\\n        \").concat(this.getOutputDepthSize(), \";\\n      int in_d = d + offset_d;\\n\\n      float result = \").concat(this.getInputSamplingString(), \";\\n      setOutput(result);\\n    }\\n  \");\n  }\n\n  getHeightCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[1]\" : \"coords[2]\";\n  }\n\n  getWidthCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[2]\" : \"coords[3]\";\n  }\n\n  getDepthCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[3]\" : \"coords[1]\";\n  }\n\n  getOutputDepthSize() {\n    return \"NHWC\" === this.dataFormat ? this.outputShape[3] : this.outputShape[1];\n  }\n\n  getInputSamplingString() {\n    return \"NHWC\" === this.dataFormat ? \"getX(b, in_h, in_w, in_d)\" : \"getX(b, in_d, in_h, in_w)\";\n  }\n\n}\n\nvar r$ = {\n  kernelName: \"DepthToSpace\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockSize: a,\n      dataFormat: i\n    } = s;\n    l(a > 1, () => \"blockSize should be > 1 for depthToSpace, but was: \".concat(a));\n    var o = r.shape[0],\n        u = (\"NHWC\" === i ? r.shape[1] : r.shape[2]) * a,\n        c = (\"NHWC\" === i ? r.shape[2] : r.shape[3]) * a,\n        h = (\"NHWC\" === i ? r.shape[3] : r.shape[1]) / (a * a),\n        d = new s$(\"NHWC\" === i ? [o, u, c, h] : [o, h, u, c], a, i);\n    return n.runWebGLProgram(d, [r], r.dtype);\n  }\n};\n\nclass a$ {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var a = e.inHeight,\n        i = e.inWidth,\n        o = e.padInfo.top,\n        l = e.padInfo.left,\n        u = e.strideHeight,\n        c = e.strideWidth,\n        h = e.dilationHeight,\n        d = e.dilationWidth,\n        p = e.filterHeight,\n        f = e.filterWidth,\n        g = e.outChannels / e.inChannels;\n    var m = \"\",\n        b = \"\";\n    n && (m = s ? \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"float activation(float a) {\\n          float b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"\\n          float activation(float x) {\\n            \".concat(n, \"\\n          }\\n        \"), b = \"result = activation(result);\");\n    var x = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(m, \"\\n\\n      const ivec2 strides = ivec2(\").concat(u, \", \").concat(c, \");\\n      const ivec2 pads = ivec2(\").concat(o, \", \").concat(l, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(g, \";\\n        int q = d2 - d1 * \").concat(g, \";\\n\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\\n        for (int wR = 0; wR < \").concat(p, \"; wR++) {\\n          int xR = xRCorner + wR * \").concat(h, \";\\n\\n          if (xR < 0 || xR >= \").concat(a, \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(f, \"; wC++) {\\n            int xC = xCCorner + wC * \").concat(d, \";\\n\\n            if (xC < 0 || xC >= \").concat(i, \") {\\n              continue;\\n            }\\n\\n            float xVal = getX(batch, xR, xC, d1);\\n            float wVal = getW(wR, wC, d1, q);\\n            dotProd += xVal * wVal;\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \").concat(x, \"\\n        \").concat(b, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass i$ {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e.outShape;\n    var a = e.outChannels / e.inChannels,\n        o = e.inHeight,\n        l = e.inWidth,\n        u = e.padInfo.top,\n        c = e.padInfo.left,\n        h = e.strideHeight,\n        d = e.strideWidth,\n        p = e.dilationHeight,\n        f = e.dilationWidth,\n        g = e.filterHeight,\n        m = e.filterWidth,\n        b = m;\n    var x = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n    for (var _e478 = 0; _e478 < m; _e478++) {\n      x += \"\\n          vec4 xTexelC\".concat(2 * _e478, \";\\n          int xTexelC\").concat(2 * _e478, \"Ready;\\n          vec4 xTexelC\").concat(2 * _e478 + 1, \";\\n          int xTexelC\").concat(2 * _e478 + 1, \"Ready;\\n          vec4 xC\").concat(_e478, \";\");\n    }\n\n    for (var _e479 = 0; _e479 < g; _e479++) {\n      for (var _e480 = 0; _e480 < m; _e480++) {\n        x += \"\\n          xTexelC\".concat(2 * _e480, \" = vec4(0.0);\\n          xTexelC\").concat(2 * _e480, \"Ready = 0;\\n          xTexelC\").concat(2 * _e480 + 1, \" = vec4(0.0);\\n          xTexelC\").concat(2 * _e480 + 1, \"Ready = 0;\\n          xC\").concat(_e480, \" = vec4(0.0);\");\n      }\n\n      x += \"\\n        xR = xRCorner + \".concat(_e479 * p, \";\\n        if (xR >=0 && xR < \").concat(o, \") {\\n      \");\n\n      for (var _t398 = 0; _t398 < (b + 1) / 2; _t398++) {\n        var _n290 = 2 * _t398,\n            _s231 = _n290 * f;\n\n        if (x += \"\\n          xC = xCCorner + \".concat(_s231, \";\\n          \"), 1 === d) {\n          if (_n290 < m && (c % 2 == 1 ? (x += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < \".concat(l, \" && xTexelC\").concat(_n290, \"Ready == 0) {\\n                  xTexelC\").concat(_n290, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n290, \"Ready = 1;\\n                }\\n              \"), x += 1 === f && _s231 > 0 ? \"\\n                xC\".concat(_n290, \" = vec4(xTexelC\").concat(_n290 - 2, \".zw, xTexelC\").concat(_n290, \".xy);\\n                \") : \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < \".concat(l, \") {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(l, \") {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\").concat(_n290, \" = vec4(previous.zw, xTexelC\").concat(_n290, \".xy);\\n                  } else {\\n                    xC\").concat(_n290, \" = vec4(0.0, 0.0, xTexelC\").concat(_n290, \".xy);\\n                  }\\n                  \")) : x += \"\\n                if (xC >= 0 && xC < \".concat(l, \" && xTexelC\").concat(_n290, \"Ready == 0) {\\n                  xTexelC\").concat(_n290, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n290, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n290, \" = xTexelC\").concat(_n290, \";\\n                \"), _s231 + 1 < m)) {\n            var _e481 = c % 2 == 0 ? i(f) : f;\n\n            f % 2 == 0 && c % 2 == 1 || f % 2 != 0 && c % 2 != 1 ? (x += \"\\n                  xCOffset = xC + \".concat(c % 2, \" + \").concat(_e481, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < \").concat(l, \" && xTexelC\").concat(_n290 + 1, \"Ready == 0) {\\n                    xTexelC\").concat(_n290 + 1, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(l, \") {\\n                      xTexelC\").concat(_n290 + 1, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(_n290 + 1, \"Ready = 1;\\n                  }\\n                  \"), f > 1 && (x += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < \".concat(l, \" && xTexelC\").concat(_n290, \"Ready == 0) {\\n                      xTexelC\").concat(_n290, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(_n290, \"Ready = 1;\\n                    }\\n                    \")), x += \"\\n                  xC\".concat(_n290 + 1, \" = vec4(xTexelC\").concat(_n290, \".zw, xTexelC\").concat(_n290 + 1, \".xy);\\n                  \")) : x += 1 === _e481 ? \"\\n                    xC\".concat(_n290 + 1, \" = xTexelC\").concat(_n290, \";\\n                    \") : \"\\n                    xCOffset = xC + \".concat(_e481, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < \").concat(l, \" && xTexelC\").concat(_n290 + 1, \"Ready == 0) {\\n                      xTexelC\").concat(_n290 + 1, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= \").concat(l, \") {\\n                        xTexelC\").concat(_n290 + 1, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(_n290 + 1, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(_n290 + 1, \" = xTexelC\").concat(_n290 + 1, \";\\n                    \");\n          }\n        } else _s231 < m && (c % 2 == 1 ? (x += \"\\n                xCOffset = xC + 1 - \".concat(d, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(l, \" && xTexelC\").concat(_n290, \"Ready == 0) {\\n                  xTexelC\").concat(_n290, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n290, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \").concat(l, \" && xTexelC\").concat(_n290 + 1, \"Ready == 0) {\\n                  xTexelC\").concat(_n290 + 1, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290 + 1, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n290 + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n290, \" = vec4(xTexelC\").concat(_n290, \".zw, xTexelC\").concat(_n290 + 1, \".zw);\\n              \"), _s231 + 1 < m && (x += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + \".concat(d, \";\\n                  if(xCOffset >= 0 && xCOffset < \").concat(l, \") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\").concat(_n290 + 1, \" = vec4(xTexelC\").concat(_n290 + 1, \".xy, final.xy);\\n                \"))) : (x += \"\\n                if(xC >= 0 && xC < \".concat(l, \" && xTexelC\").concat(_n290, \"Ready == 0) {\\n                  xTexelC\").concat(_n290, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n290, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + \").concat(d, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(l, \" && xTexelC\").concat(_n290 + 1, \"Ready == 0) {\\n                  xTexelC\").concat(_n290 + 1, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= \").concat(l, \") {\\n                    xTexelC\").concat(_n290 + 1, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(_n290 + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n290, \" = vec4(\\n                  xTexelC\").concat(_n290, \".xy, xTexelC\").concat(_n290 + 1, \".xy);\\n              \"), _s231 + 1 < m && (x += \"\\n                  xC\".concat(_n290 + 1, \" = vec4(xTexelC\").concat(_n290, \".zw, xTexelC\").concat(_n290 + 1, \".zw);\\n                \"))));\n\n        _n290 < m && (x += \"\\n            wTexel = getW(\".concat(_e479, \", \").concat(_s231, \", d1, q);\\n            dotProd += xC\").concat(_n290, \" * vec4(wTexel.xz, wTexel.xz);\\n          \"), _s231 + 1 < m && (x += \"\\n              wTexel = getW(\".concat(_e479, \", \").concat(_s231 + 1, \", d1, q);\\n              dotProd += xC\").concat(_n290 + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \")));\n      }\n\n      x += \"\\n        }\\n      \";\n    }\n\n    var y = \"\",\n        k = \"\";\n    n && (y = s ? \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"vec4 activation(vec4 x) {\\n          \".concat(n, \"\\n        }\"), k = \"result = activation(result);\");\n    var w = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(y, \"\\n\\n      const ivec2 strides = ivec2(\").concat(h, \", \").concat(d, \");\\n      const ivec2 pads = ivec2(\").concat(u, \", \").concat(c, \");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(a, \";\\n        int q = d2 - d1 * \").concat(a, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(x, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(w, \"\\n        \").concat(k, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar o$ = {\n  kernelName: \"DepthwiseConv2dNative\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: u,\n      dimRoundingMode: c\n    } = s;\n    var h = u;\n    null == h && (h = [1, 1]), l(Ss(i, h), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '\").concat(h, \"'\"));\n    var d = ys(r.shape, a.shape, i, h, o, c, !0);\n    var p;\n    return p = V().getBool(\"WEBGL_PACK_DEPTHWISECONV\") && d.strideWidth <= 2 && d.outChannels / d.inChannels == 1 ? new i$(d) : new a$(d), n.runWebGLProgram(p, [r, a], \"float32\");\n  }\n};\n\nclass l$ {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int dm = coords.w;\\n        int d2 = d1 * \".concat(e.outChannels / e.inChannels, \" + dm;\\n\\n        float dotProd = 0.0;\\n\\n        // TO DO: Vec4 over the batch size\\n        for (int b = 0; b < \").concat(e.batchSize, \"; b++) {\\n          for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n            int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n              int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass u$ {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterHeight,\n        n = e.filterWidth,\n        s = e.outChannels / e.inChannels;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        float dotProd = 0.0;\\n\\n        for (int wR = 0; wR < \").concat(t, \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \").concat(t, \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \").concat(n, \" - 1 - wC;\\n\\n            // TO DO: Vec4 over the channelMul\\n            for (int dm = 0; dm < \").concat(s, \"; dm++) {\\n              int d2 = d1 * \").concat(s, \" + dm;\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar c$ = {\n  kernelName: \"DepthwiseConv2dNativeBackpropFilter\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s,\n        h = ys(r.shape, c, i, o, l, u, !0),\n        d = new l$(h);\n    return n.runWebGLProgram(d, [r, a], \"float32\");\n  }\n},\n    h$ = {\n  kernelName: \"DepthwiseConv2dNativeBackpropInput\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      inputShape: c\n    } = s,\n        h = ys(c, a.shape, i, o, l, u, !0),\n        d = new u$(h);\n    return n.runWebGLProgram(d, [r, a], \"float32\");\n  }\n};\n\nclass d$ {\n  constructor(e) {\n    this.variableNames = [\"X\"], this.outputShape = [e, e], this.userCode = \"\\n      void main() {\\n          ivec2 coords = getOutputCoords();\\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\\n          setOutput(val);\\n      }\\n    \";\n  }\n\n}\n\nvar p$ = {\n  kernelName: \"Diag\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = [...s.shape, ...s.shape],\n        a = d(s.shape),\n        i = cv({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [a]\n      }\n    }),\n        o = new d$(a),\n        l = n.runWebGLProgram(o, [i], i.dtype),\n        u = cv({\n      inputs: {\n        x: l\n      },\n      backend: n,\n      attrs: {\n        shape: r\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(l), u;\n  }\n};\n\nclass f$ {\n  constructor(e) {\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var {\n      inHeight: t,\n      inWidth: n,\n      padInfo: s,\n      strideHeight: r,\n      strideWidth: a,\n      filterHeight: i,\n      filterWidth: o,\n      dilationHeight: l,\n      dilationWidth: u\n    } = e,\n        {\n      top: c,\n      left: h\n    } = s;\n    this.userCode = \"\\n      const ivec2 strides = ivec2(\".concat(r, \", \").concat(a, \");\\n      const ivec2 pads = ivec2(\").concat(c, \", \").concat(h, \");\\n      const float neg_infinity = -3.4e38;\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.w;\\n        ivec2 outTopLeftCorner =\\n            coords.yz * strides - pads;\\n        int hBeg = outTopLeftCorner.x;\\n        int wBeg = outTopLeftCorner.y;\\n\\n        float curVal = neg_infinity;\\n        for (int h = 0; h < \").concat(i, \"; h++) {\\n          int hIn = hBeg + h * \").concat(l, \";\\n\\n          if (hIn >= 0 && hIn < \").concat(t, \") {\\n            for (int w = 0; w < \").concat(o, \"; w++) {\\n              int wIn = wBeg + w * \").concat(u, \";\\n\\n              if (wIn >= 0 && wIn < \").concat(n, \") {\\n                float xVal = getX(batch, hIn, wIn, d1);\\n                float wVal = getW(h, w, d1);\\n\\n                float val = xVal + wVal;\\n                if (val > curVal) {\\n                  curVal = val;\\n                }\\n              }\\n            }\\n          }\\n        }\\n\\n        float result = curVal;\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar g$ = {\n  kernelName: \"Dilation2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s,\n        u = ms(r.shape, a.shape, i, o, \"NHWC\", l);\n    var c;\n    var h = new f$(u);\n    c = n.runWebGLProgram(h, [r, a], \"float32\");\n    var d = cv({\n      inputs: {\n        x: c\n      },\n      backend: n,\n      attrs: {\n        shape: u.outShape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(c), d;\n  }\n},\n    m$ = {\n  kernelName: \"Einsum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      equation: r\n    } = s,\n        a = t,\n        {\n      allDims: i,\n      summedDims: o,\n      idDims: l\n    } = Ho(r, a.length);\n    qo(i.length, l, a);\n    var {\n      path: u,\n      steps: c\n    } = Ko(o, l),\n        h = c.length;\n    var d = null,\n        f = i.length;\n    var g = [];\n\n    for (var _e482 = 0; _e482 < h; ++_e482) {\n      for (var _t399 of c[_e482]) {\n        var {\n          permutationIndices: _e483,\n          expandDims: _s232\n        } = jo(f, l[_t399]);\n\n        var _r168 = void 0;\n\n        Xo(_e483) ? _r168 = a[_t399] : (_r168 = kv({\n          inputs: {\n            x: a[_t399]\n          },\n          backend: n,\n          attrs: {\n            perm: _e483\n          }\n        }), g.push(_r168));\n\n        var _i98 = _r168.shape.slice();\n\n        for (var _e484 = 0; _e484 < _s232.length; ++_e484) {\n          _i98.splice(_s232[_e484], 0, 1);\n        }\n\n        p(_r168.shape, _i98) || (_r168 = cv({\n          inputs: {\n            x: _r168\n          },\n          backend: n,\n          attrs: {\n            shape: _i98\n          }\n        }), g.push(_r168)), null === d ? d = _r168 : (d = lv({\n          inputs: {\n            a: _r168,\n            b: d\n          },\n          backend: n\n        }), g.push(d));\n      }\n\n      _e482 < h - 1 && (u[_e482] >= 0 && (d = xv({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          axis: u[_e482] - (i.length - f),\n          keepDims: !1\n        }\n      }), g.push(d)), f--);\n    }\n\n    for (var _e485 of g) {\n      _e485 !== d && n.disposeIntermediateTensorInfo(_e485);\n    }\n\n    return d;\n  }\n},\n    b$ = {\n  kernelName: \"Elu\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return (x >= 0.0) ? x : (exp(x) - 1.0);\",\n    packedOpSnippet: \"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\"\n  })\n},\n    x$ = {\n  kernelName: \"EluGrad\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      dy: s,\n      y: r\n    } = t,\n        a = V().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Hw(\"\\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\\n\", s.shape, r.shape) : new Gw(\"return (b >= 1.0) ? a : a * (b + 1.0);\", s.shape, r.shape);\n    return n.runWebGLProgram(a, [s, r], s.dtype);\n  }\n},\n    y$ = {\n  kernelName: \"Equal\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a == b);\",\n    packedOpSnippet: \"\\n  return vec4(equal(a, b));\\n\",\n    dtype: \"bool\",\n    cpuKernelImpl: qk\n  })\n},\n    k$ = {\n  kernelName: \"Erf\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: '\\n  // Error function is calculated approximately with elementary function.\\n  // See \"Handbook of Mathematical Functions with Formulas,\\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\\n  float p = 0.3275911;\\n  float a1 = 0.254829592;\\n  float a2 = -0.284496736;\\n  float a3 = 1.421413741;\\n  float a4 = -1.453152027;\\n  float a5 = 1.061405429;\\n\\n  float sign = sign(x);\\n  x = abs(x);\\n  float t = 1.0 / (1.0 + p * x);\\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\\n'\n  })\n},\n    w$ = \"return exp(x);\",\n    v$ = nv({\n  opSnippet: w$,\n  packedOpSnippet: w$,\n  cpuKernelImpl: Kk\n}),\n    I$ = {\n  kernelName: \"Exp\",\n  backendName: \"webgl\",\n  kernelFunc: v$\n};\n\nfunction $$(e) {\n  var {\n    inputs: t,\n    attrs: n,\n    backend: s\n  } = e,\n      {\n    dim: r\n  } = n,\n      {\n    input: a\n  } = t,\n      i = a.shape.length,\n      o = a.shape.slice();\n  var u = r;\n  return r < 0 && (l(-(i + 1) <= r, () => \"Axis must be in the interval [\".concat(-(i + 1), \", \").concat(i, \"]\")), u = i + r + 1), o.splice(u, 0, 1), cv({\n    inputs: {\n      x: a\n    },\n    backend: s,\n    attrs: {\n      shape: o\n    }\n  });\n}\n\nvar N$ = {\n  kernelName: \"ExpandDims\",\n  backendName: \"webgl\",\n  kernelFunc: $$\n},\n    C$ = \"return exp(x) - 1.0;\",\n    S$ = {\n  kernelName: \"Expm1\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: C$,\n    packedOpSnippet: C$,\n    cpuKernelImpl: Xk\n  })\n};\n\nclass T$ {\n  constructor(e, t, n) {\n    this.variableNames = [\"real\", \"imag\"];\n    var s = t[1];\n    this.outputShape = t;\n    var r = n ? \"2.0 * \".concat(Math.PI) : \"-2.0 * \".concat(Math.PI),\n        a = n ? \"\".concat(s, \".0\") : \"1.0\";\n    var i;\n    if (\"real\" === e) i = \"return real * expR - imag * expI;\";else {\n      if (\"imag\" !== e) throw new Error(\"FFT component must be either \\\"real\\\" or \\\"imag\\\", got \".concat(e, \".\"));\n      i = \"return real * expI + imag * expR;\";\n    }\n    this.userCode = \"\\n      const float exponentMultiplier = \".concat(r, \";\\n\\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\\n        \").concat(i, \"\\n      }\\n\\n      float mulMatDFT(int batch, int index) {\\n        float indexRatio = float(index) / float(\").concat(s, \");\\n        float exponentMultiplierTimesIndexRatio =\\n            exponentMultiplier * indexRatio;\\n\\n        float result = 0.0;\\n\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          // x = (-2|2 * PI / N) * index * i;\\n          float x = exponentMultiplierTimesIndexRatio * float(i);\\n          float expR = cos(x);\\n          float expI = sin(x);\\n          float real = getReal(batch, i);\\n          float imag = getImag(batch, i);\\n\\n          result +=\\n              unaryOpComplex(real, expR, imag, expI) / \").concat(a, \";\\n        }\\n\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        setOutput(mulMatDFT(coords[0], coords[1]));\\n      }\\n    \");\n  }\n\n}\n\nfunction E$(e, t, n) {\n  var s = n.texData.get(e.dataId),\n      r = d(e.shape),\n      a = e.shape[e.shape.length - 1],\n      i = cv({\n    inputs: {\n      x: e\n    },\n    backend: n,\n    attrs: {\n      shape: [r / a, a]\n    }\n  }),\n      o = i.shape,\n      l = new T$(\"real\", o, t),\n      u = new T$(\"imag\", o, t),\n      c = [{\n    dataId: s.complexTensorInfos.real.dataId,\n    dtype: s.complexTensorInfos.real.dtype,\n    shape: o\n  }, {\n    dataId: s.complexTensorInfos.imag.dataId,\n    dtype: s.complexTensorInfos.imag.dtype,\n    shape: o\n  }],\n      h = n.runWebGLProgram(l, c, \"float32\"),\n      p = n.runWebGLProgram(u, c, \"float32\"),\n      f = Kw({\n    inputs: {\n      real: h,\n      imag: p\n    },\n    backend: n\n  });\n  n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(p);\n  var g = cv({\n    inputs: {\n      x: f\n    },\n    backend: n,\n    attrs: {\n      shape: e.shape\n    }\n  });\n  return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(f), g;\n}\n\nvar R$ = {\n  kernelName: \"FFT\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t;\n    return E$(s, !1, n);\n  }\n};\n\nclass A$ {\n  constructor(e, t) {\n    this.outputShape = [], this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.variableNames = [\"x\"], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        // Input can be obtained from uniform value.\\n        setOutput(value);\\n      }\\n    \";\n  }\n\n}\n\nfunction F$(e) {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    shape: s,\n    value: r\n  } = n;\n  var {\n    dtype: a\n  } = n;\n\n  if (a = a || T(r), \"string\" === a) {\n    var _e486 = v(a, d(s));\n\n    return _e486.fill(r), t.makeTensorInfo(s, a, _e486);\n  }\n\n  {\n    var _e487 = new A$(s, r);\n\n    return t.runWebGLProgram(_e487, [], a, [[r]]);\n  }\n}\n\nvar D$ = {\n  kernelName: \"Fill\",\n  backendName: \"webgl\",\n  kernelFunc: F$\n};\n\nclass _$ {\n  constructor(e) {\n    this.variableNames = [\"Image\"], this.outputShape = [];\n    var t = e[2];\n    this.outputShape = e, this.userCode = \"\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int x = coords[2];\\n\\n          int coordX = \".concat(t, \" - x - 1;\\n          float outputValue;\\n          if(coordX >= 0 && coordX < \").concat(t, \") {\\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\\n          } else {\\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\\n          }\\n          setOutput(outputValue);\\n        }\\n    \");\n  }\n\n}\n\nvar O$ = {\n  kernelName: \"FlipLeftRight\",\n  backendName: \"webgl\",\n  kernelFunc: _ref28 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref28;\n    var {\n      image: n\n    } = e,\n        s = t,\n        r = new _$(n.shape);\n    return s.runWebGLProgram(r, [n], n.dtype);\n  }\n},\n    M$ = \"return floor(x);\",\n    L$ = {\n  kernelName: \"Floor\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: M$,\n    packedOpSnippet: M$,\n    cpuKernelImpl: Yk\n  })\n},\n    z$ = {\n  kernelName: \"FloorDiv\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\",\n    packedOpSnippet: \"\\n  ivec4 ia = round(a);\\n  ivec4 ib = round(b);\\n  bvec4 cond = notEqual(ib, ivec4(0));\\n  ivec4 result = ivec4(0);\\n  vec4 s = sign(a) * sign(b);\\n\\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n  if (cond[0]) {\\n    result[0] = idiv(ia[0], ib[0], s[0]);\\n  }\\n  if (cond[1]) {\\n    result[1] = idiv(ia[1], ib[1], s[1]);\\n  }\\n  if (cond[2]) {\\n    result[2] = idiv(ia[2], ib[2], s[2]);\\n  }\\n  if (cond[3]) {\\n    result[3] = idiv(ia[3], ib[3], s[3]);\\n  }\\n  return vec4(result);\\n\",\n    dtype: \"int32\"\n  })\n};\n\nclass B$ {\n  constructor(e) {\n    this.variableNames = [\"A\"];\n    var t = lk(),\n        [n, s] = e;\n    this.outputShape = e, this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\".concat(s, \".0, \").concat(n, \".0);\\n\\n        vec4 values = \").concat(t.texture2D, \"(A, uv);\\n        float value;\\n        if (depth == 0) {\\n          value = values.r;\\n        } else if (depth == 1) {\\n          value = values.g;\\n        } else if (depth == 2) {\\n          value = values.b;\\n        } else if (depth == 3) {\\n          value = values.a;\\n        }\\n\\n        setOutput(floor(value * 255.0 + 0.5));\\n      }\\n    \");\n  }\n\n}\n\nclass P$ {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0;\n    var t = lk(),\n        [n, s] = e;\n    this.outputShape = e, this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n\\n        vec4 result = vec4(0.);\\n\\n        for(int row=0; row<=1; row++) {\\n          for(int col=0; col<=1; col++) {\\n            texC = coords[1] + row;\\n            depth = coords[2] + col;\\n\\n            vec2 uv = (vec2(texC, texR) + halfCR) /\\n                       vec2(\".concat(s, \".0, \").concat(n, \".0);\\n            vec4 values = \").concat(t.texture2D, \"(A, uv);\\n            float value;\\n            if (depth == 0) {\\n              value = values.r;\\n            } else if (depth == 1) {\\n              value = values.g;\\n            } else if (depth == 2) {\\n              value = values.b;\\n            } else if (depth == 3) {\\n              value = values.a;\\n            }\\n\\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\\n          }\\n        }\\n\\n        \").concat(t.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nvar W$ = {\n  kernelName: \"FromPixels\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e;\n    var {\n      pixels: r\n    } = t;\n    var {\n      numChannels: a\n    } = s,\n        i = \"undefined\" != typeof HTMLVideoElement && r instanceof HTMLVideoElement,\n        o = \"undefined\" != typeof HTMLImageElement && r instanceof HTMLImageElement,\n        [l, u] = i ? [r.videoWidth, r.videoHeight] : [r.width, r.height],\n        c = [u, l],\n        h = [u, l, a];\n    (o || i) && (null == U$ && (U$ = document.createElement(\"canvas\").getContext(\"2d\")), U$.canvas.width = l, U$.canvas.height = u, U$.drawImage(r, 0, 0, l, u), r = U$.canvas);\n    var d = n.makeTensorInfo(c, \"int32\");\n    n.texData.get(d.dataId).usage = _y.PIXELS, n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId), r);\n    var p = V().getBool(\"WEBGL_PACK\") ? new P$(h) : new B$(h),\n        f = n.runWebGLProgram(p, [d], \"int32\");\n    return n.disposeData(d.dataId), f;\n  }\n};\nvar U$;\nvar V$ = {\n  kernelName: \"FusedConv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s,\n        g = Ts(c),\n        m = ys(r.shape, a.shape, l, h, u, d, !1, g);\n    var b;\n    var x = [];\n    if (1 !== m.filterHeight || 1 !== m.filterWidth || 1 !== m.dilationHeight || 1 !== m.dilationWidth || 1 !== m.strideHeight || 1 !== m.strideWidth || \"SAME\" !== m.padInfo.type && \"VALID\" !== m.padInfo.type) {\n      if (V().getBool(\"WEBGL_CONV_IM2COL\") && 1 === r.shape[0]) b = LI({\n        x: r,\n        filter: a,\n        convInfo: m,\n        backend: n,\n        bias: i,\n        activation: p,\n        preluActivationWeights: o,\n        leakyreluAlpha: f\n      });else {\n        var _e488 = null != i,\n            _t400 = null != o,\n            _s233 = \"leakyrelu\" === p,\n            _l54 = p ? rv(p, !1) : null,\n            _u41 = new DI(m, _e488, _l54, _t400, _s233),\n            _c35 = [r, a];\n\n        if (i && _c35.push(i), o && _c35.push(o), _s233) {\n          var _e489 = n.makeTensorInfo([], \"float32\", We(f, \"float32\"));\n\n          _c35.push(_e489), x.push(_e489);\n        }\n\n        b = n.runWebGLProgram(_u41, _c35, \"float32\");\n      }\n    } else b = MI({\n      x: r,\n      filter: a,\n      convInfo: m,\n      backend: n,\n      bias: i,\n      activation: p,\n      preluActivationWeights: o,\n      leakyreluAlpha: f\n    });\n    var y = cv({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        shape: m.outShape\n      }\n    });\n    return x.push(b), x.forEach(e => n.disposeIntermediateTensorInfo(e)), y;\n  }\n},\n    G$ = {\n  kernelName: \"FusedDepthwiseConv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: u,\n      pad: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s,\n        g = [];\n    var m = h;\n    null == m && (m = [1, 1]), l(Ss(u, m), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(u, \" and dilations '\").concat(m, \"'\"));\n    var b = ys(r.shape, a.shape, u, m, c, d, !0),\n        x = V().getBool(\"WEBGL_PACK_DEPTHWISECONV\") && b.strideWidth <= 2 && b.outChannels / b.inChannels == 1,\n        y = p ? rv(p, x) : null,\n        k = [r, a],\n        w = null != i,\n        v = null != o,\n        I = \"leakyrelu\" === p;\n\n    if (w && k.push(i), v && k.push(o), I) {\n      var _e490 = n.makeTensorInfo([], \"float32\", We(f, \"float32\"));\n\n      k.push(_e490), g.push(_e490);\n    }\n\n    var $;\n    $ = x ? new i$(b, w, y, v, I) : new a$(b, w, y, v, I);\n    var N = n.runWebGLProgram($, k, \"float32\");\n    return g.forEach(e => n.disposeIntermediateTensorInfo(e)), N;\n  }\n};\n\nclass H$ {\n  constructor(e, t, n) {\n    this.sliceDim = e, this.strides = t, this.variableNames = [\"x\", \"indices\"], this.outputShape = n;\n    var s = Mk(t.length),\n        r = Mk(n.length);\n    this.userCode = \"\\n        \".concat(s, \" strides = \").concat(s, \"(\").concat(this.strides, \");\\n         void main() {\\n          \").concat(r, \" coords = getOutputCoords();\\n          int flattenIndex = 0;\\n          for (int j = 0; j < \").concat(this.sliceDim, \"; j++) {\\n            int index = round(getIndices(coords[0], j));\\n            flattenIndex += index * \").concat(this.sliceDim > 1 ? \"strides[j]\" : \"strides\", \";\\n          }\\n          setOutput(getX(flattenIndex, coords[1]));\\n        }\\n      \");\n  }\n\n}\n\nvar j$ = {\n  kernelName: \"GatherNd\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      params: s,\n      indices: r\n    } = t,\n        a = r.shape,\n        i = a[a.length - 1],\n        o = d(s.shape),\n        [l, u, c, h] = Nn(s, r),\n        p = cv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [u, i]\n      }\n    }),\n        f = cv({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [d(s.shape) / c, c]\n      }\n    });\n\n    if (n.shouldExecuteOnCPU([s, r]) || \"string\" === s.dtype) {\n      var _e491 = n.readSync(r.dataId),\n          _t401 = n.bufferSync(s),\n          _a137 = Jk(_e491, _t401, s.dtype, u, i, c, h, s.shape, o);\n\n      return n.makeTensorInfo(l, s.dtype, _a137.values);\n    }\n\n    var g = new H$(i, h, [u, c]),\n        m = n.runWebGLProgram(g, [f, p], f.dtype),\n        b = cv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: l\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(m), b;\n  }\n};\n\nclass q$ {\n  constructor(e, t) {\n    this.variableNames = [\"A\", \"indices\"], this.outputShape = t, this.rank = t.length;\n\n    var n = Mk(this.rank),\n        s = function (e, t) {\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\"],\n          s = [];\n\n      for (var _t402 = 0; _t402 < e.length; _t402++) {\n        s.push(2 === _t402 ? \"int(getIndices(resRC.x, resRC.z))\" : \"\".concat(n[_t402]));\n      }\n\n      return s.join();\n    }(e);\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(n, \" resRC = getOutputCoords();\\n        setOutput(getA(\").concat(s, \"));\\n      }\\n    \");\n  }\n\n}\n\nfunction K$(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    indices: a\n  } = t,\n      {\n    axis: i,\n    batchDims: o\n  } = s,\n      l = el(r, a, y(i, r.shape)[0], o),\n      u = d(a.shape),\n      c = [],\n      h = cv({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: [l.batchSize, l.outerSize, l.dimSize, l.sliceSize]\n    }\n  }),\n      p = cv({\n    inputs: {\n      x: a\n    },\n    backend: n,\n    attrs: {\n      shape: [l.batchSize, u / l.batchSize]\n    }\n  });\n  c.push(h), c.push(p);\n  var f = [l.batchSize, l.outerSize, u / l.batchSize, l.sliceSize];\n\n  if (n.shouldExecuteOnCPU([r, a]) || \"string\" === r.dtype) {\n    var _e492 = n.bufferSync(p),\n        _t403 = n.bufferSync(h),\n        _s234 = Zk(_t403, _e492, f);\n\n    return c.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(l.outputShape, _s234.dtype, _s234.values);\n  }\n\n  var g = new q$(h.shape, f),\n      m = n.runWebGLProgram(g, [h, p], h.dtype);\n  c.push(m);\n  var b = cv({\n    inputs: {\n      x: m\n    },\n    backend: n,\n    attrs: {\n      shape: l.outputShape\n    }\n  });\n  return c.forEach(e => n.disposeIntermediateTensorInfo(e)), b;\n}\n\nvar X$ = {\n  kernelName: \"GatherV2\",\n  backendName: \"webgl\",\n  kernelFunc: K$\n},\n    Y$ = {\n  kernelName: \"Greater\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a > b);\",\n    packedOpSnippet: \"\\n  return vec4(greaterThan(a, b));\\n\",\n    cpuKernelImpl: Qk,\n    dtype: \"bool\"\n  })\n},\n    J$ = {\n  kernelName: \"GreaterEqual\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a >= b);\",\n    packedOpSnippet: \"\\n  return vec4(greaterThanEqual(a, b));\\n\",\n    dtype: \"bool\",\n    cpuKernelImpl: ew\n  })\n},\n    Z$ = {\n  kernelName: \"IFFT\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t;\n    return E$(s, !0, n);\n  }\n},\n    Q$ = {\n  kernelName: \"IsFinite\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return float(!isnan(x) && !isinf(x));\",\n    dtype: \"bool\"\n  })\n},\n    eN = {\n  kernelName: \"IsInf\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return float(isinf(x));\",\n    dtype: \"bool\"\n  })\n},\n    tN = {\n  kernelName: \"IsNan\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return float(isnan(x));\",\n    dtype: \"bool\"\n  })\n},\n    nN = {\n  kernelName: \"Less\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a < b);\",\n    packedOpSnippet: \"\\n  return vec4(lessThan(a, b));\\n\",\n    cpuKernelImpl: tw,\n    dtype: \"bool\"\n  })\n},\n    sN = {\n  kernelName: \"LessEqual\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a <= b);\",\n    packedOpSnippet: \"\\n  return vec4(lessThanEqual(a, b));\\n\",\n    cpuKernelImpl: nw,\n    dtype: \"bool\"\n  })\n},\n    rN = {\n  kernelName: \"LinSpace\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      num: a\n    } = n,\n        i = sw(s, r, a);\n    return t.makeTensorInfo([i.length], \"float32\", i);\n  }\n},\n    aN = {\n  kernelName: \"Log\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (x < 0.0) return NAN;\\n  return log(x);\",\n    packedOpSnippet: \"\\n  vec4 result = log(x);\\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: rw\n  })\n},\n    iN = {\n  kernelName: \"Log1p\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return log(1.0 + x);\"\n  })\n},\n    oN = {\n  kernelName: \"LogicalAnd\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a >= 1.0 && b >= 1.0);\",\n    packedOpSnippet: \"\\n  return vec4(\\n    vec4(greaterThanEqual(a, vec4(1.0))) *\\n    vec4(greaterThanEqual(b, vec4(1.0))));\\n\",\n    dtype: \"bool\"\n  })\n},\n    lN = {\n  kernelName: \"LogicalNot\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return float(!(x >= 1.0));\"\n  })\n},\n    uN = {\n  kernelName: \"LogicalOr\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return float(a >= 1.0 || b >= 1.0);\",\n    packedOpSnippet: \"\\n  return min(\\n    vec4(greaterThanEqual(a, vec4(1.0))) +\\n    vec4(greaterThanEqual(b, vec4(1.0))),\\n    vec4(1.0));\\n\",\n    dtype: \"bool\"\n  })\n};\n\nclass cN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"x\"], this.outputShape = [];\n    var a = t,\n        i = e[3] - 1;\n    var o;\n    this.outputShape = e;\n    var l = \"float(\".concat(n, \") + float(\").concat(s, \") * sum\");\n    o = .5 === r ? \"inversesqrt(\".concat(l, \")\") : 1 === r ? \"1.0/(\".concat(l, \")\") : \"exp(log(\".concat(l, \") * float(-\").concat(r, \"));\"), this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n        int d = coords[3];\\n        float x = getX(b, r, c, d);\\n        float sum = 0.0;\\n        for (int j = -\".concat(a, \"; j <= \").concat(a, \"; j++) {\\n          int idx = d + j;\\n          if (idx >= 0 && idx <=  \").concat(i, \") {\\n            float z = getX(b, r, c, idx);\\n            sum += z * z;\\n          }\\n        }\\n        float val = x * \").concat(o, \";\\n        setOutput(val);\\n      }\\n    \");\n  }\n\n}\n\nclass hN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"x\"], this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0;\n    var a = t,\n        i = e[3] - 1;\n    var o;\n    this.outputShape = e;\n    var l = \"float(\".concat(n, \") + float(\").concat(s, \") * sum\");\n    o = .5 === r ? \"inversesqrt(\".concat(l, \")\") : 1 === r ? \"1.0/(\".concat(l, \")\") : \"exp(log(\".concat(l, \") * float(-\").concat(r, \"));\"), this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords.x;\\n        int r = coords.y;\\n        int c = coords.z;\\n        int d = coords.w;\\n\\n        bool hasNextCol = d < \".concat(this.outputShape[3], \";\\n        bool hasNextRow = c < \").concat(this.outputShape[2], \";\\n\\n        vec4 sum = vec4(0.);\\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\\n\\n        vec4 xAtOutputCoords = vec4(\\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\\n          hasNextCol ?\\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\\n          hasNextRow ?\\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\\n        );\\n\\n        int firstChannel = d - \").concat(a, \";\\n        vec2 cache = vec2(0.);\\n        if(firstChannel >= 0){\\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\\n            if(hasNextRow){\\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\\n            }\\n        }\\n\\n        ivec2 depth = ivec2(d, d + 1);\\n        for (int j = - \").concat(a, \"; j <= \").concat(a, \"; j++) {\\n          ivec2 idx = depth + j;\\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(\").concat(i, \"));\\n\\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\\n\\n          if(depthInRange || depthPlusOneInRange){\\n            vec4 z = vec4(0.);\\n            vec4 xFragAtCurrentDepth;\\n            z.xz = cache.xy;\\n            if(depthPlusOneInRange && hasNextCol){\\n              xFragAtCurrentDepth = idx.y != d ?\\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\\n              if(hasNextRow){\\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\\n              }\\n            }\\n            cache.xy = z.yw;\\n            sum += z * z;\\n          }\\n        }\\n        vec4 result = xAtOutputCoords * \").concat(o, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar dN = {\n  kernelName: \"LRN\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = s,\n        u = V().getBool(\"WEBGL_PACK_NORMALIZATION\") ? new hN(r.shape, a, i, o, l) : new cN(r.shape, a, i, o, l);\n    return n.runWebGLProgram(u, [r], r.dtype);\n  }\n};\n\nclass pN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"inputImage\", \"outputImage\", \"dy\"], this.outputShape = [], this.outputShape = e, this.depth = e[3], this.depthRadius = t, this.bias = n, this.alpha = s, this.beta = r, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float result = 0.0;\\n        for (int d = 0; d < \".concat(this.depth, \"; ++d) {\\n          int depthBegin = int(max(0.0, float(d - \").concat(t, \")));\\n          int depthEnd = int(min(float(\").concat(this.depth, \"),\\n              float(d + \").concat(t, \" + 1)));\\n\\n          const int MIN_DEPTH_BEGIN = 0;\\n          const int MAX_DEPTH_END = \").concat(this.depth, \";\\n\\n          float norm = 0.0;\\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd) {\\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n\\n          norm = float(\").concat(s, \") * norm + float(\").concat(n, \");\\n\\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd){\\n              float dyi = -2.0 * float(\").concat(s, \")\\n                * float(\").concat(r, \")\\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\\n                / norm;\\n              if (k == d) {\\n                dyi += pow(norm, -1.0 * \").concat(r, \");\\n              }\\n              if (k == coords[3]) {\\n                dyi *= getDy(b, r, c, d);\\n                result += dyi;\\n              }\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n      }\\n      setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar fN = {\n  kernelName: \"LRNGrad\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      y: a,\n      dy: i\n    } = t,\n        {\n      depthRadius: o,\n      bias: l,\n      alpha: u,\n      beta: c\n    } = s,\n        h = new pN(r.shape, o, l, u, c);\n    return n.runWebGLProgram(h, [r, a, i], r.dtype);\n  }\n};\n\nfunction gN(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reductionIndices: a,\n    keepDims: i\n  } = s,\n      o = r.shape.length,\n      l = y(a, r.shape);\n  var u = l;\n  var c = Jr(u, o),\n      h = null != c,\n      p = n.shouldExecuteOnCPU([r]);\n  var f = r;\n\n  if (h) {\n    if (p) {\n      var _e493 = n.texData.get(f.dataId).values,\n          _t404 = new Array(o);\n\n      for (var _e494 = 0; _e494 < _t404.length; _e494++) {\n        _t404[_e494] = r.shape[c[_e494]];\n      }\n\n      var _s235 = Cw(_e493, r.shape, r.dtype, c, _t404);\n\n      f = n.makeTensorInfo(_t404, r.dtype), n.texData.get(f.dataId).values = _s235;\n    } else f = bv(r, c, n);\n\n    u = Qr(u.length, o);\n  }\n\n  Yr(\"max\", u, o);\n  var [g, m] = Kr(f.shape, u);\n  var b,\n      x = g;\n\n  if (i && (x = Xr(g, l)), p) {\n    var _e495 = n.texData.get(f.dataId),\n        _t405 = aw(_e495.values, d(m), x, r.dtype);\n\n    b = n.makeTensorInfo(x, r.dtype), n.texData.get(b.dataId).values = _t405;\n  } else b = function (e, t, n, s) {\n    var r = d(t),\n        a = cv({\n      inputs: {\n        x: e\n      },\n      attrs: {\n        shape: [d(e.shape) / r, r]\n      },\n      backend: s\n    }),\n        i = fv(a, e.dtype, \"max\", s),\n        o = cv({\n      inputs: {\n        x: i\n      },\n      attrs: {\n        shape: n\n      },\n      backend: s\n    });\n    return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(i), o;\n  }(f, m, x, n);\n\n  return h && n.disposeIntermediateTensorInfo(f), b;\n}\n\nvar mN = {\n  kernelName: \"Max\",\n  backendName: \"webgl\",\n  kernelFunc: gN\n},\n    bN = {\n  kernelName: \"Maximum\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return max(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = vec4(max(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: iw\n  })\n},\n    xN = {\n  kernelName: \"MaxPool\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    ik(r, \"maxPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ss(i, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = bs(r.shape, a, i, 1, o, u);\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) return jw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var h = new qv(c, \"max\", !1);\n    return n.runWebGLProgram(h, [r], r.dtype);\n  }\n},\n    yN = {\n  kernelName: \"MaxPool3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u\n    } = s,\n        c = xs(r.shape, a, i, [1, 1, 1], o, u, l),\n        h = new Kv(c, \"max\", !1);\n    return n.runWebGLProgram(h, [r], r.dtype);\n  }\n};\n\nclass kN {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"maxPos\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterHeight,\n        n = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \";\\n          wR += \").concat(e.dilationHeight, \") {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n            int maxPosValue = \").concat(t * n - 1, \" - int(getMaxPos(b, idyR, idyC, d));\\n\\n            // Get the current value, check it against the value from the\\n            // position matrix.\\n            int curPosValue = wR * \").concat(n, \" + wC;\\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n            dotProd += dyValue * mask;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass wN {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"maxPos\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterDepth,\n        n = e.effectiveFilterHeight,\n        s = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(t, \";\\n           wD += \").concat(e.dilationDepth, \") {\\n          float dyD = float(dyDCorner + wD) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyD < 0.0 || dyD >= \").concat(e.outDepth, \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \").concat(n, \";\\n              wR += \").concat(e.dilationHeight, \") {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \").concat(s, \";\\n                wC += \").concat(e.dilationWidth, \") {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n              int maxPosValue = \").concat(t * n * s - 1, \" -\\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\\n\\n              // Get the current value, check it against the value from the\\n              // position matrix.\\n              int curPosValue =\\n                  wD * \").concat(n, \" * \").concat(s, \" +\\n                  wR * \").concat(s, \" + wC;\\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n              dotProd += dyValue * mask;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar vN = {\n  kernelName: \"MaxPool3DGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a,\n        {\n      filterSize: o,\n      strides: l,\n      pad: u,\n      dimRoundingMode: c\n    } = s,\n        h = xs(i.shape, o, l, [1, 1, 1], u, c),\n        d = new Kv(h, \"max\", !0),\n        p = n.runWebGLProgram(d, [i], i.dtype),\n        f = new wN(h),\n        g = n.runWebGLProgram(f, [r, p], i.dtype);\n    return n.disposeIntermediateTensorInfo(p), g;\n  }\n},\n    IN = {\n  kernelName: \"MaxPoolGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a,\n      output: i\n    } = t,\n        o = a;\n    ik([a, i], \"maxPoolGrad\");\n    var {\n      filterSize: l,\n      strides: u,\n      pad: c,\n      dimRoundingMode: h\n    } = s,\n        d = bs(o.shape, l, u, 1, c, h),\n        p = new qv(d, \"max\", !0),\n        f = n.runWebGLProgram(p, [o], o.dtype),\n        g = new kN(d),\n        m = n.runWebGLProgram(g, [r, f], o.dtype);\n    return n.disposeIntermediateTensorInfo(f), m;\n  }\n},\n    $N = {\n  kernelName: \"MaxPoolWithArgmax\",\n  backendName: \"webgl\",\n  kernelFunc: _ref29 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref29;\n    var {\n      x: s\n    } = e,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      includeBatchInIndex: o\n    } = t,\n        u = n;\n    l(4 === s.shape.length, () => \"Error in maxPool: input must be rank 4 but got rank \".concat(s.shape.length, \".\"));\n    var c = [1, 1];\n    l(Ss(a, c), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(a, \" and dilations '\").concat(c, \"'\"));\n\n    var h = bs(s.shape, r, a, c, i),\n        [d, p] = function (e, t, n, s) {\n      var r = new qv(n, \"max\", !1);\n      var a = s.runWebGLProgram(r, [e], \"float32\");\n      return r = new qv(n, \"max\", !0, !0, t), [a, s.runWebGLProgram(r, [e], \"float32\")];\n    }(s, o, h, u);\n\n    return [d, p];\n  }\n},\n    NN = {\n  kernelName: \"Mean\",\n  backendName: \"webgl\",\n  kernelFunc: _ref30 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref30;\n    var {\n      x: s\n    } = e,\n        {\n      keepDims: r,\n      axis: a\n    } = t,\n        i = n,\n        o = s.shape.length,\n        l = y(a, s.shape);\n    var u = l;\n    var c = Jr(u, o),\n        h = null != c,\n        p = i.shouldExecuteOnCPU([s]),\n        f = [];\n    var g = s;\n\n    if (h) {\n      if (p) {\n        var _e496 = i.texData.get(g.dataId).values,\n            _t406 = new Array(o);\n\n        for (var _e497 = 0; _e497 < _t406.length; _e497++) {\n          _t406[_e497] = s.shape[c[_e497]];\n        }\n\n        var _n291 = Cw(_e496, s.shape, s.dtype, c, _t406);\n\n        g = i.makeTensorInfo(_t406, s.dtype), i.texData.get(g.dataId).values = _n291;\n      } else g = bv(s, c, i);\n\n      f.push(g), u = Qr(u.length, o);\n    }\n\n    Yr(\"sum\", u, o);\n    var [m, b] = Kr(g.shape, u);\n    var x = m;\n    r && (x = Xr(m, l));\n\n    var k = function (e, t, n, s) {\n      var r = d(t),\n          a = cv({\n        inputs: {\n          x: e\n        },\n        attrs: {\n          shape: [d(e.shape) / r, r]\n        },\n        backend: s\n      }),\n          i = fv(a, \"float32\", \"mean\", s),\n          o = cv({\n        inputs: {\n          x: i\n        },\n        attrs: {\n          shape: n\n        },\n        backend: s\n      });\n      return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(i), o;\n    }(g, b, x, i);\n\n    for (var _e498 of f) {\n      i.disposeIntermediateTensorInfo(_e498);\n    }\n\n    return k;\n  }\n},\n    CN = {\n  kernelName: \"Min\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Jr(u, o);\n    var h = r;\n    null != c && (h = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = Qr(u.length, r.shape.length)), Yr(\"min\", u, o);\n    var [p, f] = Kr(h.shape, u),\n        g = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = fv(g, g.dtype, \"min\", n);\n    var b;\n    return b = cv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Xr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n},\n    SN = {\n  kernelName: \"Minimum\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return min(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = vec4(min(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: ow\n  })\n};\n\nclass TN {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Mk(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = [\"coords[0]\", \"coords[1]\", \"coords[2]\", \"coords[3]\"].slice(0, s),\n        l = \"reflect\" === n ? 0 : 1;\n    this.userCode = 1 !== s ? \"\\n      \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outC = getOutputCoords();\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          if (outC[i] < start[i]) {\\n            outC[i] = start[i] * 2 - outC[i] - \").concat(l, \";\\n          } else if(outC[i] >= end[i]) {\\n            outC[i] = (end[i] - 1) * 2 - outC[i] + \").concat(l, \";\\n          }\\n        }\\n        \").concat(r, \" coords = outC - start;\\n        setOutput(getX(\").concat(o, \"));\\n      }\\n    \") : \"\\n        int start = \".concat(a, \";\\n        int end = \").concat(i, \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start) {\\n            outC = start * 2 - outC - \").concat(l, \";\\n          } else if(outC >= end) {\\n            outC = (end - 1) * 2 - outC + \").concat(l, \";\\n          }\\n          setOutput(getX(outC - start));\\n        }\\n      \");\n  }\n\n}\n\nclass EN {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Mk(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = Ew(\"rc\", s),\n        l = Ew(\"source\", s),\n        u = \"\".concat(o[s - 1], \" < \").concat(this.outputShape[s - 1]),\n        c = 1 === s ? \"source\" : \"vec2(\".concat(l.slice(-2).join(), \")\"),\n        h = \"reflect\" === n ? 0 : 1;\n    var d = \"\";\n\n    if (1 === s) {\n      var _e499 = \"\\n        \".concat(r, \" source = rc;\\n        if (source < start) {\\n          source = start * 2 - source - \").concat(h, \";\\n        } else if (source >= end) {\\n          source = (end - 1) * 2 - source + \").concat(h, \";\\n        }\\n        source -= start;\\n      \");\n\n      d = \"\\n        \".concat(r, \" rc = outputLoc;\\n        \").concat(_e499, \"\\n        result[0] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        \").concat(o[s - 1], \" += 1;\\n        if(\").concat(u, \") {\\n          \").concat(_e499, \"\\n          result[1] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n      \");\n    } else {\n      var _e500 = \"\\n        \".concat(r, \" source = rc;\\n        \").concat(r, \" lt = \").concat(r, \"(lessThan(source, start));\\n        \").concat(r, \" gte = \").concat(r, \"(greaterThanEqual(source, end));\\n        \").concat(r, \" orig = 1 - (lt + gte);\\n        source = orig * source +\\n                lt * (start * 2 - source - \").concat(h, \") +\\n                gte * ((end - 1) * 2 - source + \").concat(h, \");\\n        source -= start;\\n      \");\n\n      d = \"\\n        \".concat(r, \" rc = outputLoc;\\n        \").concat(_e500, \"\\n        result[0] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        \").concat(o[s - 1], \" += 1;\\n        if(\").concat(u, \") {\\n          \").concat(_e500, \"\\n          result[1] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n        rc = outputLoc;\\n        \").concat(o[s - 2], \" += 1;\\n        if(\").concat(o[s - 2], \" < \").concat(this.outputShape[s - 2], \") {\\n          \").concat(_e500, \"\\n          result[2] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n          \").concat(o[s - 1], \" += 1;\\n          if(\").concat(u, \") {\\n            \").concat(_e500, \"\\n            result[3] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n          }\\n        }\\n      \");\n    }\n\n    this.userCode = \"\\n      const \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      const \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \").concat(d, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar RN = {\n  kernelName: \"MirrorPad\",\n  backendName: \"webgl\",\n  kernelFunc: _ref31 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref31;\n    var {\n      x: s\n    } = e,\n        {\n      paddings: r,\n      mode: a\n    } = n,\n        i = V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new EN(s.shape, r, a) : new TN(s.shape, r, a);\n    return t.runWebGLProgram(i, [s], s.dtype);\n  }\n},\n    AN = {\n  kernelName: \"Mod\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"if (b == 0.0) return NAN;\\n  return mod(a, b);\",\n    packedOpSnippet: \"\\n  vec4 result = mod(a, b);\\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n};\n\nclass FN {\n  constructor(e, t, n) {\n    this.variableNames = [\"probs\"], this.customUniforms = [{\n      name: \"seed\",\n      type: \"float\"\n    }], this.outputShape = [e, n], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n\\n        float r = random(seed);\\n        float cdf = 0.0;\\n\\n        for (int i = 0; i < \".concat(t - 1, \"; i++) {\\n          cdf += getProbs(batch, i);\\n\\n          if (r < cdf) {\\n            setOutput(float(i));\\n            return;\\n          }\\n        }\\n\\n        // If no other event happened, last event happened.\\n        setOutput(float(\").concat(t - 1, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar DN = sv({\n  opSnippet: \"\\nif (a == b) {\\n  return 1.0;\\n};\\nreturn a / b;\",\n  packedOpSnippet: \"\\n  // vec4 one = vec4(equal(a, b));\\n  // return one + (vec4(1.0) - one) * a / b;\\n  vec4 result = a / b;\\n  if(a.x == b.x) {\\n    result.x = 1.;\\n  }\\n  if(a.y == b.y) {\\n    result.y = 1.;\\n  }\\n  if(a.z == b.z) {\\n    result.z = 1.;\\n  }\\n  if(a.w == b.w) {\\n    result.w = 1.;\\n  }\\n\\n  return result;\\n\",\n  checkOutOfBounds: !0\n}),\n    _N = {\n  kernelName: \"RealDiv\",\n  backendName: \"webgl\",\n  kernelFunc: DN\n},\n    ON = \"return a - b;\",\n    MN = sv({\n  opSnippet: ON,\n  packedOpSnippet: ON,\n  supportsComplex: !0,\n  cpuKernelImpl: Iw\n}),\n    LN = {\n  kernelName: \"Sub\",\n  backendName: \"webgl\",\n  kernelFunc: MN\n};\n\nfunction zN(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    logits: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = y([a], r.shape),\n      o = gN({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      reductionIndices: i,\n      keepDims: !1\n    }\n  }),\n      l = Xr(o.shape, i),\n      u = cv({\n    inputs: {\n      x: o\n    },\n    backend: n,\n    attrs: {\n      shape: l\n    }\n  }),\n      c = MN({\n    inputs: {\n      a: r,\n      b: u\n    },\n    backend: n\n  }),\n      h = v$({\n    inputs: {\n      x: c\n    },\n    backend: n\n  }),\n      d = xv({\n    inputs: {\n      x: h\n    },\n    backend: n,\n    attrs: {\n      axis: i,\n      keepDims: !1\n    }\n  }),\n      p = cv({\n    inputs: {\n      x: d\n    },\n    backend: n,\n    attrs: {\n      shape: l\n    }\n  }),\n      f = DN({\n    inputs: {\n      a: h,\n      b: p\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(c), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(p), f;\n}\n\nvar BN = {\n  kernelName: \"Softmax\",\n  backendName: \"webgl\",\n  kernelFunc: zN\n},\n    PN = {\n  kernelName: \"Multinomial\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      logits: r\n    } = t,\n        {\n      numSamples: a,\n      seed: i,\n      normalized: o\n    } = s,\n        l = o ? r : zN({\n      inputs: {\n        logits: r\n      },\n      backend: n,\n      attrs: {\n        dim: r.shape.length - 1\n      }\n    }),\n        u = new FN(l.shape[0], l.shape[1], a),\n        c = n.runWebGLProgram(u, [l], \"int32\", [[i]]);\n    return o || n.disposeIntermediateTensorInfo(l), c;\n  }\n},\n    WN = \"return -x;\",\n    UN = {\n  kernelName: \"Neg\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n\n    if (n.shouldExecuteOnCPU([s])) {\n      var _e501 = n.texData.get(s.dataId),\n          [_t407, _r169] = uw(_e501.values, s.shape, s.dtype);\n\n      return n.makeTensorInfo(_r169, s.dtype, _t407);\n    }\n\n    var r;\n    return r = V().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") ? new zw(s.shape, WN) : new Mw(s.shape, WN), n.runWebGLProgram(r, [s], s.dtype);\n  }\n},\n    VN = ji,\n    GN = {\n  kernelName: \"NonMaxSuppressionV3\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    Oo(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l\n    } = s,\n        u = n.readSync(r.dataId),\n        c = n.readSync(a.dataId),\n        {\n      selectedIndices: h\n    } = VN(u, c, i, o, l);\n    return n.makeTensorInfo([h.length], \"int32\", new Int32Array(h));\n  }\n},\n    HN = qi,\n    jN = {\n  kernelName: \"NonMaxSuppressionV4\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    Oo(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      padToMaxOutputSize: u\n    } = s,\n        c = n.readSync(r.dataId),\n        h = n.readSync(a.dataId),\n        {\n      selectedIndices: d,\n      validOutputs: p\n    } = HN(c, h, i, o, l, u);\n    return [n.makeTensorInfo([d.length], \"int32\", new Int32Array(d)), n.makeTensorInfo([], \"int32\", new Int32Array([p]))];\n  }\n},\n    qN = Ki,\n    KN = {\n  kernelName: \"NonMaxSuppressionV5\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    Oo(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      softNmsSigma: u\n    } = s,\n        c = n.readSync(r.dataId),\n        h = n.readSync(a.dataId),\n        d = i,\n        p = o,\n        f = l,\n        g = u,\n        {\n      selectedIndices: m,\n      selectedScores: b\n    } = qN(c, h, d, p, f, g);\n    return [n.makeTensorInfo([m.length], \"int32\", new Int32Array(m)), n.makeTensorInfo([b.length], \"float32\", new Float32Array(b))];\n  }\n};\n\nclass XN {\n  constructor(e, t, n, s) {\n    this.variableNames = [\"indices\"], this.outputShape = [e, t], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int index = round(getIndices(coords.x));\\n        setOutput(mix(float(\".concat(s, \"), float(\").concat(n, \"),\\n                      float(index == coords.y)));\\n      }\\n    \");\n  }\n\n}\n\nvar YN = {\n  kernelName: \"OneHot\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r\n    } = t,\n        {\n      depth: a,\n      onValue: i,\n      offValue: o\n    } = s,\n        l = d(r.shape),\n        u = new XN(l, a, i, o),\n        c = cv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [l]\n      }\n    }),\n        h = n.runWebGLProgram(u, [c], r.dtype);\n    n.disposeIntermediateTensorInfo(c);\n    var p = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [...r.shape, a]\n      }\n    });\n    return n.disposeIntermediateTensorInfo(h), p;\n  }\n};\n\nfunction JN(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n\n  if (\"complex64\" === s.dtype) {\n    var _e502 = fI({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _t408 = JN({\n      inputs: {\n        x: _e502\n      },\n      backend: n\n    }),\n        _r170 = TI({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _a138 = JN({\n      inputs: {\n        x: _r170\n      },\n      backend: n\n    }),\n        _i99 = Kw({\n      inputs: {\n        real: _t408,\n        imag: _a138\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e502), n.disposeIntermediateTensorInfo(_t408), n.disposeIntermediateTensorInfo(_r170), n.disposeIntermediateTensorInfo(_a138), _i99;\n  }\n\n  return F$({\n    attrs: {\n      shape: s.shape,\n      dtype: s.dtype,\n      value: \"string\" === s.dtype ? \"\" : 0\n    },\n    backend: n\n  });\n}\n\nvar ZN = {\n  kernelName: \"ZerosLike\",\n  backendName: \"webgl\",\n  kernelFunc: JN\n},\n    QN = {\n  kernelName: \"OnesLike\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        {\n      x: r\n    } = n;\n    if (\"string\" === r.dtype) throw new Error(\"onesLike is not supported under string dtype\");\n\n    if (\"complex64\" === r.dtype) {\n      var _t409 = fI({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _n292 = e({\n        inputs: {\n          x: _t409\n        },\n        backend: s\n      }),\n          _a139 = TI({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _i100 = JN({\n        inputs: {\n          x: _a139\n        },\n        backend: s\n      }),\n          _o75 = Kw({\n        inputs: {\n          real: _n292,\n          imag: _i100\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_t409), s.disposeIntermediateTensorInfo(_n292), s.disposeIntermediateTensorInfo(_a139), s.disposeIntermediateTensorInfo(_i100), _o75;\n    }\n\n    return F$({\n      attrs: {\n        shape: r.shape,\n        dtype: r.dtype,\n        value: 1\n      },\n      backend: s\n    });\n  }\n},\n    eC = {\n  kernelName: \"Pack\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      axis: r\n    } = s;\n    if (1 === t.length) return $$({\n      inputs: {\n        input: t[0]\n      },\n      backend: n,\n      attrs: {\n        dim: r\n      }\n    });\n    var a = t[0].shape,\n        i = t[0].dtype;\n    t.forEach(e => {\n      u(a, e.shape, \"All tensors passed to stack must have matching shapes\"), l(i === e.dtype, () => \"All tensors passed to stack must have matching dtypes\");\n    });\n    var o = [],\n        c = AI({\n      inputs: t.map(e => {\n        var t = $$({\n          inputs: {\n            input: e\n          },\n          backend: n,\n          attrs: {\n            dim: r\n          }\n        });\n        return o.push(t), t;\n      }),\n      backend: n,\n      attrs: {\n        axis: r\n      }\n    });\n    return o.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n};\n\nclass tC {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Mk(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = [\"coords[0]\", \"coords[1]\", \"coords[2]\", \"coords[3]\"].slice(0, s);\n    this.userCode = 1 !== s ? \"\\n      \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outC = getOutputCoords();\\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\\n          setOutput(value);\\n        } else {\\n          \").concat(r, \" coords = outC - start;\\n          setOutput(getX(\").concat(o, \"));\\n        }\\n      }\\n    \") : \"\\n        int start = \".concat(a, \";\\n        int end = \").concat(i, \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start || outC >= end) {\\n            setOutput(value);\\n          } else {\\n            setOutput(getX(outC - start));\\n          }\\n        }\\n      \");\n  }\n\n}\n\nclass nC {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Mk(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = Ew(\"rc\", s),\n        l = Ew(\"source\", s),\n        u = \"\".concat(o[s - 1], \" < \").concat(this.outputShape[s - 1]),\n        c = 1 === s ? \"source\" : \"vec2(\".concat(l.slice(-2).join(), \")\"),\n        h = [\"\".concat(r, \" rc = outputLoc;\"), \"\".concat(o[s - 1], \" += 1;\\n       if(\").concat(u, \") {\\n      \"), 1 === s ? \"\" : \"}\\n       rc = outputLoc;\\n       \".concat(o[s - 2], \" += 1;\\n       if(\").concat(o[s - 2], \" < \").concat(this.outputShape[s - 2], \") {\"), 1 === s ? \"\" : \"  \".concat(o[s - 1], \" += 1;\\n         if(\").concat(u, \") {\")],\n        d = 1 === s ? \"rc < start || rc >= end\" : \"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))\";\n    var p = \"\";\n\n    for (var _e503 = 0, _t410 = 1 === s ? 2 : 4; _e503 < _t410; _e503++) {\n      p += \"\\n        \".concat(h[_e503], \"\\n        if (\").concat(d, \") {\\n          result[\").concat(_e503, \"] = float(value);\\n        } else {\\n          \").concat(r, \" source = rc - start;\\n          result[\").concat(_e503, \"] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n      \");\n    }\n\n    p += 1 === s ? \"} \" : \"}}\", this.userCode = \"\\n      const \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      const \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \").concat(p, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar sC = e => {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    paddings: a,\n    constantValue: i\n  } = s,\n      o = V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new nC(r.shape, a, i) : new tC(r.shape, a, i);\n  return n.runWebGLProgram(o, [r], r.dtype, [[i]]);\n},\n    rC = {\n  kernelName: \"PadV2\",\n  backendName: \"webgl\",\n  kernelFunc: sC\n},\n    aC = {\n  kernelName: \"Pow\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"\\n  if(a < 0.0 && floor(b) < b){\\n    return NAN;\\n  }\\n  if (b == 0.0) {\\n    return 1.0;\\n  }\\n  return (round(mod(b, 2.0)) != 1) ?\\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\",\n    packedOpSnippet: \"\\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\\n  vec4 result = multiplier * pow(abs(a), b);\\n\\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\\n  bvec4 isExpZero = equal(b, vec4(0.0));\\n  result.r = isExpZero.r ? 1.0 : result.r;\\n  result.g = isExpZero.g ? 1.0 : result.g;\\n  result.b = isExpZero.b ? 1.0 : result.b;\\n  result.a = isExpZero.a ? 1.0 : result.a;\\n\\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    iC = {\n  kernelName: \"Prod\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = [],\n        u = y(a, r.shape);\n    var c = u;\n    var h = Jr(c, o);\n    var p,\n        f = r;\n\n    if (null != h && (f = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: h\n      }\n    }), c = Qr(c.length, o), l.push(f)), Yr(\"prod\", c, o), n.shouldExecuteOnCPU([f])) {\n      var _e504 = n.texData.get(f.dataId).values,\n          {\n        outVals: _t411,\n        outShape: _s236,\n        outDtype: _r171\n      } = hw(f.shape, f.dtype, _e504, c);\n      p = n.makeTensorInfo(_s236, _r171, _t411);\n    } else {\n      var [_e505, _t412] = Kr(f.shape, c),\n          _s237 = d(_t412),\n          _a140 = cv({\n        inputs: {\n          x: f\n        },\n        backend: n,\n        attrs: {\n          shape: [-1, _s237]\n        }\n      }),\n          _i101 = fv(_a140, pt(r.dtype), \"prod\", n);\n\n      p = cv({\n        inputs: {\n          x: _i101\n        },\n        backend: n,\n        attrs: {\n          shape: _e505\n        }\n      }), l.push(_a140), l.push(_i101);\n    }\n\n    if (i) {\n      l.push(p);\n\n      var _e506 = Xr(p.shape, u);\n\n      p = cv({\n        inputs: {\n          x: p\n        },\n        backend: n,\n        attrs: {\n          shape: _e506\n        }\n      });\n    }\n\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;\n  }\n},\n    oC = e => {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    start: s,\n    stop: r,\n    step: a,\n    dtype: i\n  } = n,\n      o = dw(s, r, a, i);\n  return t.makeTensorInfo([o.length], i, o);\n},\n    lC = {\n  kernelName: \"Range\",\n  backendName: \"webgl\",\n  kernelFunc: oC\n},\n    uC = {\n  kernelName: \"Reciprocal\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return 1.0 / x;\"\n  })\n},\n    cC = {\n  kernelName: \"Relu\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : x;\\n\",\n    packedOpSnippet: \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    hC = {\n  kernelName: \"Relu6\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : min(6.0, x);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\"\n  })\n};\n\nclass dC {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)\" : \"vec2(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec2 inputShapeRC = vec2(\").concat(i, \".0, \").concat(o, \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the four integer indices.\\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\\n        ivec2 sourceCeilRC = ivec2(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\\n\\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\\n\\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\\n        float newValue = top + (bottom - top) * fracRC.x;\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nclass pC {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)\" : \"vec3(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec3 inputShapeRC = vec3(\").concat(i, \".0, \").concat(o, \".0,\\n                                     \").concat(o, \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the four integer indices.\\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\\n        ivec3 sourceCeilRC = ivec3(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \").concat(l - 1, \";\\n        bool hasNextRow = coords.z < \").concat(n - 1, \";\\n\\n        // In parallel, construct four corners for all four components in\\n        // packed 2x2 cell.\\n        vec4 topLeft = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomLeft = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 topRight = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomRight = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\\n\\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\\n        vec4 newValue = mix(top, bottom, fracRC.x);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nvar fC = {\n  kernelName: \"ResizeBilinear\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s,\n        [l, u] = o,\n        c = V().getBool(\"WEBGL_PACK_IMAGE_OPERATIONS\") ? new pC(r.shape, l, u, a, i) : new dC(r.shape, l, u, a, i);\n    return n.runWebGLProgram(c, [r], \"float32\");\n  }\n};\n\nclass gC {\n  constructor(e, t, n) {\n    this.variableNames = [\"dy\"], this.outputShape = [], this.outputShape = t;\n    var [, s, r] = t,\n        [, a, i] = e,\n        o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r],\n        l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i],\n        u = o[0] / l[0],\n        c = o[1] / l[1],\n        h = 1 / u,\n        d = 1 / c,\n        p = 2 * Math.ceil(h) + 2,\n        f = 2 * Math.ceil(d) + 2;\n    this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\".concat(u, \");\\n        const float widthScale = float(\").concat(c, \");\\n\\n        const float invHeightScale = float(\").concat(h, \");\\n        const float invWidthScale = float(\").concat(d, \");\\n\\n        const int winHeight = int(\").concat(p, \");\\n        const int winWidth = int(\").concat(f, \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(startRLerp - float(winHeight / 2));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(startCLerp - float(winWidth / 2));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \").concat(a, \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \").concat(i, \") {\\n              continue;\\n            }\\n\\n            float dxR = float(dyR) * heightScale;\\n            int topDxRIndex = int(floor(dxR));\\n            int bottomDxRIndex = int(min(ceil(dxR), \").concat(s - 1, \".0));\\n            float dxRLerp = dxR - float(topDxRIndex);\\n            float inverseDxRLerp = 1.0 - dxRLerp;\\n\\n            float dxC = float(dyC) * widthScale;\\n            int leftDxCIndex = int(floor(dxC));\\n            int rightDxCIndex = int(min(ceil(dxC), \").concat(r - 1, \".0));\\n            float dxCLerp = dxC - float(leftDxCIndex);\\n            float inverseDxCLerp = 1.0 - dxCLerp;\\n\\n            if (r == topDxRIndex && c == leftDxCIndex) {\\n              // topLeft\\n              accumulator +=\\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == topDxRIndex && c == rightDxCIndex) {\\n              // topRight\\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\\n              // bottomLeft\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\\n              // bottomRight\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \");\n  }\n\n}\n\nvar mC = {\n  kernelName: \"ResizeBilinearGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s,\n        o = new gC(a.shape, r.shape, i);\n    return n.runWebGLProgram(o, [a], a.dtype);\n  }\n};\n\nclass bC {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))\" : \"vec2(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec2 inputShapeRC = vec2(\").concat(i, \".0, \").concat(o, \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec2 sourceNearestRC = ivec2(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \").concat(s ? \"0.5\" : \"0.0\", \")));\\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nclass xC {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))\" : \"vec3(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec3 inputShapeRC = vec3(\").concat(i, \".0, \").concat(o, \".0,\\n                                     \").concat(o, \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec3 sourceNearestRC = ivec3(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \").concat(s ? \"0.5\" : \"0.0\", \")));\\n\\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \").concat(l - 1, \";\\n        bool hasNextRow = coords.z < \").concat(n - 1, \";\\n\\n        vec4 newValue = vec4(\\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nvar yC = {\n  kernelName: \"ResizeNearestNeighbor\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s,\n        [l, u] = o,\n        c = V().getBool(\"WEBGL_PACK_IMAGE_OPERATIONS\") ? new xC(r.shape, l, u, a, i) : new bC(r.shape, l, u, a, i);\n    return n.runWebGLProgram(c, [r], r.dtype);\n  }\n};\n\nclass kC {\n  constructor(e, t, n) {\n    this.variableNames = [\"dy\"], this.outputShape = [], this.outputShape = t;\n    var [, s, r] = t,\n        [, a, i] = e,\n        o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r],\n        l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i],\n        u = o[0] / l[0],\n        c = o[1] / l[1],\n        h = 1 / u,\n        d = 1 / c,\n        p = 2 * Math.ceil(h) + 2,\n        f = 2 * Math.ceil(d) + 2;\n    this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\".concat(u, \");\\n        const float widthScale = float(\").concat(c, \");\\n\\n        const float invHeightScale = float(\").concat(h, \");\\n        const float invWidthScale = float(\").concat(d, \");\\n\\n        const int winHeight = int(\").concat(p, \");\\n        const int winWidth = int(\").concat(f, \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \").concat(a, \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \").concat(i, \") {\\n              continue;\\n            }\\n\\n            float sourceFracRow =\\n              float(\").concat(o[0], \") *\\n                (float(dyR) / float(\").concat(l[0], \"));\\n\\n            float sourceFracCol =\\n                float(\").concat(o[1], \") *\\n                  (float(dyC) / float(\").concat(l[1], \"));\\n\\n            int sourceNearestRow = int(min(\\n                float(int(\").concat(s, \") - 1),\\n                \").concat(n, \" ? float(round(sourceFracRow)) :\\n                                  float(floor(sourceFracRow))));\\n\\n            int sourceNearestCol = int(min(\\n                float(int(\").concat(r, \") - 1),\\n                \").concat(n, \" ? float(round(sourceFracCol)) :\\n                                  float(floor(sourceFracCol))));\\n\\n            if (r == sourceNearestRow && c == sourceNearestCol) {\\n              accumulator += getDy(b, dyR, dyC, d);\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \");\n  }\n\n}\n\nvar wC = {\n  kernelName: \"ResizeNearestNeighborGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s,\n        o = new kC(a.shape, r.shape, i);\n    return n.runWebGLProgram(o, [a], a.dtype);\n  }\n};\n\nclass vC {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var n = e.length;\n    if (n > 4) throw new Error(\"WebGL backend: Reverse of rank-\".concat(n, \" tensor is not yet supported\"));\n    if (this.outputShape = e, 1 === n) return void (this.userCode = \"\\n        void main() {\\n          int coord = getOutputCoords();\\n          setOutput(getX(\".concat(e[0], \" - coord - 1));\\n        }\\n      \"));\n    var s = e.map((n, s) => (n => -1 !== t.indexOf(n) && 1 !== e[n] ? \"\".concat(e[n], \" - coords[\").concat(n, \"] - 1\") : \"coords[\".concat(n, \"]\"))(s)).join(\",\"),\n        r = Mk(n);\n    this.userCode = \"\\n      void main() {\\n        \".concat(r, \" coords = getOutputCoords();\\n        setOutput(getX(\").concat(s, \"));\\n      }\\n    \");\n  }\n\n}\n\nclass IC {\n  constructor(e, t) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0;\n    var n = e.length;\n    if (n > 4) throw new Error(\"WebGL backend: Reverse of rank-\".concat(n, \" tensor is not yet supported\"));\n    this.outputShape = e;\n    var s = Ew(\"rc\", n),\n        r = \"\".concat(s[n - 1], \" + 1 < \").concat(this.outputShape[n - 1]),\n        a = \"\".concat(s[n - 2], \" + 1 < \").concat(this.outputShape[n - 2]),\n        i = Mk(n);\n\n    function o(n) {\n      var s = e.map((s, r) => function (n, s) {\n        return -1 !== t.indexOf(n) && 1 !== e[n] ? \"\".concat(e[n], \" - \").concat(s[n], \" - 1\") : \"\".concat(s[n]);\n      }(r, n));\n      return \"getChannel(getX(\".concat(s.join(\",\"), \"), vec2(\").concat(s.slice(-2).join(\",\"), \"))\");\n    }\n\n    this.userCode = 1 === n ? \"\\n        void main(){\\n          int rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = getChannel(getX(\".concat(e[0], \" - rc - 1),\\n            \").concat(e[0], \" - rc - 1);\\n          if(\").concat(r, \"){\\n              result.g = getChannel(getX(\").concat(e[0], \" - (rc  + 1) - 1),\\n                \").concat(e[0], \" - (rc  + 1) - 1);\\n          }\\n          setOutput(result);\\n        }\\n      \") : \"\\n        void main() {\\n          \".concat(i, \" rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = \").concat(function (e) {\n      return o(e);\n    }(s.slice()), \";\\n          if(\").concat(r, \"){\\n            result.g = \").concat(function (e) {\n      return e[n - 1] = \"(\" + e[n - 1] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n          }\\n          if(\").concat(a, \") {\\n            result.b = \").concat(function (e) {\n      return e[n - 2] = \"(\" + e[n - 2] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n            if(\").concat(r, \") {\\n              result.a = \").concat(function (e) {\n      return e[n - 1] = \"(\" + e[n - 1] + \" + 1)\", e[n - 2] = \"(\" + e[n - 2] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n            }\\n          }\\n          setOutput(result);\\n        }\\n    \");\n  }\n\n}\n\nvar $C = {\n  kernelName: \"Reverse\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      dims: a\n    } = s,\n        i = r.shape.length,\n        o = y(a, r.shape);\n    if (0 === i) return jw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var l = V().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new IC(r.shape, o) : new vC(r.shape, o);\n    return n.runWebGLProgram(l, [r], r.dtype);\n  }\n};\n\nclass NC {\n  constructor(e, t) {\n    this.variableNames = [\"Image\"], this.outputShape = [], this.customUniforms = [{\n      name: \"params\",\n      type: \"vec4\"\n    }];\n    var n = e[1],\n        s = e[2];\n    this.outputShape = e;\n    var r = \"\";\n    r = \"number\" == typeof t ? \"float outputValue = \".concat(t.toFixed(2), \";\") : \"\\n        vec3 fill = vec3(\".concat(t.join(\",\"), \");\\n        float outputValue = fill[coords[3]];\"), this.userCode = \"\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int x = coords[2];\\n          int y = coords[1];\\n          float coordXFloat = (float(x) - params[0]) * params[3] -\\n            (float(y) - params[1]) * params[2];\\n          float coordYFloat = (float(x) - params[0]) * params[2] +\\n            (float(y) - params[1]) * params[3];\\n          int coordX = int(round(coordXFloat + params[0]));\\n          int coordY = int(round(coordYFloat + params[1]));\\n          \".concat(r, \"\\n          if(coordX >= 0 && coordX < \").concat(s, \" && coordY >= 0 && coordY < \").concat(n, \") {\\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\\n          }\\n          setOutput(outputValue);\\n        }\\n    \");\n  }\n\n}\n\nvar CC = {\n  kernelName: \"RotateWithOffset\",\n  backendName: \"webgl\",\n  kernelFunc: _ref32 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref32;\n    var {\n      image: s\n    } = e,\n        {\n      radians: r,\n      fillValue: a,\n      center: i\n    } = t,\n        o = n,\n        l = new NC(s.shape, a),\n        [u, c] = Eo(i, s.shape[1], s.shape[2]),\n        h = [[u, c, Math.sin(r), Math.cos(r)]];\n    return o.runWebGLProgram(l, [s], s.dtype, h);\n  }\n},\n    SC = {\n  kernelName: \"Round\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  // OpenGL ES does not support round function.\\n  // The algorithm is based on banker's rounding.\\n  float base = floor(x);\\n  if ((x - base) < 0.5) {\\n    return floor(x);\\n  } else if ((x - base) > 0.5) {\\n    return ceil(x);\\n  } else {\\n    if (mod(base, 2.0) == 0.0) {\\n      return base;\\n    } else {\\n      return base + 1.0;\\n    }\\n  }\\n\"\n  })\n},\n    TC = {\n  kernelName: \"Rsqrt\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return inversesqrt(x);\",\n    cpuKernelImpl: pw\n  })\n};\n\nclass EC {\n  constructor(e, t, n, s, r, a) {\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !0;\n    this.variableNames = [\"updates\", \"indices\", \"defaultValue\"], this.outputShape = a;\n    var o = Mk(r.length),\n        l = Mk(a.length);\n    var u = \"\";\n    1 === n ? u = \"i\" : 2 === n && (u = \"i, j\");\n    var c = \"\";\n    1 === s ? c = \"i\" : 2 === s && (c = \"i, coords[1]\"), this.userCode = \"\\n        \".concat(o, \" strides = \").concat(o, \"(\").concat(r, \");\\n\\n        void main() {\\n          \").concat(l, \" coords = getOutputCoords();\\n          float sum = 0.0;\\n          bool found = false;\\n          for (int i = 0; i < \").concat(e, \"; i++) {\\n            int flattenedIndex = 0;\\n            for (int j = 0; j < \").concat(t, \"; j++) {\\n              int index = round(getIndices(\").concat(u, \"));\\n              flattenedIndex += index * \").concat(t > 1 ? \"strides[j]\" : \"strides\", \";\\n            }\\n            if (flattenedIndex == coords[0]) {\\n              sum += getUpdates(\").concat(c, \");\\n              found = true;\\n            }\\n          }\\n          setOutput(mix(getDefaultValue(), sum, float(found)));\\n        }\\n      \");\n  }\n\n}\n\nvar RC = {\n  kernelName: \"ScatterNd\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r,\n      updates: a\n    } = t,\n        {\n      shape: i\n    } = s,\n        {\n      sliceRank: o,\n      numUpdates: l,\n      sliceSize: u,\n      strides: c,\n      outputSize: h\n    } = Sn(0, r, i),\n        d = [h / u, u];\n    if (0 === h) return n.makeTensorInfo(i, r.dtype);\n    var p = cv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [l, o]\n      }\n    }),\n        f = cv({\n      inputs: {\n        x: a\n      },\n      backend: n,\n      attrs: {\n        shape: [l, u]\n      }\n    }),\n        g = n.makeTensorInfo([], \"float32\", new Float32Array([0])),\n        m = new EC(l, o, p.shape.length, f.shape.length, c, d),\n        b = n.runWebGLProgram(m, [f, p, g], f.dtype),\n        x = cv({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        shape: i\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(g), x;\n  }\n};\n\nclass AC {\n  constructor(e, t, n) {\n    var s, r;\n    if (this.variableNames = [\"c\", \"a\", \"b\"], this.outputShape = t, n > 4) throw Error(\"Where for rank \".concat(n, \" is not yet supported\"));\n    if (1 === n) r = \"resRC\", s = \"resRC\";else {\n      var _n293 = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\"],\n          _a141 = [],\n          _i102 = [];\n\n      for (var _s238 = 0; _s238 < t.length; _s238++) {\n        _i102.push(\"\".concat(_n293[_s238])), _s238 < e && _a141.push(\"\".concat(_n293[_s238]));\n      }\n\n      s = _a141.join(), r = _i102.join();\n    }\n    var a = Mk(n);\n    this.userCode = \"\\n      void main() {\\n        \".concat(a, \" resRC = getOutputCoords();\\n        float cVal = getC(\").concat(s, \");\\n        if (cVal >= 1.0) {\\n          setOutput(getA(\").concat(r, \"));\\n        } else {\\n          setOutput(getB(\").concat(r, \"));\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar FC = {\n  kernelName: \"Select\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      condition: s,\n      t: r,\n      e: a\n    } = t,\n        i = new AC(s.shape.length, r.shape, r.shape.length);\n    return n.runWebGLProgram(i, [s, r, a], dt(r.dtype, a.dtype));\n  }\n},\n    DC = {\n  kernelName: \"Selu\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\\n  // see: https://arxiv.org/abs/1706.02515\\n  float scaleAlpha = 1.7580993408473768;\\n  float scale = 1.0507009873554805;\\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\\n\"\n  })\n},\n    _C = {\n  kernelName: \"Sigmoid\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return 1.0 / (1.0 + exp(-1.0 * x));\"\n  })\n},\n    OC = {\n  kernelName: \"Sign\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  if (isnan(x)) { return 0.0; }\\n  return sign(x);\\n\"\n  })\n},\n    MC = {\n  kernelName: \"Sin\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return sin(x);\\n\"\n  })\n},\n    LC = {\n  kernelName: \"Sinh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  float e2x = exp(x);\\n  return (e2x - 1.0 / e2x) / 2.0;\\n\"\n  })\n},\n    zC = {\n  kernelName: \"Softplus\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  float epsilon = 1.1920928955078125e-7;\\n  float threshold = log(epsilon) + 2.0;\\n\\n  bool too_large = x > -threshold;\\n  bool too_small = x < threshold;\\n\\n  float result;\\n  float exp_x = exp(x);\\n\\n  if (too_large){\\n    result = x;\\n  }\\n  else if (too_small){\\n    result = exp_x;\\n  }\\n  else{\\n    result = log(exp_x + 1.0);\\n  }\\n  return result;\\n\"\n  })\n},\n    BC = {\n  kernelName: \"SpaceToBatchND\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      paddings: i\n    } = s;\n    l(r.shape.length <= 4, () => \"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet\");\n    var o = a.reduce((e, t) => e * t),\n        u = [[0, 0]];\n    u.push(...i);\n\n    for (var _e507 = 1 + a.length; _e507 < r.shape.length; ++_e507) {\n      u.push([0, 0]);\n    }\n\n    var c = [],\n        h = sC({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        paddings: u,\n        constantValue: 0\n      }\n    }),\n        d = Ro(h.shape, a, o, !1),\n        p = Ao(d.length, a.length, !1),\n        f = Fo(h.shape, a, o, !1),\n        g = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: d\n      }\n    }),\n        m = kv({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        perm: p\n      }\n    }),\n        b = cv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: f\n      }\n    });\n    return c.push(h), c.push(g), c.push(m), c.forEach(e => n.disposeIntermediateTensorInfo(e)), b;\n  }\n},\n    PC = {\n  kernelName: \"SparseFillEmptyRows\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      indices: s,\n      values: r,\n      denseShape: a,\n      defaultValue: i\n    } = t;\n    if (1 !== a.shape.length) throw new Error(\"Dense shape must be a vector, saw:\\n         \".concat(a.shape));\n    if (2 !== s.shape.length) throw new Error(\"Indices must be a matrix, saw:\\n         \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Values must be a vector, saw:\\n         \".concat(r.shape));\n    if (0 !== i.shape.length) throw new Error(\"Default value must be a scalar, saw:\\n        \".concat(i.shape));\n    var o = n.readSync(s.dataId),\n        l = n.readSync(r.dataId),\n        u = n.readSync(a.dataId),\n        c = n.readSync(i.dataId)[0],\n        [h, d, p, f, g] = mw(o, s.shape, s.dtype, l, r.dtype, u, c);\n    return [n.makeTensorInfo(d, s.dtype, h), n.makeTensorInfo([d[0]], r.dtype, p), n.makeTensorInfo([f.length], \"bool\", new Uint8Array(f.map(e => Number(e)))), n.makeTensorInfo([g.length], s.dtype, new Int32Array(g))];\n  }\n},\n    WC = {\n  kernelName: \"SparseReshape\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    } = t;\n    if (2 !== s.shape.length) throw new Error(\"Input indices should be a matrix but received shape \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Input shape should be a vector but received shape \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Target shape should be a vector but received shape \".concat(a.shape));\n    var i = Array.from(n.readSync(r.dataId)),\n        o = n.readSync(s.dataId),\n        l = Array.from(n.readSync(a.dataId)),\n        [u, c, h] = bw(o, s.shape, s.dtype, i, l);\n    return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))];\n  }\n},\n    UC = {\n  kernelName: \"SparseSegmentMean\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n              \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n              \".concat(a.shape));\n    var i = n.readSync(s.dataId),\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        [u, c] = xw(i, s.shape, s.dtype, o, l, !0);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    VC = {\n  kernelName: \"SparseSegmentSum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n             \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n             \".concat(a.shape));\n    var i = n.readSync(s.dataId),\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        [u, c] = xw(i, s.shape, s.dtype, o, l);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    GC = {\n  kernelName: \"SparseToDense\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      sparseIndices: r,\n      sparseValues: a,\n      defaultValue: i\n    } = t,\n        {\n      outputShape: o\n    } = s,\n        {\n      sliceRank: l,\n      numUpdates: u,\n      strides: c,\n      outputSize: h\n    } = Sn(0, r, o),\n        d = new EC(u, l, r.shape.length, a.shape.length, c, [h, 1], !1),\n        p = n.runWebGLProgram(d, [a, r, i], a.dtype),\n        f = cv({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        shape: o\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), f;\n  }\n},\n    HC = {\n  kernelName: \"SplitV\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      numOrSizeSplits: a,\n      axis: i\n    } = s,\n        o = y(i, r.shape)[0],\n        l = Jo(r, a, o),\n        u = new Array(r.shape.length).fill(0),\n        c = r.shape.slice();\n    return l.map(e => {\n      var t = [...c];\n      t[o] = e;\n      var s = lI({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: u,\n          size: t\n        }\n      });\n      return u[o] += e, s;\n    });\n  }\n},\n    jC = {\n  kernelName: \"Sqrt\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return sqrt(x);\"\n  })\n},\n    qC = {\n  kernelName: \"Square\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return x * x;\"\n  })\n},\n    KC = {\n  kernelName: \"SquaredDifference\",\n  backendName: \"webgl\",\n  kernelFunc: sv({\n    opSnippet: \"return (a - b) * (a - b);\",\n    packedOpSnippet: \"return (a - b) * (a - b);\"\n  })\n},\n    XC = {\n  kernelName: \"Step\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(_ref33) {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref33;\n    var {\n      x: s\n    } = e,\n        r = new Mw(s.shape, \"if (isnan(x)) return x;\\n    return x > 0.0 ? 1.0 : float(\".concat(t.alpha, \");\\n  \"));\n    return n.runWebGLProgram(r, [s], s.dtype);\n  }\n};\n\nclass YC {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = n;\n    var s = n.length,\n        r = Mk(n.length),\n        a = Mk(n.length);\n    var i = \"\";\n    if (1 === s) i = \"coords * strides + begin\";else {\n      var _e508 = 0;\n      i = n.map((t, s) => (_e508++, 1 === n.length ? \"coords * strides[\".concat(s, \"] + begin[\").concat(s, \"]\") : \"coords[\".concat(_e508 - 1, \"] * strides[\").concat(s, \"] + begin[\").concat(s, \"]\"))).join(\",\");\n    }\n    this.userCode = \"\\n      \".concat(r, \" begin = \").concat(r, \"(\").concat(e, \");\\n      \").concat(r, \" strides = \").concat(r, \"(\").concat(t, \");\\n\\n      void main() {\\n        \").concat(a, \" coords = getOutputCoords();\\n        setOutput(getX(\").concat(i, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar JC = {\n  kernelName: \"StridedSlice\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      begin: a,\n      end: i,\n      strides: o,\n      beginMask: l,\n      endMask: u,\n      ellipsisMask: c,\n      newAxisMask: h,\n      shrinkAxisMask: d\n    } = s,\n        {\n      nonStrided: p,\n      $begin: f,\n      $strides: g,\n      size: m,\n      newShape: b,\n      outShape: x\n    } = Vn(r.shape, a, i, o, l, u, c, h, d),\n        y = cv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: b\n      }\n    });\n    var k;\n\n    if (p) {\n      var _e509 = lI({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          begin: f,\n          size: m\n        }\n      });\n\n      k = cv({\n        inputs: {\n          x: _e509\n        },\n        backend: n,\n        attrs: {\n          shape: x\n        }\n      }), n.disposeIntermediateTensorInfo(_e509);\n    } else if (x.some(e => 0 === e)) k = n.makeTensorInfo(x, r.dtype, []);else if (n.shouldExecuteOnCPU([y])) {\n      var _e510 = n.texData.get(y.dataId),\n          _t413 = dn(y.shape, y.dtype, _e510.values),\n          _s239 = yw(x, _t413, g, f);\n\n      k = n.makeTensorInfo(x, y.dtype, _s239.values);\n    } else {\n      var _e511 = new YC(f, g, x);\n\n      k = n.runWebGLProgram(_e511, [y], y.dtype);\n    }\n\n    var w = cv({\n      inputs: {\n        x: k\n      },\n      backend: n,\n      attrs: {\n        shape: x\n      }\n    });\n    return n.disposeIntermediateTensorInfo(y), n.disposeIntermediateTensorInfo(k), w;\n  }\n},\n    ZC = {\n  kernelName: \"StringNGrams\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      separator: r,\n      nGramWidths: a,\n      leftPad: i,\n      rightPad: o,\n      padWidth: l,\n      preserveShortSequences: u\n    } = s,\n        {\n      data: c,\n      dataSplits: h\n    } = t,\n        d = n.readSync(c.dataId),\n        p = n.readSync(h.dataId),\n        [f, g] = kw(d, p, r, a, i, o, l, u);\n    return [n.makeTensorInfo([f.length], \"string\", f), n.makeTensorInfo(h.shape, \"int32\", g)];\n  }\n},\n    QC = {\n  kernelName: \"StringSplit\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      skipEmpty: r\n    } = s,\n        {\n      input: a,\n      delimiter: i\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (1 !== a.shape.length) throw new Error(\"Input must be a vector, got shape: \".concat(a.shape));\n    if (0 !== i.shape.length) throw new Error(\"Delimiter must be a scalar, got shape: \".concat(i.shape));\n    var o = n.readSync(a.dataId),\n        l = n.readSync(i.dataId)[0],\n        [u, c, h] = ww(o, l, r),\n        d = c.length;\n    return [n.makeTensorInfo([d, 2], \"int32\", u), n.makeTensorInfo([d], \"string\", c), n.makeTensorInfo([2], \"int32\", new Int32Array(h))];\n  }\n},\n    eS = {\n  kernelName: \"StringToHashBucketFast\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      numBuckets: r\n    } = s,\n        {\n      input: a\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (r <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    var i = n.readSync(a.dataId),\n        o = vw(i, r);\n    return n.makeTensorInfo(a.shape, \"int32\", o);\n  }\n},\n    tS = {\n  kernelName: \"Tan\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"return tan(x);\"\n  })\n},\n    nS = {\n  kernelName: \"Tanh\",\n  backendName: \"webgl\",\n  kernelFunc: nv({\n    opSnippet: \"\\n  float e2x = exp(-2.0 * abs(x));\\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\\n\"\n  })\n};\n\nclass sS {\n  constructor(e, t) {\n    this.variableNames = [\"A\"];\n    var n = new Array(e.length);\n\n    for (var _s240 = 0; _s240 < n.length; _s240++) {\n      n[_s240] = e[_s240] * t[_s240];\n    }\n\n    this.outputShape = n, this.rank = n.length;\n\n    var s = Mk(this.rank),\n        r = function (e) {\n      var t = e.length;\n      if (t > 5) throw Error(\"Tile for rank \".concat(t, \" is not yet supported\"));\n      if (1 === t) return \"imod(resRC, \".concat(e[0], \")\");\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\", \"resRC.u\"],\n          s = [];\n\n      for (var _t414 = 0; _t414 < e.length; _t414++) {\n        s.push(\"imod(\".concat(n[_t414], \", \").concat(e[_t414], \")\"));\n      }\n\n      return s.join();\n    }(e);\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(s, \" resRC = getOutputCoords();\\n        setOutput(getA(\").concat(r, \"));\\n      }\\n    \");\n  }\n\n}\n\nfunction rS(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reps: a\n  } = s;\n\n  if (\"string\" === r.dtype || r.shape.length > 5) {\n    var _e512 = n.readSync(r.dataId),\n        _t415 = \"string\" === r.dtype ? _e512.map(e => He(e)) : _e512,\n        _s241 = dn(r.shape, r.dtype, _t415),\n        _i103 = $w(_s241, a);\n\n    return n.makeTensorInfo(_i103.shape, _i103.dtype, _i103.values);\n  }\n\n  var i = new sS(r.shape, a);\n  return n.runWebGLProgram(i, [r], r.dtype);\n}\n\nvar aS = {\n  kernelName: \"Tile\",\n  backendName: \"webgl\",\n  kernelFunc: rS\n};\n\nclass iS {\n  constructor(e) {\n    this.variableNames = [\"x\", \"indices\"], this.customUniforms = [{\n      name: \"n\",\n      type: \"int\"\n    }, {\n      name: \"firstPass\",\n      type: \"int\"\n    }, {\n      name: \"negativeInf\",\n      type: \"float\"\n    }, {\n      name: \"dir\",\n      type: \"int\"\n    }, {\n      name: \"inc\",\n      type: \"int\"\n    }], this.outputShape = e, this.userCode = \"\\n       void main() {\\n         ivec2 coords = getOutputCoords();\\n         int batch = coords[0];\\n         int elemIdx = coords[1];\\n\\n         // We compare elements pair-wise within a group of size 2 * inc.\\n         // The comparing rule for each group alternates between ascending\\n         // and descending. Within each group, we compare each pair at\\n         // positions i and i+inc. To decide whether an element at position i\\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\\n         // inc, it is in the first half of the group, we denote it as x0,\\n         // otherwise we denote it as x1.\\n         // For example, as shown in the Bitonic top K paper referenced above,\\n         // Figure5(a) shows that element[1] is in the\\n         // second half of the group when group size is 2, but it is in the\\n         // first half of the group when group size is 4.\\n\\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\\n\\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\\n\\n         // Denotes which direction indices are in (ascending or descending).\\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\\n         if (reverse == isGreater) { // Elements in opposite order of direction\\n           int iTemp = i0;\\n           i0 = i1;\\n           i1 = iTemp;\\n         }\\n         if (isFirstInPair) {\\n            setOutput(float(i0));\\n         } else {\\n            setOutput(float(i1));\\n         }\\n       }\\n     \";\n  }\n\n}\n\nclass oS {\n  constructor(e) {\n    this.variableNames = [\"x\", \"indices\"], this.customUniforms = [{\n      name: \"n\",\n      type: \"int\"\n    }, {\n      name: \"firstPass\",\n      type: \"int\"\n    }, {\n      name: \"k\",\n      type: \"int\"\n    }], this.outputShape = e, this.userCode = \"\\n    void main() {\\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\\n         ivec2 coords = getOutputCoords();\\n         int batch = coords[0];\\n         int elemIdx = coords[1];\\n\\n         // The output size is half of the previous size.\\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\\n         // we only need to output the indices at positions |, the indices at\\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\\n         // (Merge phase) in the Bitonic Top K paper referenced above.\\n         // For example, the paper shows we only need to output the orange bars.\\n         // The output sequence should look like this | | | | | | | |.\\n         // Because the sequence is halved, to map the output index back\\n         // to the previous sequence to find the corresponding value,\\n         // we need to double the index. When we double the index,\\n         // we basically interpolate a position, so 2i looks like\\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\\n         // of each 2k positions by - elemIdx % k. E.g. for output at\\n         // index 4,5,6,7, we want to get the corresponding element at\\n         // original index 8,9,10,11, for output at index 8,9,10,11,\\n         // we want to get the corresponding element at original index\\n         // 16,17,18,19, so on and so forth.\\n\\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\\n\\n         float x0 = getX(batch, i0);\\n         float x1 = i1 < n ? getX(batch, i1) : x0;\\n\\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\\n       }\\n     \";\n  }\n\n}\n\nfunction lS(e, t) {\n  null !== t && e.disposeIntermediateTensorInfo(t);\n}\n\nfunction uS(e) {\n  var t = 1;\n\n  for (; t < e;) {\n    t *= 2;\n  }\n\n  return t;\n}\n\nvar cS = {\n  kernelName: \"TopK\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      k: a,\n      sorted: i\n    } = s,\n        o = V().getNumber(\"TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD\"),\n        l = V().getNumber(\"TOPK_K_CPU_HANDOFF_THRESHOLD\"),\n        u = r.shape,\n        c = u[u.length - 1];\n\n    if (n.shouldExecuteOnCPU([r]) || c < o || a > l) {\n      var _e513 = n.readSync(r.dataId),\n          [_t416, _s242] = Nw(_e513, u, r.dtype, a, i);\n\n      return [n.makeTensorInfo(_t416.shape, _t416.dtype, _t416.values), n.makeTensorInfo(_s242.shape, _s242.dtype, _s242.values)];\n    }\n\n    if (0 === a) return u[u.length - 1] = 0, [n.makeTensorInfo(u, r.dtype, []), n.makeTensorInfo(u, \"int32\", [])];\n    if (1 === c) return [r, F$({\n      attrs: {\n        shape: u,\n        dtype: \"int32\",\n        value: 0\n      },\n      backend: n\n    })];\n    var h = n.texData.get(r.dataId),\n        p = null !== h && h.isPacked,\n        f = p ? n.unpackTensor(r) : r,\n        g = d(u) / c,\n        m = cv({\n      inputs: {\n        x: f\n      },\n      attrs: {\n        shape: [g, c]\n      },\n      backend: n\n    });\n    p && lS(n, f);\n    var b = uS(a),\n        x = uS(c);\n    var y = null;\n\n    var k = () => null === y ? [m, m] : [m, y],\n        w = (e, t, s) => {\n      var r = k(),\n          a = new iS(s),\n          i = y;\n      y = n.runWebGLProgram(a, r, \"int32\", [[c], [null === y ? 1 : 0], [Number.NEGATIVE_INFINITY], [e], [t]]), lS(n, i);\n    };\n\n    for (var _e514 = 1; _e514 < b; _e514 *= 2) {\n      var _t417 = 2 * _e514;\n\n      for (var _n294 = _e514; _n294 >= 1; _n294 /= 2) {\n        w(_t417, _n294, [g, x]);\n      }\n    }\n\n    for (var _e515 = x; _e515 > b; _e515 /= 2) {\n      var _t418 = k(),\n          _s243 = new oS([g, _e515 / 2]),\n          _r172 = y;\n\n      y = n.runWebGLProgram(_s243, _t418, \"int32\", [[c], [null === y ? 1 : 0], [b]]), lS(n, _r172);\n\n      var _a142 = b / 2,\n          _i104 = 2 * _a142;\n\n      for (var _e516 = _a142; _e516 >= 1; _e516 /= 2) {\n        w(_i104, _e516, y.shape);\n      }\n    }\n\n    var v = y;\n    y = lI({\n      inputs: {\n        x: y\n      },\n      backend: n,\n      attrs: {\n        begin: 0,\n        size: [g, a]\n      }\n    }), lS(n, v);\n    var I = K$({\n      inputs: {\n        x: m,\n        indices: y\n      },\n      backend: n,\n      attrs: {\n        axis: 1,\n        batchDims: 1\n      }\n    });\n    lS(n, m);\n    var $ = u.slice(0, -1);\n    $.push(a), v = y, y = cv({\n      inputs: {\n        x: y\n      },\n      attrs: {\n        shape: $\n      },\n      backend: n\n    }), lS(n, v);\n    var N = I;\n    return I = cv({\n      inputs: {\n        x: I\n      },\n      attrs: {\n        shape: $\n      },\n      backend: n\n    }), lS(n, N), [I, y];\n  }\n};\n\nclass hS {\n  constructor(e, t, n, s, r, a) {\n    this.variableNames = [\"Image\", \"Transforms\"], this.outputShape = a;\n    var i = \"nearest\" === n ? 1 : 2;\n    var o;\n\n    switch (s) {\n      case \"constant\":\n        o = 1;\n        break;\n\n      case \"reflect\":\n        o = 2;\n        break;\n\n      case \"wrap\":\n        o = 3;\n        break;\n\n      case \"nearest\":\n        o = 4;\n        break;\n\n      default:\n        o = 1;\n    }\n\n    this.userCode = \"\\n            float mapCoord(float outCoord, float len) {\\n              float inCoord = outCoord;\\n              if(\".concat(o, \" == 2) {\\n                if (inCoord < 0.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz2 = 2.0 * len;\\n                    if (inCoord < sz2) {\\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\\n                      inCoord;\\n                    }\\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\\n                  }\\n                } else if (inCoord > len - 1.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz2 = 2.0 * len;\\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\\n                    if (inCoord >= len) {\\n                      inCoord = sz2 - inCoord - 1.0;\\n                    }\\n                  }\\n                }\\n                return clamp(inCoord, 0.0, len - 1.0);\\n              } else if (\").concat(o, \" == 3) {\\n                if (inCoord < 0.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz = len - 1.0;\\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\\n                  }\\n                } else if (inCoord > len - 1.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz = len - 1.0;\\n                    inCoord -= len * float(int(float(inCoord / sz)));\\n                  }\\n                }\\n                return clamp(inCoord, 0.0, len - 1.0);\\n              } else if (\").concat(o, \" == 4) {\\n                return clamp(outCoord, 0.0, len - 1.0);\\n              } else {\\n                return outCoord;\\n              }\\n            }\\n\\n            float readWithFillValue(int batch, int coordY, int coordX,\\n              int channel) {\\n              float outputValue;\\n              if (0 <= coordY && coordY < \").concat(e, \" && 0 <= coordX && coordX < \").concat(t, \") {\\n                  outputValue = getImage(batch, coordY, coordX, channel);\\n              } else {\\n                outputValue = float(\").concat(r, \");\\n              }\\n              return outputValue;\\n            }\\n\\n            void main() {\\n              ivec4 coords = getOutputCoords();\\n              float outputValue;\\n              int batch = coords[0];\\n              int x = coords[2];\\n              int y = coords[1];\\n              int channel = coords[3];\\n              float xf = float(x);\\n              float yf = float(y);\\n              float a1 = getTransforms(batch, 0);\\n              float a2 = getTransforms(batch, 1);\\n              float a3 = getTransforms(batch, 2);\\n              float b1 = getTransforms(batch, 3);\\n              float b2 = getTransforms(batch, 4);\\n              float b3 = getTransforms(batch, 5);\\n              float c1 = getTransforms(batch, 6);\\n              float c2 = getTransforms(batch, 7);\\n              float projection = c1 * xf + c2 * yf + 1.0;\\n              if (projection == 0.0) {\\n                outputValue = float(\").concat(r, \");\\n              } else {\\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\\n                float mapX = mapCoord(inX, float(\").concat(t, \"));\\n                float mapY = mapCoord(inY, float(\").concat(e, \"));\\n\\n                if (\").concat(i, \" == 1) {\\n                  int coordY = int(round(mapY));\\n                  int coordX = int(round(mapX));\\n                  outputValue = readWithFillValue(batch, coordY, coordX,\\n                    channel);\\n                } else {\\n                  float yFloor = floor(mapY);\\n                  float xFloor = floor(mapX);\\n                  float yCeil = yFloor + 1.0;\\n                  float xCeil = xFloor + 1.0;\\n                  float valueYFloor = (xCeil - mapX) *\\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\\n                  (mapX - xFloor) *\\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\\n                  float valueYCeil = (xCeil - mapX) *\\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\\n                  (mapX - xFloor) *\\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\\n                  outputValue = (yCeil - mapY) * valueYFloor +\\n                  (mapY - yFloor) * valueYCeil;\\n                }\\n              }\\n              setOutput(outputValue);\\n            }\\n        \");\n  }\n\n}\n\nvar dS = {\n  kernelName: \"Transform\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      transforms: a\n    } = t,\n        {\n      interpolation: i,\n      fillMode: o,\n      fillValue: l,\n      outputShape: u\n    } = s,\n        [c, h, d, p] = r.shape,\n        [f, g] = null != u ? u : [h, d],\n        m = new hS(h, d, i, o, l, [c, f, g, p]);\n    return n.runWebGLProgram(m, [r, a], \"float32\");\n  }\n},\n    pS = {\n  kernelName: \"Unique\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      axis: r\n    } = n,\n        {\n      x: a\n    } = t;\n    ik(a, \"unique\"), console.warn(\"WARNING: \", \"UI might be locked temporarily as data is being downloaded\");\n    var i = s.readSync(a.dataId),\n        {\n      outputValues: o,\n      outputShape: l,\n      indices: u\n    } = Sw(i, r, a.shape, a.dtype);\n    return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], \"int32\", u)];\n  }\n},\n    fS = {\n  kernelName: \"Unpack\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      value: r\n    } = t;\n    var {\n      axis: a\n    } = s;\n    a < 0 && (a += r.shape.length);\n    var i = r,\n        o = i.shape.length,\n        l = r.shape[a],\n        u = new Array(o - 1);\n    var c = 0;\n\n    for (var _e517 = 0; _e517 < o; _e517++) {\n      _e517 !== a && (u[c++] = i.shape[_e517]);\n    }\n\n    var h = [],\n        d = new Array(o).fill(0),\n        p = i.shape.slice();\n    p[a] = 1;\n    var f = new Array(l);\n\n    for (var _e518 = 0; _e518 < f.length; _e518++) {\n      d[a] = _e518;\n\n      var _t419 = lI({\n        inputs: {\n          x: i\n        },\n        backend: n,\n        attrs: {\n          begin: d,\n          size: p\n        }\n      }),\n          _s244 = cv({\n        inputs: {\n          x: _t419\n        },\n        backend: n,\n        attrs: {\n          shape: u\n        }\n      });\n\n      f[_e518] = _s244, h.push(_t419);\n    }\n\n    return h.forEach(e => n.disposeIntermediateTensorInfo(e)), f;\n  }\n};\n\nclass gS {\n  constructor(e, t) {\n    this.variableNames = [\"x\", \"segmentIds\"];\n    var n = e.windowSize,\n        s = e.batchSize,\n        r = e.inSize,\n        a = e.numSegments,\n        i = a * Math.ceil(r / n);\n    this.outputShape = [s, i];\n    var o = 4 * Math.floor(n / 4),\n        l = n % 4,\n        u = \"\\n        sumValue += dot(values, segFilter);\\n    \";\n    var c = \"\";\n    r % n > 0 && (c = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return initializationValue;\\n        }\\n      \"));\n    var h = \"\";\n    r % n > 0 && (h = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return -1.0;\\n        }\\n      \")), this.userCode = \"\\n      const float initializationValue = 0.0;\\n\\n      float getValue(int batch, int inIdx) {\\n        \".concat(c, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      float getSegmentIdAtIndex(int inIdx) {\\n        \").concat(h, \"\\n        return getSegmentIds(inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = int(floor(float(outIdx) / float(\\n          \").concat(a, \")) * float(\").concat(n, \"));\\n        int currentSeg = int(mod(float(outIdx), float(\").concat(a, \")));\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(o, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\\n          );\\n\\n          \").concat(u, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(o, \";\\n        if (\").concat(1 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            0,\\n            0,\\n            0\\n          );\\n\\n          \").concat(u, \"\\n        } else if (\").concat(2 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n              0,\\n              0\\n          );\\n\\n          \").concat(u, \"\\n        } else if (\").concat(3 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            0\\n          );\\n\\n          \").concat(u, \"\\n        }\\n        setOutput(sumValue);\\n      }\\n    \");\n  }\n\n}\n\nvar mS = [dN, fN, Iv, Nv, Cv, Sv, Ev, Fv, Dv, _v, Pv, Wv, Uv, Vv, Hv, Gv, jv, Yv, Xv, Qv, eI, tI, rI, cI, hI, mI, xI, wI, $I, Xw, FI, VI, GI, zI, jI, qI, HI, KI, XI, JI, t$, n$, r$, c$, h$, o$, p$, g$, m$, b$, x$, y$, k$, I$, N$, S$, R$, D$, O$, L$, z$, W$, V$, G$, j$, X$, Y$, J$, qw, Z$, EI, Q$, eN, tN, Zw, nN, sN, rN, iN, aN, oN, lN, uN, mN, yN, xN, vN, IN, $N, bN, NN, CN, SN, RN, AN, PN, uv, UN, GN, jN, KN, pI, YN, QN, eC, rC, aC, tv, iC, lC, gI, _N, uC, hC, cC, hv, fC, mC, yC, wC, $C, CC, SC, TC, RC, FC, DC, _C, OC, MC, LC, uI, BN, zC, BC, PC, WC, UC, VC, GC, HC, jC, qC, KC, XC, JC, ZC, QC, eS, LN, yv, tS, nS, aS, cS, dS, wv, pS, fS, {\n  kernelName: \"UnsortedSegmentSum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      segmentIds: a\n    } = t,\n        {\n      numSegments: i\n    } = s,\n        o = r.shape.length,\n        l = [];\n    var u = 0;\n    var c = Jr([u], o);\n    var h = r;\n    null != c && (h = kv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), l.push(h), u = Qr(1, o)[0]);\n    var p = Qo(h.shape, u, i),\n        f = d([h.shape[u]]),\n        g = cv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, f]\n      }\n    });\n    l.push(g);\n\n    var m = pt(r.dtype),\n        b = (e, t, s, r, a) => {\n      var i = e.shape[0],\n          o = e.shape[1],\n          u = Zo(o, a),\n          c = new gS({\n        windowSize: u,\n        inSize: o,\n        batchSize: i,\n        numSegments: a\n      }, t),\n          h = n.compileAndRun(c, [e, s], r);\n      if (l.push(h), h.shape[1] === a) return h;\n      var d = oC({\n        backend: n,\n        attrs: {\n          start: 0,\n          stop: a,\n          step: 1,\n          dtype: \"float32\"\n        }\n      }),\n          p = rS({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          reps: [o / u]\n        }\n      });\n      return l.push(d), l.push(p), b(h, t, p, r, a);\n    },\n        x = cv({\n      inputs: {\n        x: b(g, \"unsortedSegmentSum\", a, m, i)\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    });\n\n    var y = x;\n\n    if (null != c) {\n      l.push(x);\n\n      var _e519 = Zr(c);\n\n      y = kv({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          perm: _e519\n        }\n      });\n    }\n\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), y;\n  }\n}, ZN];\n\nfor (var _e520 of mS) {\n  Q(_e520);\n}\n\nvar bS = [\"worker\"],\n    xS = {\n  train: function () {\n    var _train = _asyncToGenerator(function* (e) {\n      var {\n        data: t\n      } = e;\n      var n = [];\n\n      var s = function (e, t, n) {\n        if (c(e), null != t && 3 !== t.length) throw new Error(\"tensor3d() requires shape to have three numbers\");\n        var s = Ct(e, n);\n        if (3 !== s.length && 1 !== s.length) throw new Error(\"tensor3d() requires values to be number[][][] or flat/TypedArray\");\n        if (1 === s.length && null == t) throw new Error(\"tensor3d() requires shape to be provided when `values` are a flat array\");\n        return Dt(e, t, s, n);\n      }(t.xData, [t.xData.length, t.model.inputShape[0], t.model.inputShape[1]]),\n          r = In(mi(t.yData, \"int32\"), t.model.labels.length),\n          {\n        epochs: a,\n        model: i\n      } = function (e, t) {\n        var n = new Ed(void 0);\n        return \"\" == t && (n.add(Of({\n          inputShape: e.inputShape,\n          kernelSize: [4],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(Lf({\n          poolSize: [2]\n        })), n.add(Mf({\n          rate: .1\n        })), n.add(Of({\n          kernelSize: [2],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(Lf({\n          poolSize: [2]\n        })), n.add(Mf({\n          rate: .1\n        })), n.add(Of({\n          kernelSize: [2],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(Mf({\n          rate: .1\n        })), n.add(new Hp(void 0)), n.add(new Gp({\n          units: e.outputShape,\n          activation: \"softmax\"\n        })), n.compile({\n          loss: \"categoricalCrossentropy\",\n          optimizer: \"adam\",\n          metrics: [\"accuracy\"]\n        })), {\n          model: n,\n          epochs: 250\n        };\n      }(t.model, t.modelBlockJSON);\n\n      var o;\n      yield i.fit(s, r, {\n        epochs: a,\n        callbacks: {\n          onEpochEnd: yS\n        }\n      }).then(e => {\n        n = e.history.acc;\n      }), yield i.save({\n        save: e => {\n          o = e;\n          var t = {\n            modelArtifactsInfo: {\n              dateSaved: new Date(),\n              modelTopologyType: \"JSON\"\n            }\n          };\n          return Promise.resolve(t);\n        }\n      });\n      var l = o.weightData;\n      return o.weightData = null, {\n        modelJSON: JSON.stringify(o),\n        modelWeights: l,\n        trainingInfo: n\n      };\n    });\n\n    function train(_x56) {\n      return _train.apply(this, arguments);\n    }\n\n    return train;\n  }(),\n  predict: function () {\n    var _predict = _asyncToGenerator(function* (e) {\n      var {\n        data: t\n      } = e,\n          n = _t(t.zData),\n          s = JSON.parse(t.model.modelJSON);\n\n      s.weightData = new Uint32Array(t.model.weights).buffer;\n      var r = yield (a = {\n        load: () => Promise.resolve(s)\n      }, null == i && (i = {}), function () {\n        var _ref34 = _asyncToGenerator(function* (e, t) {\n          if (null == t && (t = {}), \"string\" == typeof e) {\n            var _n295 = Gt.getLoadHandlers(e, t);\n\n            if (0 === _n295.length) _n295.push(wn(e, t));else if (_n295.length > 1) throw new bu(\"Found more than one (\".concat(_n295.length, \") load handlers for URL '\").concat(e, \"'\"));\n            e = _n295[0];\n          }\n\n          return function () {\n            var _ref35 = _asyncToGenerator(function* (e, t, n) {\n              if (null == n && (n = {}), null == e.load) throw new bu(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n              var s = yield e.load();\n              var r = s.modelTopology;\n              null != r.model_config && (r = r.model_config);\n              var a = null == n.strict || n.strict,\n                  i = null != s.weightData && null != s.weightSpecs && a,\n                  o = Eh(td(r), void 0, i),\n                  l = s.trainingConfig;\n\n              if (null != l && o.loadTrainingConfig(l), null != s.userDefinedMetadata && o.setUserDefinedMetadata(s.userDefinedMetadata), null != s.weightData) {\n                if (null == s.weightSpecs) throw new bu(\"LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.\");\n\n                var {\n                  modelWeights: _e521,\n                  optimizerWeights: _t420\n                } = function (e, t) {\n                  var n = function (e, t) {\n                    var n = {};\n                    var s,\n                        r = 0;\n\n                    for (var _a143 of t) {\n                      var _t421 = _a143.name,\n                          _i105 = _a143.dtype,\n                          _o76 = _a143.shape,\n                          _l55 = d(_o76);\n\n                      var _u42 = void 0;\n\n                      if (\"quantization\" in _a143) {\n                        var _n296 = _a143.quantization;\n\n                        if (\"uint8\" === _n296.dtype || \"uint16\" === _n296.dtype) {\n                          if (!(\"min\" in _n296) || !(\"scale\" in _n296)) throw new Error(\"Weight \".concat(_a143.name, \" with quantization \").concat(_n296.dtype, \" doesn't have corresponding metadata min and scale.\"));\n                        } else {\n                          if (\"float16\" !== _n296.dtype) throw new Error(\"Weight \".concat(_a143.name, \" has unknown quantization dtype \").concat(_n296.dtype, \". Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.\"));\n                          if (\"float32\" !== _i105) throw new Error(\"Weight \".concat(_a143.name, \" is quantized with \").concat(_n296.dtype, \" which only supports weights of type float32 not \").concat(_i105, \".\"));\n                        }\n\n                        var _o77 = Ot[_n296.dtype],\n                            _c36 = e.slice(r, r + _l55 * _o77),\n                            _h19 = \"uint8\" === _n296.dtype ? new Uint8Array(_c36) : new Uint16Array(_c36);\n\n                        if (\"float32\" === _i105) {\n                          if (\"uint8\" === _n296.dtype || \"uint16\" === _n296.dtype) {\n                            _u42 = new Float32Array(_h19.length);\n\n                            for (var _e522 = 0; _e522 < _h19.length; _e522++) {\n                              _u42[_e522] = _h19[_e522] * _n296.scale + _n296.min;\n                            }\n                          } else {\n                            if (\"float16\" !== _n296.dtype) throw new Error(\"Unsupported quantization type \".concat(_n296.dtype, \" for weight type float32.\"));\n                            void 0 === s && (s = Vt()), _u42 = s(_h19);\n                          }\n                        } else {\n                          if (\"int32\" !== _i105) throw new Error(\"Unsupported dtype in weight '\".concat(_t421, \"': \").concat(_i105));\n                          if (\"uint8\" !== _n296.dtype && \"uint16\" !== _n296.dtype) throw new Error(\"Unsupported quantization type \".concat(_n296.dtype, \" for weight type int32.\"));\n                          _u42 = new Int32Array(_h19.length);\n\n                          for (var _e523 = 0; _e523 < _h19.length; _e523++) {\n                            _u42[_e523] = Math.round(_h19[_e523] * _n296.scale + _n296.min);\n                          }\n                        }\n                        r += _l55 * _o77;\n                      } else if (\"string\" === _i105) {\n                        var _t422 = d(_a143.shape);\n\n                        _u42 = [];\n\n                        for (var _n297 = 0; _n297 < _t422; _n297++) {\n                          var _t423 = new Uint32Array(e.slice(r, r + 4))[0];\n                          r += 4;\n\n                          var _n298 = new Uint8Array(e.slice(r, r + _t423));\n\n                          _u42.push(_n298), r += _t423;\n                        }\n                      } else {\n                        var _s245 = Ot[_i105],\n                            _a144 = e.slice(r, r + _l55 * _s245);\n\n                        if (\"float32\" === _i105) _u42 = new Float32Array(_a144);else if (\"int32\" === _i105) _u42 = new Int32Array(_a144);else if (\"bool\" === _i105) _u42 = new Uint8Array(_a144);else {\n                          if (\"complex64\" !== _i105) throw new Error(\"Unsupported dtype in weight '\".concat(_t421, \"': \").concat(_i105));\n                          {\n                            _u42 = new Float32Array(_a144);\n\n                            var _e524 = new Float32Array(_u42.length / 2),\n                                _s246 = new Float32Array(_u42.length / 2);\n\n                            for (var _t424 = 0; _t424 < _e524.length; _t424++) {\n                              _e524[_t424] = _u42[2 * _t424], _s246[_t424] = _u42[2 * _t424 + 1];\n                            }\n\n                            var _r173 = _t(_e524, _o76, \"float32\"),\n                                _i106 = _t(_s246, _o76, \"float32\");\n\n                            n[_t421] = Ft(_r173, _i106), _r173.dispose(), _i106.dispose();\n                          }\n                        }\n                        r += _l55 * _s245;\n                      }\n\n                      \"complex64\" !== _i105 && (n[_t421] = _t(_u42, _o76, _i105));\n                    }\n\n                    return n;\n                  }(e, t),\n                      s = {},\n                      r = [];\n\n                  return t.forEach(e => {\n                    \"optimizer\" === e.group ? r.push({\n                      name: e.name,\n                      tensor: n[e.name]\n                    }) : s[e.name] = n[e.name];\n                  }), {\n                    modelWeights: s,\n                    optimizerWeights: r\n                  };\n                }(s.weightData, s.weightSpecs);\n\n                o.loadWeights(_e521, a), null != o.optimizer && _t420.length > 0 && (yield o.optimizer.setWeights(_t420)), Jn(_e521), Jn(_t420.map(e => e.tensor));\n              }\n\n              return o;\n            });\n\n            return function (_x60, _x61, _x62) {\n              return _ref35.apply(this, arguments);\n            };\n          }()(e, 0, t);\n        });\n\n        return function (_x58, _x59) {\n          return _ref34.apply(this, arguments);\n        };\n      }()(a, i));\n      var a, i;\n      var o = yield r.predict(n);\n      return {\n        prediction: yield o.dataSync()\n      };\n    });\n\n    function predict(_x57) {\n      return _predict.apply(this, arguments);\n    }\n\n    return predict;\n  }()\n};\n\nfunction yS(e, t) {\n  self.postMessage({\n    type: \"progress\",\n    data: t\n  });\n}\n\nself.addEventListener(\"message\", /*#__PURE__*/function () {\n  var _ref36 = _asyncToGenerator(function* (t) {\n    var n = t.data,\n        {\n      worker: s\n    } = n,\n        r = function (e, t) {\n      if (null == e) return {};\n      var n,\n          s,\n          r = {},\n          a = Object.keys(e);\n\n      for (s = 0; s < a.length; s++) {\n        t.indexOf(n = a[s]) >= 0 || (r[n] = e[n]);\n      }\n\n      return r;\n    }(n, bS);\n\n    if (\"tf\" !== s) return;\n    var a = e({\n      worker: s\n    }, r, {\n      data: yield function () {\n        var _ref37 = _asyncToGenerator(function* (e) {\n          try {\n            var _t425 = xS[e.type];\n            return yield null == _t425 ? void 0 : _t425(e);\n          } catch (e) {\n            return void console.error(e);\n          }\n        });\n\n        return function (_x64) {\n          return _ref37.apply(this, arguments);\n        };\n      }()(n)\n    });\n    self.postMessage(a);\n  });\n\n  return function (_x63) {\n    return _ref36.apply(this, arguments);\n  };\n}()), console.debug(\"jacdac tf: worker registered\");"],"names":[],"sourceRoot":""}