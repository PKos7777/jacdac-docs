{"version":3,"file":"8e0cf18a-a659f84bba9bf6f8e267.js","mappings":";;;;;AAAA,wBAAwB,mBAAO,CAAC,KAAiI;;AAEjK,mBAAO,CAAC,KAAkC;;AAE1C;AACA;AACA,oBAAoB,sBAAsB;AAC1C;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,+EAA+E,gBAAgB;AAC/F;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC,iCAAiC;AACjC;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,4DAA4D,8CAA8C;AAC1G;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,4DAA4D,8CAA8C,6CAA6C;AACvJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,UAAU;AAClC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,wBAAwB,oBAAoB;AAChF;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,iCAAiC;AACjC;;AAEA;AACA,mBAAmB,oBAAoB;AACvC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,wFAAwF,aAAa;AACrG;AACA;;AAEA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,mDAAmD,+BAA+B,qBAAM,QAAQ,qBAAM,CAAC,sDAAsD;AAC7J;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS;AACT;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,0sCAA0sC;AAC1sC,EAAE;;AAEF;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD,WAAW;AACX;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4CAA4C,cAAc;AAC1D;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;;AAEA,WAAW,aAAa;AACxB;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;;AAEA,8DAA8D,4BAA4B;AAC1F;AACA;;AAEA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,SAAS;AAC1B;;AAEA,8GAA8G,0BAA0B;AACxI;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,gBAAgB;AACtC;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0EAA0E;AAC1E;;AAEA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,aAAa;AAC9C;;AAEA,wBAAwB,SAAS;AACjC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB,UAAU;AACjC;;AAEA;AACA;;AAEA;;AAEA,2BAA2B,UAAU;AACrC;;AAEA;AACA;AACA,IAAI,wBAAwB,UAAU;AACtC;;AAEA;AACA;;AAEA;AACA;;AAEA,oBAAoB,oBAAoB;AACxC;AACA;;AAEA;;AAEA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,4FAA4F,eAAe;AAC3G;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,wEAAwE,eAAe;AACvF;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,qBAAqB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,oCAAoC,2BAA2B;AAC/D;;AAEA;AACA;;AAEA;AACA,2FAA2F;AAC3F;;AAEA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP,KAAK,SAAS;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA,SAAS;;AAET;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,4CAA4C;AACnE;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB;AAChB;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA;AACA;;AAEA;;AAEA,6BAA6B,iBAAiB;AAC9C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;;AAEA,2BAA2B,4BAA4B;AACvD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,yBAAyB,iBAAiB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qCAAqC;;AAErC;AACA;AACA;;AAEA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sCAAsC,WAAW;AACjD;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0EAA0E,eAAe;AACzF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,SAAS,2CAA2C;AACpD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,kBAAkB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,WAAW;;AAEX;AACA;AACA;AACA,SAAS;;AAET;AACA,QAAQ;;AAER;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,aAAa,mBAAmB;AAChC;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA,uBAAuB,aAAa;AACpC;AACA;;AAEA,0BAA0B,aAAa;AACvC;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;;AAEA,uBAAuB,WAAW;AAClC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA,GAAG;AACH;AACA;;AAEA,uBAAuB,WAAW;AAClC;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX,UAAU;AACV;AACA;;AAEA;;AAEA;AACA;AACA;AACA,WAAW;;AAEX;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa;;AAEb;AACA;AACA,aAAa;AACb;;AAEA;;AAEA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,gDAAgD,aAAa;AAC7D;AACA;;AAEA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,2BAA2B,iBAAiB;AAC5C;AACA;;AAEA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,gBAAgB;AAChB;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA;AACA,IAAI;AACJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,mBAAO,CAAC,KAAM;AAC9B;;AAEA;AACA,oFAAoF,mBAAO,CAAC,KAAY;AACxG;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA,0DAA0D;AAC1D;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,oGAAoG;AACpG;AACA;AACA;AACA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,mBAAmB;AACxC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,4BAA4B,iBAAiB;AAC7C;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI,wBAAwB,UAAU;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,0CAA0C;AAC1C;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,gEAAgE;AAChE;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,KAAK,iEAAiE;AACtE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,aAAa,uBAAuB;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,kCAAkC,WAAW;AAC7C,2CAA2C;AAC3C;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;AACA,gEAAgE,qCAAqC;AACrG;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA,gCAAgC;AAChC;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,yBAAyB,UAAU;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,eAAe;AACtC;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA,8GAA8G,qBAAM,GAAG,qBAAM;;AAE7H;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,cAAc;AACtC;AACA;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,oCAAoC,6BAA6B,cAAc;AAC/E;AACA;;AAEA,eAAe,aAAa;AAC5B;AACA;;AAEA,oBAAoB,qBAAqB;AACzC;AACA;;AAEA,+DAA+D,OAAO;AACtE;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gHAAgH,OAAO;AACvH;AACA;;AAEA,iFAAiF,OAAO;AACxF;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP,sBAAsB,mBAAmB;AACzC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;;AAEV;AACA,OAAO;AACP,sBAAsB;AACtB,OAAO;AACP;;AAEA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ,SAAS;AACjB;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,2CAA2C,MAAM;AACjD;AACA;;AAEA,eAAe,OAAO;AACtB;AACA;;AAEA;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA,wBAAwB;AACxB,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,6BAA6B,MAAM;AACnC;AACA;;AAEA,kBAAkB,OAAO;AACzB;AACA;;AAEA;AACA,sDAAsD,IAAI;AAC1D;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA,qCAAqC,aAAa;AAClD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA,GAAG;AACH,CAAC;;AAED;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,WAAW,GAAG;AACd;AACA;AACA;;AAEA;AACA;AACA,QAAQ;;AAER;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iLAAiL;AACjL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,OAAO;AACrF;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,uBAAuB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW,gBAAgB;AAC3B;AACA;;AAEA,kBAAkB,WAAW;AAC7B;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa,MAAM;AACnB;;AAEA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,SAAS,6BAA6B;AACtC;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;;AAEA;;AAEA,kCAAkC,cAAc;AAChD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,2BAA2B,iBAAiB;AAC5C;AACA;AACA,OAAO;AACP,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;AACA;AACA,yCAAyC,aAAa;AACtD;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;;AAEA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC,eAAe;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA,UAAU;AACV;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,8EAA8E;AAC9E;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,UAAU;AACrC;AACA;AACA,IAAI;AACJ;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,yBAAyB;AAC9C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,UAAU;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;;AAEA,qBAAqB,iBAAiB;AACtC;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,iJAAiJ;AACjJ;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uEAAuE,GAAG;AAC1E;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA,yBAAyB,UAAU;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,kCAAkC,WAAW;AAC7C,2CAA2C;AAC3C;;AAEA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,yBAAyB,2BAA2B;AACpD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC,uBAAuB,uBAAu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uBAAuB,eAAe;AACtC;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA,UAAU,0CAA0C,aAAa;AACjE,6BAA6B,aAAa;AAC1C;AACA;AACA,UAAU,0CAA0C,aAAa;AACjE,6BAA6B,aAAa;AAC1C,+BAA+B,aAAa;AAC5C;AACA;AACA;AACA,UAAU;AACV;;AAEA,6BAA6B,aAAa;AAC1C,+BAA+B,aAAa;AAC5C,iCAAiC,aAAa;AAC9C,mCAAmC,aAAa;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2BAA2B,UAAU;AACrC;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,qFAAqF;AACrF;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,kCAAkC,qCAAqC;AACvE;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,iCAAiC;;AAEjC;AACA;AACA;;AAEA;;AAEA;;AAEA,kCAAkC;AAClC;;AAEA;AACA,iCAAiC;;AAEjC;AACA;AACA;;AAEA;;AAEA,kCAAkC;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,kGAAkG;;AAElG;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA,UAAU;AACV;;AAEA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,sEAAsE;AACtE;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;AACA,4CAA4C;AAC5C;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,iDAAiD,0BAA0B;AAC3E;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,eAAe;AACf;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,SAAS;AACT;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,iTAAiT;AACjT;;AAEA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,mCAAmC;AAC5D;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA,KAAK;AACL,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC,eAAe;;AAEhB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;AACA,4CAA4C;AAC5C;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;AAC1B;AACA;;AAEA;AACA;AACA,6JAA6J;AAC7J;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;;AAEA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA,6BAA6B;AAC7B;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,qBAAqB;AACrB;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;;AAEA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;;AAEA;AACA,qFAAqF,oCAAoC;AACzH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,yEAAyE;AACzE;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,aAAa;AACpC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0BAA0B,mBAAmB,mBAAmB;AAChE;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA,mBAAmB;AACnB;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB;;AAExB;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,oBAAoB;AAC5C;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,aAAa;AAC/B;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,wGAAwG;AACxG;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,wEAAwE;AACxE;;AAEA,wBAAwB,2CAA2C;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB;AAChB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,cAAc;AACd,cAAc;AACd,cAAc;AACd,cAAc;AACd,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB,mCAAmC;AAC5D;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sDAAsD;AACtD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,4BAA4B,oCAAoC;AAChE;AACA;;AAEA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kCAAkC;AAC1D;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,2BAA2B;AAClD;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;;AAEZ;;AAEA,8BAA8B,qBAAqB;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,yBAAyB,kCAAkC;AAC3D;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,2BAA2B,kCAAkC;AAC7D;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB,kCAAkC;AAC3D;AACA;;AAEA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;;AAEA,+BAA+B,kCAAkC;AACjE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kCAAkC;AAC1D;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,cAAc;AACd;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,WAAW,OAAO;AAClB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,yIAAyI,mBAAmB;AAC5J;AACA;AACA;AACA;;AAEA;AACA,qIAAqI;AACrI;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA,uIAAuI;AACvI;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,oCAAoC,wDAAwD;AAC5F;AACA;AACA;AACA,2DAA2D;AAC3D;AACA,GAAG,EAAE;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,gDAAgD,kBAAkB;AAClE;AACA;AACA;;AAEA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,qCAAqC,kBAAkB;AACvD;AACA;AACA;;AAEA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,0CAA0C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA,SAAS;AACT;AACA,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,6BAA6B;AACrD;AACA;AACA;;AAEA;AACA;AACA,0BAA0B,6BAA6B;AACvD;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;;AAEA,0BAA0B,6BAA6B;AACvD;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,0DAA0D,kBAAkB;AAC5E;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,sCAAsC,kBAAkB;AACxD;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA,aAAa;AACb;AACA;AACA;AACA;;AAEA,iBAAiB,oBAAoB;AACrC;;AAEA;AACA;;AAEA,8BAA8B,kBAAkB;AAChD;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,iBAAiB;AAC1C;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oDAAoD,kBAAkB;AACtE;AACA;AACA;AACA,aAAa;AACb,YAAY;AACZ;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,sCAAsC;AAC9D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,sBAAsB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;;AAEA,+CAA+C,oBAAoB;AACnE;AACA;;AAEA,8BAA8B,oBAAoB;AAClD;AACA;AACA;;AAEA,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,4BAA4B;AACxD;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA,4BAA4B,mCAAmC;AAC/D;;AAEA;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oCAAoC;AAChE;;AAEA,uFAAuF;AACvF;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,4BAA4B;AACtD;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA,0BAA0B,mCAAmC;AAC7D;;AAEA;AACA;;AAEA,0BAA0B,oCAAoC;AAC9D;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,0RAA0R;AAC1R;;AAEA;AACA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;AACA,cAAc;;AAEd;;AAEA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8CAA8C,kBAAkB;AAChE;AACA;AACA;;AAEA;AACA;;AAEA,gDAAgD,kBAAkB;AAClE;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;;AAEA,yCAAyC,iBAAiB;AAC1D;;AAEA;AACA;;AAEA;AACA,qBAAqB;AACrB;AACA;AACA;;AAEA,mCAAmC,UAAU;AAC7C;;AAEA;AACA;;AAEA;AACA,eAAe;;AAEf;AACA;AACA;AACA,aAAa;AACb,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,uUAAuU;AACvU;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;;AAEf;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,aAAa;;AAEb;;AAEA;AACA;;AAEA,mBAAmB,eAAe;AAClC;AACA;AACA;AACA;;AAEA,oDAAoD,+BAA+B;AACnF;;AAEA;AACA,4KAA4K;AAC5K;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;;AAEA;AACA;;AAEA,wCAAwC,sBAAsB;AAC9D;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,sCAAsC,qBAAqB;AAC3D;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;;AAErB,wCAAwC,+BAA+B;AACvE;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,2DAA2D;AAC7G;;AAEA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,cAAc;AACnB;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA,SAAS;;AAET;AACA;;AAEA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,wHAAwH;AACxH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,iDAAiD;AACjD;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,yBAAyB;AACzB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,mDAAmD;AAC5E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,6BAA6B,oEAAoE,2PAA2P,qEAAqE;AACja;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,kBAAkB;AACvE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,6BAA6B,kDAAkD;AAC/E;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,kDAAkD;AAC3E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB,iDAAiD;AAC1E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,2GAA2G;AAC3G,MAAM,kJAAkJ;AACxJ;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,4IAA4I;AAC5I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS,iGAAiG,2HAA2H;AACrO;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,mBAAmB;AAC3C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;;AAEP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,eAAe;AACzC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,2MAA2M;AAC3M,MAAM;AACN;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8JAA8J,4PAA4P;AAC1Z;AACA;;AAEA,4BAA4B,6BAA6B;AACzD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,mBAAmB;AACxB;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,SAAS;AACT,QAAQ;;AAER;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,2BAA2B;AAC3B;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,0BAA0B,8BAA8B;AACxD;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uIAAuI,iOAAiO;AACxW;AACA;;AAEA,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,0BAA0B;AAC1B;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAS;AACT,QAAQ;;AAER;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,kDAAkD,cAAc;AAChE;AACA;AACA;;AAEA;AACA,KAAK;;AAEL,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,gCAAgC;AACxD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,qBAAqB;AACrB;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,gBAAgB;AAC5C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA,wBAAwB,iCAAiC;AACzD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,yBAAyB;AACzB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA,6EAA6E,kCAAkC,kCAAkC;AACjJ;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,gCAAgC,uBAAuB;AACvD;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA,cAAc;AACd;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA,0DAA0D;AAC1D;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA,UAAU;AACV;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA,UAAU;;AAEV;AACA;;AAEA;AACA;;AAEA,kCAAkC,mBAAmB;AACrD;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA,6CAA6C,gDAAgD;AAC7F;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,wBAAwB;AACxB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4BAA4B;AAC5B;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,0BAA0B;AAClD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4BAA4B,wIAAwI,uGAAuG;AAC3Q;;AAEA;;AAEA,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA,sHAAsH;AACtH;AACA;AACA;AACA,uFAAuF,kEAAkE;AACzJ;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,kMAAkM;AAClM;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,iNAAiN;AACjN;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,yFAAyF;AACzF;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,CAAC,eAAe;AAChB;AACA,mEAAmE;AACnE,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,wYAAwY;AACxY;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,kBAAkB;AACzE;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,kBAAkB;AACzE;AACA;AACA;;AAEA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B,uBAAuB,UAAU;AACjC;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA;;AAEA,0BAA0B,oBAAoB;AAC9C;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA;AACA;;AAEA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,4BAA4B,WAAW;AACvC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,4BAA4B,YAAY;AACxC;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,YAAY;AACxC;AACA;AACA;;AAEA;;AAEA,sBAAsB,WAAW;AACjC;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,+BAA+B,WAAW;AAC1C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,gBAAgB;AACtC;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,0BAA0B,eAAe;AACzC;AACA;;AAEA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA,QAAQ;AACR,4BAA4B,eAAe;AAC3C;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB,UAAU;AACjC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,UAAU;AACnC;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,0BAA0B,YAAY;AACtC;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA,wBAAwB,YAAY;AACpC;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,WAAW,YAAY;AACvB;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA,qBAAqB,qBAAqB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,UAAU;AAC/B;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;;AAEA,sBAAsB,yBAAyB;AAC/C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,uDAAuD,YAAY;AACnE,6CAA6C,sBAAsB;AACnE;AACA;;AAEA,aAAa,sBAAsB;AACnC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA,YAAY;AACZ;AACA;AACA;AACA;;AAEA,sBAAsB,cAAc;AACpC;;AAEA,uCAAuC;AACvC;;AAEA,0BAA0B,cAAc;AACxC,4BAA4B,cAAc;AAC1C;AACA;AACA;;AAEA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC,0BAA0B,cAAc;AACxC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,iCAAiC,aAAa;AAC9C,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,aAAa;AAClD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,aAAa;AAC7C;;AAEA,mCAAmC,cAAc;AACjD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C,wBAAwB,sBAAsB;AAC9C,0BAA0B,qBAAqB;AAC/C;;AAEA;;AAEA,eAAe,QAAQ;AACvB;AACA;;AAEA;;AAEA,2BAA2B,mBAAmB;AAC9C;;AAEA;;AAEA,iBAAiB,QAAQ;AACzB;AACA;;AAEA;;AAEA;AACA;;AAEA,gCAAgC,cAAc;AAC9C;;AAEA,iCAAiC,YAAY;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,eAAe,QAAQ;AACvB;AACA;;AAEA;AACA;;AAEA,4BAA4B,qBAAqB;AACjD;;AAEA;;AAEA,iBAAiB,SAAS;AAC1B;AACA;;AAEA;AACA;;AAEA,8BAA8B,oBAAoB;AAClD;;AAEA;;AAEA,mBAAmB,SAAS;AAC5B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,kCAAkC,YAAY;AAC9C;;AAEA,qCAAqC,cAAc;AACnD;;AAEA,uCAAuC,cAAc;AACrD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK,EAAE;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,mBAAmB;AAC/C,8BAA8B,oBAAoB;AAClD,gCAAgC,mBAAmB;AACnD;AACA;AACA;;AAEA;;AAEA,kCAAkC,WAAW;AAC7C;;AAEA,4GAA4G,WAAW;AACvH;;AAEA,+GAA+G,WAAW;AAC1H;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,oBAAoB;AAChD,8BAA8B,mBAAmB;AACjD;AACA;;AAEA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,2GAA2G,WAAW;AACtH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;;AAEA,gCAAgC,sBAAsB;AACtD;;AAEA,kCAAkC,uBAAuB;AACzD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,2BAA2B,qBAAqB;AAChD,6BAA6B,sBAAsB;AACnD;;AAEA,+BAA+B,oBAAoB;AACnD,qCAAqC,cAAc;AACnD;;AAEA,wCAAwC,cAAc;AACtD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;;AAEA,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,cAAc;AACnD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,oBAAoB;AAC9C;AACA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;AACA;;AAEA,8BAA8B,qBAAqB;AACnD;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;;AAEA;AACA;;AAEA,kCAAkC,oBAAoB;AACtD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;;AAEA;;AAEA;;AAEA;;AAEA,sCAAsC,sBAAsB;AAC5D;;AAEA,wCAAwC,uBAAuB;AAC/D;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,qBAAqB;AAClD;;AAEA,+BAA+B,sBAAsB;AACrD;;AAEA,iCAAiC,oBAAoB;AACrD;AACA;;AAEA,uCAAuC,cAAc;AACrD;AACA;;AAEA,yCAAyC,cAAc;AACvD;AACA;;AAEA,2CAA2C,cAAc;AACzD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA,+BAA+B,UAAU;AACzC;AACA;AACA;;AAEA;;AAEA,sCAAsC,cAAc;AACpD;;AAEA,uCAAuC,cAAc;AACrD;;AAEA,wCAAwC,YAAY;AACpD;AACA;;AAEA,wCAAwC,WAAW;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,0DAA0D,WAAW;AACrE,8BAA8B,WAAW;AACzC;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;;AAEA;AACA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,UAAU,yBAAyB,WAAW;AAC9C;;AAEA;AACA,gCAAgC,WAAW;AAC3C;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C,0BAA0B,WAAW;AACrC;;AAEA,qDAAqD;AACrD;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,qBAAqB;AAC3C;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;;AAEA,4BAA4B,oBAAoB;AAChD;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;AACA;;AAEA,gCAAgC,sBAAsB;AACtD;;AAEA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA,2BAA2B,sBAAsB;AACjD;AACA;;AAEA;;AAEA,6BAA6B,oBAAoB;AACjD,mCAAmC,cAAc;AACjD;;AAEA,sCAAsC,cAAc;AACpD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;;AAEA,oCAAoC,cAAc;AAClD;;AAEA,qCAAqC,cAAc;AACnD;AACA;;AAEA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,2BAA2B,UAAU;AACrC;;AAEA,6BAA6B,UAAU;AACvC;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,+DAA+D,WAAW;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA,UAAU;;AAEV;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;;AAET;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,MAAM;AACN;;AAEA,wBAAwB,WAAW;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,8BAA8B,WAAW;AACzC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,aAAa,QAAQ;AACrB;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,8BAA8B,eAAe;AAC7C;AACA;;AAEA;;AAEA,8BAA8B,eAAe;AAC7C;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,wBAAwB,sBAAsB;AAC9C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK,EAAE;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB,oBAAoB;AAC7C,2BAA2B,qBAAqB;AAChD,6BAA6B,mBAAmB;AAChD;;AAEA;;AAEA,mBAAmB,QAAQ;AAC3B;AACA;;AAEA;;AAEA,gCAAgC,qBAAqB;AACrD;;AAEA;;AAEA,qBAAqB,SAAS;AAC9B;AACA;;AAEA;;AAEA,kCAAkC,oBAAoB;AACtD;;AAEA;;AAEA,uBAAuB,QAAQ;AAC/B;AACA;;AAEA;;AAEA;AACA;;AAEA,sCAAsC,aAAa;AACnD;;AAEA,yCAAyC,aAAa;AACtD;;AAEA,0CAA0C,aAAa;AACvD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,mBAAmB;AAC/C,8BAA8B,oBAAoB;AAClD,gCAAgC,mBAAmB;AACnD;AACA;AACA;;AAEA;;AAEA,kCAAkC,WAAW;AAC7C;;AAEA,4GAA4G,WAAW;AACvH;;AAEA,8GAA8G,UAAU;AACxH;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,qBAAqB;AAC7C,0BAA0B,sBAAsB;AAChD,4BAA4B,oBAAoB;AAChD,8BAA8B,mBAAmB;AACjD;AACA;;AAEA;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA,2GAA2G,WAAW;AACtH;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;AACA;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA;;AAEA;;AAEA;;AAEA,4BAA4B,WAAW;AACvC;;AAEA;;AAEA;;AAEA;;AAEA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA,4BAA4B,WAAW;AACvC;AACA;AACA;;AAEA,8BAA8B,WAAW;AACzC;;AAEA,gCAAgC,WAAW;AAC3C;;AAEA;;AAEA;AACA;;AAEA,0GAA0G,WAAW;AACrH;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,gBAAgB;AACxC;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC;;AAEA,4BAA4B,WAAW;AACvC;;AAEA,6BAA6B,UAAU;AACvC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB,WAAW;AACjC;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C,0BAA0B,WAAW;AACrC;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,mCAAmC,wBAAwB;AAC3D;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,oEAAoE;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;;AAEA;AACA;AACA,UAAU,sCAAsC;AAChD;;AAEA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,0BAA0B,WAAW;AACrC,4BAA4B,WAAW;AACvC,8BAA8B,WAAW;AACzC;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA,OAAO;AACP,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;AACA,CAAC,eAAe;AAChB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA,mKAAmK,8CAA8C,+DAA+D,SAAS,wCAAwC,sHAAsH,SAAS,uJAAuJ,yCAAyC,SAAS,sCAAsC,iDAAiD,SAAS,2MAA2M,oEAAoE,SAAS,sCAAsC,+EAA+E,SAAS,6CAA6C,iCAAiC,sCAAsC,SAAS,+BAA+B,iDAAiD,SAAS,8CAA8C,yCAAyC,SAAS,mCAAmC,iDAAiD,SAAS;AAClhD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kFAAkF,4JAA4J;AAC9O;;AAEA;AACA;AACA;AACA,mGAAmG,sMAAsM;AACzS;;AAEA;AACA;AACA,8CAA8C,mFAAmF,KAAK;AACtI;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;AACA,CAAC;AACD,oDAAoD,2CAA2C,6CAA6C,qBAAqB,wCAAwC,OAAO,gCAAgC,4BAA4B,wCAAwC,QAAQ,wBAAwB,oDAAoD,QAAQ,yBAAyB,qDAAqD,OAAO,qCAAqC,wCAAwC,kDAAkD,gCAAgC,wBAAwB,gCAAgC,0BAA0B,kCAAkC,sCAAsC,gCAAgC,0BAA0B,mCAAmC,sCAAsC,yBAAyB,KAAK;AAC/7B;AACA;AACA,EAAE;;AAEF;AACA;;AAEA;AACA;;AAEA,iHAAiH,oDAAoD,kDAAkD;AACvN;AACA;AACA,QAAQ;;AAER;AACA;AACA,sDAAsD;AACtD;;AAEA;AACA,wDAAwD;AACxD;;AAEA;AACA,wDAAwD;AACxD;;AAEA;AACA,wDAAwD;AACxD;;AAEA,uDAAuD;AACvD;AACA,GAAG;AACH;AACA;AACA,qCAAqC;AACrC;;AAEA;AACA,uCAAuC,wCAAwC;AAC/E;;AAEA;AACA,uCAAuC,0CAA0C;AACjF;;AAEA;AACA,uCAAuC,0CAA0C;AACjF;;AAEA,sCAAsC;AACtC;;AAEA;AACA,qHAAqH;AACrH,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,gDAAgD;AAC9G;AACA;AACA,kCAAkC;AAClC;AACA;;AAEA;AACA,gGAAgG,kDAAkD,UAAU;AAC5J;AACA;;AAEA,2FAA2F,yGAAyG,+EAA+E;AACnR;AACA,QAAQ,8DAA8D;;AAEtE,0CAA0C,kDAAkD,mFAAmF,6BAA6B;AAC5M,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,6JAA6J,yDAAyD,SAAS;AAC/N;AACA;AACA;AACA;AACA;AACA,8DAA8D,gDAAgD;AAC9G;AACA,0JAA0J,kDAAkD,uEAAuE,OAAO;AAC1R,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA,0EAA0E,6DAA6D,OAAO;AAC9I,GAAG;;AAEH;AACA;AACA;AACA,6DAA6D,0BAA0B,gCAAgC,6CAA6C,0EAA0E,2BAA2B,cAAc,cAAc,cAAc,cAAc,cAAc,QAAQ,2BAA2B,cAAc,cAAc,cAAc,cAAc,cAAc,cAAc,QAAQ,0BAA0B,0IAA0I,+BAA+B,OAAO,4CAA4C,wBAAwB,6BAA6B,oCAAoC,mBAAmB,SAAS,mBAAmB,OAAO,wJAAwJ,iCAAiC,mDAAmD,sCAAsC,2CAA2C,OAAO;AACvpC,GAAG;;AAEH;AACA;AACA;AACA,6CAA6C,iBAAiB,OAAO;;AAErE;AACA;AACA;AACA,kEAAkE,yEAAyE,SAAS,0CAA0C,0DAA0D,SAAS,4DAA4D,yEAAyE,SAAS,0CAA0C,0DAA0D,SAAS,6CAA6C,2GAA2G,uHAAuH,iEAAiE,OAAO,sCAAsC,sHAAsH,iEAAiE,OAAO;AACvjC,SAAS;;AAET;AACA;AACA;AACA,oEAAoE,6GAA6G,qFAAqF,SAAS,4CAA4C,oFAAoF,SAAS;AACxZ;AACA,qDAAqD,2GAA2G,qEAAqE,uHAAuH,kEAAkE,iDAAiD,oDAAoD,6BAA6B,OAAO,wCAAwC,sHAAsH,kEAAkE,6CAA6C,gDAAgD,6BAA6B,OAAO;AACx4B,SAAS;;AAET;AACA;AACA,wDAAwD,2GAA2G,qEAAqE,qFAAqF,uHAAuH,gEAAgE,wCAAwC,mCAAmC,mDAAmD,oDAAoD,gCAAgC,OAAO;AAC7sB;AACA;AACA;AACA,iDAAiD,sHAAsH,gEAAgE,yCAAyC,oCAAoC,+CAA+C,gDAAgD,gCAAgC,OAAO;AAC1b,SAAS;;AAET;AACA;AACA,wDAAwD,2GAA2G,uHAAuH,gEAAgE,uEAAuE,qFAAqF,yDAAyD,0CAA0C,qCAAqC,wCAAwC,mCAAmC,mDAAmD,oDAAoD,oCAAoC,OAAO;AAC31B;AACA;AACA;AACA;AACA;AACA;;AAEA,8BAA8B,sBAAsB;AACpD,uGAAuG,sDAAsD;AAC7J;;AAEA,oEAAoE,uHAAuH,gEAAgE,iEAAiE,oCAAoC,+CAA+C,gDAAgD,2DAA2D,OAAO;AACjgB,SAAS;AACT;AACA,GAAG;AACH,4CAA4C,mCAAmC,OAAO;AACtF,GAAG;AACH;AACA;AACA,6CAA6C,iBAAiB,OAAO;;AAErE;AACA;AACA,kEAAkE,yDAAyD,SAAS,0CAA0C,sDAAsD,SAAS,4DAA4D,yDAAyD,SAAS,0CAA0C,sDAAsD,SAAS,6CAA6C,iHAAiH,wDAAwD,OAAO,sCAAsC,sHAAsH,2DAA2D,OAAO;AAC/4B,SAAS;;AAET;AACA;AACA,iEAAiE,2EAA2E,SAAS,4CAA4C,gFAAgF,SAAS,8DAA8D,qHAAqH,+DAA+D,iCAAiC,SAAS,4CAA4C,0HAA0H,kEAAkE,iCAAiC,SAAS,8DAA8D,qHAAqH,+DAA+D,iCAAiC,SAAS,4CAA4C,0HAA0H,kEAAkE,iCAAiC,SAAS,+CAA+C,iHAAiH,6DAA6D,oCAAoC,wCAAwC,2BAA2B,OAAO,wCAAwC,sHAAsH,gEAAgE,0CAA0C,8CAA8C,2BAA2B,OAAO;AACzhE,SAAS;;AAET;AACA;AACA,sDAAsD,6GAA6G,2DAA2D,oEAAoE,KAAK;AACvS;AACA,iDAAiD,sHAAsH,gEAAgE,oDAAoD,OAAO;AAClS,SAAS;;AAET;AACA;AACA,wDAAwD,4FAA4F,6DAA6D,kFAAkF,OAAO;AAC1S;AACA,iDAAiD,iGAAiG,gEAAgE,wDAAwD,OAAO;AACjR,SAAS;;AAET;AACA;AACA;AACA,iDAAiD,sHAAsH,kEAAkE,0EAA0E,wBAAwB,OAAO;AAClV,SAAS;;AAET;AACA;AACA;AACA,iDAAiD,iGAAiG,gEAAgE,4EAA4E,sBAAsB,OAAO;AAC3T,SAAS;;AAET;AACA;AACA;AACA,GAAG;AACH,6CAA6C,kDAAkD,OAAO;AACtG,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,kEAAkE,uBAAuB;AACzF;AACA,uEAAuE,uDAAuD,SAAS;AACvI;AACA,oDAAoD,mGAAmG,iDAAiD,OAAO;AAC/M;AACA,6CAA6C,6EAA6E,iDAAiD,OAAO;AAClL,OAAO;;AAEP;AACA;AACA;AACA;AACA,mFAAmF,qCAAqC;AACxH;AACA;AACA;AACA,gFAAgF,uDAAuD,SAAS;AAChJ;AACA,sEAAsE,wGAAwG,mDAAmD,SAAS,oDAAoD,wFAAwF,mDAAmD,SAAS,kEAAkE,wGAAwG,mDAAmD,SAAS,oDAAoD,wFAAwF,mDAAmD,SAAS,sDAAsD,2GAA2G,iDAAiD,OAAO,gDAAgD,qFAAqF,iDAAiD,OAAO;AACtvC,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,2GAA2G,mDAAmD,SAAS,yDAAyD,6FAA6F,iDAAiD,OAAO;AACld;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,qGAAqG,2DAA2D,SAAS;AACzK;;AAEA,0FAA0F,6EAA6E,qCAAqC;AAC5M;AACA;AACA;AACA,6EAA6E,gGAAgG,gFAAgF,mDAAmD,SAAS,yDAAyD,yFAAyF,8DAA8D,iDAAiD,OAAO,uEAAuE,gGAAgG,gFAAgF,mDAAmD,SAAS,yDAAyD,yFAAyF,8DAA8D,iDAAiD,OAAO,6DAA6D,uJAAuJ,4FAA4F,mDAAmD,SAAS,uDAAuD,0IAA0I,kEAAkE,+CAA+C,KAAK;AAC/xD,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,oHAAoH,6DAA6D,WAAW;AAC5L;;AAEA,qGAAqG,4HAA4H,qCAAqC;AACtQ;AACA;AACA;AACA;AACA,wGAAwG,+CAA+C,kCAAkC,+DAA+D,iIAAiI,mDAAmD,SAAS,wEAAwE,oCAAoC,wEAAwE,mHAAmH,qDAAqD,WAAW;AAC5xB,wGAAwG,4EAA4E,oCAAoC,6GAA6G,mDAAmD,SAAS,oEAAoE,qEAAqE,kCAAkC,yFAAyF,iDAAiD,OAAO;AAC7rB;AACA,4EAA4E,iJAAiJ,6CAA6C,yFAAyF,0FAA0F,iDAAiD,OAAO,sEAAsE,wKAAwK,sEAAsE,mDAAmD,SAAS;AACr2B,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,4HAA4H,2DAA2D,SAAS;AAChM;;AAEA,iHAAiH,oJAAoJ,qCAAqC;AAC1S;AACA;AACA;AACA;AACA,qDAAqD;AACrD,+DAA+D;AAC/D,+DAA+D;AAC/D,oHAAoH,kFAAkF,8GAA8G,iIAAiI,mDAAmD,SAAS,kFAAkF,kCAAkC,4HAA4H,+GAA+G,mDAAmD,SAAS;AAC54B,oHAAoH,8JAA8J,qCAAqC,gIAAgI,mDAAmD,SAAS,kFAAkF,kIAAkI,qCAAqC,8GAA8G,mDAAmD,SAAS;AACt5B;AACA,wFAAwF,qOAAqO,2GAA2G,iDAAiD,OAAO,8EAA8E,wLAAwL,qFAAqF,iDAAiD,OAAO;AACn3B,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,qIAAqI,2DAA2D,SAAS;AACzM;;AAEA,6HAA6H,4KAA4K,qCAAqC;AAC9U;AACA;AACA;AACA;AACA,yHAAyH,yBAAyB,gJAAgJ,+GAA+G,mDAAmD,SAAS,qHAAqH,wLAAwL,4BAA4B,8GAA8G,mDAAmD,SAAS,4FAA4F,uOAAuO,oEAAoE,iDAAiD,OAAO;AAC/3C,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;;AAEV;AACA;AACA,sKAAsK,2DAA2D,SAAS;AAC1O;;AAEA;AACA;AACA;AACA;AACA;AACA,4JAA4J,wPAAwP,qCAAqC;AACzb;AACA;AACA;AACA;AACA,0JAA0J,yBAAyB,8KAA8K,+GAA+G,mDAAmD,SAAS,sJAAsJ,iQAAiQ,4BAA4B,8GAA8G,mDAAmD,SAAS,2HAA2H,iQAAiQ,oEAAoE,iDAAiD,OAAO;AACjmD,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yFAAyF,mEAAmE,OAAO;AACnK,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,iIAAiI,wFAAwF,4DAA4D,OAAO;AACxV;AACA,qDAAqD,wFAAwF,4DAA4D,OAAO;AAChN,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,2GAA2G,gEAAgE,SAAS,0DAA0D,yFAAyF,gEAAgE,SAAS;AAC5e,mEAAmE,iIAAiI,0EAA0E,+FAA+F,4DAA4D,OAAO;AAChb;AACA,4DAA4D,mHAAmH,4DAA4D,OAAO;AAClP,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wHAAwH,iEAAiE,WAAW;AACpM;;AAEA;AACA,0EAA0E,iIAAiI,0EAA0E,0FAA0F,2HAA2H,4DAA4D,OAAO;AAC7iB;AACA;AACA;AACA,mEAAmE,8IAA8I,4DAA4D,OAAO;AACpR,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA,kFAAkF,0EAA0E,0FAA0F,6EAA6E,gDAAgD,2CAA2C,iIAAiI,6CAA6C,oDAAoD,4FAA4F,oDAAoD,OAAO;AACvxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,eAAe;AAC3C;AACA;;AAEA,0DAA0D,mCAAmC,0CAA0C,iDAAiD,qFAAqF,4DAA4D,OAAO;AAChV,OAAO;AACP;AACA;;AAEA,kEAAkE,+BAA+B,sCAAsC,gEAAgE,GAAG,4DAA4D,+BAA+B,oCAAoC,2CAA2C,gEAAgE,GAAG;AACvb,wGAAwG,gEAAgE,oCAAoC,2CAA2C,gEAAgE,GAAG;AAC1T,yIAAyI,+EAA+E,+BAA+B,sCAAsC,gEAAgE,GAAG;AAChW,2DAA2D,yCAAyC,0HAA0H,KAAK,0CAA0C,2CAA2C,8CAA8C,KAAK;;AAE3W;AACA;AACA;;AAEA;AACA;AACA;AACA,uCAAuC,4BAA4B,mBAAmB,MAAM,yBAAyB,mCAAmC,SAAS,OAAO;AACxK;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oJAAoJ,gIAAgI,SAAS,uBAAuB,+EAA+E,kEAAkE,mCAAmC,0BAA0B,KAAK,MAAM,sCAAsC,yDAAyD,+CAA+C,WAAW,2CAA2C,SAAS;AAC1tB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oJAAoJ,gIAAgI,SAAS,uBAAuB,+EAA+E,kEAAkE,mCAAmC,0BAA0B,KAAK,MAAM,sCAAsC,yDAAyD,6EAA6E,WAAW,2CAA2C,SAAS;AACxvB;;AAEA;;AAEA;AACA;AACA;AACA;AACA,wFAAwF,sCAAsC,kDAAkD,SAAS;AACzL;;AAEA;;AAEA;AACA;AACA;AACA;AACA,wFAAwF,2CAA2C,4EAA4E,kDAAkD,SAAS;AAC1Q;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,+IAA+I,sFAAsF,KAAK,qCAAqC,2CAA2C,iDAAiD,0CAA0C,+CAA+C,4CAA4C,+CAA+C,2EAA2E,wDAAwD,yBAAyB,6BAA6B,+BAA+B,YAAY,sBAAsB,+BAA+B,YAAY,sBAAsB,+BAA+B,YAAY,MAAM,+BAA+B,WAAW,qEAAqE,SAAS;AACngC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,YAAY;AACpC,0BAA0B,YAAY;AACtC;;AAEA,+CAA+C,8HAA8H,iDAAiD,gIAAgI,mDAAmD,sDAAsD,0CAA0C,mDAAmD,gDAAgD,mDAAmD,+EAA+E,uDAAuD,kCAAkC,uDAAuD,gBAAgB,uBAAuB,uDAAuD,gBAAgB,uBAAuB,uDAAuD,gBAAgB,MAAM,uDAAuD,eAAe,aAAa,WAAW;AACtpC;AACA;;AAEA,wGAAwG,sFAAsF,KAAK,uCAAuC,6CAA6C,qCAAqC,wCAAwC,8BAA8B,oBAAoB,wBAAwB,iFAAiF,WAAW;AAC1gB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,iJAAiJ;AACjJ,wIAAwI;AACxI,MAAM,gHAAgH;AACtH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,OAAO;AACP,MAAM;;AAEN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,kBAAkB;AAC9C;AACA;;AAEA;AACA;AACA;AACA,+HAA+H,0BAA0B;AACzJ,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,sDAAsD,iDAAiD,uCAAuC,6CAA6C,qBAAqB,4CAA4C,sBAAsB,OAAO;AAChS,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA,aAAa,wBAAwB;AACrC;AACA;;AAEA;AACA,KAAK;;AAEL,wBAAwB,YAAY;AACpC;AACA;AACA,QAAQ;;AAER;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;;AAEF;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,yDAAyD,gDAAgD,WAAW,UAAU;AAC9H;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,WAAW;AAC3C;AACA;;AAEA;AACA,OAAO;AACP;AACA;AACA;AACA,+CAA+C,gCAAgC,sBAAsB,sBAAsB,2CAA2C,yCAAyC;AAC/M,OAAO;AACP;AACA;AACA;AACA;;AAEA,8BAA8B,YAAY;AAC1C,gCAAgC,YAAY;AAC5C;;AAEA,kCAAkC,WAAW;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA,OAAO;;AAEP,8CAA8C,qDAAqD,sCAAsC,iCAAiC,cAAc,MAAM,mFAAmF,aAAa,WAAW;AACzS;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA,wBAAwB,WAAW;AACnC,+BAA+B;AAC/B,iDAAiD,0CAA0C,6GAA6G,0DAA0D,0EAA0E,4EAA4E,4HAA4H,kCAAkC;AACtjB;;AAEA;AACA,sIAAsI;AACtI;;AAEA;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,YAAY;AAC5C;AACA;;AAEA;AACA,OAAO;;AAEP,yFAAyF,kKAAkK;AAC3P,KAAK,yFAAyF,OAAO,4FAA4F,sFAAsF,KAAK,qCAAqC,uCAAuC,mCAAmC,yBAAyB,kFAAkF,kFAAkF,wDAAwD,SAAS;AACzoB;;AAEA;;AAEA;AACA;AACA,mJAAmJ;AACnJ;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,sKAAsK,gCAAgC,uBAAuB,sCAAsC,sCAAsC,yBAAyB,SAAS;AAC3U;;AAEA;;AAEA,mBAAmB;;AAEnB;AACA;AACA,oNAAoN,gCAAgC,uBAAuB,qCAAqC,qCAAqC,yBAAyB,SAAS;AACvX;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,WAAW;AACrC;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA,0CAA0C,+CAA+C,kDAAkD,+DAA+D,SAAS;AACnN;;AAEA;;AAEA;AACA,WAAW;AACX;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,mFAAmF;AACnF,MAAM,0CAA0C;;AAEhD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;;AAER;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,QAAQ,wDAAwD;AAChE;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,uCAAuC,kBAAkB;AACzD;;AAEA;AACA,6OAA6O;AAC7O;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,8BAA8B,kBAAkB;AAChD;AACA;;AAEA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,gGAAgG;AAChG,2CAA2C;AAC3C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iJAAiJ;AACzJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;AACA;AACA;;AAEA;AACA,UAAU;AACV,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB,gBAAgB;AAChB;;AAEA,0BAA0B,gCAAgC;AAC1D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;;AAEZ;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,oEAAoE;AACpE;AACA;AACA;AACA,UAAU;AACV,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sDAAsD,kDAAkD,kDAAkD,kDAAkD,iDAAiD,mDAAmD,mDAAmD;AACnW;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,4LAA4L,gCAAgC,uBAAuB,sCAAsC,sCAAsC,2CAA2C,SAAS;AACnX;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,0BAA0B,0BAA0B,YAAY,uEAAuE,0HAA0H,4BAA4B,4BAA4B,0GAA0G,4BAA4B,4BAA4B,eAAe;AAC9jB;;AAEA,6JAA6J,uHAAuH,4DAA4D,4DAA4D,kFAAkF,gJAAgJ,+HAA+H,4DAA4D,4DAA4D,kFAAkF;AACv7B;AACA,mEAAmE,gCAAgC,uBAAuB,qCAAqC,qCAAqC,gDAAgD,sDAAsD,SAAS;AACnT;;AAEA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD,sCAAsC;AACtC,+DAA+D,yEAAyE;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,sCAAsC;AACtC,+DAA+D,yEAAyE;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,uCAAuC;AACvC,2FAA2F,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB,8BAA8B,+BAA+B;AACzW,+CAA+C,uDAAuD,qDAAqD,qDAAqD,qDAAqD,oBAAoB,8CAA8C;AACvU,2GAA2G,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB,8BAA8B,yCAAyC;AACnY;AACA;AACA,kEAAkE;AAClE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,4DAA4D,oCAAoC,mCAAmC,oDAAoD,oCAAoC,+BAA+B,oCAAoC,qCAAqC;AAC/W,gDAAgD;AAChD;AACA;AACA;AACA,kTAAkT,yCAAyC,gCAAgC,0BAA0B,oBAAoB,MAAM,wCAAwC,wCAAwC,wDAAwD,wDAAwD,qMAAqM,8DAA8D,WAAW,wBAAwB,SAAS,uBAAuB,uCAAuC,2CAA2C,kFAAkF,SAAS;AAClmC;;AAEA;;AAEA;AACA;AACA,4MAA4M,gCAAgC,uBAAuB,8CAA8C,8CAA8C,8CAA8C,8CAA8C,iEAAiE,SAAS;AACrgB;;AAEA;;AAEA,uBAAuB;;AAEvB;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA,6DAA6D;AAC7D,4DAA4D;AAC5D;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,2CAA2C;;AAE3C;AACA;;AAEA,+FAA+F;AAC/F;;AAEA;AACA,2EAA2E,uBAAuB,WAAW,iFAAiF,gDAAgD,2DAA2D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,iDAAiD,iCAAiC,4BAA4B,oBAAoB,SAAS,qCAAqC,4MAA4M,uCAAuC,kDAAkD,qCAAqC,sEAAsE,wCAAwC,gCAAgC,wHAAwH,wCAAwC,gCAAgC,4JAA4J,uCAAuC,8BAA8B,SAAS;AACv+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,wCAAwC,UAAU,qCAAqC,6EAA6E,uCAAuC,UAAU,MAAM,4DAA4D,qEAAqE,8DAA8D,wCAAwC,2DAA2D,sCAAsC,aAAa,WAAW,SAAS;AACvnB;AACA,gFAAgF,gEAAgE,6EAA6E,uGAAuG,gEAAgE,6EAA6E;AACjd;AACA,2EAA2E,uCAAuC,WAAW,sFAAsF,mDAAmD,gDAAgD,4DAA4D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,iDAAiD,oDAAoD,gCAAgC,+BAA+B,+BAA+B,+BAA+B,4BAA4B,oBAAoB,SAAS,qCAAqC,gOAAgO,uCAAuC,kDAAkD,qCAAqC,2MAA2M,wCAAwC,gCAAgC,kNAAkN,wCAAwC,gCAAgC,yNAAyN,uCAAuC,oCAAoC,SAAS;AACt/D;;AAEA;;AAEA;AACA;AACA;;AAEA,WAAW,gDAAgD;AAC3D;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;;AAEH;;AAEA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,wCAAwC,gDAAgD,wCAAwC,OAAO;AACvI;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,wCAAwC,6CAA6C,+BAA+B,mCAAmC,4BAA4B,qCAAqC,SAAS,wCAAwC,6EAA6E,qCAAqC,8BAA8B,uCAAuC,WAAW,SAAS,0BAA0B,OAAO;AACrf;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;;AAEA,sBAAsB,kBAAkB;AACxC;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB,iBAAiB,KAAK,mBAAmB;AACtG,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,4BAA4B,oCAAoC;AACvG,GAAG;AACH,CAAC;AACD,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,oEAAoE;AACpE,KAAK;AACL;AACA,0CAA0C,oFAAoF,4BAA4B,SAAS;AACnK;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE,KAAK;AACL;AACA,0CAA0C,mFAAmF,4BAA4B,SAAS;AAClK;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,mHAAmH,2CAA2C,gCAAgC,iCAAiC,gDAAgD,qCAAqC,mDAAmD,4BAA4B,oBAAoB,MAAM,oDAAoD,iDAAiD,KAAK,iDAAiD,2EAA2E,oCAAoC,gCAAgC,aAAa,WAAW,sCAAsC,SAAS;AAC9wB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,iGAAiG,kCAAkC,uFAAuF,kCAAkC,uFAAuF,kCAAkC,uFAAuF,kCAAkC;AAC9e,MAAM,6DAA6D,kCAAkC,6CAA6C,kCAAkC,6CAA6C,kCAAkC,6CAA6C,kCAAkC;;AAElV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2UAA2U;AAC3U;AACA,kFAAkF,sJAAsJ,SAAS;AACjP,sEAAsE,gIAAgI,SAAS,2CAA2C,oDAAoD,8EAA8E,8EAA8E,2LAA2L,+BAA+B,uCAAuC,0CAA0C,4BAA4B,oBAAoB,MAAM,2BAA2B,sEAAsE,yCAAyC,sHAAsH,mRAAmR,mEAAmE,qBAAqB,WAAW,+BAA+B,SAAS;AACz8C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB,iBAAiB,KAAK,mBAAmB;AACtG,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kCAAkC;AACzE,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,mBAAmB;AAC1D,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,wBAAwB;AAC9F,mDAAmD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AAChU,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,4CAA4C,6CAA6C;AAChI,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yIAAyI,mEAAmE,yBAAyB,6CAA6C,kCAAkC,8BAA8B,2DAA2D,uCAAuC,uCAAuC,+HAA+H,yCAAyC,mCAAmC,iCAAiC,+BAA+B,oBAAoB,uCAAuC,qCAAqC,8DAA8D,yBAAyB,eAAe,iCAAiC,oBAAoB,yCAAyC,uCAAuC,+DAA+D,2BAA2B,iBAAiB,uDAAuD,gOAAgO,+CAA+C,sCAAsC,yCAAyC,sQAAsQ,iBAAiB,eAAe,aAAa,6CAA6C,WAAW;AAC55D;AACA;AACA;AACA;AACA,yCAAyC,wCAAwC,UAAU,MAAM,iDAAiD,SAAS;AAC3J,wFAAwF,iEAAiE,yDAAyD,mDAAmD,4BAA4B,4DAA4D,uDAAuD,uCAAuC,WAAW,uBAAuB,wCAAwC,SAAS,uBAAuB,2CAA2C,gCAAgC,4BAA4B,yDAAyD,qCAAqC,qCAAqC,yIAAyI,+BAA+B,sBAAsB,6BAA6B,oBAAoB,qCAAqC,mCAAmC,4DAA4D,uBAAuB,aAAa,+BAA+B,qBAAqB,UAAU,sDAAsD,yRAAyR,2CAA2C,iDAAiD,uCAAuC,uMAAuM,4CAA4C,gCAAgC,+NAA+N,4CAA4C,gCAAgC,2PAA2P,2CAA2C,WAAW,oCAAoC,SAAS;AACllF;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sKAAsK,mFAAmF,yBAAyB,6CAA6C,iCAAiC,8BAA8B,mFAAmF,qCAAqC,qCAAqC,qCAAqC,wIAAwI,yCAAyC,mCAAmC,+BAA+B,oBAAoB,uCAAuC,qCAAqC,6DAA6D,yBAAyB,eAAe,iCAAiC,oBAAoB,yCAAyC,uCAAuC,gEAAgE,2BAA2B,iBAAiB,mCAAmC,oBAAoB,2CAA2C,yCAAyC,iEAAiE,6BAA6B,mBAAmB,8DAA8D,wOAAwO,iDAAiD,wCAAwC,2CAA2C,wYAAwY,mBAAmB,iBAAiB,eAAe,aAAa,6CAA6C,WAAW;AAC/4E;AACA;AACA;AACA;AACA,yCAAyC,wCAAwC,UAAU,MAAM,iDAAiD,SAAS;AAC3J,iHAAiH,iFAAiF,yDAAyD,mDAAmD,4BAA4B,qEAAqE,uDAAuD,uCAAuC,WAAW,uBAAuB,6CAA6C,SAAS,uBAAuB,2CAA2C,+BAA+B,4BAA4B,iFAAiF,mCAAmC,mCAAmC,mCAAmC,iJAAiJ,+BAA+B,sBAAsB,6BAA6B,oBAAoB,qCAAqC,mCAAmC,2DAA2D,uBAAuB,aAAa,+BAA+B,oBAAoB,qCAAqC,qCAAqC,8DAA8D,yBAAyB,eAAe,iCAAiC,qBAAqB,UAAU,wDAAwD,yTAAyT,+CAA+C,mDAAmD,yCAAyC,wNAAwN,gDAAgD,gCAAgC,qPAAqP,gDAAgD,gCAAgC,sRAAsR,+CAA+C,aAAa,sCAAsC,WAAW,SAAS;AACljG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8HAA8H,6FAA6F,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gDAAgD,uCAAuC,uCAAuC,oLAAoL,2BAA2B,oBAAoB,oDAAoD,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,kDAAkD,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,wDAAwD,mDAAmD,aAAa,WAAW,6BAA6B,SAAS;AACn+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,6GAA6G,uBAAuB,2CAA2C,+BAA+B,4BAA4B,wEAAwE,qCAAqC,qCAAqC,qCAAqC,4MAA4M,6BAA6B,oBAAoB,mDAAmD,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,sDAAsD,gFAAgF,0GAA0G,yBAAyB,eAAe,kCAAkC,iCAAiC,oBAAoB,uDAAuD,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,qEAAqE,qDAAqD,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAC1gE;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wJAAwJ,sCAAsC,4CAA4C,oDAAoD,uCAAuC,uCAAuC,4EAA4E,oEAAoE,SAAS;AACrgB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wJAAwJ,sCAAsC,sCAAsC,uCAAuC,2CAA2C,mDAAmD,4EAA4E,iDAAiD,SAAS;AAC/e;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,2CAA2C,oDAAoD,qHAAqH,mEAAmE,sEAAsE,SAAS;AACtW;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,8CAA8C,8EAA8E,0CAA0C,oCAAoC,0CAA0C,SAAS;AAC7P,2EAA2E,8EAA8E,0CAA0C,oCAAoC,gFAAgF,4CAA4C,sCAAsC,WAAW,SAAS;AAC7Z,4IAA4I,mFAAmF;AAC/N,0CAA0C,mDAAmD,mCAAmC,yDAAyD,4EAA4E,SAAS;AAC9Q;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,mCAAmC;AACnC;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,iEAAiE,0CAA0C,6BAA6B,6BAA6B,mBAAmB,WAAW,oDAAoD,SAAS;AACrQ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,+DAA+D,yCAAyC,oCAAoC,6BAA6B,mBAAmB,WAAW,gEAAgE,SAAS;AACrR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA,uGAAuG,+CAA+C,+CAA+C,iCAAiC,+RAA+R,SAAS;AAC9gB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA,kEAAkE;;AAElE,wBAAwB,kBAAkB;AAC1C,sHAAsH;AACtH;;AAEA,0FAA0F,2CAA2C,2CAA2C,4BAA4B,4BAA4B,qDAAqD;AAC7R;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;AACA;AACA,qDAAqD,8FAA8F,WAAW;;AAE9J,wBAAwB,kBAAkB;AAC1C;AACA,kHAAkH,mJAAmJ,WAAW;AAChR;;AAEA;AACA,iJAAiJ,iFAAiF,iCAAiC,uBAAuB,oDAAoD,mEAAmE,8DAA8D,8DAA8D,gDAAgD,WAAW,8DAA8D,8DAA8D,gDAAgD,WAAW,8DAA8D,4HAA4H,gDAAgD,WAAW,4BAA4B,SAAS;AACzhC;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6DAA6D,oCAAoC,qCAAqC,qDAAqD,oCAAoC,6CAA6C,wCAAwC,+CAA+C;AACjZ,gDAAgD;AAChD,8PAA8P,iEAAiE,uBAAuB,2CAA2C,gCAAgC,0CAA0C,kHAAkH,qCAAqC,qCAAqC,kLAAkL,2BAA2B,qBAAqB,OAAO,oDAAoD,4DAA4D,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,sDAAsD,6DAA6D,yBAAyB,eAAe,iCAAiC,qBAAqB,UAAU,6NAA6N,uCAAuC,qPAAqP,mDAAmD,kBAAkB,MAAM,qPAAqP,mDAAmD,iBAAiB,eAAe,2CAA2C,uCAAuC,8IAA8I,kBAAkB,MAAM,8IAA8I,iBAAiB,kBAAkB,gCAAgC,+JAA+J,uCAAuC,6KAA6K,mDAAmD,kBAAkB,MAAM,6KAA6K,mDAAmD,iBAAiB,kBAAkB,gCAAgC,sNAAsN,uCAAuC,yOAAyO,mDAAmD,kBAAkB,MAAM,yOAAyO,mDAAmD,iBAAiB,iBAAiB,aAAa,WAAW,mCAAmC,4EAA4E,SAAS;AAC/0I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wGAAwG,iFAAiF,uBAAuB,2CAA2C,+BAA+B,4BAA4B,oFAAoF,sCAAsC,sCAAsC,sCAAsC,wMAAwM,2BAA2B,qBAAqB,OAAO,oDAAoD,2DAA2D,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,sDAAsD,8DAA8D,yBAAyB,eAAe,iCAAiC,qBAAqB,OAAO,wDAAwD,+DAA+D,2BAA2B,iBAAiB,mCAAmC,qBAAqB,UAAU,qQAAqQ,yPAAyP,qDAAqD,iBAAiB,6CAA6C,kJAAkJ,kBAAkB,gCAAgC,qLAAqL,+KAA+K,mDAAmD,kBAAkB,gCAAgC,qPAAqP,4OAA4O,mDAAmD,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACvvG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,2FAA2F,mEAAmE;AAC9J;;AAEA,wBAAwB,YAAY;AACpC,0BAA0B,YAAY;AACtC,gEAAgE,4CAA4C,oGAAoG,oEAAoE,gEAAgE,6PAA6P,2GAA2G,kEAAkE,+CAA+C,yCAAyC,6CAA6C,4KAA4K,oBAAoB,MAAM,6CAA6C,4KAA4K,mBAAmB,iBAAiB,eAAe,aAAa;AACl2C;AACA;;AAEA,0CAA0C,uCAAuC,kCAAkC,8DAA8D,yBAAyB,oEAAoE,SAAS;AACvR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,EAAE;AACT;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oLAAoL,4BAA4B,6BAA6B,MAAM,6BAA6B,+BAA+B,OAAO,0FAA0F,8DAA8D,yBAAyB,eAAe,iCAAiC,8BAA8B,OAAO,4FAA4F,+DAA+D,2BAA2B,iBAAiB,qEAAqE,uDAAuD,qDAAqD,gDAAgD,kBAAkB,MAAM,uDAAuD,qDAAqD,gDAAgD,iBAAiB,iBAAiB,aAAa,WAAW,6BAA6B,SAAS;AACjgD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,gCAAgC,kDAAkD,0GAA0G,qCAAqC,qCAAqC,wLAAwL,2BAA2B,qBAAqB,OAAO,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,qDAAqD,iCAAiC,iCAAiC,OAAO,uCAAuC,8DAA8D,8DAA8D,6CAA6C,kBAAkB,MAAM,8DAA8D,8DAA8D,6CAA6C,iBAAiB,iBAAiB,aAAa,WAAW,6BAA6B,SAAS;AAC73D;;AAEA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,4BAA4B,gCAAgC,4BAA4B,6BAA6B,MAAM,6BAA6B,8BAA8B,OAAO,2FAA2F,6DAA6D,yBAAyB,eAAe,iCAAiC,+BAA+B,OAAO,4FAA4F,gEAAgE,2BAA2B,iBAAiB,mCAAmC,8BAA8B,OAAO,8FAA8F,iEAAiE,6BAA6B,mBAAmB,6DAA6D,yDAAyD,gDAAgD,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACh7C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,uBAAuB,2CAA2C,+BAA+B,4BAA4B,0EAA0E,qCAAqC,qCAAqC,qCAAqC,gCAAgC,2BAA2B,qBAAqB,OAAO,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,gFAAgF,wGAAwG,yBAAyB,eAAe,kCAAkC,qDAAqD,iCAAiC,qBAAqB,OAAO,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,uDAAuD,mCAAmC,iCAAiC,OAAO,oEAAoE,sEAAsE,6CAA6C,iBAAiB,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAC/5D;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kBAAkB;AACzD,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,wCAAwC,mCAAmC;AAC3E,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,wDAAwD,qBAAqB,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,8DAA8D,mCAAmC,mCAAmC,mCAAmC,gFAAgF,kDAAkD,mBAAmB,WAAW,gDAAgD,6CAA6C,wCAAwC,qDAAqD,6CAA6C,mBAAmB,WAAW,sCAAsC,qDAAqD,6CAA6C,mBAAmB,WAAW,qDAAqD,mCAAmC,2GAA2G,gEAAgE,+EAA+E,+EAA+E,6EAA6E,+EAA+E,oEAAoE,oEAAoE,8EAA8E,6DAA6D,gCAAgC,YAAY,MAAM,oKAAoK,kFAAkF,gCAAgC,WAAW,SAAS;AACntE;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,oNAAoN,uDAAuD,iDAAiD,qCAAqC,0CAA0C,+BAA+B,qCAAqC,+CAA+C,sDAAsD,WAAW,yBAAyB,SAAS;AACjmB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL,wBAAwB,sCAAsC;AAC9D;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,0JAA0J,yCAAyC,0BAA0B,wDAAwD,wDAAwD,wDAAwD,wCAAwC,+CAA+C,sCAAsC,+CAA+C,gHAAgH,gCAAgC,oEAAoE,0BAA0B,OAAO;AACtyB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,8CAA8C,6DAA6D,oCAAoC,qCAAqC,qDAAqD,oCAAoC,6CAA6C,wCAAwC,+CAA+C;AACjZ,gDAAgD;AAChD,+MAA+M,2CAA2C,+BAA+B,uDAAuD,4BAA4B,uCAAuC,2CAA2C,uCAAuC,qCAAqC,iLAAiL,2GAA2G,qBAAqB,OAAO,kDAAkD,8CAA8C,uBAAuB,aAAa,+BAA+B,qBAAqB,OAAO,oDAAoD,gDAAgD,yBAAyB,eAAe,qDAAqD,+CAA+C,qCAAqC,aAAa,WAAW,mCAAmC,4EAA4E,SAAS;AACt6C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ,aAAa,qBAAqB,eAAe,WAAW;;AAEjG,wBAAwB,WAAW;AACnC,0DAA0D,mDAAmD,mDAAmD,uDAAuD,sCAAsC;AAC7P;;AAEA,wBAAwB,WAAW;AACnC,0BAA0B,WAAW;AACrC,mEAAmE,mDAAmD,0DAA0D,uDAAuD,6CAA6C;AACpR;;AAEA,uEAAuE,yCAAyC;;AAEhH,0BAA0B,qBAAqB;AAC/C;;AAEA,oEAAoE;AACpE,oFAAoF,oGAAoG,8EAA8E,sLAAsL,+DAA+D,qBAAqB,uDAAuD,mBAAmB,8JAA8J,kEAAkE,kEAAkE,+DAA+D,4LAA4L,gDAAgD,uBAAuB,8FAA8F,sBAAsB,MAAM,0FAA0F,qBAAqB,wHAAwH,wEAAwE,8CAA8C,+DAA+D,qBAAqB,uDAAuD,mBAAmB,qEAAqE;AACx3D;;AAEA,mJAAmJ,6GAA6G,oFAAoF,4LAA4L,qEAAqE,uBAAuB,6DAA6D,qBAAqB,4EAA4E,wGAAwG,kFAAkF,2DAA2D,uBAAuB,oJAAoJ,wHAAwH,oFAAoF,+GAA+G,sFAAsF,wDAAwD,uEAAuE,yBAAyB,+DAA+D,uBAAuB,iFAAiF;AAC13D;AACA,UAAU,wFAAwF,mGAAmG,8EAA8E,oLAAoL,+DAA+D,qBAAqB,uDAAuD,mBAAmB,sGAAsG,gFAAgF,8KAA8K,mEAAmE,qBAAqB,2DAA2D,mBAAmB,gHAAgH,kFAAkF,mDAAmD,+DAA+D,4DAA4D,qBAAqB,+FAA+F,uHAAuH,wEAAwE,8CAA8C,+DAA+D,qBAAqB,uDAAuD,mBAAmB,+CAA+C,wGAAwG,kFAAkF,oDAAoD,kEAAkE,qBAAqB,2DAA2D,mBAAmB,oIAAoI,+JAA+J;;AAEnsF,sGAAsG,2EAA2E,wHAAwH,iFAAiF;AAC1X;;AAEA,uBAAuB;AACvB;;AAEA;AACA;AACA,4CAA4C,4DAA4D,oCAAoC,mCAAmC,oDAAoD,oCAAoC,+BAA+B,oCAAoC,qCAAqC;AAC/W,gDAAgD;AAChD,+MAA+M,2CAA2C,+BAA+B,uDAAuD,4BAA4B,uCAAuC,2CAA2C,qCAAqC,qCAAqC,wIAAwI,sFAAsF,4EAA4E,SAAS;AAC3zB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,8GAA8G,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,sEAAsE,gCAAgC,wEAAwE,8BAA8B,MAAM,6BAA6B,+BAA+B,OAAO,0FAA0F,8DAA8D,yBAAyB,eAAe,iCAAiC,8BAA8B,OAAO,4FAA4F,+DAA+D,2BAA2B,iBAAiB,uDAAuD,mDAAmD,8CAA8C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AAChtC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,gCAAgC,6BAA6B,4CAA4C,qCAAqC,qCAAqC,gCAAgC,6BAA6B,qBAAqB,OAAO,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,mDAAmD,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,qDAAqD,iFAAiF,qBAAqB,OAAO,kDAAkD,4DAA4D,4DAA4D,2CAA2C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACz+C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iGAAiG,6CAA6C,uEAAuE,2BAA2B,SAAS;AACzP;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN,wFAAwF,iEAAiE,2CAA2C,uBAAuB,2CAA2C,+BAA+B,4BAA4B,2EAA2E,wCAAwC,wCAAwC,wCAAwC,0BAA0B,oBAAoB,MAAM,gDAAgD,qDAAqD,8BAA8B,oBAAoB,MAAM,oDAAoD,yDAAyD,yDAAyD,8CAA8C,4CAA4C,qCAAqC,iCAAiC,mBAAmB,iBAAiB,eAAe,aAAa,WAAW,kCAAkC,4BAA4B,SAAS;AAC7qC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA,UAAU;;AAEV;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;;AAET;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,uDAAuD;AACvD,sCAAsC,uDAAuD,qDAAqD,qDAAqD,qDAAqD,oBAAoB;AAChR,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN,0HAA0H,6EAA6E,uEAAuE;AAC9Q;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,mDAAmD;AACnD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,+OAA+O,2BAA2B,4BAA4B,2BAA2B,4BAA4B,2BAA2B,2BAA2B,eAAe,kCAAkC,+EAA+E;AACnhB,GAAG;AACH,CAAC;AACD,wBAAwB;AACxB;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,EAAE;AAC9D;AACA,4CAA4C;AAC5C;AACA,4EAA4E,gFAAgF,iCAAiC,iDAAiD,kEAAkE,iGAAiG,+BAA+B,4BAA4B,oBAAoB,MAAM,+CAA+C,mEAAmE,gCAAgC,gCAAgC,2CAA2C,2CAA2C,+FAA+F,WAAW,0BAA0B,SAAS,uBAAuB,2CAA2C,qDAAqD,SAAS;AAC3/B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,2FAA2F,iFAAiF,SAAS;AAC1L;;AAEA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,kEAAkE,6CAA6C,8BAA8B,iDAAiD,8BAA8B,wDAAwD,8EAA8E,cAAc,MAAM,iFAAiF,aAAa,mCAAmC,WAAW;AAClgB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,gDAAgD,sBAAsB,sBAAsB,kBAAkB,kHAAkH,MAAM,MAAM,iBAAiB,KAAK;AAClQ,8CAA8C,wBAAwB,wCAAwC,4BAA4B,+BAA+B,gGAAgG,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,kBAAkB,2CAA2C,KAAK,wBAAwB;AACvhB;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,gEAAgE,2CAA2C,+BAA+B,+BAA+B,gCAAgC,0FAA0F,0DAA0D,sBAAsB,2BAA2B,6BAA6B,YAAY,sBAAsB,6BAA6B,YAAY,sBAAsB,6BAA6B,YAAY,sBAAsB,6BAA6B,WAAW,kDAAkD,SAAS;AAC9qB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,gEAAgE,2CAA2C,+BAA+B,+BAA+B,gCAAgC,mCAAmC,2BAA2B,QAAQ,QAAQ,2BAA2B,QAAQ,QAAQ,qCAAqC,sCAAsC,wHAAwH,4DAA4D,0BAA0B,+BAA+B,iCAAiC,gBAAgB,sBAAsB,iCAAiC,gBAAgB,sBAAsB,iCAAiC,gBAAgB,sBAAsB,iCAAiC,eAAe,mEAAmE,aAAa,WAAW,2CAA2C,SAAS;AAC9gC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,EAAE;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iGAAiG,wBAAwB,sDAAsD,iCAAiC,4BAA4B,gCAAgC,MAAM,0DAA0D,gGAAgG,aAAa,qDAAqD,WAAW;AACzf;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,0CAA0C,kDAAkD,0CAA0C,SAAS;AAC/I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,yDAAyD;AACzD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,8DAA8D;AAC9D;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,qDAAqD;AACrD;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,sDAAsD;AACtD;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,qCAAqC;AACrC,2DAA2D;AAC3D;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,wCAAwC,kBAAkB;AAC1D,+CAA+C,8CAA8C,+CAA+C,+CAA+C,+CAA+C,+CAA+C,oBAAoB;AAC7S;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC;AACpC,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD;AACnD,8HAA8H;AAC9H;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,0CAA0C;AAC1C,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD;AACnD,6IAA6I;AAC7I;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,qCAAqC,0BAA0B,uCAAuC,qBAAqB,MAAM,4BAA4B,qDAAqD,2CAA2C,2BAA2B,aAAa,WAAW,yCAAyC,yBAAyB,SAAS;AACxsB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,0CAA0C,2CAA2C,2BAA2B,2BAA2B,2BAA2B,2BAA2B,kEAAkE,iEAAiE,gCAAgC,sDAAsD,oZAAoZ,kDAAkD,gCAAgC,gCAAgC,gEAAgE,0EAA0E,6BAA6B,kFAAkF,eAAe,WAAW,0CAA0C,yCAAyC,qBAAqB,MAAM,kCAAkC,oEAAoE,8EAA8E,yEAAyE,8EAA8E,sDAAsD,gCAAgC,uCAAuC,8BAA8B,oDAAoD,+GAA+G,sEAAsE,+BAA+B,4EAA4E,iBAAiB,eAAe,8BAA8B,2BAA2B,aAAa,WAAW,yDAAyD,4BAA4B,SAAS;AACl7E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA,wOAAwO,2CAA2C,4BAA4B,4BAA4B,4BAA4B,+BAA+B,0BAA0B,4BAA4B,MAAM,sEAAsE,kHAAkH,4CAA4C,8DAA8D,+BAA+B,0CAA0C,mBAAmB,MAAM,kCAAkC,yBAAyB,eAAe,yDAAyD,8EAA8E,eAAe,oBAAoB,sBAAsB,eAAe,aAAa,0EAA0E,2CAA2C,mBAAmB,KAAK,kCAAkC,yBAAyB,eAAe,wDAAwD,oMAAoM,6BAA6B,0DAA0D,iBAAiB,qCAAqC,2CAA2C,gCAAgC,iBAAiB,eAAe,oBAAoB,sBAAsB,eAAe,aAAa,SAAS,0BAA0B,SAAS;AACz6D;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,0BAA0B,sBAAsB;AAChD;AACA;;AAEA;;AAEA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,uBAAuB;AAC7F,wDAAwD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACrU;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8HAA8H,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gDAAgD,uCAAuC,uCAAuC,oLAAoL,2BAA2B,oBAAoB,kDAAkD,8EAA8E,uFAAuF,uBAAuB,aAAa,gCAAgC,+BAA+B,qBAAqB,OAAO,+EAA+E,yGAAyG,yBAAyB,eAAe,kCAAkC,wDAAwD,0FAA0F,uKAAuK,yEAAyE,0CAA0C,aAAa,WAAW,6BAA6B,SAAS;AAC3pD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oKAAoK,uBAAuB,2CAA2C,+BAA+B,4BAA4B,wEAAwE,qCAAqC,qCAAqC,qCAAqC,4MAA4M,6BAA6B,oBAAoB,kDAAkD,6EAA6E,sFAAsF,uBAAuB,aAAa,gCAAgC,+BAA+B,oBAAoB,sDAAsD,gFAAgF,0GAA0G,yBAAyB,eAAe,kCAAkC,iCAAiC,oBAAoB,uDAAuD,iFAAiF,6GAA6G,2BAA2B,iBAAiB,oCAAoC,qEAAqE,8HAA8H,0PAA0P,2EAA2E,4CAA4C,eAAe,aAAa,WAAW,6BAA6B,SAAS;AACt1E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,4BAA4B,sBAAsB;AAClD;AACA;;AAEA;;AAEA;AACA,QAAQ;;AAER;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,2CAA2C,2BAA2B,uBAAuB;AAC7F,wDAAwD,iEAAiE,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACrU;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,4DAA4D,uBAAuB,kDAAkD,0BAA0B,oBAAoB,MAAM,qCAAqC,gEAAgE,cAAc,4BAA4B,oEAAoE,aAAa,WAAW,+CAA+C,0CAA0C,SAAS,gDAAgD,mCAAmC,yBAAyB,yCAAyC,+BAA+B,uDAAuD,cAAc,sBAAsB,2DAA2D,aAAa,0CAA0C,WAAW;AAC9+B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,uDAAuD,+BAA+B,yDAAyD,YAAY,yBAAyB,6DAA6D,WAAW,0BAA0B;;AAEtR,kDAAkD,0GAA0G,qCAAqC,8BAA8B,8GAA8G,WAAW;AACxV,MAAM;AACN,uDAAuD,sEAAsE,6EAA6E,+CAA+C,kKAAkK,0BAA0B;;AAErb,kDAAkD,0GAA0G,qCAAqC,8BAA8B,8GAA8G,WAAW,yBAAyB,qCAAqC,4EAA4E,8GAA8G,uCAAuC,gCAAgC,kHAAkH,aAAa,WAAW;AACjyB;;AAEA,wFAAwF,kEAAkE,uBAAuB,uDAAuD,iCAAiC,oDAAoD,SAAS;AACtU;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,yCAAyC,qBAAqB;AAC9D,kDAAkD,2CAA2C,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACzS,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,oEAAoE,2CAA2C,gCAAgC,mCAAmC,0BAA0B,4BAA4B,uBAAuB,MAAM,sCAAsC,4BAA4B,kCAAkC,qBAAqB,aAAa,WAAW,8GAA8G,SAAS;AAClhB;;AAEA;;AAEA;AACA,6BAA6B,eAAe,IAAI,eAAe;AAC/D,wDAAwD,8CAA8C,wBAAwB,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB,oBAAoB,KAAK,oBAAoB;AACtU;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,CAAC;AACD,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA,uGAAuG,2CAA2C,kDAAkD,uHAAuH,SAAS;AACpU;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,4FAA4F,4DAA4D,uBAAuB,kDAAkD,+EAA+E,6BAA6B,YAAY,MAAM,iDAAiD,4CAA4C,WAAW,SAAS,gDAAgD,mCAAmC,yBAAyB,yCAAyC,8CAA8C,+BAA+B,cAAc,MAAM,4CAA4C,aAAa,WAAW;AAC1wB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,+BAA+B,6BAA6B,6BAA6B,wBAAwB,mCAAmC,2EAA2E,gDAAgD,+BAA+B;AACzV;AACA;;AAEA,iDAAiD,eAAe;AAChE,yEAAyE,sDAAsD,YAAY,MAAM,+CAA+C,iGAAiG,WAAW;AAC5S;;AAEA,sBAAsB,OAAO,uFAAuF,kEAAkE,uBAAuB,uDAAuD,iCAAiC,oDAAoD,SAAS;AAClW;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,gDAAgD,iBAAiB,KAAK,mBAAmB,iBAAiB,KAAK,wFAAwF;AACvM,yKAAyK,wEAAwE,8CAA8C,yHAAyH,4CAA4C,4CAA4C,4CAA4C,4CAA4C,8EAA8E,iDAAiD,6CAA6C,6CAA6C,6CAA6C,oBAAoB;AACl2B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,+BAA+B;AACtE,iFAAiF,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB;AAClS,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,yCAAyC;AAChF,gGAAgG,2BAA2B,0CAA0C,wCAAwC,wCAAwC,wCAAwC,oBAAoB;AACjT,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0RAA0R,2EAA2E,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gCAAgC,yFAAyF,yHAAyH,mGAAmG,yEAAyE,yEAAyE,uEAAuE,yEAAyE,kEAAkE,kEAAkE,4EAA4E,2DAA2D,gCAAgC,SAAS;AAC14C;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+TAA+T,mIAAmI,uDAAuD,0DAA0D,SAAS,uBAAuB,2CAA2C,4BAA4B,4BAA4B,yGAAyG,yFAAyF,yHAAyH,mGAAmG,sIAAsI,0DAA0D,2gBAA2gB,kaAAka,gaAAga,+ZAA+Z,kEAAkE,2DAA2D,kEAAkE,qDAAqD,gCAAgC,SAAS;AAC7xG;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oCAAoC,2DAA2D,yDAAyD,+DAA+D,4DAA4D,sDAAsD,mDAAmD,wHAAwH,gEAAgE,+DAA+D,+DAA+D,6DAA6D,uBAAuB,cAAc,2CAA2C,uHAAuH,uBAAuB,aAAa,sCAAsC,sBAAsB,cAAc,6CAA6C,2HAA2H,yBAAyB,eAAe,qDAAqD,gDAAgD,6EAA6E,uDAAuD,mDAAmD,oDAAoD,iDAAiD,4EAA4E,wDAAwD,mDAAmD,4DAA4D,kIAAkI,eAAe,6DAA6D,2GAA2G,eAAe,+DAA+D,6GAA6G,eAAe,gEAAgE,uGAAuG,eAAe,aAAa,WAAW,gEAAgE,SAAS;AACv0F;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8RAA8R,2EAA2E,uBAAuB,2CAA2C,4BAA4B,4BAA4B,gCAAgC,yFAAyF,0MAA0M,4EAA4E,gCAAgC,SAAS;AAC35B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mUAAmU,mIAAmI,uDAAuD,0DAA0D,SAAS,uBAAuB,2CAA2C,4BAA4B,4BAA4B,yGAAyG,yFAAyF,0MAA0M,sIAAsI,0DAA0D,obAAob,gCAAgC,SAAS;AACnuD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAA2C,4BAA4B,4BAA4B,4BAA4B,4BAA4B,oCAAoC,2DAA2D,yDAAyD,+DAA+D,4DAA4D,sDAAsD,mDAAmD,wHAAwH,uEAAuE,+DAA+D,sEAAsE,6DAA6D,uBAAuB,cAAc,2CAA2C,uHAAuH,uBAAuB,aAAa,sCAAsC,sBAAsB,cAAc,6CAA6C,2HAA2H,yBAAyB,eAAe,yIAAyI,6IAA6I,kOAAkO,kOAAkO,qEAAqE,qDAAqD,eAAe,aAAa,WAAW,gEAAgE,SAAS;AAC34E;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4FAA4F,0CAA0C,0DAA0D,WAAW;AAC3M;AACA;AACA,0CAA0C,mDAAmD,0CAA0C,SAAS;AAChJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA,qDAAqD,uCAAuC,mCAAmC,4GAA4G,+BAA+B,mIAAmI,aAAa,8BAA8B,WAAW,qCAAqC,iDAAiD,mCAAmC;AAC5jB;AACA,KAAK,eAAe,+BAA+B;AACnD;AACA,KAAK,eAAe,aAAa,gCAAgC;AACjE;AACA,KAAK,eAAe,kCAAkC;AACtD;AACA,KAAK,eAAe,eAAe,aAAa,8BAA8B,WAAW;AACzF;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,6EAA6E,0DAA0D,8CAA8C,4CAA4C,6CAA6C,8BAA8B,8BAA8B,qHAAqH,qHAAqH,6DAA6D,6DAA6D,2HAA2H,2EAA2E,aAAa,mCAAmC,WAAW;AAC/6B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,8IAA8I,2BAA2B,sBAAsB,MAAM,4BAA4B,qBAAqB,MAAM,MAAM,kCAAkC,oBAAoB,QAAQ,MAAM,0BAA0B,OAAO,KAAK;AAC5W,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2IAA2I,yBAAyB,sDAAsD,4BAA4B,+BAA+B,4BAA4B,oBAAoB,MAAM,qCAAqC,8BAA8B,oBAAoB,MAAM,8DAA8D,wFAAwF,eAAe,gDAAgD,kDAAkD,6BAA6B,eAAe,aAAa,iEAAiE,WAAW;AACpzB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA;AACA;AACA,0CAA0C,kDAAkD,4CAA4C,4BAA4B,4CAA4C,YAAY,MAAM,4CAA4C,WAAW,SAAS;AAClS;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,6KAA6K,qCAAqC,gEAAgE;AAClR,GAAG;AACH,CAAC;AACD,6CAA6C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,oCAAoC,aAAa,mBAAmB;AACpE,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,kBAAkB;AACzD,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,uCAAuC,mCAAmC;AAC1E,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,0DAA0D,yCAAyC,sCAAsC,mCAAmC,mBAAmB,yBAAyB,qBAAqB,iBAAiB,KAAK,wBAAwB,qBAAqB,KAAK,SAAS,gCAAgC,KAAK,kBAAkB;AACrX,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA,mCAAmC,wBAAwB;AAC3D;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA,CAAC;AACD,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,yCAAyC;AACzC,+CAA+C;AAC/C,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN,oDAAoD,wDAAwD;AAC5G;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA,kFAAkF,gEAAgE,uBAAuB,oDAAoD,0CAA0C,SAAS;AAChR;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,oEAAoE;AAC1E;AACA;AACA;;AAEA;AACA,MAAM;AACN;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;AACA,mDAAmD,+CAA+C;AAClG,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,0BAA0B,kBAAkB;AAC5C;AACA;;AAEA;AACA,KAAK;;AAEL,0CAA0C,kDAAkD,0CAA0C,SAAS;AAC/I;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,gEAAgE,4CAA4C,iCAAiC,mCAAmC,o0BAAo0B,2DAA2D,qEAAqE,+EAA+E,6DAA6D,6DAA6D,yIAAyI,6DAA6D,uCAAuC,sEAAsE,qBAAqB,wBAAwB,YAAY,+BAA+B,mCAAmC,aAAa,MAAM,mCAAmC,YAAY,UAAU;AAC5zD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK,6DAA6D,iHAAiH,iCAAiC,mCAAmC,2wCAA2wC,mEAAmE,2EAA2E,wCAAwC,oDAAoD,yDAAyD,UAAU;AAC/yD;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,SAAS,MAAM;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;;AAEA,8BAA8B,YAAY;AAC1C;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,8BAA8B,YAAY;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,8EAA8E,yCAAyC,wCAAwC,sCAAsC,qCAAqC,oCAAoC,sBAAsB,MAAM,4CAA4C,0CAA0C,2GAA2G,uBAAuB,gFAAgF,qBAAqB,oBAAoB,+BAA+B,qCAAqC,oCAAoC,sBAAsB,MAAM,4CAA4C,wEAAwE,2CAA2C,sDAAsD,uBAAuB,qBAAqB,mBAAmB,wDAAwD,kBAAkB,+BAA+B,sCAAsC,qCAAqC,oCAAoC,sBAAsB,MAAM,2CAA2C,gFAAgF,qBAAqB,oBAAoB,+BAA+B,qCAAqC,oCAAoC,sBAAsB,MAAM,2CAA2C,uEAAuE,qBAAqB,mBAAmB,wDAAwD,kBAAkB,+BAA+B,yDAAyD,kBAAkB,MAAM,kCAAkC,iBAAiB,eAAe,wGAAwG,kCAAkC,uGAAuG,2EAA2E,kBAAkB,MAAM,sDAAsD,iBAAiB,mCAAmC,eAAe,6BAA6B,iDAAiD,kCAAkC,sCAAsC,kCAAkC,kCAAkC,wCAAwC,oCAAoC,oCAAoC,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,mDAAmD,2DAA2D,wCAAwC,sDAAsD,kBAAkB,MAAM,oEAAoE,oEAAoE,oEAAoE,oEAAoE,8CAA8C,kDAAkD,kDAAkD,yGAAyG,oBAAoB,MAAM,+CAA+C,+CAA+C,+CAA+C,+CAA+C,6PAA6P,0PAA0P,iHAAiH,mBAAmB,iBAAiB,uCAAuC,eAAe;AACxsJ;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,WAAW;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,kBAAkB;AAC1C;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA,2EAA2E,uCAAuC,WAAW;AAC7H;AACA,2EAA2E,wBAAwB,WAAW,4EAA4E,gDAAgD,2DAA2D,SAAS,gDAAgD,8DAA8D,SAAS,uBAAuB,2CAA2C,gCAAgC,iCAAiC,+GAA+G,0EAA0E,iCAAiC,4BAA4B,oBAAoB,SAAS,qCAAqC,4MAA4M,6UAA6U,uCAAuC,kDAAkD,qCAAqC,uLAAuL,6DAA6D,qKAAqK,wCAAwC,gCAAgC,8LAA8L,iOAAiO,wCAAwC,gCAAgC,qMAAqM,qRAAqR,uCAAuC,8BAA8B,SAAS;AACv+F;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,OAAO,sBAAsB;AAC7B;AACA,kCAAkC;AAClC;;AAEA,yDAAyD;AACzD;AACA;;AAEA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,gDAAgD,qBAAqB;AACrE;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA,8CAA8C,qBAAqB;AACnE;AACA;AACA;AACA;AACA,wBAAwB;AACxB;;AAEA;;AAEA,4CAA4C,eAAe;AAC3D;AACA;;AAEA;;AAEA;AACA;AACA,wBAAwB;AACxB;AACA;;AAEA,gFAAgF,yDAAyD,wDAAwD;AACjM;AACA;AACA;;AAEA;AACA;;AAEA,gDAAgD,sBAAsB;AACtE;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,mBAAmB;AACnB,4BAA4B;AAC5B;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,mBAAmB;AACnB;AACA;AACA;AACA,iBAAiB;;AAEjB;AACA;;AAEA;AACA,aAAa;;AAEb;AACA;AACA;AACA,WAAW;AACX,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,gBAAgB;AAChB;;AAEA,kBAAkB,cAAc;AAChC;AACA;;AAEA;AACA,KAAK;;AAEL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,GAAG;;AAEH;AACA;AACA;AACA,CAAC","sources":["webpack://jacdac-docs/./src/workers/tf/dist/node_modules/tf-worker.js"],"sourcesContent":["var _asyncToGenerator = require(\"/home/runner/work/jacdac-docs/jacdac-docs/node_modules/babel-preset-gatsby/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nrequire(\"core-js/modules/es.math.hypot.js\");\n\nfunction e() {\n  return (e = Object.assign || function (e) {\n    for (var t = 1; t < arguments.length; t++) {\n      var n = arguments[t];\n\n      for (var s in n) {\n        Object.prototype.hasOwnProperty.call(n, s) && (e[s] = n[s]);\n      }\n    }\n\n    return e;\n  }).apply(this, arguments);\n}\n\nclass t {\n  constructor(e, t) {\n    this.backend = e, this.dataMover = t, this.data = new WeakMap(), this.dataIdsCount = 0;\n  }\n\n  get(e) {\n    return this.data.has(e) || this.dataMover.moveData(this.backend, e), this.data.get(e);\n  }\n\n  set(e, t) {\n    this.dataIdsCount++, this.data.set(e, t);\n  }\n\n  has(e) {\n    return this.data.has(e);\n  }\n\n  delete(e) {\n    return this.dataIdsCount--, this.data.delete(e);\n  }\n\n  numDataIds() {\n    return this.dataIdsCount;\n  }\n\n}\n\nclass n {\n  refCount(e) {\n    return s(\"refCount\");\n  }\n\n  incRef(e) {\n    return s(\"incRef\");\n  }\n\n  timerAvailable() {\n    return !0;\n  }\n\n  time(e) {\n    return s(\"time\");\n  }\n\n  read(e) {\n    return s(\"read\");\n  }\n\n  readSync(e) {\n    return s(\"readSync\");\n  }\n\n  numDataIds() {\n    return s(\"numDataIds\");\n  }\n\n  disposeData(e, t) {\n    return s(\"disposeData\");\n  }\n\n  write(e, t, n) {\n    return s(\"write\");\n  }\n\n  move(e, t, n, r, a) {\n    return s(\"move\");\n  }\n\n  memory() {\n    return s(\"memory\");\n  }\n\n  floatPrecision() {\n    return s(\"floatPrecision\");\n  }\n\n  epsilon() {\n    return 32 === this.floatPrecision() ? 1e-7 : 1e-4;\n  }\n\n  dispose() {\n    return s(\"dispose\");\n  }\n\n}\n\nfunction s(e) {\n  throw new Error(\"'\".concat(e, \"' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen\"));\n}\n\nfunction r(e) {\n  var t = e.length,\n      n = 0;\n\n  for (; t > 0;) {\n    n = Math.random() * t | 0, t--, o(e, t, n);\n  }\n}\n\nfunction a(e, t, n) {\n  return Math.max(e, Math.min(t, n));\n}\n\nfunction i(e) {\n  return e % 2 == 0 ? e : e + 1;\n}\n\nfunction o(e, t, n) {\n  var s = e[t];\n  e[t] = e[n], e[n] = s;\n}\n\nfunction l(e, t) {\n  if (!e) throw new Error(\"string\" == typeof t ? t : t());\n}\n\nfunction u(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"\";\n  l(p(e, t), () => n + \" Shapes \".concat(e, \" and \").concat(t, \" must match\"));\n}\n\nfunction c(e) {\n  l(null != e, () => \"The input to the tensor constructor must be a non-null value.\");\n}\n\nfunction h(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (null == t && (t = []), Array.isArray(e) || $(e) && !n) for (var _s2 = 0; _s2 < e.length; ++_s2) {\n    h(e[_s2], t, n);\n  } else t.push(e);\n  return t;\n}\n\nfunction d(e) {\n  if (0 === e.length) return 1;\n  var t = e[0];\n\n  for (var _n2 = 1; _n2 < e.length; _n2++) {\n    t *= e[_n2];\n  }\n\n  return t;\n}\n\nfunction p(e, t) {\n  if (e === t) return !0;\n  if (null == e || null == t) return !1;\n  if (e.length !== t.length) return !1;\n\n  for (var _n3 = 0; _n3 < e.length; _n3++) {\n    if (e[_n3] !== t[_n3]) return !1;\n  }\n\n  return !0;\n}\n\nfunction f(e) {\n  return e % 1 == 0;\n}\n\nfunction g(e) {\n  var t = Math.ceil(Math.sqrt(e));\n  return [t, Math.ceil(e / t)];\n}\n\nfunction m(e, t) {\n  return t <= e.length ? e : e + \" \".repeat(t - e.length);\n}\n\nfunction b(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e => 0;\n  var n = arguments.length > 2 ? arguments[2] : undefined;\n  return new Promise((s, r) => {\n    var a = 0;\n\n    var i = () => {\n      if (e()) return void s();\n      a++;\n      var o = t(a);\n      null != n && a >= n ? r() : setTimeout(i, o);\n    };\n\n    i();\n  });\n}\n\nfunction x(e, t) {\n  var n = 1,\n      s = -1;\n\n  for (var _t2 = 0; _t2 < e.length; ++_t2) {\n    if (e[_t2] >= 0) n *= e[_t2];else if (-1 === e[_t2]) {\n      if (-1 !== s) throw Error(\"Shapes can only have 1 implicit size. Found -1 at dim \".concat(s, \" and dim \").concat(_t2));\n      s = _t2;\n    } else if (e[_t2] < 0) throw Error(\"Shapes can not be < 0. Found \".concat(e[_t2], \" at dim \").concat(_t2));\n  }\n\n  if (-1 === s) {\n    if (t > 0 && t !== n) throw Error(\"Size(\".concat(t, \") must match the product of shape \").concat(e));\n    return e;\n  }\n\n  if (0 === n) throw Error(\"Cannot infer the missing size in [\".concat(e, \"] when there are 0 elements\"));\n  if (t % n != 0) throw Error(\"The implicit shape can't be a fractional number. Got \".concat(t, \" / \").concat(n));\n  var r = e.slice();\n  return r[s] = t / n, r;\n}\n\nfunction y(e, t) {\n  var n = t.length;\n  return l((e = null == e ? t.map((e, t) => t) : [].concat(e)).every(e => e >= -n && e < n), () => \"All values in axis param must be in range [-\".concat(n, \", \").concat(n, \") but got axis \").concat(e)), l(e.every(e => f(e)), () => \"All values in axis param must be integers but got axis \".concat(e)), e.map(e => e < 0 ? n + e : e);\n}\n\nfunction k(e, t) {\n  var n = [],\n      s = [],\n      r = null != t && Array.isArray(t) && 0 === t.length,\n      a = null == t || r ? null : y(t, e).sort();\n  var i = 0;\n\n  for (var _t3 = 0; _t3 < e.length; ++_t3) {\n    if (null != a) {\n      if (a[i] === _t3 && 1 !== e[_t3]) throw new Error(\"Can't squeeze axis \".concat(_t3, \" since its dim '\").concat(e[_t3], \"' is not 1\"));\n      (null == a[i] || a[i] > _t3) && 1 === e[_t3] && (n.push(e[_t3]), s.push(_t3)), a[i] <= _t3 && i++;\n    }\n\n    1 !== e[_t3] && (n.push(e[_t3]), s.push(_t3));\n  }\n\n  return {\n    newShape: n,\n    keptDims: s\n  };\n}\n\nfunction w(e, t) {\n  var n = null;\n  if (null == e || \"float32\" === e) n = new Float32Array(t);else if (\"int32\" === e) n = new Int32Array(t);else {\n    if (\"bool\" !== e) throw new Error(\"Unknown data type \".concat(e));\n    n = new Uint8Array(t);\n  }\n  return n;\n}\n\nfunction v(e, t) {\n  var n = null;\n  if (null == e || \"float32\" === e) n = new Float32Array(t);else if (\"int32\" === e) n = new Int32Array(t);else if (\"bool\" === e) n = new Uint8Array(t);else {\n    if (\"string\" !== e) throw new Error(\"Unknown data type \".concat(e));\n    n = new Array(t);\n  }\n  return n;\n}\n\nfunction I(e, t) {\n  return !(\"complex64\" === t || \"float32\" === t && \"complex64\" !== e || \"int32\" === t && \"float32\" !== e && \"complex64\" !== e || \"bool\" === t && \"bool\" === e);\n}\n\nfunction $(e) {\n  return e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array;\n}\n\nfunction S(e) {\n  if (\"float32\" === e || \"int32\" === e) return 4;\n  if (\"complex64\" === e) return 8;\n  if (\"bool\" === e) return 1;\n  throw new Error(\"Unknown dtype \".concat(e));\n}\n\nfunction N(e) {\n  return \"string\" == typeof e || e instanceof String;\n}\n\nfunction C(e) {\n  return \"number\" == typeof e;\n}\n\nfunction T(e) {\n  return Array.isArray(e) ? T(e[0]) : e instanceof Float32Array ? \"float32\" : e instanceof Int32Array || e instanceof Uint8Array ? \"int32\" : C(e) ? \"float32\" : N(e) ? \"string\" : \"boolean\" == typeof e ? \"bool\" : \"float32\";\n}\n\nfunction E(e) {\n  return !!(e && e.constructor && e.call && e.apply);\n}\n\nfunction R(e, t) {\n  for (var _n4 = t; _n4 < e; ++_n4) {\n    if (e % _n4 == 0) return _n4;\n  }\n\n  return e;\n}\n\nfunction A(e) {\n  var t = e.length;\n  if (t < 2) return [];\n  var n = new Array(t - 1);\n  n[t - 2] = e[t - 1];\n\n  for (var _s3 = t - 3; _s3 >= 0; --_s3) {\n    n[_s3] = n[_s3 + 1] * e[_s3 + 1];\n  }\n\n  return n;\n}\n\nfunction F(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = new Array();\n\n  if (1 === t.length) {\n    var _a2 = t[0] * (s ? 2 : 1);\n\n    for (var _t4 = 0; _t4 < _a2; _t4++) {\n      r[_t4] = n[e + _t4];\n    }\n  } else {\n    var _a3 = t[0],\n        _i2 = t.slice(1),\n        _o2 = _i2.reduce((e, t) => e * t) * (s ? 2 : 1);\n\n    for (var _t5 = 0; _t5 < _a3; _t5++) {\n      r[_t5] = F(e + _t5 * _o2, _i2, n, s);\n    }\n  }\n\n  return r;\n}\n\nfunction D(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (0 === e.length) return t[0];\n  var s = e.reduce((e, t) => e * t) * (n ? 2 : 1);\n  if (0 === s) return [];\n  if (s !== t.length) throw new Error(\"[\".concat(e, \"] does not match the input size \").concat(t.length).concat(n ? \" for a complex tensor\" : \"\", \".\"));\n  return F(0, e, t, n);\n}\n\nfunction _(e, t) {\n  var n = O(e, t);\n\n  for (var _e2 = 0; _e2 < n.length; _e2++) {\n    n[_e2] = 1;\n  }\n\n  return n;\n}\n\nfunction O(e, t) {\n  if (null == t || \"float32\" === t || \"complex64\" === t) return new Float32Array(e);\n  if (\"int32\" === t) return new Int32Array(e);\n  if (\"bool\" === t) return new Uint8Array(e);\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction M(e, t) {\n  var n = e.reduce((e, t) => e * t, 1);\n  if (null == t || \"float32\" === t) return D(e, new Float32Array(n));\n  if (\"int32\" === t) return D(e, new Int32Array(n));\n  if (\"bool\" === t) return D(e, new Uint8Array(n));\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction L(e) {\n  e.forEach(t => {\n    l(Number.isInteger(t) && t >= 0, () => \"Tensor must have a shape comprised of positive integers but got shape [\".concat(e, \"].\"));\n  });\n}\n\nfunction z(e, t, n) {\n  if (0 === t) return 0;\n  if (1 === t) return e[0];\n  var s = e[e.length - 1];\n\n  for (var _t6 = 0; _t6 < e.length - 1; ++_t6) {\n    s += n[_t6] * e[_t6];\n  }\n\n  return s;\n}\n\nfunction B(e, t, n) {\n  if (0 === t) return [];\n  if (1 === t) return [e];\n  var s = new Array(t);\n\n  for (var _t7 = 0; _t7 < s.length - 1; ++_t7) {\n    s[_t7] = Math.floor(e / n[_t7]), e -= s[_t7] * n[_t7];\n  }\n\n  return s[s.length - 1] = e, s;\n}\n\nfunction P(e) {\n  return e && e.then && \"function\" == typeof e.then;\n}\n\nfunction W() {\n  G().getBool(\"IS_TEST\") || G().getBool(\"PROD\") || console.warn(...arguments);\n}\n\nclass U {\n  constructor(e) {\n    this.global = e, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = V, this.populateURLFlags();\n  }\n\n  setPlatform(e, t) {\n    null != this.platform && W(\"Platform \".concat(this.platformName, \" has already been set. Overwriting the platform with \").concat(t, \".\")), this.platformName = e, this.platform = t;\n  }\n\n  registerFlag(e, t, n) {\n    if (this.flagRegistry[e] = {\n      evaluationFn: t,\n      setHook: n\n    }, null != this.urlFlags[e]) {\n      var _t8 = this.urlFlags[e];\n      W(\"Setting feature override from URL \".concat(e, \": \").concat(_t8, \".\")), this.set(e, _t8);\n    }\n  }\n\n  getAsync(e) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return e in _this.flags || (_this.flags[e] = yield _this.evaluateFlag(e)), _this.flags[e];\n    })();\n  }\n\n  get(e) {\n    if (e in this.flags) return this.flags[e];\n    var t = this.evaluateFlag(e);\n    if (P(t)) throw new Error(\"Flag \".concat(e, \" cannot be synchronously evaluated. Please use getAsync() instead.\"));\n    return this.flags[e] = t, this.flags[e];\n  }\n\n  getNumber(e) {\n    return this.get(e);\n  }\n\n  getBool(e) {\n    return this.get(e);\n  }\n\n  getFlags() {\n    return this.flags;\n  }\n\n  get features() {\n    return this.flags;\n  }\n\n  set(e, t) {\n    if (null == this.flagRegistry[e]) throw new Error(\"Cannot set flag \".concat(e, \" as it has not been registered.\"));\n    this.flags[e] = t, null != this.flagRegistry[e].setHook && this.flagRegistry[e].setHook(t);\n  }\n\n  evaluateFlag(e) {\n    if (null == this.flagRegistry[e]) throw new Error(\"Cannot evaluate flag '\".concat(e, \"': no evaluation function found.\"));\n    return this.flagRegistry[e].evaluationFn();\n  }\n\n  setFlags(e) {\n    this.flags = Object.assign({}, e);\n  }\n\n  reset() {\n    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();\n  }\n\n  populateURLFlags() {\n    if (void 0 === this.global || void 0 === this.global.location || void 0 === this.global.location.search) return;\n    var e = this.getQueryParams(this.global.location.search);\n    \"tfjsflags\" in e && e.tfjsflags.split(\",\").forEach(e => {\n      var [t, n] = e.split(\":\");\n\n      this.urlFlags[t] = function (e, t) {\n        if (\"true\" === (t = t.toLowerCase()) || \"false\" === t) return \"true\" === t;\n        if (\"\" + +t === t) return +t;\n        throw new Error(\"Could not parse value flag value \".concat(t, \" for flag \").concat(e, \".\"));\n      }(t, n);\n    });\n  }\n\n}\n\nfunction V(e) {\n  var t = {};\n  return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (e) {\n    for (var _len = arguments.length, n = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      n[_key - 1] = arguments[_key];\n    }\n\n    return function (e, t, n) {\n      e[decodeURIComponent(t)] = decodeURIComponent(n || \"\");\n    }(t, n[0], n[1]), n.join(\"=\");\n  }), t;\n}\n\nfunction G() {\n  return q;\n}\n\nvar H,\n    q = null;\n\nfunction j() {\n  if (null == H) {\n    var _e3;\n\n    if (\"undefined\" != typeof window) _e3 = window;else if (\"undefined\" != typeof global) _e3 = global;else if (\"undefined\" != typeof process) _e3 = process;else {\n      if (\"undefined\" == typeof self) throw new Error(\"Could not find a global object\");\n      _e3 = self;\n    }\n    H = _e3;\n  }\n\n  return H;\n}\n\nfunction K(e, t) {\n  var n = function () {\n    var e = j();\n    return null == e._tfGlobals && (e._tfGlobals = new Map()), e._tfGlobals;\n  }();\n\n  if (n.has(e)) return n.get(e);\n  {\n    var _s4 = t();\n\n    return n.set(e, _s4), n.get(e);\n  }\n}\n\nvar X = K(\"kernelRegistry\", () => new Map()),\n    Y = K(\"gradRegistry\", () => new Map());\n\nfunction J(e, t) {\n  var n = ne(e, t);\n  return X.get(n);\n}\n\nfunction Z(e) {\n  return Y.get(e);\n}\n\nfunction Q(e) {\n  var t = X.entries(),\n      n = [];\n\n  for (;;) {\n    var {\n      done: _s5,\n      value: _r2\n    } = t.next();\n    if (_s5) break;\n\n    var [_a4, _i3] = _r2,\n        [_o3] = _a4.split(\"_\");\n\n    _o3 === e && n.push(_i3);\n  }\n\n  return n;\n}\n\nfunction ee(e) {\n  var {\n    kernelName: t,\n    backendName: n\n  } = e,\n      s = ne(t, n);\n  X.has(s) && W(\"The kernel '\".concat(t, \"' for backend '\").concat(n, \"' is already registered\")), X.set(s, e);\n}\n\nfunction te(e) {\n  var {\n    kernelName: t\n  } = e;\n  Y.has(t) && G().getBool(\"DEBUG\") && W(\"Overriding the gradient for '\".concat(t, \"'\")), Y.set(t, e);\n}\n\nfunction ne(e, t) {\n  return \"\".concat(t, \"_\").concat(e);\n}\n\nvar se = ae,\n    re = null;\n\ntry {\n  re = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n} catch (e) {}\n\nfunction ae(e, t, n) {\n  this.low = 0 | e, this.high = 0 | t, this.unsigned = !!n;\n}\n\nfunction ie(e) {\n  return !0 === (e && e.__isLong__);\n}\n\nObject.defineProperty(ae.prototype, \"__isLong__\", {\n  value: !0\n}), ae.isLong = ie;\nvar oe = {},\n    le = {};\n\nfunction ue(e, t) {\n  var n, s, r;\n  return t ? (r = 0 <= (e >>>= 0) && e < 256) && (s = le[e]) ? s : (n = he(e, (0 | e) < 0 ? -1 : 0, !0), r && (le[e] = n), n) : (r = -128 <= (e |= 0) && e < 128) && (s = oe[e]) ? s : (n = he(e, e < 0 ? -1 : 0, !1), r && (oe[e] = n), n);\n}\n\nfunction ce(e, t) {\n  if (isNaN(e)) return t ? ke : ye;\n\n  if (t) {\n    if (e < 0) return ke;\n    if (e >= me) return Se;\n  } else {\n    if (e <= -be) return Ne;\n    if (e + 1 >= be) return $e;\n  }\n\n  return e < 0 ? ce(-e, t).neg() : he(e % ge | 0, e / ge | 0, t);\n}\n\nfunction he(e, t, n) {\n  return new ae(e, t, n);\n}\n\nae.fromInt = ue, ae.fromNumber = ce, ae.fromBits = he;\nvar de = Math.pow;\n\nfunction pe(e, t, n) {\n  if (0 === e.length) throw Error(\"empty string\");\n  if (\"NaN\" === e || \"Infinity\" === e || \"+Infinity\" === e || \"-Infinity\" === e) return ye;\n  if (\"number\" == typeof t ? (n = t, t = !1) : t = !!t, (n = n || 10) < 2 || 36 < n) throw RangeError(\"radix\");\n  var s;\n  if ((s = e.indexOf(\"-\")) > 0) throw Error(\"interior hyphen\");\n  if (0 === s) return pe(e.substring(1), t, n).neg();\n\n  for (var r = ce(de(n, 8)), a = ye, i = 0; i < e.length; i += 8) {\n    var o = Math.min(8, e.length - i),\n        l = parseInt(e.substring(i, i + o), n);\n\n    if (o < 8) {\n      var u = ce(de(n, o));\n      a = a.mul(u).add(ce(l));\n    } else a = (a = a.mul(r)).add(ce(l));\n  }\n\n  return a.unsigned = t, a;\n}\n\nfunction fe(e, t) {\n  return \"number\" == typeof e ? ce(e, t) : \"string\" == typeof e ? pe(e, t) : he(e.low, e.high, \"boolean\" == typeof t ? t : e.unsigned);\n}\n\nae.fromString = pe, ae.fromValue = fe;\nvar ge = 4294967296,\n    me = ge * ge,\n    be = me / 2,\n    xe = ue(1 << 24),\n    ye = ue(0);\nae.ZERO = ye;\nvar ke = ue(0, !0);\nae.UZERO = ke;\nvar we = ue(1);\nae.ONE = we;\nvar ve = ue(1, !0);\nae.UONE = ve;\nvar Ie = ue(-1);\nae.NEG_ONE = Ie;\nvar $e = he(-1, 2147483647, !1);\nae.MAX_VALUE = $e;\nvar Se = he(-1, -1, !0);\nae.MAX_UNSIGNED_VALUE = Se;\nvar Ne = he(0, -2147483648, !1);\nae.MIN_VALUE = Ne;\nvar Ce = ae.prototype;\nCe.toInt = function () {\n  return this.unsigned ? this.low >>> 0 : this.low;\n}, Ce.toNumber = function () {\n  return this.unsigned ? (this.high >>> 0) * ge + (this.low >>> 0) : this.high * ge + (this.low >>> 0);\n}, Ce.toString = function (e) {\n  if ((e = e || 10) < 2 || 36 < e) throw RangeError(\"radix\");\n  if (this.isZero()) return \"0\";\n\n  if (this.isNegative()) {\n    if (this.eq(Ne)) {\n      var t = ce(e),\n          n = this.div(t),\n          s = n.mul(t).sub(this);\n      return n.toString(e) + s.toInt().toString(e);\n    }\n\n    return \"-\" + this.neg().toString(e);\n  }\n\n  for (var r = ce(de(e, 6), this.unsigned), a = this, i = \"\";;) {\n    var o = a.div(r),\n        l = (a.sub(o.mul(r)).toInt() >>> 0).toString(e);\n    if ((a = o).isZero()) return l + i;\n\n    for (; l.length < 6;) {\n      l = \"0\" + l;\n    }\n\n    i = \"\" + l + i;\n  }\n}, Ce.getHighBits = function () {\n  return this.high;\n}, Ce.getHighBitsUnsigned = function () {\n  return this.high >>> 0;\n}, Ce.getLowBits = function () {\n  return this.low;\n}, Ce.getLowBitsUnsigned = function () {\n  return this.low >>> 0;\n}, Ce.getNumBitsAbs = function () {\n  if (this.isNegative()) return this.eq(Ne) ? 64 : this.neg().getNumBitsAbs();\n\n  for (var e = 0 != this.high ? this.high : this.low, t = 31; t > 0 && 0 == (e & 1 << t); t--) {\n    ;\n  }\n\n  return 0 != this.high ? t + 33 : t + 1;\n}, Ce.isZero = function () {\n  return 0 === this.high && 0 === this.low;\n}, Ce.eqz = Ce.isZero, Ce.isNegative = function () {\n  return !this.unsigned && this.high < 0;\n}, Ce.isPositive = function () {\n  return this.unsigned || this.high >= 0;\n}, Ce.isOdd = function () {\n  return 1 == (1 & this.low);\n}, Ce.isEven = function () {\n  return 0 == (1 & this.low);\n}, Ce.equals = function (e) {\n  return ie(e) || (e = fe(e)), (this.unsigned === e.unsigned || this.high >>> 31 != 1 || e.high >>> 31 != 1) && this.high === e.high && this.low === e.low;\n}, Ce.eq = Ce.equals, Ce.notEquals = function (e) {\n  return !this.eq(e);\n}, Ce.neq = Ce.notEquals, Ce.ne = Ce.notEquals, Ce.lessThan = function (e) {\n  return this.comp(e) < 0;\n}, Ce.lt = Ce.lessThan, Ce.lessThanOrEqual = function (e) {\n  return this.comp(e) <= 0;\n}, Ce.lte = Ce.lessThanOrEqual, Ce.le = Ce.lessThanOrEqual, Ce.greaterThan = function (e) {\n  return this.comp(e) > 0;\n}, Ce.gt = Ce.greaterThan, Ce.greaterThanOrEqual = function (e) {\n  return this.comp(e) >= 0;\n}, Ce.gte = Ce.greaterThanOrEqual, Ce.ge = Ce.greaterThanOrEqual, Ce.compare = function (e) {\n  if (ie(e) || (e = fe(e)), this.eq(e)) return 0;\n  var t = this.isNegative(),\n      n = e.isNegative();\n  return t && !n ? -1 : !t && n ? 1 : this.unsigned ? e.high >>> 0 > this.high >>> 0 || e.high === this.high && e.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(e).isNegative() ? -1 : 1;\n}, Ce.comp = Ce.compare, Ce.negate = function () {\n  return !this.unsigned && this.eq(Ne) ? Ne : this.not().add(we);\n}, Ce.neg = Ce.negate, Ce.add = function (e) {\n  ie(e) || (e = fe(e));\n  var t = 0,\n      n = 0,\n      s = 0,\n      r = 0;\n  return s += (r += (65535 & this.low) + (65535 & e.low)) >>> 16, n += (s += (this.low >>> 16) + (e.low >>> 16)) >>> 16, t += (n += (65535 & this.high) + (65535 & e.high)) >>> 16, t += (this.high >>> 16) + (e.high >>> 16), he((s &= 65535) << 16 | (r &= 65535), (t &= 65535) << 16 | (n &= 65535), this.unsigned);\n}, Ce.subtract = function (e) {\n  return ie(e) || (e = fe(e)), this.add(e.neg());\n}, Ce.sub = Ce.subtract, Ce.multiply = function (e) {\n  if (this.isZero()) return ye;\n  if (ie(e) || (e = fe(e)), re) return he(re.mul(this.low, this.high, e.low, e.high), re.get_high(), this.unsigned);\n  if (e.isZero()) return ye;\n  if (this.eq(Ne)) return e.isOdd() ? Ne : ye;\n  if (e.eq(Ne)) return this.isOdd() ? Ne : ye;\n  if (this.isNegative()) return e.isNegative() ? this.neg().mul(e.neg()) : this.neg().mul(e).neg();\n  if (e.isNegative()) return this.mul(e.neg()).neg();\n  if (this.lt(xe) && e.lt(xe)) return ce(this.toNumber() * e.toNumber(), this.unsigned);\n  var t = 65535 & this.high,\n      n = this.low >>> 16,\n      s = 65535 & this.low,\n      r = 65535 & e.high,\n      a = e.low >>> 16,\n      i = 65535 & e.low,\n      o = 0,\n      l = 0,\n      u = 0,\n      c = 0;\n  return u += (c += s * i) >>> 16, l += (u += n * i) >>> 16, u &= 65535, l += (u += s * a) >>> 16, o += (l += t * i) >>> 16, l &= 65535, o += (l += n * a) >>> 16, l &= 65535, o += (l += s * r) >>> 16, o += (this.high >>> 16) * i + t * a + n * r + s * (e.high >>> 16), he((u &= 65535) << 16 | (c &= 65535), (o &= 65535) << 16 | (l &= 65535), this.unsigned);\n}, Ce.mul = Ce.multiply, Ce.divide = function (e) {\n  if (ie(e) || (e = fe(e)), e.isZero()) throw Error(\"division by zero\");\n  var t, n, s;\n  if (re) return this.unsigned || -2147483648 !== this.high || -1 !== e.low || -1 !== e.high ? he((this.unsigned ? re.div_u : re.div_s)(this.low, this.high, e.low, e.high), re.get_high(), this.unsigned) : this;\n  if (this.isZero()) return this.unsigned ? ke : ye;\n\n  if (this.unsigned) {\n    if (e.unsigned || (e = e.toUnsigned()), e.gt(this)) return ke;\n    if (e.gt(this.shru(1))) return ve;\n    s = ke;\n  } else {\n    if (this.eq(Ne)) return e.eq(we) || e.eq(Ie) ? Ne : e.eq(Ne) ? we : (t = this.shr(1).div(e).shl(1)).eq(ye) ? e.isNegative() ? we : Ie : (n = this.sub(e.mul(t)), s = t.add(n.div(e)));\n    if (e.eq(Ne)) return this.unsigned ? ke : ye;\n    if (this.isNegative()) return e.isNegative() ? this.neg().div(e.neg()) : this.neg().div(e).neg();\n    if (e.isNegative()) return this.div(e.neg()).neg();\n    s = ye;\n  }\n\n  for (n = this; n.gte(e);) {\n    t = Math.max(1, Math.floor(n.toNumber() / e.toNumber()));\n\n    for (var r = Math.ceil(Math.log(t) / Math.LN2), a = r <= 48 ? 1 : de(2, r - 48), i = ce(t), o = i.mul(e); o.isNegative() || o.gt(n);) {\n      o = (i = ce(t -= a, this.unsigned)).mul(e);\n    }\n\n    i.isZero() && (i = we), s = s.add(i), n = n.sub(o);\n  }\n\n  return s;\n}, Ce.div = Ce.divide, Ce.modulo = function (e) {\n  return ie(e) || (e = fe(e)), re ? he((this.unsigned ? re.rem_u : re.rem_s)(this.low, this.high, e.low, e.high), re.get_high(), this.unsigned) : this.sub(this.div(e).mul(e));\n}, Ce.mod = Ce.modulo, Ce.rem = Ce.modulo, Ce.not = function () {\n  return he(~this.low, ~this.high, this.unsigned);\n}, Ce.and = function (e) {\n  return ie(e) || (e = fe(e)), he(this.low & e.low, this.high & e.high, this.unsigned);\n}, Ce.or = function (e) {\n  return ie(e) || (e = fe(e)), he(this.low | e.low, this.high | e.high, this.unsigned);\n}, Ce.xor = function (e) {\n  return ie(e) || (e = fe(e)), he(this.low ^ e.low, this.high ^ e.high, this.unsigned);\n}, Ce.shiftLeft = function (e) {\n  return ie(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? he(this.low << e, this.high << e | this.low >>> 32 - e, this.unsigned) : he(0, this.low << e - 32, this.unsigned);\n}, Ce.shl = Ce.shiftLeft, Ce.shiftRight = function (e) {\n  return ie(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? he(this.low >>> e | this.high << 32 - e, this.high >> e, this.unsigned) : he(this.high >> e - 32, this.high >= 0 ? 0 : -1, this.unsigned);\n}, Ce.shr = Ce.shiftRight, Ce.shiftRightUnsigned = function (e) {\n  if (ie(e) && (e = e.toInt()), 0 == (e &= 63)) return this;\n  var t = this.high;\n  return e < 32 ? he(this.low >>> e | t << 32 - e, t >>> e, this.unsigned) : he(32 === e ? t : t >>> e - 32, 0, this.unsigned);\n}, Ce.shru = Ce.shiftRightUnsigned, Ce.shr_u = Ce.shiftRightUnsigned, Ce.toSigned = function () {\n  return this.unsigned ? he(this.low, this.high, !1) : this;\n}, Ce.toUnsigned = function () {\n  return this.unsigned ? this : he(this.low, this.high, !0);\n}, Ce.toBytes = function (e) {\n  return e ? this.toBytesLE() : this.toBytesBE();\n}, Ce.toBytesLE = function () {\n  var e = this.high,\n      t = this.low;\n  return [255 & t, t >>> 8 & 255, t >>> 16 & 255, t >>> 24, 255 & e, e >>> 8 & 255, e >>> 16 & 255, e >>> 24];\n}, Ce.toBytesBE = function () {\n  var e = this.high,\n      t = this.low;\n  return [e >>> 24, e >>> 16 & 255, e >>> 8 & 255, 255 & e, t >>> 24, t >>> 16 & 255, t >>> 8 & 255, 255 & t];\n}, ae.fromBytes = function (e, t, n) {\n  return n ? ae.fromBytesLE(e, t) : ae.fromBytesBE(e, t);\n}, ae.fromBytesLE = function (e, t) {\n  return new ae(e[0] | e[1] << 8 | e[2] << 16 | e[3] << 24, e[4] | e[5] << 8 | e[6] << 16 | e[7] << 24, t);\n}, ae.fromBytesBE = function (e, t) {\n  return new ae(e[4] << 24 | e[5] << 16 | e[6] << 8 | e[7], e[0] << 24 | e[1] << 16 | e[2] << 8 | e[3], t);\n};\nvar Te = se;\nvar Ee = Te || Object.assign(Object.create(null), se, {\n  default: Te\n});\n\nfunction Re(e) {\n  return Ee.fromString(e, !0, 16);\n}\n\nvar Ae = Re(\"c3a5c85c97cb3127\"),\n    Fe = Re(\"b492b66fbe98f273\"),\n    De = Re(\"9ae16a3b2f90404f\");\n\nfunction _e(e) {\n  return e.xor(e.shru(47));\n}\n\nfunction Oe(e, t, n) {\n  var s = e.slice(t, t + n);\n  return Ee.fromBytes(Array.from(s), !0, !0);\n}\n\nfunction Me(e, t) {\n  return Oe(e, t, 8);\n}\n\nfunction Le(e, t) {\n  return Oe(e, t, 4);\n}\n\nfunction ze(e, t) {\n  return 0 === t ? e : e.shru(t).or(e.shl(64 - t));\n}\n\nfunction Be(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : Re(\"9ddfea08eb382d69\");\n  var s = e.xor(t).mul(n);\n  s = s.xor(s.shru(47));\n  var r = t.xor(s).mul(n);\n  return r = r.xor(r.shru(47)), r = r.mul(n), r;\n}\n\nfunction Pe(e, t, n, s) {\n  return function (e, t, n, s, r, a) {\n    r = r.add(e), a = ze(a.add(r).add(s), 21);\n    var i = r;\n    return r = (r = r.add(t)).add(n), a = a.add(ze(r, 44)), [r.add(s), a.add(i)];\n  }(Me(e, t), Me(e, t + 8), Me(e, t + 16), Me(e, t + 24), n, s);\n}\n\nfunction We(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n  var n = Ee.fromNumber(81, !0);\n  if (t <= 32) return t <= 16 ? function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n\n    if (t >= 8) {\n      var _n5 = De.add(2 * t),\n          _s6 = Me(e, 0).add(De),\n          _r3 = Me(e, t - 8);\n\n      return Be(ze(_r3, 37).mul(_n5).add(_s6), ze(_s6, 25).add(_r3).mul(_n5), _n5);\n    }\n\n    if (t >= 4) {\n      var _n6 = De.add(2 * t);\n\n      return Be(Le(e, 0).shl(3).add(t), Le(e, t - 4), _n6);\n    }\n\n    if (t > 0) {\n      var _n7 = t + (e[t - 1] << 2);\n\n      return _e(De.mul(e[0] + (e[t >> 1] << 8)).xor(Ae.mul(_n7))).mul(De);\n    }\n\n    return De;\n  }(e, t) : function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n    var n = De.add(2 * t),\n        s = Me(e, 0).mul(Fe),\n        r = Me(e, 8),\n        a = Me(e, t - 8).mul(n),\n        i = Me(e, t - 16).mul(De);\n    return Be(ze(s.add(r), 43).add(ze(a, 30)).add(i), s.add(ze(r.add(De), 18)).add(a), n);\n  }(e, t);\n  if (t <= 64) return function (e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;\n    var n = De.add(2 * t),\n        s = Me(e, 0).mul(De),\n        r = Me(e, 8),\n        a = Me(e, t - 8).mul(n),\n        i = Me(e, t - 16).mul(De),\n        o = ze(s.add(r), 43).add(ze(a, 30)).add(i),\n        l = Be(o, s.add(ze(r.add(De), 18)).add(a), n),\n        u = Me(e, 16).mul(n),\n        c = Me(e, 24),\n        h = o.add(Me(e, t - 32)).mul(n),\n        d = l.add(Me(e, t - 24)).mul(n);\n    return Be(ze(u.add(c), 43).add(ze(h, 30)).add(d), u.add(ze(c.add(s), 18)).add(h), n);\n  }(e, t);\n\n  var s = n,\n      r = n.mul(Fe).add(113),\n      a = _e(r.mul(De).add(113)).mul(De),\n      i = [Ee.UZERO, Ee.UZERO],\n      o = [Ee.UZERO, Ee.UZERO];\n\n  s = s.mul(De).add(Me(e, 0));\n  var l = 0;\n  var u = 64 * (t - 1 >> 6),\n      c = u + (t - 1 & 63) - 63;\n\n  do {\n    s = ze(s.add(r).add(i[0]).add(Me(e, l + 8)), 37).mul(Fe), r = ze(r.add(i[1]).add(Me(e, l + 48)), 42).mul(Fe), s = s.xor(o[1]), r = r.add(i[0]).add(Me(e, l + 40)), a = ze(a.add(o[0]), 33).mul(Fe), i = Pe(e, l, i[1].mul(Fe), s.add(o[0])), o = Pe(e, l + 32, a.add(o[1]), r.add(Me(e, l + 16))), [a, s] = [s, a], l += 64;\n  } while (l !== u);\n\n  var h = Fe.add(a.and(255).shl(1));\n  return l = c, o[0] = o[0].add(t - 1 & 63), i[0] = i[0].add(o[0]), o[0] = o[0].add(i[0]), s = ze(s.add(r).add(i[0]).add(Me(e, l + 8)), 37).mul(h), r = ze(r.add(i[1]).add(Me(e, l + 48)), 42).mul(h), s = s.xor(o[1].mul(9)), r = r.add(i[0].mul(9).add(Me(e, l + 40))), a = ze(a.add(o[0]), 33).mul(h), i = Pe(e, l, i[1].mul(h), s.add(o[0])), o = Pe(e, l + 32, a.add(o[1]), r.add(Me(e, l + 16))), [a, s] = [s, a], Be(Be(i[0], o[0], h).add(_e(r).mul(Ae)).add(a), Be(i[1], o[1], h).add(s), h);\n}\n\nfunction Ue(e, t) {\n  return \"string\" === t ? He(e) : Ve([e], t);\n}\n\nfunction Ve(e, t) {\n  if (\"string\" === t) throw new Error(\"Cannot convert a string[] to a TypedArray\");\n  if (Array.isArray(e) && (e = h(e)), G().getBool(\"DEBUG\") && function (e, t) {\n    for (var _n8 = 0; _n8 < e.length; _n8++) {\n      var _s7 = e[_n8];\n      if (isNaN(_s7) || !isFinite(_s7)) throw Error(\"A tensor of type \".concat(t, \" being uploaded contains \").concat(_s7, \".\"));\n    }\n  }(e, t), function (e, t) {\n    return e instanceof Float32Array && \"float32\" === t || e instanceof Int32Array && \"int32\" === t || e instanceof Uint8Array && \"bool\" === t;\n  }(e, t)) return e;\n  if (null == t || \"float32\" === t || \"complex64\" === t) return new Float32Array(e);\n  if (\"int32\" === t) return new Int32Array(e);\n\n  if (\"bool\" === t) {\n    var _t9 = new Uint8Array(e.length);\n\n    for (var _n9 = 0; _n9 < _t9.length; ++_n9) {\n      0 !== Math.round(e[_n9]) && (_t9[_n9] = 1);\n    }\n\n    return _t9;\n  }\n\n  throw new Error(\"Unknown data type \".concat(t));\n}\n\nfunction Ge() {\n  return G().platform.now();\n}\n\nfunction He(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"utf-8\";\n  return t = t || \"utf-8\", G().platform.encode(e, t);\n}\n\nfunction qe(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"utf-8\";\n  return t = t || \"utf-8\", G().platform.decode(e, t);\n}\n\nclass je {\n  constructor(e, t) {\n    this.backendTimer = e, this.logger = t, null == t && (this.logger = new Xe());\n  }\n\n  profileKernel(e, t, n) {\n    var s;\n\n    var r = () => {\n      s = n();\n    };\n\n    var a;\n    var i = Ge();\n    if (this.backendTimer.timerAvailable()) a = this.backendTimer.time(r);else {\n      r();\n\n      for (var _e4 of s) {\n        _e4.dataSync();\n      }\n\n      a = Promise.resolve({\n        kernelMs: Ge() - i\n      });\n    }\n\n    if (G().getBool(\"CHECK_COMPUTATION_FOR_ERRORS\")) {\n      var _loop = function _loop(_t10) {\n        var n = s[_t10];\n        n.data().then(t => {\n          Ke(t, n.dtype, e);\n        });\n      };\n\n      for (var _t10 = 0; _t10 < s.length; _t10++) {\n        _loop(_t10);\n      }\n    }\n\n    return {\n      kernelName: e,\n      outputs: s,\n      inputs: t,\n      timeMs: a.then(e => e.kernelMs),\n      extraInfo: a.then(e => null != e.getExtraProfileInfo ? e.getExtraProfileInfo() : \"\")\n    };\n  }\n\n  logKernelProfile(e) {\n    var {\n      kernelName: t,\n      outputs: n,\n      timeMs: s,\n      inputs: r,\n      extraInfo: a\n    } = e;\n    n.forEach(e => {\n      Promise.all([e.data(), s, a]).then(n => {\n        this.logger.logKernelProfile(t, e, n[0], n[1], r, n[2]);\n      });\n    });\n  }\n\n}\n\nfunction Ke(e, t, n) {\n  if (\"float32\" !== t) return !1;\n\n  for (var _t11 = 0; _t11 < e.length; _t11++) {\n    var _s8 = e[_t11];\n    if (isNaN(_s8) || !isFinite(_s8)) return console.warn(\"Found \".concat(_s8, \" in the result of '\").concat(n, \"'\")), !0;\n  }\n\n  return !1;\n}\n\nclass Xe {\n  logKernelProfile(e, t, n, s, r, a) {\n    var i = \"number\" == typeof s ? m(\"\".concat(s, \"ms\"), 9) : s.error,\n        o = m(e, 25),\n        l = t.rank,\n        u = t.size,\n        c = m(t.shape.toString(), 14);\n    var h = \"\";\n\n    for (var _e5 in r) {\n      var _n10 = r[_e5];\n\n      if (null != _n10) {\n        var _s9 = _n10.shape || t.shape,\n            _r4 = _s9.length;\n\n        h += \"\".concat(_e5, \": \").concat(_r4, \"D \").concat(_r4 > 0 ? _s9 : \"\", \" \");\n      }\n    }\n\n    console.log(\"%c\".concat(o, \"\\t%c\").concat(i, \"\\t%c\").concat(l, \"D \").concat(c, \"\\t%c\").concat(u, \"\\t%c\").concat(h, \"\\t%c\").concat(a), \"font-weight:bold\", \"color:red\", \"color:blue\", \"color: orange\", \"color: green\", \"color: steelblue\");\n  }\n\n}\n\nfunction Ye(e, t, n, s) {\n  var r = A(t),\n      a = function (e, t, n, s) {\n    var r = d(t),\n        a = s[s.length - 1],\n        i = new Array(a).fill(0),\n        o = t.length,\n        l = \"complex64\" === n ? et(e) : e;\n    if (o > 1) for (var _e6 = 0; _e6 < r / a; _e6++) {\n      var _t12 = _e6 * a;\n\n      for (var _e7 = 0; _e7 < a; _e7++) {\n        i[_e7] = Math.max(i[_e7], Je(l[_t12 + _e7], 0, n).length);\n      }\n    }\n    return i;\n  }(e, t, n, r),\n      i = t.length,\n      o = Qe(e, t, n, r, a),\n      l = [\"Tensor\"];\n\n  return s && (l.push(\"  dtype: \".concat(n)), l.push(\"  rank: \".concat(i)), l.push(\"  shape: [\".concat(t, \"]\")), l.push(\"  values:\")), l.push(o.map(e => \"    \" + e).join(\"\\n\")), l.join(\"\\n\");\n}\n\nfunction Je(e, t, n) {\n  var s;\n  return s = Array.isArray(e) ? \"\".concat(parseFloat(e[0].toFixed(7)), \" + \").concat(parseFloat(e[1].toFixed(7)), \"j\") : N(e) ? \"'\".concat(e, \"'\") : \"bool\" === n ? Ze(e) : parseFloat(e.toFixed(7)).toString(), m(s, t);\n}\n\nfunction Ze(e) {\n  return 0 === e ? \"false\" : \"true\";\n}\n\nfunction Qe(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !0;\n  var i = \"complex64\" === n ? 2 : 1,\n      o = t[0],\n      l = t.length;\n  if (0 === l) return \"complex64\" === n ? [Je(et(e)[0], 0, n)] : \"bool\" === n ? [Ze(e[0])] : [e[0].toString()];\n\n  if (1 === l) {\n    if (o > 20) {\n      var _t13 = Array.from(e.slice(0, 3 * i)),\n          _s10 = Array.from(e.slice((o - 3) * i, o * i));\n\n      return \"complex64\" === n && (_t13 = et(_t13), _s10 = et(_s10)), [\"[\" + _t13.map((e, t) => Je(e, r[t], n)).join(\", \") + \", ..., \" + _s10.map((e, t) => Je(e, r[o - 3 + t], n)).join(\", \") + \"]\"];\n    }\n\n    return [\"[\" + (\"complex64\" === n ? et(e) : Array.from(e)).map((e, t) => Je(e, r[t], n)).join(\", \") + \"]\"];\n  }\n\n  var u = t.slice(1),\n      c = s.slice(1),\n      h = s[0] * i,\n      d = [];\n\n  if (o > 20) {\n    for (var _t14 = 0; _t14 < 3; _t14++) {\n      var _s11 = _t14 * h;\n\n      d.push(...Qe(e.slice(_s11, _s11 + h), u, n, c, r, !1));\n    }\n\n    d.push(\"...\");\n\n    for (var _t15 = o - 3; _t15 < o; _t15++) {\n      var _s12 = _t15 * h;\n\n      d.push(...Qe(e.slice(_s12, _s12 + h), u, n, c, r, _t15 === o - 1));\n    }\n  } else for (var _t16 = 0; _t16 < o; _t16++) {\n    var _s13 = _t16 * h;\n\n    d.push(...Qe(e.slice(_s13, _s13 + h), u, n, c, r, _t16 === o - 1));\n  }\n\n  var p = 2 === l ? \",\" : \"\";\n  d[0] = \"[\" + d[0] + p;\n\n  for (var _e8 = 1; _e8 < d.length - 1; _e8++) {\n    d[_e8] = \" \" + d[_e8] + p;\n  }\n\n  var f = \",\\n\";\n\n  for (var _e9 = 2; _e9 < l; _e9++) {\n    f += \"\\n\";\n  }\n\n  return d[d.length - 1] = \" \" + d[d.length - 1] + \"]\" + (a ? \"\" : f), d;\n}\n\nfunction et(e) {\n  var t = [];\n\n  for (var _n11 = 0; _n11 < e.length; _n11 += 2) {\n    t.push([e[_n11], e[_n11 + 1]]);\n  }\n\n  return t;\n}\n\nclass tt {\n  constructor(e, t, n) {\n    if (this.dtype = t, this.shape = e.slice(), this.size = d(e), null != n) {\n      var _e10 = n.length;\n      l(_e10 === this.size, () => \"Length of values '\".concat(_e10, \"' does not match the size inferred by the shape '\").concat(this.size, \"'.\"));\n    }\n\n    if (\"complex64\" === t) throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).\");\n    this.values = n || v(t, this.size), this.strides = A(e);\n  }\n\n  set(e) {\n    for (var _len2 = arguments.length, t = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n      t[_key2 - 1] = arguments[_key2];\n    }\n\n    0 === t.length && (t = [0]), l(t.length === this.rank, () => \"The number of provided coordinates (\".concat(t.length, \") must match the rank (\").concat(this.rank, \")\"));\n    var n = this.locToIndex(t);\n    this.values[n] = e;\n  }\n\n  get() {\n    for (var _len3 = arguments.length, e = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n      e[_key3] = arguments[_key3];\n    }\n\n    0 === e.length && (e = [0]);\n    var t = 0;\n\n    for (var _n12 of e) {\n      if (_n12 < 0 || _n12 >= this.shape[t]) throw new Error(\"Requested out of range element at \".concat(e, \".   Buffer shape=\").concat(this.shape));\n      t++;\n    }\n\n    var n = e[e.length - 1];\n\n    for (var _t17 = 0; _t17 < e.length - 1; ++_t17) {\n      n += this.strides[_t17] * e[_t17];\n    }\n\n    return this.values[n];\n  }\n\n  locToIndex(e) {\n    if (0 === this.rank) return 0;\n    if (1 === this.rank) return e[0];\n    var t = e[e.length - 1];\n\n    for (var _n13 = 0; _n13 < e.length - 1; ++_n13) {\n      t += this.strides[_n13] * e[_n13];\n    }\n\n    return t;\n  }\n\n  indexToLoc(e) {\n    if (0 === this.rank) return [];\n    if (1 === this.rank) return [e];\n    var t = new Array(this.shape.length);\n\n    for (var _n14 = 0; _n14 < t.length - 1; ++_n14) {\n      t[_n14] = Math.floor(e / this.strides[_n14]), e -= t[_n14] * this.strides[_n14];\n    }\n\n    return t[t.length - 1] = e, t;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  toTensor() {\n    return nt().makeTensor(this.values, this.shape, this.dtype);\n  }\n\n}\n\nvar nt = null,\n    st = null;\n\nclass rt {\n  constructor(e, t, n, s) {\n    this.kept = !1, this.isDisposedInternal = !1, this.shape = e.slice(), this.dtype = t || \"float32\", this.size = d(e), this.strides = A(e), this.dataId = n, this.id = s, this.rankType = this.rank < 5 ? this.rank.toString() : \"higher\";\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  buffer() {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this2.data();\n      return st.buffer(_this2.shape, _this2.dtype, e);\n    })();\n  }\n\n  bufferSync() {\n    return st.buffer(this.shape, this.dtype, this.dataSync());\n  }\n\n  array() {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this3.data();\n      return D(_this3.shape, e, \"complex64\" === _this3.dtype);\n    })();\n  }\n\n  arraySync() {\n    return D(this.shape, this.dataSync(), \"complex64\" === this.dtype);\n  }\n\n  data() {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      _this4.throwIfDisposed();\n\n      var e = nt().read(_this4.dataId);\n\n      if (\"string\" === _this4.dtype) {\n        var _t18 = yield e;\n\n        try {\n          return _t18.map(e => qe(e));\n        } catch (e) {\n          throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\");\n        }\n      }\n\n      return e;\n    })();\n  }\n\n  dataSync() {\n    this.throwIfDisposed();\n    var e = nt().readSync(this.dataId);\n    if (\"string\" === this.dtype) try {\n      return e.map(e => qe(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\");\n    }\n    return e;\n  }\n\n  bytes() {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      _this5.throwIfDisposed();\n\n      var e = yield nt().read(_this5.dataId);\n      return \"string\" === _this5.dtype ? e : new Uint8Array(e.buffer);\n    })();\n  }\n\n  dispose() {\n    this.isDisposed || (nt().disposeTensor(this), this.isDisposedInternal = !0);\n  }\n\n  get isDisposed() {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) throw new Error(\"Tensor is disposed.\");\n  }\n\n  print() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return st.print(this, e);\n  }\n\n  clone() {\n    return this.throwIfDisposed(), st.clone(this);\n  }\n\n  toString() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return Ye(this.dataSync(), this.shape, this.dtype, e);\n  }\n\n  cast(e) {\n    return this.throwIfDisposed(), st.cast(this, e);\n  }\n\n  variable() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !0;\n    var t = arguments.length > 1 ? arguments[1] : undefined;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    return this.throwIfDisposed(), nt().makeVariable(this, e, t, n);\n  }\n\n}\n\nfunction at() {\n  return K(\"Tensor\", () => rt);\n}\n\nObject.defineProperty(rt, Symbol.hasInstance, {\n  value: e => !!e && null != e.data && null != e.dataSync && null != e.throwIfDisposed\n}), at();\n\nclass it extends rt {\n  constructor(e, t, n, s) {\n    super(e.shape, e.dtype, e.dataId, s), this.trainable = t, this.name = n;\n  }\n\n  assign(e) {\n    if (e.dtype !== this.dtype) throw new Error(\"dtype of the new value (\".concat(e.dtype, \") and previous value (\").concat(this.dtype, \") must match\"));\n    if (!p(e.shape, this.shape)) throw new Error(\"shape of the new value (\".concat(e.shape, \") and previous value (\").concat(this.shape, \") must match\"));\n    nt().disposeTensor(this), this.dataId = e.dataId, nt().incRef(this, null);\n  }\n\n  dispose() {\n    nt().disposeVariable(this), this.isDisposedInternal = !0;\n  }\n\n}\n\nvar ot, lt, ut, ct, ht;\nObject.defineProperty(it, Symbol.hasInstance, {\n  value: e => e instanceof rt && null != e.assign && e.assign instanceof Function\n}), function (e) {\n  e.R0 = \"R0\", e.R1 = \"R1\", e.R2 = \"R2\", e.R3 = \"R3\", e.R4 = \"R4\", e.R5 = \"R5\", e.R6 = \"R6\";\n}(ot || (ot = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"int32\", e.bool = \"int32\", e.complex64 = \"complex64\";\n}(lt || (lt = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"int32\", e.bool = \"bool\", e.complex64 = \"complex64\";\n}(ut || (ut = {})), function (e) {\n  e.float32 = \"float32\", e.int32 = \"float32\", e.bool = \"float32\", e.complex64 = \"complex64\";\n}(ct || (ct = {})), function (e) {\n  e.float32 = \"complex64\", e.int32 = \"complex64\", e.bool = \"complex64\", e.complex64 = \"complex64\";\n}(ht || (ht = {}));\nvar dt = {\n  float32: ct,\n  int32: lt,\n  bool: ut,\n  complex64: ht\n};\n\nfunction pt(e, t) {\n  if (\"string\" === e || \"string\" === t) {\n    if (\"string\" === e && \"string\" === t) return \"string\";\n    throw new Error(\"Can not upcast \".concat(e, \" with \").concat(t));\n  }\n\n  return dt[e][t];\n}\n\nfunction ft(e) {\n  return pt(e, \"int32\");\n}\n\nfunction gt(e, t) {\n  if (e.dtype === t.dtype) return [e, t];\n  var n = pt(e.dtype, t.dtype);\n  return [e.cast(n), t.cast(n)];\n}\n\nfunction mt(e) {\n  var t = [];\n  return bt(e, t, new Set()), t;\n}\n\nfunction bt(e, t, n) {\n  if (null == e) return;\n  if (e instanceof rt) return void t.push(e);\n  if (s = e, !Array.isArray(s) && \"object\" != typeof s) return;\n  var s;\n  var r = e;\n\n  for (var _e11 in r) {\n    var _s14 = r[_e11];\n    n.has(_s14) || (n.add(_s14), bt(_s14, t, n));\n  }\n}\n\nfunction xt(e) {\n  return null != e.kernelName;\n}\n\nclass yt {\n  constructor() {\n    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = new WeakMap(), this.profiling = !1, this.activeProfile = {\n      newBytes: 0,\n      newTensors: 0,\n      peakBytes: 0,\n      kernels: [],\n      result: null,\n\n      get kernelNames() {\n        return Array.from(new Set(this.kernels.map(e => e.name)));\n      }\n\n    };\n  }\n\n  dispose() {\n    for (var _e12 in this.registeredVariables) {\n      this.registeredVariables[_e12].dispose();\n    }\n  }\n\n}\n\nclass kt {\n  constructor(e) {\n    this.ENV = e, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new yt();\n  }\n\n  ready() {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null != _this6.pendingBackendInit) return _this6.pendingBackendInit.then(() => {});\n      if (null != _this6.backendInstance) return;\n\n      var e = _this6.getSortedBackends();\n\n      for (var _t19 = 0; _t19 < e.length; _t19++) {\n        var _n15 = e[_t19];\n        if (yield _this6.initializeBackend(_n15).success) return void (yield _this6.setBackend(_n15));\n      }\n\n      throw new Error(\"Could not initialize any backends, all backend initializations failed.\");\n    })();\n  }\n\n  get backend() {\n    if (null != this.pendingBackendInit) throw new Error(\"Backend '\".concat(this.backendName, \"' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods\"));\n\n    if (null == this.backendInstance) {\n      var {\n        name: _e13,\n        asyncInit: _t20\n      } = this.initializeBackendsAndReturnBest();\n      if (_t20) throw new Error(\"The highest priority backend '\".concat(_e13, \"' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods\"));\n      this.setBackend(_e13);\n    }\n\n    return this.backendInstance;\n  }\n\n  backendNames() {\n    return Object.keys(this.registryFactory);\n  }\n\n  findBackend(e) {\n    if (!(e in this.registry)) {\n      if (!(e in this.registryFactory)) return null;\n      {\n        var {\n          asyncInit: _t21\n        } = this.initializeBackend(e);\n        if (_t21) return null;\n      }\n    }\n\n    return this.registry[e];\n  }\n\n  findBackendFactory(e) {\n    return e in this.registryFactory ? this.registryFactory[e].factory : null;\n  }\n\n  registerBackend(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    return e in this.registryFactory ? (W(\"\".concat(e, \" backend was already registered. Reusing existing backend factory.\")), !1) : (this.registryFactory[e] = {\n      factory: t,\n      priority: n\n    }, !0);\n  }\n\n  setBackend(e) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null == _this7.registryFactory[e]) throw new Error(\"Backend name '\".concat(e, \"' not found in registry\"));\n\n      if (_this7.backendName = e, null == _this7.registry[e]) {\n        _this7.backendInstance = null;\n\n        var {\n          success: _t22,\n          asyncInit: _n16\n        } = _this7.initializeBackend(e);\n\n        if (!(_n16 ? yield _t22 : _t22)) return !1;\n      }\n\n      return _this7.backendInstance = _this7.registry[e], _this7.setupRegisteredKernels(), _this7.profiler = new je(_this7.backendInstance), !0;\n    })();\n  }\n\n  setupRegisteredKernels() {\n    Q(this.backendName).forEach(e => {\n      null != e.setupFunc && e.setupFunc(this.backendInstance);\n    });\n  }\n\n  disposeRegisteredKernels(e) {\n    Q(e).forEach(t => {\n      null != t.disposeFunc && t.disposeFunc(this.registry[e]);\n    });\n  }\n\n  initializeBackend(e) {\n    var t = this.registryFactory[e];\n    if (null == t) throw new Error(\"Cannot initialize backend \".concat(e, \", no registration found.\"));\n\n    try {\n      var _s15 = t.factory();\n\n      if (!_s15 || _s15 instanceof n || \"function\" != typeof _s15.then) return this.registry[e] = _s15, {\n        success: !0,\n        asyncInit: !1\n      };\n      {\n        var _t23 = ++this.pendingBackendInitId,\n            _n17 = _s15.then(n => !(_t23 < this.pendingBackendInitId || (this.registry[e] = n, this.pendingBackendInit = null, 0))).catch(n => (_t23 < this.pendingBackendInitId || (this.pendingBackendInit = null, W(\"Initialization of backend \".concat(e, \" failed\")), W(n.stack || n.message)), !1));\n\n        return this.pendingBackendInit = _n17, {\n          success: _n17,\n          asyncInit: !0\n        };\n      }\n    } catch (t) {\n      return W(\"Initialization of backend \".concat(e, \" failed\")), W(t.stack || t.message), {\n        success: !1,\n        asyncInit: !1\n      };\n    }\n  }\n\n  removeBackend(e) {\n    if (!(e in this.registryFactory)) throw new Error(\"\".concat(e, \" backend not found in registry\"));\n    this.backendName === e && null != this.pendingBackendInit && this.pendingBackendInitId++, e in this.registry && (this.disposeRegisteredKernels(e), this.registry[e].dispose(), delete this.registry[e]), delete this.registryFactory[e], this.backendName === e && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);\n  }\n\n  getSortedBackends() {\n    if (0 === Object.keys(this.registryFactory).length) throw new Error(\"No backend found in registry.\");\n    return Object.keys(this.registryFactory).sort((e, t) => this.registryFactory[t].priority - this.registryFactory[e].priority);\n  }\n\n  initializeBackendsAndReturnBest() {\n    var e = this.getSortedBackends();\n\n    for (var _t24 = 0; _t24 < e.length; _t24++) {\n      var _n18 = e[_t24],\n          {\n        success: _s16,\n        asyncInit: _r5\n      } = this.initializeBackend(_n18);\n      if (_r5 || _s16) return {\n        name: _n18,\n        asyncInit: _r5\n      };\n    }\n\n    throw new Error(\"Could not initialize any backends, all backend initializations failed.\");\n  }\n\n  moveData(e, t) {\n    var n = this.state.tensorInfo.get(t),\n        s = n.backend,\n        r = this.readSync(t),\n        a = s.refCount(t);\n    s.disposeData(t, !0), n.backend = e, e.move(t, r, n.shape, n.dtype, a), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n  }\n\n  tidy(e, t) {\n    var n,\n        s = null;\n\n    if (null == t) {\n      if (\"function\" != typeof e) throw new Error(\"Please provide a function to tidy()\");\n      t = e;\n    } else {\n      if (\"string\" != typeof e && !(e instanceof String)) throw new Error(\"When calling with two arguments, the first argument to tidy() must be a string\");\n      if (\"function\" != typeof t) throw new Error(\"When calling with two arguments, the 2nd argument to tidy() must be a function\");\n      s = e;\n    }\n\n    return this.scopedRun(() => this.startScope(s), () => this.endScope(n), () => (n = t(), n instanceof Promise && console.error(\"Cannot return a Promise inside of tidy.\"), n));\n  }\n\n  scopedRun(e, t, n) {\n    e();\n\n    try {\n      var _e14 = n();\n\n      return t(), _e14;\n    } catch (e) {\n      throw t(), e;\n    }\n  }\n\n  nextTensorId() {\n    return kt.nextTensorId++;\n  }\n\n  nextVariableId() {\n    return kt.nextVariableId++;\n  }\n\n  clone(e) {\n    var t = vt.runKernel(\"Identity\", {\n      x: e\n    });\n    return this.addTapeNode(this.state.activeScope.name, {\n      x: e\n    }, [t], e => ({\n      x: () => vt.runKernel(\"Cast\", {\n        x: e\n      }, {\n        dtype: \"float32\"\n      })\n    }), [], {}), t;\n  }\n\n  runKernel(e, t, n) {\n    if (null == J(e, this.backendName)) throw new Error(\"Kernel '\".concat(e, \"' not registered for backend '\").concat(this.backendName, \"'\"));\n    return this.runKernelFunc({\n      kernelName: e,\n      inputs: t,\n      attrs: n\n    });\n  }\n\n  shouldCheckForMemLeaks() {\n    return this.ENV.getBool(\"IS_TEST\");\n  }\n\n  checkKernelForMemLeak(e, t, n) {\n    var s = this.backend.numDataIds();\n    var r = 0;\n    n.forEach(e => {\n      r += \"complex64\" === e.dtype ? 3 : 1;\n    });\n    var a = s - t - r - this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n    if (a > 0) throw new Error(\"Backend '\".concat(this.backendName, \"' has an internal memory leak (\").concat(a, \" data ids) after running '\").concat(e, \"'\"));\n  }\n\n  runKernelFunc(e) {\n    var t,\n        n = [];\n    var s = this.isTapeOn(),\n        r = this.state.numBytes,\n        a = this.state.numTensors;\n    var i, o;\n    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);\n    var u = xt(e) ? e.kernelName : null != this.state.activeScope ? this.state.activeScope.name : \"\";\n\n    if (xt(e)) {\n      var {\n        kernelName: _t25,\n        inputs: _r6,\n        attrs: _a5\n      } = e,\n          _u2 = J(_t25, this.backendName);\n\n      l(null != _u2, () => \"Cannot find registered kernel '\".concat(_t25, \"' for backend '\").concat(this.backendName, \"'\")), i = () => {\n        var e = this.backend.numDataIds();\n        o = _u2.kernelFunc({\n          inputs: _r6,\n          attrs: _a5,\n          backend: this.backend\n        });\n        var i = Array.isArray(o) ? o : [o];\n        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(_t25, e, i);\n        var l = i.map(e => {\n          if (null != e.rank) return e;\n          var {\n            dataId: t,\n            shape: n,\n            dtype: s\n          } = e;\n          return this.makeTensorFromDataId(t, n, s);\n        });\n\n        if (s) {\n          var _e15 = this.getTensorsForGradient(_t25, _r6, l);\n\n          n = this.saveTensorsForBackwardMode(_e15);\n        }\n\n        return l;\n      };\n    } else {\n      var {\n        forwardFunc: _t26\n      } = e,\n          _r7 = e => {\n        s && (n = e.map(e => this.keep(this.clone(e))));\n      };\n\n      i = () => {\n        var e = this.backend.numDataIds();\n        o = this.tidy(() => _t26(this.backend, _r7));\n        var n = Array.isArray(o) ? o : [o];\n        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(u, e, n), n;\n      };\n    }\n\n    var {\n      inputs: c,\n      attrs: h\n    } = e,\n        d = xt(e) ? null : e.backwardsFunc;\n    var p;\n    return this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n      this.ENV.getBool(\"DEBUG\") || this.state.profiling ? (p = this.profiler.profileKernel(u, c, () => i()), this.ENV.getBool(\"DEBUG\") && this.profiler.logKernelProfile(p), t = p.outputs) : t = i();\n    }), s && this.addTapeNode(u, c, t, d, n, h), this.state.profiling && this.state.activeProfile.kernels.push({\n      name: u,\n      bytesAdded: this.state.numBytes - r,\n      totalBytesSnapshot: this.state.numBytes,\n      tensorsAdded: this.state.numTensors - a,\n      totalTensorsSnapshot: this.state.numTensors,\n      inputShapes: Object.keys(c).map(e => null != c[e] ? c[e].shape : null),\n      outputShapes: t.map(e => e.shape),\n      kernelTimeMs: p.timeMs,\n      extraInfo: p.extraInfo\n    }), Array.isArray(o) ? t : t[0];\n  }\n\n  saveTensorsForBackwardMode(e) {\n    return e.map(e => this.keep(this.clone(e)));\n  }\n\n  getTensorsForGradient(e, t, n) {\n    var s = Z(e);\n\n    if (null != s) {\n      var _e16 = s.inputsToSave || [],\n          _r8 = s.outputsToSave || [];\n\n      var _a6;\n\n      s.saveAllInputs ? (l(Array.isArray(t), () => \"saveAllInputs is true, expected inputs to be an array.\"), _a6 = Object.keys(t).map(e => t[e])) : _a6 = _e16.map(e => t[e]);\n\n      var _i4 = n.filter((e, t) => _r8[t]);\n\n      return _a6.concat(_i4);\n    }\n\n    return [];\n  }\n\n  makeTensor(e, t, n, s) {\n    if (null == e) throw new Error(\"Values passed to engine.makeTensor() are null\");\n    s = s || this.backend;\n    var r = e;\n    \"string\" === (n = n || \"float32\") && N(e[0]) && (r = e.map(e => He(e)));\n    var a = s.write(r, t, n),\n        i = new rt(t, n, a, this.nextTensorId());\n\n    if (this.trackTensor(i, s), \"string\" === n) {\n      var _e17 = this.state.tensorInfo.get(a),\n          _t27 = function (e) {\n        if (null == e) return 0;\n        var t = 0;\n        return e.forEach(e => t += e.length), t;\n      }(r);\n\n      this.state.numBytes += _t27 - _e17.bytes, _e17.bytes = _t27;\n    }\n\n    return i;\n  }\n\n  makeTensorFromDataId(e, t, n, s) {\n    var r = new rt(t, n = n || \"float32\", e, this.nextTensorId());\n    return this.trackTensor(r, s), r;\n  }\n\n  makeVariable(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    n = n || this.nextVariableId().toString(), null != s && s !== e.dtype && (e = e.cast(s));\n    var r = new it(e, t, n, this.nextTensorId());\n    if (null != this.state.registeredVariables[r.name]) throw new Error(\"Variable with name \".concat(r.name, \" was already registered\"));\n    return this.state.registeredVariables[r.name] = r, this.incRef(r, this.backend), r;\n  }\n\n  trackTensor(e, t) {\n    this.state.numTensors++, \"string\" === e.dtype && this.state.numStringTensors++;\n    var n = 0;\n    \"complex64\" !== e.dtype && \"string\" !== e.dtype && (n = e.size * S(e.dtype)), this.state.numBytes += n, this.state.tensorInfo.has(e.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(e.dataId, {\n      backend: t || this.backend,\n      dtype: e.dtype,\n      shape: e.shape,\n      bytes: n\n    })), e instanceof it || this.track(e);\n  }\n\n  incRef(e, t) {\n    this.trackTensor(e, t), this.backend.incRef(e.dataId);\n  }\n\n  removeDataId(e, t) {\n    this.state.tensorInfo.has(e) && this.state.tensorInfo.get(e).backend === t && (this.state.tensorInfo.delete(e), this.state.numDataBuffers--);\n  }\n\n  disposeTensor(e) {\n    if (!this.state.tensorInfo.has(e.dataId)) return;\n    var t = this.state.tensorInfo.get(e.dataId);\n\n    if (this.state.numTensors--, \"string\" === e.dtype && (this.state.numStringTensors--, this.state.numBytes -= t.bytes), \"complex64\" !== e.dtype && \"string\" !== e.dtype) {\n      var _t28 = e.size * S(e.dtype);\n\n      this.state.numBytes -= _t28;\n    }\n\n    t.backend.disposeData(e.dataId) && this.removeDataId(e.dataId, t.backend);\n  }\n\n  disposeVariables() {\n    for (var _e18 in this.state.registeredVariables) {\n      this.disposeVariable(this.state.registeredVariables[_e18]);\n    }\n  }\n\n  disposeVariable(e) {\n    this.disposeTensor(e), null != this.state.registeredVariables[e.name] && delete this.state.registeredVariables[e.name];\n  }\n\n  memory() {\n    var e = this.backend.memory();\n    return e.numTensors = this.state.numTensors, e.numDataBuffers = this.state.numDataBuffers, e.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (e.unreliable = !0, null == e.reasons && (e.reasons = []), e.reasons.push(\"Memory usage by string tensors is approximate (2 bytes per character)\")), e;\n  }\n\n  profile(e) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      _this8.state.profiling = !0;\n      var t = _this8.state.numBytes,\n          n = _this8.state.numTensors;\n      _this8.state.activeProfile.kernels = [], _this8.state.activeProfile.result = yield e(), _this8.state.profiling = !1, _this8.state.activeProfile.peakBytes = Math.max(..._this8.state.activeProfile.kernels.map(e => e.totalBytesSnapshot)), _this8.state.activeProfile.newBytes = _this8.state.numBytes - t, _this8.state.activeProfile.newTensors = _this8.state.numTensors - n;\n\n      for (var _e19 of _this8.state.activeProfile.kernels) {\n        _e19.kernelTimeMs = yield _e19.kernelTimeMs, _e19.extraInfo = yield _e19.extraInfo;\n      }\n\n      return _this8.state.activeProfile;\n    })();\n  }\n\n  isTapeOn() {\n    return this.state.gradientDepth > 0 && 0 === this.state.kernelDepth;\n  }\n\n  addTapeNode(e, t, n, s, r, a) {\n    var i = {\n      id: this.state.nextTapeNodeId++,\n      kernelName: e,\n      inputs: t,\n      outputs: n,\n      saved: r\n    },\n        o = Z(e);\n    null != o && (s = o.gradFunc), null != s && (i.gradient = e => (e = e.map((e, t) => {\n      if (null == e) {\n        var _e20 = n[t],\n            _s17 = O(_e20.size, _e20.dtype);\n\n        return this.makeTensor(_s17, _e20.shape, _e20.dtype);\n      }\n\n      return e;\n    }), s(e.length > 1 ? e : e[0], r, a))), this.state.activeTape.push(i);\n  }\n\n  keep(e) {\n    return e.kept = !0, e;\n  }\n\n  startTape() {\n    0 === this.state.gradientDepth && (this.state.activeTape = []), this.state.gradientDepth++;\n  }\n\n  endTape() {\n    this.state.gradientDepth--;\n  }\n\n  startScope(e) {\n    var t = {\n      track: [],\n      name: \"unnamed scope\",\n      id: this.state.nextScopeId++\n    };\n    e && (t.name = e), this.state.scopeStack.push(t), this.state.activeScope = t;\n  }\n\n  endScope(e) {\n    var t = mt(e),\n        n = new Set(t.map(e => e.id));\n\n    for (var _e21 = 0; _e21 < this.state.activeScope.track.length; _e21++) {\n      var _t29 = this.state.activeScope.track[_e21];\n      _t29.kept || n.has(_t29.id) || _t29.dispose();\n    }\n\n    var s = this.state.scopeStack.pop();\n    this.state.activeScope = 0 === this.state.scopeStack.length ? null : this.state.scopeStack[this.state.scopeStack.length - 1], t.forEach(e => {\n      e.kept || e.scopeId !== s.id || this.track(e);\n    });\n  }\n\n  gradients(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    if (l(t.length > 0, () => \"gradients() received an empty list of xs.\"), null != n && \"float32\" !== n.dtype) throw new Error(\"dy must have 'float32' dtype, but has '\".concat(n.dtype, \"'\"));\n    var r = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy(\"forward\", e));\n    l(r instanceof rt, () => \"The result y returned by f() must be a tensor.\");\n\n    var a = function (e, t, n) {\n      var s = {},\n          r = {};\n\n      for (var _e22 = 0; _e22 < t.length; _e22++) {\n        s[t[_e22].id] = !0;\n      }\n\n      for (var _n19 = 0; _n19 < e.length; _n19++) {\n        var _a7 = e[_n19],\n            _i5 = _a7.inputs;\n\n        for (var _e23 in _i5) {\n          var _n20 = _i5[_e23];\n\n          var _o4 = !1;\n\n          for (var _e24 = 0; _e24 < t.length; _e24++) {\n            if (s[_n20.id]) {\n              _a7.outputs.forEach(e => s[e.id] = !0), _o4 = !0, r[_a7.id] = !0;\n              break;\n            }\n          }\n\n          if (_o4) break;\n        }\n      }\n\n      var a = {};\n      a[n.id] = !0;\n      var i = {};\n\n      for (var _t30 = e.length - 1; _t30 >= 0; _t30--) {\n        var _n21 = e[_t30],\n            _s18 = _n21.inputs;\n\n        for (var _e25 = 0; _e25 < _n21.outputs.length; _e25++) {\n          if (a[_n21.outputs[_e25].id]) {\n            for (var _e26 in _s18) {\n              a[_s18[_e26].id] = !0, i[_n21.id] = !0;\n            }\n\n            break;\n          }\n        }\n      }\n\n      var o = [];\n\n      for (var _t31 = 0; _t31 < e.length; _t31++) {\n        var _n22 = e[_t31];\n\n        if (r[_n22.id] && i[_n22.id]) {\n          var _e27 = {};\n\n          for (var _t33 in _n22.inputs) {\n            var _r9 = _n22.inputs[_t33];\n            s[_r9.id] && (_e27[_t33] = _r9);\n          }\n\n          var _t32 = Object.assign({}, _n22);\n\n          _t32.inputs = _e27, _t32.outputs = _n22.outputs, o.push(_t32);\n        }\n      }\n\n      return o;\n    }(this.state.activeTape, t, r);\n\n    if (!s && 0 === a.length && t.length > 0) throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.\");\n    return this.tidy(\"backward\", () => {\n      var e = {};\n      e[r.id] = null == n ? function (e) {\n        var t = _(d(e), \"float32\");\n\n        return vt.makeTensor(t, e, \"float32\");\n      }(r.shape) : n, function (e, t, n, s) {\n        var _loop2 = function _loop2(_r10) {\n          var a = t[_r10],\n              i = [];\n          if (a.outputs.forEach(t => {\n            var n = e[t.id];\n            i.push(null != n ? n : null);\n          }), null == a.gradient) throw new Error(\"Cannot compute gradient: gradient function not found for \".concat(a.kernelName, \".\"));\n          var o = a.gradient(i);\n\n          var _loop3 = function _loop3(_t34) {\n            if (!(_t34 in o)) throw new Error(\"Cannot backprop through input \".concat(_t34, \". Available gradients found: \").concat(Object.keys(o), \".\"));\n            var r = n(() => o[_t34]());\n            if (\"float32\" !== r.dtype) throw new Error(\"Error in gradient for op \".concat(a.kernelName, \". The gradient of input \").concat(_t34, \" must have 'float32' dtype, but has '\").concat(r.dtype, \"'\"));\n            var i = a.inputs[_t34];\n            if (!p(r.shape, i.shape)) throw new Error(\"Error in gradient for op \".concat(a.kernelName, \". The gradient of input '\").concat(_t34, \"' has shape '\").concat(r.shape, \"', which does not match the shape of the input '\").concat(i.shape, \"'\"));\n            if (null == e[i.id]) e[i.id] = r;else {\n              var _t35 = e[i.id];\n              e[i.id] = s(_t35, r), _t35.dispose();\n            }\n          };\n\n          for (var _t34 in a.inputs) {\n            _loop3(_t34);\n          }\n        };\n\n        for (var _r10 = t.length - 1; _r10 >= 0; _r10--) {\n          _loop2(_r10);\n        }\n      }(e, a, e => this.tidy(e), It);\n      var s = t.map(t => e[t.id]);\n      return 0 === this.state.gradientDepth && (this.state.activeTape.forEach(e => {\n        for (var _t36 of e.saved) {\n          _t36.dispose();\n        }\n      }), this.state.activeTape = null), {\n        value: r,\n        grads: s\n      };\n    });\n  }\n\n  customGrad(e) {\n    var _this9 = this;\n\n    return l(E(e), () => \"The f passed in customGrad(f) must be a function.\"), function () {\n      for (var _len4 = arguments.length, t = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n        t[_key4] = arguments[_key4];\n      }\n\n      var n;\n      l(t.every(e => e instanceof rt), () => \"The args passed in customGrad(f)(x1, x2,...) must all be tensors\");\n      var s = {};\n      return t.forEach((e, t) => {\n        s[t] = e;\n      }), _this9.runKernelFunc({\n        forwardFunc: (s, r) => (n = e(...t, r), l(n.value instanceof rt, () => \"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor\"), l(E(n.gradFunc), () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.\"), n.value),\n        backwardsFunc: (e, s) => {\n          var r = n.gradFunc(e, s),\n              a = Array.isArray(r) ? r : [r];\n          l(a.length === t.length, () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).\"), l(a.every(e => e instanceof rt), () => \"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.\");\n          var i = {};\n          return a.forEach((e, t) => {\n            i[t] = () => e;\n          }), i;\n        },\n        inputs: s\n      });\n    };\n  }\n\n  readSync(e) {\n    return this.state.tensorInfo.get(e).backend.readSync(e);\n  }\n\n  read(e) {\n    return this.state.tensorInfo.get(e).backend.read(e);\n  }\n\n  time(e) {\n    var _this10 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = Ge(),\n          n = yield _this10.backend.time(e);\n      return n.wallMs = Ge() - t, n;\n    })();\n  }\n\n  track(e) {\n    return null != this.state.activeScope && (e.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(e)), e;\n  }\n\n  get registeredVariables() {\n    return this.state.registeredVariables;\n  }\n\n  reset() {\n    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new yt();\n\n    for (var _e28 in this.registry) {\n      this.disposeRegisteredKernels(_e28), this.registry[_e28].dispose(), delete this.registry[_e28];\n    }\n\n    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;\n  }\n\n}\n\nfunction wt() {\n  var e = j();\n\n  if (null == e._tfengine) {\n    var _t37 = new U(e);\n\n    e._tfengine = new kt(_t37);\n  }\n\n  return q = e._tfengine.ENV, nt = () => e._tfengine, e._tfengine;\n}\n\nkt.nextTensorId = 0, kt.nextVariableId = 0;\nvar vt = wt();\n\nfunction It(e, t) {\n  return vt.runKernel(\"Add\", {\n    a: e,\n    b: t\n  });\n}\n\nfunction $t(e) {\n  if (e || \"undefined\" != typeof navigator && null != navigator) {\n    if (e || (e = navigator), \"ReactNative\" === e.product) return !0;\n\n    var _t38 = e.userAgent || e.vendor || (\"undefined\" != typeof window ? window.opera : \"\");\n\n    if (!_t38) {\n      var _t39 = e;\n      return _t39.userAgentData && _t39.userAgentData.mobile;\n    }\n\n    return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(_t38) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(_t38.substr(0, 4));\n  }\n\n  return !1;\n}\n\nfunction St() {\n  return \"undefined\" != typeof window && null != window.document || \"undefined\" != typeof WorkerGlobalScope;\n}\n\nvar Nt = G();\n\nfunction Ct(e, t) {\n  var n = e;\n  if ($(e)) return \"string\" === t ? [] : [e.length];\n  if (!Array.isArray(e)) return [];\n  var s = [];\n\n  for (; Array.isArray(n) || $(n) && \"string\" !== t;) {\n    s.push(n.length), n = n[0];\n  }\n\n  return Array.isArray(e) && G().getBool(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\") && Tt(e, s, []), s;\n}\n\nfunction Tt(e, t, n) {\n  if (n = n || [], !Array.isArray(e) && !$(e)) return void l(0 === t.length, () => \"Element arr[\".concat(n.join(\"][\"), \"] is a primitive, but should be an array/TypedArray of \").concat(t[0], \" elements\"));\n  l(t.length > 0, () => \"Element arr[\".concat(n.join(\"][\"), \"] should be a primitive, but is an array of \").concat(e.length, \" elements\")), l(e.length === t[0], () => \"Element arr[\".concat(n.join(\"][\"), \"] should have \").concat(t[0], \" elements, but has \").concat(e.length, \" elements\"));\n  var s = t.slice(1);\n\n  for (var _t40 = 0; _t40 < e.length; ++_t40) {\n    Tt(e[_t40], s, n.concat(_t40));\n  }\n}\n\nfunction Et(e, t, n, s) {\n  if (\"string_or_numeric\" !== e) {\n    if (null == e) throw new Error(\"Expected dtype cannot be null.\");\n    if (\"numeric\" !== e && e !== t || \"numeric\" === e && \"string\" === t) throw new Error(\"Argument '\".concat(n, \"' passed to '\").concat(s, \"' must be \").concat(e, \" tensor, but got \").concat(t, \" tensor\"));\n  }\n}\n\nfunction Rt(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"numeric\";\n  if (e instanceof rt) return Et(s, e.dtype, t, n), e;\n  var r = T(e);\n  if (\"string\" !== r && [\"bool\", \"int32\", \"float32\"].indexOf(s) >= 0 && (r = s), Et(s, r, t, n), null == e || !$(e) && !Array.isArray(e) && \"number\" != typeof e && \"boolean\" != typeof e && \"string\" != typeof e) throw new Error(\"Argument '\".concat(t, \"' passed to '\").concat(n, \"' must be a Tensor or TensorLike, but got '\").concat(null == e ? \"null\" : e.constructor.name, \"'\"));\n  var a = Ct(e, r);\n  $(e) || Array.isArray(e) || (e = [e]);\n  var i = \"string\" !== r ? Ve(e, r) : h(e, [], !0);\n  return vt.makeTensor(i, a, r);\n}\n\nfunction At(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"numeric\";\n  if (!Array.isArray(e)) throw new Error(\"Argument \".concat(t, \" passed to \").concat(n, \" must be a `Tensor[]` or `TensorLike[]`\"));\n  return e.map((e, r) => Rt(e, \"\".concat(t, \"[\").concat(r, \"]\"), n, s));\n}\n\nfunction Ft(e) {\n  var t = Object.keys(e);\n  if (1 !== t.length) throw new Error(\"Please provide an object with a single key (operation name) mapping to a function. Got an object with \".concat(t.length, \" keys.\"));\n  var n = t[0];\n  var s = e[n];\n  n.endsWith(\"_\") && (n = n.substring(0, n.length - 1)), n += \"__op\";\n\n  var r = function r() {\n    vt.startScope(n);\n\n    try {\n      var _t41 = s(...arguments);\n\n      return P(_t41) && console.error(\"Cannot return a Promise inside of tidy.\"), vt.endScope(_t41), _t41;\n    } catch (e) {\n      throw vt.endScope(null), e;\n    }\n  };\n\n  return Object.defineProperty(r, \"name\", {\n    value: n,\n    configurable: !0\n  }), r;\n}\n\nNt.registerFlag(\"DEBUG\", () => !1, e => {\n  e && console.warn(\"Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.\");\n}), Nt.registerFlag(\"IS_BROWSER\", () => St()), Nt.registerFlag(\"IS_NODE\", () => \"undefined\" != typeof process && void 0 !== process.versions && void 0 !== process.versions.node), Nt.registerFlag(\"IS_CHROME\", () => \"undefined\" != typeof navigator && null != navigator && null != navigator.userAgent && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor)), Nt.registerFlag(\"PROD\", () => !1), Nt.registerFlag(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\", () => Nt.getBool(\"DEBUG\")), Nt.registerFlag(\"DEPRECATION_WARNINGS_ENABLED\", () => !0), Nt.registerFlag(\"IS_TEST\", () => !1), Nt.registerFlag(\"CHECK_COMPUTATION_FOR_ERRORS\", () => !0), Nt.registerFlag(\"WRAP_TO_IMAGEBITMAP\", () => !1);\nvar Dt = Ft({\n  complex_: function complex_(e, t) {\n    var n = Rt(e, \"real\", \"complex\"),\n        s = Rt(t, \"imag\", \"complex\");\n    return u(n.shape, s.shape, \"real and imag shapes, \".concat(n.shape, \" and \").concat(s.shape, \", must match in call to tf.complex().\")), vt.runKernel(\"Complex\", {\n      real: n,\n      imag: s\n    });\n  }\n});\n\nfunction _t(e, t, n, s) {\n  if (null == s && (s = T(e)), \"complex64\" === s) throw new Error(\"Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).\");\n  if (!$(e) && !Array.isArray(e) && \"number\" != typeof e && \"boolean\" != typeof e && \"string\" != typeof e) throw new Error(\"values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray\");\n\n  if (null != t) {\n    L(t);\n\n    var _e29 = d(t),\n        _s19 = d(n);\n\n    l(_e29 === _s19, () => \"Based on the provided shape, [\".concat(t, \"], the tensor should have \").concat(_e29, \" values but has \").concat(_s19));\n\n    for (var _e30 = 0; _e30 < n.length; ++_e30) {\n      var _s20 = n[_e30],\n          _r11 = _e30 !== n.length - 1 || _s20 !== d(t.slice(_e30));\n\n      l(n[_e30] === t[_e30] || !_r11, () => \"Error creating a new Tensor. Inferred shape (\".concat(n, \") does not match the provided shape (\").concat(t, \"). \"));\n    }\n  }\n\n  return $(e) || Array.isArray(e) || (e = [e]), t = t || n, e = \"string\" !== s ? Ve(e, s) : h(e, [], !0), vt.makeTensor(e, t, s);\n}\n\nfunction Ot(e, t, n) {\n  return _t(e, t, Ct(e, n), n);\n}\n\nvar Mt = {\n  float32: 4,\n  float16: 2,\n  int32: 4,\n  uint16: 2,\n  uint8: 1,\n  bool: 1,\n  complex64: 8\n};\n\nfunction Lt(_x2, _x3) {\n  return _Lt.apply(this, arguments);\n}\n\nfunction _Lt() {\n  _Lt = _asyncToGenerator(function* (e, t) {\n    var n = [],\n        s = [],\n        r = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n\n    var _loop32 = function _loop32(_a146) {\n      var i = r[_a146],\n          o = Array.isArray(e) ? e[_a146].tensor : e[i];\n      if (\"float32\" !== o.dtype && \"int32\" !== o.dtype && \"bool\" !== o.dtype && \"string\" !== o.dtype && \"complex64\" !== o.dtype) throw new Error(\"Unsupported dtype in weight '\".concat(i, \"': \").concat(o.dtype));\n      var l = {\n        name: i,\n        shape: o.shape,\n        dtype: o.dtype\n      };\n\n      if (\"string\" === o.dtype) {\n        var _e527 = new Promise( /*#__PURE__*/function () {\n          var _ref38 = _asyncToGenerator(function* (e) {\n            var t = yield o.bytes(),\n                n = t.reduce((e, t) => e + t.length, 0) + 4 * t.length,\n                s = new Uint8Array(n);\n            var r = 0;\n\n            for (var _e528 = 0; _e528 < t.length; _e528++) {\n              var _n296 = t[_e528],\n                  _a147 = new Uint8Array(new Uint32Array([_n296.length]).buffer);\n\n              s.set(_a147, r), r += 4, s.set(_n296, r), r += _n296.length;\n            }\n\n            e(s);\n          });\n\n          return function (_x65) {\n            return _ref38.apply(this, arguments);\n          };\n        }());\n\n        s.push(_e527);\n      } else s.push(o.data());\n\n      null != t && (l.group = t), n.push(l);\n    };\n\n    for (var _a146 = 0; _a146 < r.length; ++_a146) {\n      _loop32(_a146);\n    }\n\n    return {\n      data: zt(yield Promise.all(s)),\n      specs: n\n    };\n  });\n  return _Lt.apply(this, arguments);\n}\n\nfunction zt(e) {\n  if (null === e) throw new Error(\"Invalid input value: \".concat(JSON.stringify(e)));\n  var t = 0;\n  var n = [];\n  e.forEach(e => {\n    if (t += e.byteLength, n.push(e.byteLength === e.buffer.byteLength ? e : new e.constructor(e)), !(e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array)) throw new Error(\"Unsupported TypedArray subtype: \".concat(e.constructor.name));\n  });\n  var s = new Uint8Array(t);\n  var r = 0;\n  return n.forEach(e => {\n    s.set(new Uint8Array(e.buffer), r), r += e.byteLength;\n  }), s.buffer;\n}\n\nvar Bt = \"undefined\" != typeof Buffer && (\"undefined\" == typeof Blob || \"undefined\" == typeof atob || \"undefined\" == typeof btoa);\n\nfunction Pt(e) {\n  return Bt ? Buffer.byteLength(e) : new Blob([e]).size;\n}\n\nfunction Wt(e) {\n  if (1 === e.length) return e[0];\n  var t = 0;\n  e.forEach(e => {\n    t += e.byteLength;\n  });\n  var n = new Uint8Array(t);\n  var s = 0;\n  return e.forEach(e => {\n    n.set(new Uint8Array(e), s), s += e.byteLength;\n  }), n.buffer;\n}\n\nfunction Ut(e, t) {\n  var n = {\n    modelTopology: e.modelTopology,\n    format: e.format,\n    generatedBy: e.generatedBy,\n    convertedBy: e.convertedBy,\n    weightsManifest: t\n  };\n  return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), n;\n}\n\nfunction Vt(e) {\n  if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"Expected JSON model topology, received ArrayBuffer.\");\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: \"JSON\",\n    modelTopologyBytes: null == e.modelTopology ? 0 : Pt(JSON.stringify(e.modelTopology)),\n    weightSpecsBytes: null == e.weightSpecs ? 0 : Pt(JSON.stringify(e.weightSpecs)),\n    weightDataBytes: null == e.weightData ? 0 : e.weightData.byteLength\n  };\n}\n\nfunction Gt() {\n  var e = function () {\n    var e = e => {\n      var t = e << 13,\n          n = 0;\n\n      for (; 0 == (8388608 & t);) {\n        n -= 8388608, t <<= 1;\n      }\n\n      return t &= -8388609, n += 947912704, t | n;\n    },\n        t = new Uint32Array(2048);\n\n    t[0] = 0;\n\n    for (var _n23 = 1; _n23 < 1024; _n23++) {\n      t[_n23] = e(_n23);\n    }\n\n    for (var _e31 = 1024; _e31 < 2048; _e31++) {\n      t[_e31] = 939524096 + (_e31 - 1024 << 13);\n    }\n\n    return t;\n  }(),\n      t = function () {\n    var e = new Uint32Array(64);\n    e[0] = 0, e[31] = 1199570944, e[32] = 2147483648, e[63] = 3347054592;\n\n    for (var _t42 = 1; _t42 < 31; _t42++) {\n      e[_t42] = _t42 << 23;\n    }\n\n    for (var _t43 = 33; _t43 < 63; _t43++) {\n      e[_t43] = 2147483648 + (_t43 - 32 << 23);\n    }\n\n    return e;\n  }(),\n      n = function () {\n    var e = new Uint32Array(64);\n\n    for (var _t44 = 0; _t44 < 64; _t44++) {\n      e[_t44] = 1024;\n    }\n\n    return e[0] = e[32] = 0, e;\n  }();\n\n  return s => {\n    var r = new ArrayBuffer(4 * s.length),\n        a = new Uint32Array(r);\n\n    for (var _r12 = 0; _r12 < s.length; _r12++) {\n      var _i6 = s[_r12];\n      a[_r12] = e[n[_i6 >> 10] + (1023 & _i6)] + t[_i6 >> 10];\n    }\n\n    return new Float32Array(r);\n  };\n}\n\nclass Ht {\n  constructor() {\n    this.saveRouters = [], this.loadRouters = [];\n  }\n\n  static getInstance() {\n    return null == Ht.instance && (Ht.instance = new Ht()), Ht.instance;\n  }\n\n  static registerSaveRouter(e) {\n    Ht.getInstance().saveRouters.push(e);\n  }\n\n  static registerLoadRouter(e) {\n    Ht.getInstance().loadRouters.push(e);\n  }\n\n  static getSaveHandlers(e) {\n    return Ht.getHandlers(e, \"save\");\n  }\n\n  static getLoadHandlers(e, t) {\n    return Ht.getHandlers(e, \"load\", t);\n  }\n\n  static getHandlers(e, t, n) {\n    var s = [];\n    return (\"load\" === t ? Ht.getInstance().loadRouters : Ht.getInstance().saveRouters).forEach(t => {\n      var r = t(e, n);\n      null !== r && s.push(r);\n    }), s;\n  }\n\n}\n\nfunction qt() {\n  if (!G().getBool(\"IS_BROWSER\")) throw new Error(\"Failed to obtain IndexedDB factory because the current environmentis not a web browser.\");\n  var e = \"undefined\" == typeof window ? self : window,\n      t = e.indexedDB || e.mozIndexedDB || e.webkitIndexedDB || e.msIndexedDB || e.shimIndexedDB;\n  if (null == t) throw new Error(\"The current browser does not appear to support IndexedDB.\");\n  return t;\n}\n\nfunction jt(e) {\n  var t = e.result;\n  t.createObjectStore(\"models_store\", {\n    keyPath: \"modelPath\"\n  }), t.createObjectStore(\"model_info_store\", {\n    keyPath: \"modelPath\"\n  });\n}\n\nclass Kt {\n  constructor(e) {\n    if (this.indexedDB = qt(), null == e || !e) throw new Error(\"For IndexedDB, modelPath must not be null, undefined or empty.\");\n    this.modelPath = e;\n  }\n\n  save(e) {\n    var _this11 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");\n      return _this11.databaseAction(_this11.modelPath, e);\n    })();\n  }\n\n  load() {\n    var _this12 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this12.databaseAction(_this12.modelPath);\n    })();\n  }\n\n  databaseAction(e, t) {\n    return new Promise((e, n) => {\n      var s = this.indexedDB.open(\"tensorflowjs\", 1);\n      s.onupgradeneeded = () => jt(s), s.onsuccess = () => {\n        var r = s.result;\n\n        if (null == t) {\n          var _t45 = r.transaction(\"models_store\", \"readonly\"),\n              _s21 = _t45.objectStore(\"models_store\").get(this.modelPath);\n\n          _s21.onsuccess = () => {\n            if (null == _s21.result) return r.close(), n(new Error(\"Cannot find model with path '\".concat(this.modelPath, \"' in IndexedDB.\")));\n            e(_s21.result.modelArtifacts);\n          }, _s21.onerror = e => (r.close(), n(_s21.error)), _t45.oncomplete = () => r.close();\n        } else {\n          var _s22 = Vt(t),\n              _a8 = r.transaction(\"model_info_store\", \"readwrite\");\n\n          var _i7 = _a8.objectStore(\"model_info_store\");\n\n          var _o5 = _i7.put({\n            modelPath: this.modelPath,\n            modelArtifactsInfo: _s22\n          });\n\n          var _l2;\n\n          _o5.onsuccess = () => {\n            _l2 = r.transaction(\"models_store\", \"readwrite\");\n\n            var o = _l2.objectStore(\"models_store\").put({\n              modelPath: this.modelPath,\n              modelArtifacts: t,\n              modelArtifactsInfo: _s22\n            });\n\n            o.onsuccess = () => e({\n              modelArtifactsInfo: _s22\n            }), o.onerror = e => {\n              _i7 = _a8.objectStore(\"model_info_store\");\n\n              var t = _i7.delete(this.modelPath);\n\n              t.onsuccess = () => (r.close(), n(o.error)), t.onerror = e => (r.close(), n(o.error));\n            };\n          }, _o5.onerror = e => (r.close(), n(_o5.error)), _a8.oncomplete = () => {\n            null == _l2 ? r.close() : _l2.oncomplete = () => r.close();\n          };\n        }\n      }, s.onerror = e => n(s.error);\n    });\n  }\n\n}\n\nKt.URL_SCHEME = \"indexeddb://\";\n\nvar Xt = e => {\n  return G().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(Kt.URL_SCHEME) ? (t = e.slice(Kt.URL_SCHEME.length), new Kt(t)) : null;\n  var t;\n};\n\nHt.registerSaveRouter(Xt), Ht.registerLoadRouter(Xt);\n\nclass Yt {\n  constructor() {\n    this.indexedDB = qt();\n  }\n\n  listModels() {\n    var _this13 = this;\n\n    return _asyncToGenerator(function* () {\n      return new Promise((e, t) => {\n        var n = _this13.indexedDB.open(\"tensorflowjs\", 1);\n\n        n.onupgradeneeded = () => jt(n), n.onsuccess = () => {\n          var s = n.result,\n              r = s.transaction(\"model_info_store\", \"readonly\"),\n              a = r.objectStore(\"model_info_store\").getAll();\n          a.onsuccess = () => {\n            var t = {};\n\n            for (var _e32 of a.result) {\n              t[_e32.modelPath] = _e32.modelArtifactsInfo;\n            }\n\n            e(t);\n          }, a.onerror = e => (s.close(), t(a.error)), r.oncomplete = () => s.close();\n        }, n.onerror = e => t(n.error);\n      });\n    })();\n  }\n\n  removeModel(e) {\n    var _this14 = this;\n\n    return _asyncToGenerator(function* () {\n      var t;\n      return e = (t = e).startsWith(Kt.URL_SCHEME) ? t.slice(Kt.URL_SCHEME.length) : t, new Promise((t, n) => {\n        var s = _this14.indexedDB.open(\"tensorflowjs\", 1);\n\n        s.onupgradeneeded = () => jt(s), s.onsuccess = () => {\n          var r = s.result,\n              a = r.transaction(\"model_info_store\", \"readwrite\"),\n              i = a.objectStore(\"model_info_store\"),\n              o = i.get(e);\n          var l;\n          o.onsuccess = () => {\n            if (null == o.result) return r.close(), n(new Error(\"Cannot find model with path '\".concat(e, \"' in IndexedDB.\")));\n            {\n              var _s23 = i.delete(e),\n                  _a9 = () => {\n                l = r.transaction(\"models_store\", \"readwrite\");\n                var s = l.objectStore(\"models_store\").delete(e);\n                s.onsuccess = () => t(o.result.modelArtifactsInfo), s.onerror = e => n(o.error);\n              };\n\n              _s23.onsuccess = _a9, _s23.onerror = e => (_a9(), r.close(), n(o.error));\n            }\n          }, o.onerror = e => (r.close(), n(o.error)), a.oncomplete = () => {\n            null == l ? r.close() : l.oncomplete = () => r.close();\n          };\n        }, s.onerror = e => n(s.error);\n      });\n    })();\n  }\n\n}\n\nvar Jt = \"tensorflowjs_models\",\n    Zt = \"info\",\n    Qt = \"model_topology\",\n    en = \"weight_specs\",\n    tn = \"weight_data\",\n    nn = \"model_metadata\";\n\nfunction sn(e) {\n  return {\n    info: [Jt, e, Zt].join(\"/\"),\n    topology: [Jt, e, Qt].join(\"/\"),\n    weightSpecs: [Jt, e, en].join(\"/\"),\n    weightData: [Jt, e, tn].join(\"/\"),\n    modelMetadata: [Jt, e, nn].join(\"/\")\n  };\n}\n\nfunction rn(e) {\n  for (var _t46 of Object.values(e)) {\n    window.localStorage.removeItem(_t46);\n  }\n}\n\nfunction an(e) {\n  var t = e.split(\"/\");\n  if (t.length < 3) throw new Error(\"Invalid key format: \".concat(e));\n  return t.slice(1, t.length - 1).join(\"/\");\n}\n\nclass on {\n  constructor(e) {\n    if (!G().getBool(\"IS_BROWSER\") || \"undefined\" == typeof window || void 0 === window.localStorage) throw new Error(\"The current environment does not support local storage.\");\n    if (this.LS = window.localStorage, null == e || !e) throw new Error(\"For local storage, modelPath must not be null, undefined or empty.\");\n    this.modelPath = e, this.keys = sn(this.modelPath);\n  }\n\n  save(e) {\n    var _this15 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");\n      {\n        var _t47 = JSON.stringify(e.modelTopology),\n            _n24 = JSON.stringify(e.weightSpecs),\n            _s24 = Vt(e);\n\n        try {\n          return _this15.LS.setItem(_this15.keys.info, JSON.stringify(_s24)), _this15.LS.setItem(_this15.keys.topology, _t47), _this15.LS.setItem(_this15.keys.weightSpecs, _n24), _this15.LS.setItem(_this15.keys.weightData, function (e) {\n            if (Bt) return Buffer.from(e).toString(\"base64\");\n            var t = new Uint8Array(e);\n            var n = \"\";\n\n            for (var _e33 = 0, _s25 = t.length; _e33 < _s25; _e33++) {\n              n += String.fromCharCode(t[_e33]);\n            }\n\n            return btoa(n);\n          }(e.weightData)), _this15.LS.setItem(_this15.keys.modelMetadata, JSON.stringify({\n            format: e.format,\n            generatedBy: e.generatedBy,\n            convertedBy: e.convertedBy,\n            signature: null != e.signature ? e.signature : void 0,\n            userDefinedMetadata: null != e.userDefinedMetadata ? e.userDefinedMetadata : void 0,\n            modelInitializer: null != e.modelInitializer ? e.modelInitializer : void 0,\n            trainingConfig: null != e.trainingConfig ? e.trainingConfig : void 0\n          })), {\n            modelArtifactsInfo: _s24\n          };\n        } catch (e) {\n          throw rn(_this15.keys), new Error(\"Failed to save model '\".concat(_this15.modelPath, \"' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=\").concat(_s24.modelTopologyBytes, \", weightSpecsBytes=\").concat(_s24.weightSpecsBytes, \", weightDataBytes=\").concat(_s24.weightDataBytes, \".\"));\n        }\n      }\n    })();\n  }\n\n  load() {\n    var _this16 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = JSON.parse(_this16.LS.getItem(_this16.keys.info));\n      if (null == e) throw new Error(\"In local storage, there is no model with name '\".concat(_this16.modelPath, \"'\"));\n      if (\"JSON\" !== e.modelTopologyType) throw new Error(\"BrowserLocalStorage does not support loading non-JSON model topology yet.\");\n      var t = {},\n          n = JSON.parse(_this16.LS.getItem(_this16.keys.topology));\n      if (null == n) throw new Error(\"In local storage, the topology of model '\".concat(_this16.modelPath, \"' is missing.\"));\n      t.modelTopology = n;\n      var s = JSON.parse(_this16.LS.getItem(_this16.keys.weightSpecs));\n      if (null == s) throw new Error(\"In local storage, the weight specs of model '\".concat(_this16.modelPath, \"' are missing.\"));\n      t.weightSpecs = s;\n\n      var r = _this16.LS.getItem(_this16.keys.modelMetadata);\n\n      if (null != r) {\n        var _e34 = JSON.parse(r);\n\n        t.format = _e34.format, t.generatedBy = _e34.generatedBy, t.convertedBy = _e34.convertedBy, null != _e34.signature && (t.signature = _e34.signature), null != _e34.userDefinedMetadata && (t.userDefinedMetadata = _e34.userDefinedMetadata), null != _e34.modelInitializer && (t.modelInitializer = _e34.modelInitializer), null != _e34.trainingConfig && (t.trainingConfig = _e34.trainingConfig);\n      }\n\n      var a = _this16.LS.getItem(_this16.keys.weightData);\n\n      if (null == a) throw new Error(\"In local storage, the binary weight values of model '\".concat(_this16.modelPath, \"' are missing.\"));\n      return t.weightData = function (e) {\n        if (Bt) {\n          var _t48 = Buffer.from(e, \"base64\");\n\n          return _t48.buffer.slice(_t48.byteOffset, _t48.byteOffset + _t48.byteLength);\n        }\n\n        var t = atob(e),\n            n = new Uint8Array(t.length);\n\n        for (var _e35 = 0; _e35 < t.length; ++_e35) {\n          n.set([t.charCodeAt(_e35)], _e35);\n        }\n\n        return n.buffer;\n      }(a), t;\n    })();\n  }\n\n}\n\non.URL_SCHEME = \"localstorage://\";\n\nvar ln = e => {\n  return G().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(on.URL_SCHEME) ? (t = e.slice(on.URL_SCHEME.length), new on(t)) : null;\n  var t;\n};\n\nHt.registerSaveRouter(ln), Ht.registerLoadRouter(ln);\n\nclass un {\n  constructor() {\n    l(G().getBool(\"IS_BROWSER\"), () => \"Current environment is not a web browser\"), l(\"undefined\" == typeof window || void 0 !== window.localStorage, () => \"Current browser does not appear to support localStorage\"), this.LS = window.localStorage;\n  }\n\n  listModels() {\n    var _this17 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = {},\n          t = Jt + \"/\",\n          n = \"/\" + Zt;\n\n      for (var _s26 = 0; _s26 < _this17.LS.length; ++_s26) {\n        var _r13 = _this17.LS.key(_s26);\n\n        _r13.startsWith(t) && _r13.endsWith(n) && (e[an(_r13)] = JSON.parse(_this17.LS.getItem(_r13)));\n      }\n\n      return e;\n    })();\n  }\n\n  removeModel(e) {\n    var _this18 = this;\n\n    return _asyncToGenerator(function* () {\n      var t;\n      var n = sn(e = (t = e).startsWith(on.URL_SCHEME) ? t.slice(on.URL_SCHEME.length) : t);\n      if (null == _this18.LS.getItem(n.info)) throw new Error(\"Cannot find model at path '\".concat(e, \"'\"));\n      var s = JSON.parse(_this18.LS.getItem(n.info));\n      return rn(n), s;\n    })();\n  }\n\n}\n\nclass cn {\n  constructor() {\n    this.managers = {};\n  }\n\n  static getInstance() {\n    return null == cn.instance && (cn.instance = new cn()), cn.instance;\n  }\n\n  static registerManager(e, t) {\n    l(null != e, () => \"scheme must not be undefined or null.\"), e.endsWith(\"://\") && (e = e.slice(0, e.indexOf(\"://\"))), l(e.length > 0, () => \"scheme must not be an empty string.\");\n    var n = cn.getInstance();\n    l(null == n.managers[e], () => \"A model store manager is already registered for scheme '\".concat(e, \"'.\")), n.managers[e] = t;\n  }\n\n  static getManager(e) {\n    var t = this.getInstance().managers[e];\n    if (null == t) throw new Error(\"Cannot find model manager for scheme '\".concat(e, \"'\"));\n    return t;\n  }\n\n  static getSchemes() {\n    return Object.keys(this.getInstance().managers);\n  }\n\n}\n\nclass hn {\n  fetch(e, t) {\n    return fetch(e, t);\n  }\n\n  now() {\n    return performance.now();\n  }\n\n  encode(e, t) {\n    if (\"utf-8\" !== t && \"utf8\" !== t) throw new Error(\"Browser's encoder only supports utf-8, but got \".concat(t));\n    return null == this.textEncoder && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(e);\n  }\n\n  decode(e, t) {\n    return new TextDecoder(t).decode(e);\n  }\n\n}\n\nif (G().get(\"IS_BROWSER\")) {\n  G().setPlatform(\"browser\", new hn());\n\n  try {\n    cn.registerManager(on.URL_SCHEME, new un());\n  } catch (e) {}\n\n  try {\n    cn.registerManager(Kt.URL_SCHEME, new Yt());\n  } catch (e) {}\n}\n\nvar dn;\n\nfunction pn(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n  var n = arguments.length > 2 ? arguments[2] : undefined;\n  return t = t || \"float32\", L(e), new tt(e, t, n);\n}\n\nG().get(\"IS_NODE\") && G().setPlatform(\"node\", new class {\n  constructor() {\n    this.util = require(\"util\"), this.textEncoder = new this.util.TextEncoder();\n  }\n\n  fetch(e, t) {\n    return null != G().global.fetch ? G().global.fetch(e, t) : (null == dn && (dn = require(\"node-fetch\")), dn(e, t));\n  }\n\n  now() {\n    var e = process.hrtime();\n    return 1e3 * e[0] + e[1] / 1e6;\n  }\n\n  encode(e, t) {\n    if (\"utf-8\" !== t && \"utf8\" !== t) throw new Error(\"Node built-in encoder only supports utf-8, but got \".concat(t));\n    return this.textEncoder.encode(e);\n  }\n\n  decode(e, t) {\n    return 0 === e.length ? \"\" : new this.util.TextDecoder(t).decode(e);\n  }\n\n}());\nvar fn = Ft({\n  cast_: function cast_(e, t) {\n    var n = Rt(e, \"x\", \"cast\");\n    if (!function (e) {\n      return \"bool\" === e || \"complex64\" === e || \"float32\" === e || \"int32\" === e || \"string\" === e;\n    }(t)) throw new Error(\"Failed to cast to unknown dtype \".concat(t));\n    if (\"string\" === t && \"string\" !== n.dtype || \"string\" !== t && \"string\" === n.dtype) throw new Error(\"Only strings can be casted to strings\");\n    return vt.runKernel(\"Cast\", {\n      x: n\n    }, {\n      dtype: t\n    });\n  }\n}),\n    gn = Ft({\n  clone_: function clone_(e) {\n    var t = Rt(e, \"x\", \"clone\", \"string_or_numeric\");\n    return vt.runKernel(\"Identity\", {\n      x: t\n    });\n  }\n});\n\nfunction mn(e) {\n  return new Promise(e => setTimeout(e)).then(e);\n}\n\nwt(), st = {\n  buffer: pn,\n  cast: fn,\n  clone: gn,\n  print: function print(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    console.log(e.toString(t));\n  }\n};\n\nclass bn {\n  constructor(e) {\n    if (!G().getBool(\"IS_BROWSER\")) throw new Error(\"browserDownloads() cannot proceed because the current environment is not a browser.\");\n    e.startsWith(bn.URL_SCHEME) && (e = e.slice(bn.URL_SCHEME.length)), null != e && 0 !== e.length || (e = \"model\"), this.modelJsonFileName = e + \".json\", this.weightDataFileName = e + \".weights.bin\";\n  }\n\n  save(e) {\n    var _this19 = this;\n\n    return _asyncToGenerator(function* () {\n      if (\"undefined\" == typeof document) throw new Error(\"Browser downloads are not supported in this environment since `document` is not present\");\n      var t = window.URL.createObjectURL(new Blob([e.weightData], {\n        type: \"application/octet-stream\"\n      }));\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserDownloads.save() does not support saving model topology in binary formats yet.\");\n      {\n        var _n25 = Ut(e, [{\n          paths: [\"./\" + _this19.weightDataFileName],\n          weights: e.weightSpecs\n        }]),\n            _s27 = window.URL.createObjectURL(new Blob([JSON.stringify(_n25)], {\n          type: \"application/json\"\n        })),\n            _r14 = null == _this19.modelJsonAnchor ? document.createElement(\"a\") : _this19.modelJsonAnchor;\n\n        if (_r14.download = _this19.modelJsonFileName, _r14.href = _s27, yield mn(() => _r14.dispatchEvent(new MouseEvent(\"click\"))), null != e.weightData) {\n          var _e36 = null == _this19.weightDataAnchor ? document.createElement(\"a\") : _this19.weightDataAnchor;\n\n          _e36.download = _this19.weightDataFileName, _e36.href = t, yield mn(() => _e36.dispatchEvent(new MouseEvent(\"click\")));\n        }\n\n        return {\n          modelArtifactsInfo: Vt(e)\n        };\n      }\n    })();\n  }\n\n}\n\nfunction xn(e, t, n, s) {\n  !function (e) {\n    l(null != e && Array.isArray(e) && e.length > 0, () => \"promises must be a none empty array\");\n  }(e), function (e, t) {\n    l(e >= 0 && e <= 1, () => \"Progress fraction must be in range [0, 1], but got startFraction \".concat(e)), l(t >= 0 && t <= 1, () => \"Progress fraction must be in range [0, 1], but got endFraction \".concat(t)), l(t >= e, () => \"startFraction must be no more than endFraction, but got startFraction \".concat(e, \" and endFraction \").concat(t));\n  }(n = null == n ? 0 : n, s = null == s ? 1 : s);\n  var r = 0;\n  return Promise.all(e.map(a => (a.then(a => {\n    var i = n + ++r / e.length * (s - n);\n    return t(i), a;\n  }), a)));\n}\n\nbn.URL_SCHEME = \"downloads://\", Ht.registerSaveRouter(e => G().getBool(\"IS_BROWSER\") && !Array.isArray(e) && e.startsWith(bn.URL_SCHEME) ? function () {\n  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"model\";\n  return new bn(e);\n}(e.slice(bn.URL_SCHEME.length)) : null);\n\nclass yn {\n  constructor(e, t) {\n    if (this.DEFAULT_METHOD = \"POST\", null == t && (t = {}), this.weightPathPrefix = t.weightPathPrefix, this.onProgress = t.onProgress, this.weightUrlConverter = t.weightUrlConverter, null != t.fetchFunc ? (l(\"function\" == typeof t.fetchFunc, () => \"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)\"), this.fetch = t.fetchFunc) : this.fetch = G().platform.fetch, l(null != e && e.length > 0, () => \"URL path for http must not be null, undefined or empty.\"), Array.isArray(e) && l(2 === e.length, () => \"URL paths for http must have a length of 2, (actual length is \".concat(e.length, \").\")), this.path = e, null != t.requestInit && null != t.requestInit.body) throw new Error(\"requestInit is expected to have no pre-existing body, but has one.\");\n    this.requestInit = t.requestInit || {};\n  }\n\n  save(e) {\n    var _this20 = this;\n\n    return _asyncToGenerator(function* () {\n      if (e.modelTopology instanceof ArrayBuffer) throw new Error(\"BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.\");\n      var t = Object.assign({\n        method: _this20.DEFAULT_METHOD\n      }, _this20.requestInit);\n      t.body = new FormData();\n      var n = Ut(e, [{\n        paths: [\"./model.weights.bin\"],\n        weights: e.weightSpecs\n      }]);\n      t.body.append(\"model.json\", new Blob([JSON.stringify(n)], {\n        type: \"application/json\"\n      }), \"model.json\"), null != e.weightData && t.body.append(\"model.weights.bin\", new Blob([e.weightData], {\n        type: \"application/octet-stream\"\n      }), \"model.weights.bin\");\n      var s = yield _this20.fetch(_this20.path, t);\n      if (s.ok) return {\n        modelArtifactsInfo: Vt(e),\n        responses: [s]\n      };\n      throw new Error(\"BrowserHTTPRequest.save() failed due to HTTP response status \".concat(s.status, \".\"));\n    })();\n  }\n\n  load() {\n    var _this21 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = yield _this21.fetch(_this21.path, _this21.requestInit);\n      if (!e.ok) throw new Error(\"Request to \".concat(_this21.path, \" failed with status code \").concat(e.status, \". Please verify this URL points to the model JSON of the model to load.\"));\n      var t;\n\n      try {\n        t = yield e.json();\n      } catch (e) {\n        var _t49 = \"Failed to parse model JSON of response from \".concat(_this21.path, \".\");\n\n        throw _this21.path.endsWith(\".pb\") ? _t49 += \" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.\" : _t49 += \" Please make sure the server is serving valid JSON for this request.\", new Error(_t49);\n      }\n\n      if (null == t.modelTopology && null == t.weightsManifest) throw new Error(\"The JSON from HTTP path \".concat(_this21.path, \" contains neither model topology or manifest for weights.\"));\n      return function () {\n        var _ref = _asyncToGenerator(function* (e, t) {\n          var n = {\n            modelTopology: e.modelTopology,\n            format: e.format,\n            generatedBy: e.generatedBy,\n            convertedBy: e.convertedBy\n          };\n\n          if (null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), null != e.weightsManifest) {\n            var [_s28, _r15] = yield t(e.weightsManifest);\n            n.weightSpecs = _s28, n.weightData = _r15;\n          }\n\n          return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), n;\n        });\n\n        return function (_x4, _x5) {\n          return _ref.apply(this, arguments);\n        };\n      }()(t, e => _this21.loadWeights(e));\n    })();\n  }\n\n  loadWeights(e) {\n    var _this22 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = Array.isArray(_this22.path) ? _this22.path[1] : _this22.path,\n          [n, s] = function (e) {\n        var t = e.lastIndexOf(\"/\"),\n            n = e.lastIndexOf(\"?\");\n        return [e.substring(0, t) + \"/\", n > t ? e.substring(n) : \"\"];\n      }(t),\n          r = _this22.weightPathPrefix || n,\n          a = [];\n\n      for (var _t50 of e) {\n        a.push(..._t50.weights);\n      }\n\n      var i = [],\n          o = [];\n\n      for (var _t51 of e) {\n        for (var _e37 of _t51.paths) {\n          null != _this22.weightUrlConverter ? o.push(_this22.weightUrlConverter(_e37)) : i.push(r + _e37 + s);\n        }\n      }\n\n      return _this22.weightUrlConverter && i.push(...(yield Promise.all(o))), [a, Wt(yield function () {\n        var _ref2 = _asyncToGenerator(function* (e, t) {\n          null == t && (t = {});\n          var n = null == t.fetchFunc ? G().platform.fetch : t.fetchFunc,\n              s = e.map(e => n(e, t.requestInit, {\n            isBinary: !0\n          })),\n              r = (null == t.onProgress ? yield Promise.all(s) : yield xn(s, t.onProgress, 0, .5)).map(e => e.arrayBuffer());\n          return null == t.onProgress ? yield Promise.all(r) : yield xn(r, t.onProgress, .5, 1);\n        });\n\n        return function (_x6, _x7) {\n          return _ref2.apply(this, arguments);\n        };\n      }()(i, {\n        requestInit: _this22.requestInit,\n        fetchFunc: _this22.fetch,\n        onProgress: _this22.onProgress\n      }))];\n    })();\n  }\n\n}\n\nfunction kn(e) {\n  return null != e.match(yn.URL_SCHEME_REGEX);\n}\n\nyn.URL_SCHEME_REGEX = /^https?:\\/\\//;\n\nvar wn = (e, t) => {\n  if (\"undefined\" == typeof fetch && (null == t || null == t.fetchFunc)) return null;\n  {\n    var _n26 = !0;\n\n    if (_n26 = Array.isArray(e) ? e.every(e => kn(e)) : kn(e), _n26) return vn(e, t);\n  }\n  return null;\n};\n\nfunction vn(e, t) {\n  return new yn(e, t);\n}\n\nHt.registerSaveRouter(wn), Ht.registerLoadRouter(wn);\nvar In = Ft({\n  matMul_: function matMul_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Rt(e, \"a\", \"matMul\"),\n        a = Rt(t, \"b\", \"matMul\");\n    return [r, a] = gt(r, a), vt.runKernel(\"BatchMatMul\", {\n      a: r,\n      b: a\n    }, {\n      transposeA: n,\n      transposeB: s\n    });\n  }\n}),\n    $n = Ft({\n  oneHot_: function oneHot_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    if (t < 2) throw new Error(\"Error in oneHot: depth must be >=2, but it is \".concat(t));\n    var r = Rt(e, \"indices\", \"oneHot\", \"int32\");\n    return vt.runKernel(\"OneHot\", {\n      indices: r\n    }, {\n      depth: t,\n      onValue: n,\n      offValue: s\n    });\n  }\n}),\n    Sn = Ft({\n  transpose_: function transpose_(e, t) {\n    var n = Rt(e, \"x\", \"transpose\");\n    return null == t && (t = n.shape.map((e, t) => t).reverse()), l(n.rank === t.length, () => \"Error in transpose: rank of input \".concat(n.rank, \" must match length of perm \").concat(t, \".\")), t.forEach(e => {\n      l(e >= 0 && e < n.rank, () => \"All entries in 'perm' must be between 0 and \" + (n.rank - 1) + \" but got \".concat(t));\n    }), n.rank <= 1 ? n.clone() : vt.runKernel(\"Transpose\", {\n      x: n\n    }, {\n      perm: t\n    });\n  }\n});\n\nfunction Nn(e, t) {\n  var n = e.shape.length,\n      s = t.shape.length;\n  if (n < 1) throw new Error(\"tf.gatherND() expects the input to be rank 1 or higher, but the rank was \".concat(n, \".\"));\n  if (s < 1) throw new Error(\"tf.gatherND() expects the indices to be rank 1 or higher, but the rank was \".concat(s, \".\"));\n  if (\"int32\" !== t.dtype) throw new Error(\"tf.gatherND() expects the indices to be int32 type, but the dtype was \".concat(t.dtype, \".\"));\n  if (t.shape[s - 1] > n) throw new Error(\"index innermost dimension length must be <= tensor rank; saw: \".concat(t.shape[s - 1], \" vs. \").concat(n));\n  if (0 === d(e.shape)) throw new Error(\"Requested more than 0 entries, but input is empty. Input shape: \".concat(e.shape, \".\"));\n  var r = t.shape,\n      a = r[r.length - 1];\n  var i = 1;\n\n  for (var _e38 = 0; _e38 < r.length - 1; ++_e38) {\n    i *= r[_e38];\n  }\n\n  var o = e.shape,\n      l = r.slice();\n  l.pop();\n  var u = 1;\n\n  for (var _e39 = a; _e39 < n; ++_e39) {\n    u *= o[_e39], l.push(o[_e39]);\n  }\n\n  var c = [...A(e.shape).map(e => e / u), 1].slice(0, a);\n  return [l, i, u, c];\n}\n\nfunction Cn(e, t, n) {\n  var s = t.rank > 1 ? t.shape[t.rank - 1] : 1,\n      r = t.rank > 1 ? t.rank - 1 : 1,\n      a = \"Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: \".concat(n.shape, \", indices.shape: \").concat(t.shape, \", shape: \").concat(e, \", sliceDim: \").concat(s, \", and batchDim: \").concat(r, \".\");\n  if (n.rank < r) throw new Error(a + \" update.rank < \".concat(r, \". \"));\n  if (e.length < s + (n.rank - r)) throw new Error(a + \" Output shape length < \".concat(s + (n.rank - r)));\n  if (n.rank !== r + e.length - s) throw new Error(a + \" update.rank != \" + (r + e.length - s));\n\n  for (var _e40 = 0; _e40 < r; ++_e40) {\n    if (n.shape[_e40] !== t.shape[_e40]) throw new Error(a + \" updates.shape[\".concat(_e40, \"] (\").concat(n.shape[_e40], \") != indices.shape[\").concat(_e40, \"] (\").concat(t.shape[_e40], \").\"));\n  }\n\n  for (var _t52 = 0; _t52 < n.rank - r; ++_t52) {\n    if (n.shape[_t52 + r] !== e[_t52 + s]) throw new Error(a + \" updates.shape[\".concat(_t52 + r, \"] (\").concat(n.shape[_t52 + r], \") != shape[\").concat(_t52 + r, \"] (\").concat(e[_t52 + r], \")\"));\n  }\n}\n\nfunction Tn(e, t, n) {\n  var s = t.shape.length,\n      r = s > 1 ? t.shape[s - 1] : 1,\n      a = n.length;\n  var i = 1;\n\n  for (var _e41 = r; _e41 < a; ++_e41) {\n    i *= n[_e41];\n  }\n\n  var o = r < 1 ? 1 : r;\n  return {\n    sliceRank: r,\n    numUpdates: d(t.shape) / o,\n    sliceSize: i,\n    strides: [...A(n.slice(0, r)), 1],\n    outputSize: d(n)\n  };\n}\n\nfunction En(e, t, n) {\n  var s = e.shape.length;\n  l(s === t.length, () => \"Error in slice\".concat(s, \"D: Length of begin \").concat(t, \" must match the rank of the array (\").concat(s, \").\")), l(s === n.length, () => \"Error in slice\".concat(s, \"D: Length of size \").concat(n, \" must match the rank of the array (\").concat(s, \").\"));\n\n  var _loop4 = function _loop4(_r16) {\n    l(t[_r16] + n[_r16] <= e.shape[_r16], () => \"Error in slice\".concat(s, \"D: begin[\").concat(_r16, \"] + size[\").concat(_r16, \"] (\").concat(t[_r16] + n[_r16], \") would overflow input.shape[\").concat(_r16, \"] (\").concat(e.shape[_r16], \")\"));\n  };\n\n  for (var _r16 = 0; _r16 < s; ++_r16) {\n    _loop4(_r16);\n  }\n}\n\nfunction Rn(e) {\n  var t = [];\n  var n = 0;\n\n  for (; e > 0;) {\n    1 & e && t.push(n), e /= 2, n++;\n  }\n\n  return t;\n}\n\nfunction An(e, t, n) {\n  var s = [];\n\n  for (var _r17 = 0; _r17 < e.length; _r17++) {\n    s[_r17] = Math.ceil((t[_r17] - e[_r17]) / n[_r17]);\n  }\n\n  return s;\n}\n\nfunction Fn(e, t, n, s) {\n  var r = [...e];\n\n  for (var _e42 = r.length; _e42 < s.length; _e42++) {\n    r.push(1);\n  }\n\n  for (var _e43 = 0; _e43 < n; _e43++) {\n    0 === _e43 ? r[t] = 1 : (r.splice(t, 0, 1), r.pop());\n  }\n\n  return r;\n}\n\nfunction Dn(e, t, n) {\n  return n <= e ? n : n - (t - 1);\n}\n\nfunction _n(e, t) {\n  var n = [];\n\n  for (var _s29 = 0; _s29 < e; _s29++) {\n    n.push(t + _s29);\n  }\n\n  return n;\n}\n\nfunction On(e, t, n, s, r, a, i, o, l) {\n  var u = e.length;\n  var c = new Array(u),\n      h = new Array(u),\n      d = new Array(u);\n\n  if (t.length && n > 0) {\n    var _l3 = t[0],\n        _u3 = n + 1;\n\n    c = Mn(i, _l3, _u3, s, e), h = Ln(o, _l3, _u3, r, e), d = Fn(a, _l3, _u3, e);\n  } else for (var _t53 = 0; _t53 < u; _t53++) {\n    c[_t53] = Bn(i, s, a, e, _t53, l), h[_t53] = Pn(o, r, a, e, _t53, l), d[_t53] = zn(a, _t53, l);\n  }\n\n  return {\n    begin: c,\n    end: h,\n    strides: d\n  };\n}\n\nfunction Mn(e, t, n, s, r) {\n  var a = [...r],\n      i = _n(n, t);\n\n  for (var _r18 = 0; _r18 < a.length; _r18++) {\n    if (i.indexOf(_r18) > -1) a[_r18] = 0;else {\n      var _i8 = Dn(t, n, _r18);\n\n      var _o6 = s[_i8];\n      e & 1 << _i8 && (_o6 = 0), a[_r18] = _o6;\n    }\n  }\n\n  return a;\n}\n\nfunction Ln(e, t, n, s, r) {\n  var i = [...r],\n      o = _n(n, t);\n\n  for (var _r19 = 0; _r19 < i.length; _r19++) {\n    if (o.indexOf(_r19) > -1) i[_r19] = Number.MAX_SAFE_INTEGER;else {\n      var _a10 = Dn(t, n, _r19);\n\n      var _o7 = s[_a10];\n      e & 1 << _a10 && (_o7 = Number.MAX_SAFE_INTEGER), i[_r19] = _o7;\n    }\n  }\n\n  for (var _e44 = 0; _e44 < i.length; _e44++) {\n    var _t54 = r[_e44];\n    i[_e44] < 0 && (i[_e44] += _t54), i[_e44] = a(0, i[_e44], r[_e44]);\n  }\n\n  return i;\n}\n\nfunction zn(e, t, n) {\n  var s = e[t];\n  return (n & 1 << t || null == s) && (s = 1), s;\n}\n\nfunction Bn(e, t, n, s, r, i) {\n  var o = t[r];\n  (e & 1 << r || i & 1 << r || null == o) && (o = (n[r] || 1) > 0 ? Number.MIN_SAFE_INTEGER : Number.MAX_SAFE_INTEGER);\n  var l = s[r];\n  return o < 0 && (o += l), o = a(0, o, l - 1), o;\n}\n\nfunction Pn(e, t, n, s, r, i) {\n  var o = t[r];\n  var l = n[r] || 1;\n  (e & 1 << r || i & 1 << r || null == o) && (o = l > 0 ? Number.MAX_SAFE_INTEGER : Number.MIN_SAFE_INTEGER);\n  var u = s[r];\n  return o < 0 && (o += u), o = l > 0 ? a(0, o, u) : a(-1, o, u - 1), o;\n}\n\nfunction Wn(e, t, n) {\n  var s = n.length;\n\n  for (var _e45 = 0; _e45 < n.length; _e45++) {\n    if (n[_e45] > 1) {\n      s = _e45;\n      break;\n    }\n  }\n\n  for (var _r20 = s + 1; _r20 < n.length; _r20++) {\n    if (t[_r20] > 0 || n[_r20] !== e[_r20]) return !1;\n  }\n\n  return !0;\n}\n\nfunction Un(e, t) {\n  var n = e.length > 0 ? e[e.length - 1] : 1;\n\n  for (var _s30 = 0; _s30 < e.length - 1; _s30++) {\n    n += e[_s30] * t[_s30];\n  }\n\n  return n;\n}\n\nfunction Vn(e, t, n) {\n  var s;\n  var r = e.shape.length;\n  var a;\n  return s = \"number\" == typeof t ? [t, ...new Array(r - 1).fill(0)] : t.length < r ? t.concat(new Array(r - t.length).fill(0)) : t.slice(), s.forEach(e => {\n    l(-1 !== e, () => \"slice() does not support negative begin indexing.\");\n  }), a = null == n ? new Array(r).fill(-1) : \"number\" == typeof n ? [n, ...new Array(r - 1).fill(-1)] : n.length < r ? n.concat(new Array(r - n.length).fill(-1)) : n, a = a.map((t, n) => t >= 0 ? t : (l(-1 === t, () => \"Negative size values should be exactly -1 but got \".concat(t, \" for the slice() size at index \").concat(n, \".\")), e.shape[n] - s[n])), [s, a];\n}\n\nfunction Gn(e, t, n, s, r, a, i, o, l) {\n  var u = t.slice(),\n      c = n.slice(),\n      h = s;\n  null == s && (h = new Array(u.length));\n  var d = Rn(i);\n  if (d.length > 1) throw new Error(\"Multiple ellipses in slice is not allowed.\");\n  if (0 !== i && 0 !== o) throw new Error(\"Using both ellipsisMask and newAxisMask is not yet supported.\");\n  if (0 !== i && 0 !== l) throw new Error(\"Using both ellipsisMask and shrinkAxisMask is not yet supported.\");\n  var p = e.length - u.length,\n      f = Rn(o),\n      g = e.slice();\n  f.forEach(e => {\n    u[e] = 0, c[e] = 1, g.splice(e, 0, 1);\n  });\n  var {\n    begin: m,\n    end: b,\n    strides: x\n  } = On(g, d, p, u, c, h, r, a, i);\n  u = m, c = b, h = x;\n  var y = Rn(l);\n  y.forEach(e => {\n    c[e] = u[e] + 1, h[e] = 1;\n  });\n  var k = An(u, c, h),\n      w = k.filter((e, t) => -1 === y.indexOf(t));\n  return {\n    nonStrided: h.every(e => 1 === e),\n    $begin: u,\n    $end: c,\n    $strides: h,\n    size: k,\n    newShape: g,\n    outShape: w\n  };\n}\n\nvar Hn = {\n  __proto__: null,\n  assertParamsValid: En,\n  maskToAxes: Rn,\n  computeOutShape: An,\n  stridesWithElidedDims: Fn,\n  getNormalizedAxes: On,\n  startIndicesWithElidedDims: Mn,\n  stopIndicesWithElidedDims: Ln,\n  stridesForAxis: zn,\n  startForAxis: Bn,\n  stopForAxis: Pn,\n  isSliceContinous: Wn,\n  computeFlatOffset: Un,\n  parseSliceParams: Vn,\n  sliceInfo: Gn\n};\n\nclass qn {\n  getClassName() {\n    return this.constructor.className;\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nclass jn {\n  constructor() {\n    this.classNameMap = {};\n  }\n\n  static getMap() {\n    return null == jn.instance && (jn.instance = new jn()), jn.instance;\n  }\n\n  static register(e) {\n    jn.getMap().classNameMap[e.className] = [e, e.fromConfig];\n  }\n\n}\n\nfunction Kn(e) {\n  l(null != e.className, () => \"Class being registered does not have the static className property defined.\"), l(\"string\" == typeof e.className, () => \"className is required to be a string, but got type \" + typeof e.className), l(e.className.length > 0, () => \"Class being registered has an empty-string as its className, which is disallowed.\"), jn.register(e);\n}\n\nfunction Xn() {\n  return vt;\n}\n\nfunction Yn() {\n  return vt.memory();\n}\n\nfunction Jn(e, t) {\n  return vt.tidy(e, t);\n}\n\nfunction Zn(e) {\n  mt(e).forEach(e => e.dispose());\n}\n\nfunction Qn(e) {\n  return vt.keep(e);\n}\n\nfunction es(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  return vt.registerBackend(e, t, n);\n}\n\nvar ts = Ft({\n  add_: function add_(e, t) {\n    var n = Rt(e, \"a\", \"add\"),\n        s = Rt(t, \"b\", \"add\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Add\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ns = Ft({\n  floorDiv_: function floorDiv_(e, t) {\n    var n = Rt(e, \"a\", \"floorDiv\"),\n        s = Rt(t, \"b\", \"floorDiv\");\n    return [n, s] = gt(n, s), vt.runKernel(\"FloorDiv\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ss = Ft({\n  div_: function div_(e, t) {\n    var n = Rt(e, \"a\", \"div\"),\n        s = Rt(t, \"b\", \"div\");\n    return [n, s] = gt(n, s), \"int32\" === n.dtype && \"int32\" === s.dtype ? ns(n, s) : vt.runKernel(\"RealDiv\", {\n      a: n,\n      b: s\n    }, {});\n  }\n}),\n    rs = Ft({\n  mul_: function mul_(e, t) {\n    var n = Rt(e, \"a\", \"mul\"),\n        s = Rt(t, \"b\", \"mul\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Multiply\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    as = Ft({\n  abs_: function abs_(e) {\n    var t = Rt(e, \"x\", \"abs\");\n    return vt.runKernel(\"complex64\" === t.dtype ? \"ComplexAbs\" : \"Abs\", {\n      x: t\n    });\n  }\n}),\n    is = Ft({\n  acos_: function acos_(e) {\n    var t = Rt(e, \"x\", \"acos\");\n    return vt.runKernel(\"Acos\", {\n      x: t\n    });\n  }\n}),\n    os = Ft({\n  acosh_: function acosh_(e) {\n    var t = Rt(e, \"x\", \"acosh\");\n    return vt.runKernel(\"Acosh\", {\n      x: t\n    });\n  }\n}),\n    ls = Ft({\n  all_: function all_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"all\", \"bool\");\n    return vt.runKernel(\"All\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    us = Ft({\n  any_: function any_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"any\", \"bool\");\n    return vt.runKernel(\"Any\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    cs = Ft({\n  argMax_: function argMax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"argMax\");\n    return vt.runKernel(\"ArgMax\", {\n      x: n\n    }, {\n      axis: t\n    });\n  }\n}),\n    hs = Ft({\n  argMin_: function argMin_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"argMin\");\n    return vt.runKernel(\"ArgMin\", {\n      x: n\n    }, {\n      axis: t\n    });\n  }\n}),\n    ds = Ft({\n  asin_: function asin_(e) {\n    var t = Rt(e, \"x\", \"asin\");\n    return vt.runKernel(\"Asin\", {\n      x: t\n    });\n  }\n}),\n    ps = Ft({\n  asinh_: function asinh_(e) {\n    var t = Rt(e, \"x\", \"asinh\");\n    return vt.runKernel(\"Asinh\", {\n      x: t\n    });\n  }\n}),\n    fs = Ft({\n  atan_: function atan_(e) {\n    var t = Rt(e, \"x\", \"atan\");\n    return vt.runKernel(\"Atan\", {\n      x: t\n    });\n  }\n}),\n    gs = Ft({\n  atan2_: function atan2_(e, t) {\n    var n = Rt(e, \"a\", \"atan2\"),\n        s = Rt(t, \"b\", \"atan2\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Atan2\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ms = Ft({\n  atanh_: function atanh_(e) {\n    var t = Rt(e, \"x\", \"atanh\");\n    return vt.runKernel(\"Atanh\", {\n      x: t\n    });\n  }\n});\n\nfunction bs(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  return ks(e, [...t, e[3]], n, a, s, null, null, Es(r));\n}\n\nfunction xs(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"channelsLast\";\n  var [o, l] = Is(t);\n  var u;\n  if (\"channelsLast\" === i) u = [o, l, e[3], e[3]];else {\n    if (\"channelsFirst\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    u = [o, l, e[1], e[1]];\n  }\n  return ks(e, u, n, s, r, a, !1, i);\n}\n\nfunction ys(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"NDHWC\";\n  var [o, l, u] = $s(t);\n  var c, h;\n  if (\"NDHWC\" === i) h = \"channelsLast\", c = [o, l, u, e[4], e[4]];else {\n    if (\"NCDHW\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    h = \"channelsFirst\", c = [o, l, u, e[1], e[1]];\n  }\n  return ws(e, c, n, s, r, !1, h, a);\n}\n\nfunction ks(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : \"channelsLast\";\n  var [l, u, c, h] = [-1, -1, -1, -1];\n  if (\"channelsLast\" === o) [l, u, c, h] = e;else {\n    if (\"channelsFirst\" !== o) throw new Error(\"Unknown dataFormat \".concat(o));\n    [l, h, u, c] = e;\n  }\n\n  var [d, p,, f] = t,\n      [g, m] = Is(n),\n      [b, x] = Is(s),\n      y = Ss(d, b),\n      k = Ss(p, x),\n      {\n    padInfo: w,\n    outHeight: v,\n    outWidth: I\n  } = function (e, t, n, s, r, a, i, o, l) {\n    var u, c, h;\n\n    if (\"number\" == typeof e) {\n      u = {\n        top: e,\n        bottom: e,\n        left: e,\n        right: e,\n        type: 0 === e ? \"VALID\" : \"NUMBER\"\n      };\n\n      var _r21 = function (e, t, n, s, r) {\n        null == s && (s = vs(e, t, n));\n        var a = e[1];\n        return [Ns((e[0] - t + 2 * s) / n + 1, r), Ns((a - t + 2 * s) / n + 1, r)];\n      }([t, n], a, s, e, o);\n\n      c = _r21[0], h = _r21[1];\n    } else if (\"same\" === e) {\n      c = Math.ceil(t / s), h = Math.ceil(n / r);\n\n      var _e46 = Math.max(0, (c - 1) * s + a - t),\n          _o8 = Math.max(0, (h - 1) * r + i - n),\n          _l4 = Math.floor(_e46 / 2),\n          _d2 = _e46 - _l4,\n          _p2 = Math.floor(_o8 / 2);\n\n      u = {\n        top: _l4,\n        bottom: _d2,\n        left: _p2,\n        right: _o8 - _p2,\n        type: \"SAME\"\n      };\n    } else if (\"valid\" === e) u = {\n      top: 0,\n      bottom: 0,\n      left: 0,\n      right: 0,\n      type: \"VALID\"\n    }, c = Math.ceil((t - a + 1) / s), h = Math.ceil((n - i + 1) / r);else {\n      if (\"object\" != typeof e) throw Error(\"Unknown padding parameter: \".concat(e));\n      {\n        var _d3 = \"channelsLast\" === l ? e[1][0] : e[2][0],\n            _p3 = \"channelsLast\" === l ? e[1][1] : e[2][1],\n            _f2 = \"channelsLast\" === l ? e[2][0] : e[3][0],\n            _g2 = \"channelsLast\" === l ? e[2][1] : e[3][1];\n\n        u = {\n          top: _d3,\n          bottom: _p3,\n          left: _f2,\n          right: _g2,\n          type: 0 === _d3 && 0 === _p3 && 0 === _f2 && 0 === _g2 ? \"VALID\" : \"EXPLICIT\"\n        }, c = Ns((t - a + _d3 + _p3) / s + 1, o), h = Ns((n - i + _f2 + _g2) / r + 1, o);\n      }\n    }\n\n    return {\n      padInfo: u,\n      outHeight: c,\n      outWidth: h\n    };\n  }(r, u, c, g, m, y, k, a, o),\n      $ = i ? f * h : f;\n\n  var S;\n  return \"channelsFirst\" === o ? S = [l, $, v, I] : \"channelsLast\" === o && (S = [l, v, I, $]), {\n    batchSize: l,\n    dataFormat: o,\n    inHeight: u,\n    inWidth: c,\n    inChannels: h,\n    outHeight: v,\n    outWidth: I,\n    outChannels: $,\n    padInfo: w,\n    strideHeight: g,\n    strideWidth: m,\n    filterHeight: d,\n    filterWidth: p,\n    effectiveFilterHeight: y,\n    effectiveFilterWidth: k,\n    dilationHeight: b,\n    dilationWidth: x,\n    inShape: e,\n    outShape: S,\n    filterShape: t\n  };\n}\n\nfunction ws(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"channelsLast\";\n  var o = arguments.length > 7 ? arguments[7] : undefined;\n  var [l, u, c, h, d] = [-1, -1, -1, -1, -1];\n  if (\"channelsLast\" === i) [l, u, c, h, d] = e;else {\n    if (\"channelsFirst\" !== i) throw new Error(\"Unknown dataFormat \".concat(i));\n    [l, d, u, c, h] = e;\n  }\n\n  var [p, f, g,, m] = t,\n      [b, x, y] = $s(n),\n      [k, w, v] = $s(s),\n      I = Ss(p, k),\n      $ = Ss(f, w),\n      S = Ss(g, v),\n      {\n    padInfo: N,\n    outDepth: C,\n    outHeight: T,\n    outWidth: E\n  } = function (e, t, n, s, r, a, i, o, l, u, c) {\n    var h, d, p, f;\n\n    if (\"number\" == typeof e) {\n      h = {\n        top: e,\n        bottom: e,\n        left: e,\n        right: e,\n        front: e,\n        back: e,\n        type: 0 === e ? \"VALID\" : \"NUMBER\"\n      };\n\n      var _a11 = function (e, t, n, s, r, a) {\n        null == r && (r = vs(e, t, s));\n        var i = e[1],\n            o = e[2];\n        return [Ns((e[0] - t + 2 * r) / s + 1, a), Ns((i - t + 2 * r) / s + 1, a), Ns((o - t + 2 * r) / s + 1, a), 1];\n      }([t, n, s, 1], o, 0, r, e, c);\n\n      d = _a11[0], p = _a11[1], f = _a11[2];\n    } else if (\"same\" === e) {\n      d = Math.ceil(t / r), p = Math.ceil(n / a), f = Math.ceil(s / i);\n\n      var _e47 = (d - 1) * r + o - t,\n          _c2 = (p - 1) * a + l - n,\n          _g3 = (f - 1) * i + u - s,\n          _m2 = Math.floor(_e47 / 2),\n          _b2 = _e47 - _m2,\n          _x8 = Math.floor(_c2 / 2),\n          _y2 = _c2 - _x8,\n          _k2 = Math.floor(_g3 / 2);\n\n      h = {\n        top: _x8,\n        bottom: _y2,\n        left: _k2,\n        right: _g3 - _k2,\n        front: _m2,\n        back: _b2,\n        type: \"SAME\"\n      };\n    } else {\n      if (\"valid\" !== e) throw Error(\"Unknown padding parameter: \".concat(e));\n      h = {\n        top: 0,\n        bottom: 0,\n        left: 0,\n        right: 0,\n        front: 0,\n        back: 0,\n        type: \"VALID\"\n      }, d = Math.ceil((t - o + 1) / r), p = Math.ceil((n - l + 1) / a), f = Math.ceil((s - u + 1) / i);\n    }\n\n    return {\n      padInfo: h,\n      outDepth: d,\n      outHeight: p,\n      outWidth: f\n    };\n  }(r, u, c, h, b, x, y, I, $, S, o),\n      R = a ? m * d : m;\n\n  var A;\n  return \"channelsFirst\" === i ? A = [l, R, C, T, E] : \"channelsLast\" === i && (A = [l, C, T, E, R]), {\n    batchSize: l,\n    dataFormat: i,\n    inDepth: u,\n    inHeight: c,\n    inWidth: h,\n    inChannels: d,\n    outDepth: C,\n    outHeight: T,\n    outWidth: E,\n    outChannels: R,\n    padInfo: N,\n    strideDepth: b,\n    strideHeight: x,\n    strideWidth: y,\n    filterDepth: p,\n    filterHeight: f,\n    filterWidth: g,\n    effectiveFilterDepth: I,\n    effectiveFilterHeight: $,\n    effectiveFilterWidth: S,\n    dilationDepth: k,\n    dilationHeight: w,\n    dilationWidth: v,\n    inShape: e,\n    outShape: A,\n    filterShape: t\n  };\n}\n\nfunction vs(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n  var r = Ss(t, s);\n  return Math.floor((e[0] * (n - 1) - n + r) / 2);\n}\n\nfunction Is(e) {\n  return \"number\" == typeof e ? [e, e, e] : 2 === e.length ? [e[0], e[1], 1] : e;\n}\n\nfunction $s(e) {\n  return \"number\" == typeof e ? [e, e, e] : e;\n}\n\nfunction Ss(e, t) {\n  return t <= 1 ? e : e + (e - 1) * (t - 1);\n}\n\nfunction Ns(e, t) {\n  if (!t) return Math.trunc(e);\n\n  switch (t) {\n    case \"round\":\n      return Math.round(e);\n\n    case \"ceil\":\n      return Math.ceil(e);\n\n    case \"floor\":\n      return Math.floor(e);\n\n    default:\n      throw new Error(\"Unknown roundingMode \".concat(t));\n  }\n}\n\nfunction Cs(e) {\n  var [t, n, s] = Is(e);\n  return 1 === t && 1 === n && 1 === s;\n}\n\nfunction Ts(e, t) {\n  return Cs(e) || Cs(t);\n}\n\nfunction Es(e) {\n  if (\"NHWC\" === e) return \"channelsLast\";\n  if (\"NCHW\" === e) return \"channelsFirst\";\n  throw new Error(\"Unknown dataFormat \".concat(e));\n}\n\nvar Rs = Ft({\n  reshape_: function reshape_(e, t) {\n    var n = Rt(e, \"x\", \"reshape\", \"string_or_numeric\");\n    return vt.runKernel(\"Reshape\", {\n      x: n\n    }, {\n      shape: t\n    });\n  }\n}),\n    As = Ft({\n  avgPool_: function avgPool_(e, t, n, s, r) {\n    var a = Rt(e, \"x\", \"avgPool\", \"float32\");\n    l(Ts(n, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '1'\"));\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Rs(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === i.rank, () => \"Error in avgPool: x must be rank 4 but got rank \".concat(i.rank, \".\")), null != r && l(f(s), () => \"Error in avgPool: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var u = vt.runKernel(\"AvgPool\", {\n      x: i\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r\n    });\n    return u = fn(u, a.dtype), o ? Rs(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    Fs = Ft({\n  avgPool3d_: function avgPool3d_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NDHWC\";\n    var i = Rt(e, \"x\", \"avgPool3d\", \"float32\");\n    var o = i,\n        u = !1;\n    4 === i.rank && (u = !0, o = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === o.rank, () => \"Error in avgPool3d: x must be rank 5 but got rank \".concat(o.rank, \".\")), l(\"NDHWC\" === a, () => \"Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of \".concat(a)), null != r && l(f(s), () => \"Error in avgPool3d: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var c = vt.runKernel(\"AvgPool3D\", {\n      x: o\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r,\n      dataFormat: a\n    });\n    return c = fn(c, o.dtype), u ? Rs(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;\n  }\n}),\n    Ds = Ft({\n  concat_: function concat_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    l(e.length >= 1, () => \"Pass at least one tensor to concat\");\n    var n = At(e, \"tensors\", \"concat\", \"string_or_numeric\");\n    return \"complex64\" === n[0].dtype && n.forEach(e => {\n      if (\"complex64\" !== e.dtype) throw new Error(\"Cannot concatenate complex64 tensors with a tensor\\n          with dtype \".concat(e.dtype, \". \"));\n    }), 1 === n.length ? gn(n[0]) : vt.runKernel(\"Concat\", n, {\n      axis: t\n    });\n  }\n}),\n    _s = Ft({\n  sigmoid_: function sigmoid_(e) {\n    var t = Rt(e, \"x\", \"sigmoid\");\n    return vt.runKernel(\"Sigmoid\", {\n      x: t\n    });\n  }\n}),\n    Os = Ft({\n  slice_: function slice_(e, t, n) {\n    var s = Rt(e, \"x\", \"slice\", \"string_or_numeric\");\n    if (0 === s.rank) throw new Error(\"Slicing scalar is not possible\");\n    return vt.runKernel(\"Slice\", {\n      x: s\n    }, {\n      begin: t,\n      size: n\n    });\n  }\n}),\n    Ms = Ft({\n  tanh_: function tanh_(e) {\n    var t = Rt(e, \"x\", \"tanh\");\n    return vt.runKernel(\"Tanh\", {\n      x: t\n    });\n  }\n}),\n    Ls = Ft({\n  batchToSpaceND_: function batchToSpaceND_(e, t, n) {\n    var s = Rt(e, \"x\", \"batchToSpaceND\"),\n        r = t.reduce((e, t) => e * t);\n    return l(s.rank >= 1 + t.length, () => \"input rank is \".concat(s.rank, \" but should be > than blockShape.length \").concat(t.length)), l(n.length === t.length, () => \"crops.length is \".concat(n.length, \" but should be equal to blockShape.length  \").concat(t.length)), l(s.shape[0] % r == 0, () => \"input tensor batch is \".concat(s.shape[0], \" but is not divisible by the product of the elements of blockShape \").concat(t.join(\" * \"), \" === \").concat(r)), vt.runKernel(\"BatchToSpaceND\", {\n      x: s\n    }, {\n      blockShape: t,\n      crops: n\n    });\n  }\n}),\n    zs = Ft({\n  batchNorm_: function batchNorm_(e, t, n, s, r, a) {\n    null == a && (a = .001);\n    var i = Rt(e, \"x\", \"batchNorm\"),\n        o = Rt(t, \"mean\", \"batchNorm\"),\n        u = Rt(n, \"variance\", \"batchNorm\");\n    var c, h;\n    null != r && (c = Rt(r, \"scale\", \"batchNorm\")), null != s && (h = Rt(s, \"offset\", \"batchNorm\")), l(o.rank === u.rank, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == h || o.rank === h.rank, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == c || o.rank === c.rank, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\");\n\n    var d = function (e) {\n      var t;\n      return t = 0 === e.rank || 1 === e.rank ? Rs(e, [1, 1, 1, e.size]) : 2 === e.rank ? Rs(e, [1, 1, e.shape[0], e.shape[1]]) : 3 === e.rank ? Rs(e, [1, e.shape[0], e.shape[1], e.shape[2]]) : e, t;\n    }(i),\n        p = vt.runKernel(\"FusedBatchNorm\", {\n      x: d,\n      scale: c,\n      offset: h,\n      mean: o,\n      variance: u\n    }, {\n      varianceEpsilon: a\n    });\n\n    return Rs(p, i.shape);\n  }\n}),\n    Bs = Ft({\n  batchNorm2d_: function batchNorm2d_(e, t, n, s, r, a) {\n    var i = Rt(e, \"x\", \"batchNorm\"),\n        o = Rt(t, \"mean\", \"batchNorm\"),\n        u = Rt(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Rt(r, \"scale\", \"batchNorm\")), null != s && (h = Rt(s, \"offset\", \"batchNorm\")), l(2 === i.rank, () => \"Error in batchNorm2D: x must be rank 2 but got rank \".concat(i.rank, \".\")), l(2 === o.rank || 1 === o.rank, () => \"Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank \".concat(o.rank, \".\")), l(2 === u.rank || 1 === u.rank, () => \"Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(2 === c.rank || 1 === c.rank, () => \"Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(2 === h.rank || 1 === h.rank, () => \"Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank \".concat(h.rank, \".\")), zs(i, o, u, h, c, a);\n  }\n}),\n    Ps = Ft({\n  batchNorm3d_: function batchNorm3d_(e, t, n, s, r, a) {\n    var i = Rt(e, \"x\", \"batchNorm\"),\n        o = Rt(t, \"mean\", \"batchNorm\"),\n        u = Rt(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Rt(r, \"scale\", \"batchNorm\")), null != s && (h = Rt(s, \"offset\", \"batchNorm\")), l(3 === i.rank, () => \"Error in batchNorm3D: x must be rank 3 but got rank \".concat(i.rank, \".\")), l(3 === o.rank || 1 === o.rank, () => \"Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank \".concat(o.rank, \".\")), l(3 === u.rank || 1 === u.rank, () => \"Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(3 === c.rank || 1 === c.rank, () => \"Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(3 === h.rank || 1 === h.rank, () => \"Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank \".concat(h.rank, \".\")), zs(i, o, u, h, c, a);\n  }\n}),\n    Ws = Ft({\n  batchNorm4d_: function batchNorm4d_(e, t, n, s, r, a) {\n    var i = Rt(e, \"x\", \"batchNorm\"),\n        o = Rt(t, \"mean\", \"batchNorm\"),\n        u = Rt(n, \"variance\", \"batchNorm\");\n    var c, h;\n    return null != r && (c = Rt(r, \"scale\", \"batchNorm\")), null != s && (h = Rt(s, \"offset\", \"batchNorm\")), l(4 === i.rank, () => \"Error in batchNorm4D: x must be rank 4 but got rank \".concat(i.rank, \".\")), l(4 === o.rank || 1 === o.rank, () => \"Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank \".concat(o.rank, \".\")), l(4 === u.rank || 1 === u.rank, () => \"Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank \".concat(u.rank, \".\")), null != c && l(4 === c.rank || 1 === c.rank, () => \"Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank \".concat(c.rank, \".\")), null != h && l(4 === h.rank || 1 === h.rank, () => \"Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank \".concat(h.rank, \".\")), zs(i, o, u, h, c, a);\n  }\n}),\n    Us = Ft({\n  bincount_: function bincount_(e, t, n) {\n    var s = Rt(e, \"x\", \"bincount\"),\n        r = Rt(t, \"weights\", \"bincount\");\n    return l(\"int32\" === s.dtype, () => \"Error in bincount: input dtype must be int32, but got \".concat(s.dtype)), l(n >= 0, () => \"size must be non-negative, but got \".concat(n, \".\")), l(r.size === s.size || 0 === r.size, () => \"Error in bincount: weights must have the same size as input or0-length, but got input shape: \".concat(s.shape, \", weights shape: \").concat(r.shape, \".\")), vt.runKernel(\"Bincount\", {\n      x: s,\n      weights: r\n    }, {\n      size: n\n    });\n  }\n}),\n    Vs = Ft({\n  broadcastTo_: function broadcastTo_(e, t) {\n    var n = Rt(e, \"broadcastTo\", \"x\");\n    var s = n.shape;\n    if (t.some(e => !(e > 0) || e % 1 != 0)) throw new Error(\"broadcastTo(): Invalid broadcast shape [\".concat(t, \"].\"));\n    if (t.length < n.rank) throw new Error(\"broadcastTo(): shape.length=\".concat(t.length, \" < input.rank=\").concat(n.rank, \".\"));\n\n    if (t.length > n.rank) {\n      var _e48 = n.shape.slice();\n\n      for (; _e48.length < t.length;) {\n        _e48.unshift(1);\n      }\n\n      n = Rs(n, _e48);\n    }\n\n    var r = n.shape,\n        a = Array.from(t);\n\n    for (var _e49 = t.length - 1; _e49 >= 0; _e49--) {\n      if (r[_e49] === t[_e49]) a[_e49] = 1;else if (1 !== n.shape[_e49]) throw new Error(\"broadcastTo(): [\".concat(s, \"] cannot be broadcast to [\").concat(t, \"].\"));\n    }\n\n    return 0 === a.map((e, t) => e > 1 ? t : -1).filter(e => e >= 0).length ? gn(n) : vt.runKernel(\"Tile\", {\n      x: n\n    }, {\n      reps: a\n    });\n  }\n}),\n    Gs = Ft({\n  ceil_: function ceil_(e) {\n    var t = Rt(e, \"x\", \"ceil\");\n    return vt.runKernel(\"Ceil\", {\n      x: t\n    });\n  }\n}),\n    Hs = Ft({\n  clipByValue_: function clipByValue_(e, t, n) {\n    var s = Rt(e, \"x\", \"clipByValue\");\n    return l(t <= n, () => \"Error in clip: min (\".concat(t, \") must be less than or equal to max (\").concat(n, \").\")), vt.runKernel(\"ClipByValue\", {\n      x: s\n    }, {\n      clipValueMin: t,\n      clipValueMax: n\n    });\n  }\n}),\n    qs = Ft({\n  concat1d_: function concat1d_(e) {\n    return Ds(e, 0);\n  }\n}),\n    js = Ft({\n  concat2d_: function concat2d_(e, t) {\n    return Ds(e, t);\n  }\n}),\n    Ks = Ft({\n  concat3d_: function concat3d_(e, t) {\n    return Ds(e, t);\n  }\n}),\n    Xs = Ft({\n  concat4d_: function concat4d_(e, t) {\n    return Ds(e, t);\n  }\n}),\n    Ys = Ft({\n  conv2d_: function conv2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Rt(e, \"x\", \"conv2d\"),\n        u = Rt(t, \"filter\", \"conv2d\");\n    var c = o,\n        h = !1;\n    3 === o.rank && (h = !0, c = Rs(o, [1, o.shape[0], o.shape[1], o.shape[2]])), l(4 === c.rank, () => \"Error in conv2d: input must be rank 4, but got rank \".concat(c.rank, \".\")), l(4 === u.rank, () => \"Error in conv2d: filter must be rank 4, but got rank \".concat(u.rank, \".\")), null != i && l(f(s), () => \"Error in conv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\"));\n    var d = \"NHWC\" === r ? c.shape[3] : c.shape[1];\n    l(d === u.shape[2], () => \"Error in conv2d: depth of input (\".concat(d, \") must match input depth for filter \").concat(u.shape[2], \".\")), l(Ts(n, a), () => \"Error in conv2D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\"));\n    var p = vt.runKernel(\"Conv2D\", {\n      x: c,\n      filter: u\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i\n    });\n    return h ? Rs(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;\n  }\n}),\n    Js = Ft({\n  conv1d_: function conv1d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Rt(e, \"x\", \"conv1d\"),\n        u = Rt(t, \"filter\", \"conv1d\");\n    var c = o,\n        h = !1;\n    2 === o.rank && (h = !0, c = Rs(o, [1, o.shape[0], o.shape[1]])), l(3 === c.rank, () => \"Error in conv1d: input must be rank 3, but got rank \".concat(c.rank, \".\")), l(3 === u.rank, () => \"Error in conv1d: filter must be rank 3, but got rank \".concat(u.rank, \".\")), null != i && l(f(s), () => \"Error in conv1d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\")), l(c.shape[2] === u.shape[1], () => \"Error in conv1d: depth of input (\".concat(c.shape[2], \") must match input depth for filter \").concat(u.shape[1], \".\")), l(Ts(n, a), () => \"Error in conv1D: Either stride or dilation must be 1. Got stride \".concat(n, \" and dilation '\").concat(a, \"'\")), l(\"NWC\" === r, () => \"Error in conv1d: got dataFormat of \".concat(r, \" but only NWC is currently supported.\"));\n    var d = Rs(u, [1, u.shape[0], u.shape[1], u.shape[2]]),\n        p = Rs(c, [c.shape[0], 1, c.shape[1], c.shape[2]]),\n        g = Ys(p, d, [1, n], s, \"NHWC\", [1, a], i);\n    return Rs(g, h ? [g.shape[2], g.shape[3]] : [g.shape[0], g.shape[2], g.shape[3]]);\n  }\n}),\n    Zs = Ft({\n  conv2DBackpropInput_: function conv2DBackpropInput_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    l(e.length === t.rank, () => \"Length of inShape (\".concat(e.length, \") and rank of dy (\").concat(t.rank, \") must match\"));\n    var o = e,\n        u = t,\n        c = !1;\n    3 === t.rank && (c = !0, u = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2]]), o = [1, e[0], e[1], e[2]]), l(4 === o.length, () => \"Error in conv2dDerInput: inShape must be length 4, but got length \".concat(o.length, \".\")), l(4 === u.rank, () => \"Error in conv2dDerInput: dy must be rank 4, but got rank \".concat(u.rank)), l(4 === n.rank, () => \"Error in conv2dDerInput: filter must be rank 4, but got rank \".concat(n.rank));\n    var h = \"NHWC\" === a ? o[3] : o[1],\n        d = \"NHWC\" === a ? u.shape[3] : u.shape[1];\n    l(h === n.shape[2], () => \"Error in conv2dDerInput: depth of input (\".concat(h, \") must match input depth for filter \").concat(n.shape[2], \".\")), l(d === n.shape[3], () => \"Error in conv2dDerInput: depth of output (\".concat(d, \") must match output depth for filter \").concat(n.shape[3], \".\")), null != i && l(f(r), () => \"Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(r, \".\"));\n    var p = vt.runKernel(\"Conv2DBackpropInput\", {\n      dy: u,\n      filter: n\n    }, {\n      strides: s,\n      pad: r,\n      dataFormat: a,\n      dimRoundingMode: i,\n      inputShape: o\n    });\n    return c ? Rs(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;\n  }\n}),\n    Qs = Ft({\n  conv2dTranspose_: function conv2dTranspose_(e, t, n, s, r, a) {\n    var i = Rt(e, \"x\", \"conv2dTranspose\"),\n        o = Rt(t, \"filter\", \"conv2dTranspose\");\n    return Zs(n, i, o, s, r, \"NHWC\", a);\n  }\n}),\n    er = Ft({\n  conv3d_: function conv3d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NDHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1, 1];\n    var i = Rt(e, \"x\", \"conv3d\"),\n        o = Rt(t, \"filter\", \"conv3d\");\n    var u = i,\n        c = !1;\n    4 === i.rank && (c = !0, u = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === u.rank, () => \"Error in conv3d: input must be rank 5, but got rank \".concat(u.rank, \".\")), l(5 === o.rank, () => \"Error in conv3d: filter must be rank 5, but got rank \".concat(o.rank, \".\")), l(u.shape[4] === o.shape[3], () => \"Error in conv3d: depth of input (\".concat(u.shape[4], \") must match input depth for filter \").concat(o.shape[3], \".\")), l(Ts(n, a), () => \"Error in conv3D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\")), l(\"NDHWC\" === r, () => \"Error in conv3d: got dataFormat of \".concat(r, \" but only NDHWC is currently supported.\"));\n    var h = vt.runKernel(\"Conv3D\", {\n      x: u,\n      filter: o\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a\n    });\n    return c ? Rs(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;\n  }\n}),\n    tr = Ft({\n  conv3DBackpropInput_: function conv3DBackpropInput_(e, t, n, s, r) {\n    l(e.length === t.rank, () => \"Length of inShape (\".concat(e.length, \") and rank of dy (\").concat(t.rank, \") must match\"));\n    var a = e,\n        i = t,\n        o = !1;\n    4 === t.rank && (o = !0, i = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), a = [1, e[0], e[1], e[2], e[3]]);\n    var u = a[4],\n        c = i.shape[4];\n    l(5 === a.length, () => \"Error in conv3dDerInput: inShape must be length 5, but got length \".concat(a.length, \".\")), l(5 === i.rank, () => \"Error in conv3dDerInput: dy must be rank 5, but got rank \".concat(i.rank)), l(5 === n.rank, () => \"Error in conv3dDerInput: filter must be rank 5, but got rank \".concat(n.rank)), l(u === n.shape[3], () => \"Error in conv3dDerInput: depth of input (\".concat(u, \") must match input depth for filter \").concat(n.shape[3], \".\")), l(c === n.shape[4], () => \"Error in conv3dDerInput: depth of output (\".concat(c, \") must match output depth for filter \").concat(n.shape[4], \".\"));\n    var h = vt.runKernel(\"Conv3DBackpropInputV2\", {\n      dy: i,\n      filter: n\n    }, {\n      pad: r,\n      strides: s,\n      inputShape: a\n    });\n    return o ? Rs(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;\n  }\n}),\n    nr = Ft({\n  conv3dTranspose_: function conv3dTranspose_(e, t, n, s, r) {\n    var a = Rt(e, \"x\", \"conv3dTranspose\"),\n        i = Rt(t, \"filter\", \"conv3dTranspose\");\n    return tr(n, a, i, s, r);\n  }\n}),\n    sr = Ft({\n  cos_: function cos_(e) {\n    var t = Rt(e, \"x\", \"cos\");\n    return vt.runKernel(\"Cos\", {\n      x: t\n    });\n  }\n}),\n    rr = Ft({\n  cosh_: function cosh_(e) {\n    var t = Rt(e, \"x\", \"cosh\");\n    return vt.runKernel(\"Cosh\", {\n      x: t\n    });\n  }\n}),\n    ar = Ft({\n  cumsum_: function cumsum_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Rt(e, \"x\", \"cumsum\");\n    return vt.runKernel(\"Cumsum\", {\n      x: r\n    }, {\n      axis: t,\n      exclusive: n,\n      reverse: s\n    });\n  }\n}),\n    ir = Ft({\n  depthToSpace_: function depthToSpace_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"NHWC\";\n    var s = Rt(e, \"x\", \"depthToSpace\"),\n        r = \"NHWC\" === n ? s.shape[1] : s.shape[2],\n        a = \"NHWC\" === n ? s.shape[2] : s.shape[3],\n        i = \"NHWC\" === n ? s.shape[3] : s.shape[1];\n    return l(r * t >= 0, () => \"Negative dimension size caused by overflow when multiplying\\n    \".concat(r, \" and \").concat(t, \"  for depthToSpace with input shape\\n    \").concat(s.shape)), l(a * t >= 0, () => \"Negative dimension size caused by overflow when multiplying\\n    \".concat(a, \" and \").concat(t, \" for depthToSpace with input shape\\n        \").concat(s.shape)), l(i % (t * t) == 0, () => \"Dimension size must be evenly divisible by \".concat(t * t, \" but is \").concat(i, \" for depthToSpace with input shape \").concat(s.shape)), vt.runKernel(\"DepthToSpace\", {\n      x: s\n    }, {\n      blockSize: t,\n      dataFormat: n\n    });\n  }\n}),\n    or = Ft({\n  depthwiseConv2d_: function depthwiseConv2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"NHWC\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = Rt(e, \"x\", \"depthwiseConv2d\"),\n        u = Rt(t, \"filter\", \"depthwiseConv2d\");\n    var c = o,\n        h = !1;\n    3 === o.rank && (h = !0, c = Rs(o, [1, o.shape[0], o.shape[1], o.shape[2]])), l(4 === c.rank, () => \"Error in depthwiseConv2d: input must be rank 4, but got rank \".concat(c.rank, \".\")), l(4 === u.rank, () => \"Error in depthwiseConv2d: filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(c.shape[3] === u.shape[2], () => \"Error in depthwiseConv2d: number of input channels (\".concat(c.shape[3], \") must match the inChannels dimension in filter \").concat(u.shape[2], \".\")), null != i && l(f(s), () => \"Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\"));\n    var d = vt.runKernel(\"DepthwiseConv2dNative\", {\n      x: c,\n      filter: u\n    }, {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i\n    });\n    return h ? Rs(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;\n  }\n}),\n    lr = Ft({\n  dilation2d_: function dilation2d_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [1, 1];\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = Rt(e, \"x\", \"dilation2d\"),\n        o = Rt(t, \"filter\", \"dilation2d\");\n    l(3 === i.rank || 4 === i.rank, () => \"Error in dilation2d: input must be rank 3 or 4, but got rank \".concat(i.rank, \".\")), l(3 === o.rank, () => \"Error in dilation2d: filter must be rank 3, but got rank \".concat(o.rank, \".\")), l(\"NHWC\" === a, () => \"Error in dilation2d: Only NHWC is currently supported, but got dataFormat of \".concat(a));\n    var u = i,\n        c = !1;\n    3 === i.rank && (u = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2]]), c = !0);\n    var h = vt.runKernel(\"Dilation2D\", {\n      x: u,\n      filter: o\n    }, {\n      strides: n,\n      pad: s,\n      dilations: r\n    });\n    return c ? Rs(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;\n  }\n});\n\nfunction ur(e, t) {\n  var n = e.length,\n      s = [];\n\n  for (var _r22 = 0; _r22 < n; _r22++) {\n    var _a12 = n - 1 - _r22,\n        _i9 = e[_a12] || 1;\n\n    (t[t.length - 1 - _r22] || 1) > 1 && 1 === _i9 && s.unshift(_a12);\n  }\n\n  return s;\n}\n\nfunction cr(e, t) {\n  var n = [];\n\n  for (var _s31 = 0; _s31 < t.length; _s31++) {\n    var _r23 = e[e.length - _s31 - 1],\n        _a13 = t.length - _s31 - 1,\n        _i10 = t[_a13];\n\n    (null == _r23 || 1 === _r23 && _i10 > 1) && n.unshift(_a13);\n  }\n\n  return n;\n}\n\nfunction hr(e, t) {\n  var n = [],\n      s = Math.max(e.length, t.length);\n\n  for (var _r24 = 0; _r24 < s; _r24++) {\n    var _s32 = e[e.length - _r24 - 1];\n    null == _s32 && (_s32 = 1);\n    var _a14 = t[t.length - _r24 - 1];\n    if (null == _a14 && (_a14 = 1), 1 === _s32) n.unshift(_a14);else if (1 === _a14) n.unshift(_s32);else {\n      if (_s32 !== _a14) throw Error(\"Operands could not be broadcast together with shapes \".concat(e, \" and \").concat(t, \".\"));\n      n.unshift(_s32);\n    }\n  }\n\n  return n;\n}\n\nvar dr = Ft({\n  equal_: function equal_(e, t) {\n    var n = Rt(e, \"a\", \"equal\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"equal\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"Equal\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    pr = Ft({\n  where_: function where_(e, t, n) {\n    var s = Rt(t, \"a\", \"where\"),\n        r = Rt(n, \"b\", \"where\"),\n        a = Rt(e, \"condition\", \"where\", \"bool\"),\n        i = hr(hr(a.shape, s.shape), r.shape),\n        o = Vs(a, i),\n        l = Vs(s, i),\n        u = Vs(r, i);\n    return vt.runKernel(\"Select\", {\n      condition: o,\n      t: l,\n      e: u\n    });\n  }\n}),\n    fr = Ft({\n  zerosLike_: function zerosLike_(e) {\n    var t = Rt(e, \"x\", \"zerosLike\");\n    return vt.runKernel(\"ZerosLike\", {\n      x: t\n    });\n  }\n}),\n    gr = Ft({\n  divNoNan_: function divNoNan_(e, t) {\n    var n = Rt(e, \"a\", \"div\"),\n        s = Rt(t, \"b\", \"div\");\n    [n, s] = gt(n, s);\n    var r = ss(n, s),\n        a = fr(r),\n        i = dr(s, a);\n    return pr(i, a, r);\n  }\n}),\n    mr = Ft({\n  dot_: function dot_(e, t) {\n    var n = Rt(e, \"t1\", \"dot\"),\n        s = Rt(t, \"t2\", \"dot\");\n    l(!(1 !== n.rank && 2 !== n.rank || 1 !== s.rank && 2 !== s.rank), () => \"Error in dot: inputs must all be rank 1 or 2, but got ranks \".concat(n.rank, \" and \").concat(s.rank, \".\"));\n    var r = 1 === n.rank ? n.size : n.shape[1],\n        a = 1 === s.rank ? s.size : s.shape[0];\n\n    if (l(r === a, () => \"Error in dot: inner dimensions of inputs must match, but got \".concat(r, \" and \").concat(a, \".\")), 1 === n.rank && 1 === s.rank) {\n      var _e50 = Rs(n, [1, -1]),\n          _t55 = Rs(s, [-1, 1]),\n          _r25 = In(_e50, _t55);\n\n      return Rs(_r25, []);\n    }\n\n    if (1 === n.rank && 2 === s.rank) {\n      var _e51 = Rs(n, [1, -1]),\n          _t56 = Rs(s, [s.shape[0], s.shape[1]]),\n          _r26 = In(_e51, _t56);\n\n      return Rs(_r26, [_r26.size]);\n    }\n\n    if (2 === n.rank && 1 === s.rank) {\n      var _e52 = Rs(s, [-1, 1]),\n          _t57 = In(n, _e52);\n\n      return Rs(_t57, [_t57.size]);\n    }\n\n    {\n      var _e53 = Rs(s, [s.shape[0], s.shape[1]]);\n\n      return In(n, _e53);\n    }\n  }\n}),\n    br = Ft({\n  elu_: function elu_(e) {\n    var t = Rt(e, \"x\", \"elu\");\n    return vt.runKernel(\"Elu\", {\n      x: t\n    });\n  }\n}),\n    xr = Ft({\n  erf_: function erf_(e) {\n    var t = Rt(e, \"x\", \"erf\");\n    return l(\"int32\" === t.dtype || \"float32\" === t.dtype, () => \"Input dtype must be `int32` or `float32`.\"), \"int32\" === t.dtype && (t = fn(t, \"float32\")), vt.runKernel(\"Erf\", {\n      x: t\n    });\n  }\n}),\n    yr = Ft({\n  exp_: function exp_(e) {\n    var t = Rt(e, \"x\", \"exp\");\n    return vt.runKernel(\"Exp\", {\n      x: t\n    });\n  }\n}),\n    kr = Ft({\n  expandDims_: function expandDims_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"expandDims\", \"string_or_numeric\");\n    return l(t <= n.rank, () => \"Axis must be <= rank of the tensor\"), vt.runKernel(\"ExpandDims\", {\n      input: n\n    }, {\n      dim: t\n    });\n  }\n}),\n    wr = Ft({\n  expm1_: function expm1_(e) {\n    var t = Rt(e, \"x\", \"expm1\");\n    return vt.runKernel(\"Expm1\", {\n      x: t\n    });\n  }\n}),\n    vr = Ft({\n  tile_: function tile_(e, t) {\n    var n = Rt(e, \"x\", \"tile\", \"string_or_numeric\");\n    return l(n.rank === t.length, () => \"Error in transpose: rank of input \".concat(n.rank, \" must match length of reps \").concat(t, \".\")), vt.runKernel(\"Tile\", {\n      x: n\n    }, {\n      reps: t\n    });\n  }\n}),\n    Ir = Ft({\n  eye_: function eye_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n    null == t && (t = e);\n    var r = pn([e, t], s),\n        a = e <= t ? e : t;\n\n    for (var _e54 = 0; _e54 < a; ++_e54) {\n      r.set(1, _e54, _e54);\n    }\n\n    var i = Rs(r.toTensor(), [e, t]);\n    if (null == n) return i;\n    if (1 === n.length) return vr(kr(i, 0), [n[0], 1, 1]);\n    if (2 === n.length) return vr(kr(kr(i, 0), 0), [n[0], n[1], 1, 1]);\n    if (3 === n.length) return vr(kr(kr(kr(i, 0), 0), 0), [n[0], n[1], n[2], 1, 1]);\n    throw new Error(\"eye() currently supports only 1D and 2D batchShapes, but received \".concat(n.length, \"D.\"));\n  }\n});\n\nfunction $r(e, t, n) {\n  return vt.runKernel(\"Fill\", {}, {\n    shape: e,\n    value: t,\n    dtype: n\n  });\n}\n\nvar Sr = Ft({\n  floor_: function floor_(e) {\n    var t = Rt(e, \"x\", \"floor\");\n    return vt.runKernel(\"Floor\", {\n      x: t\n    });\n  }\n}),\n    Nr = Ft({\n  gather_: function gather_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = Rt(e, \"x\", \"gather\"),\n        a = Rt(t, \"indices\", \"gather\", \"int32\");\n    return vt.runKernel(\"GatherV2\", {\n      x: r,\n      indices: a\n    }, {\n      axis: n,\n      batchDims: s\n    });\n  }\n}),\n    Cr = Ft({\n  greater_: function greater_(e, t) {\n    var n = Rt(e, \"a\", \"greater\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"greater\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"Greater\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Tr = Ft({\n  greaterEqual_: function greaterEqual_(e, t) {\n    var n = Rt(e, \"a\", \"greaterEqual\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"greaterEqual\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"GreaterEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Er = Ft({\n  imag_: function imag_(e) {\n    var t = Rt(e, \"input\", \"imag\");\n    return vt.runKernel(\"Imag\", {\n      input: t\n    });\n  }\n}),\n    Rr = Ft({\n  isFinite_: function isFinite_(e) {\n    var t = Rt(e, \"x\", \"isFinite\");\n    return vt.runKernel(\"IsFinite\", {\n      x: t\n    });\n  }\n}),\n    Ar = Ft({\n  isInf_: function isInf_(e) {\n    var t = Rt(e, \"x\", \"isInf\");\n    return vt.runKernel(\"IsInf\", {\n      x: t\n    });\n  }\n}),\n    Fr = Ft({\n  isNaN_: function isNaN_(e) {\n    var t = Rt(e, \"x\", \"isNaN\");\n    return vt.runKernel(\"IsNan\", {\n      x: t\n    });\n  }\n}),\n    Dr = Ft({\n  leakyRelu_: function leakyRelu_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .2;\n    var n = Rt(e, \"x\", \"leakyRelu\");\n    return vt.runKernel(\"LeakyRelu\", {\n      x: n\n    }, {\n      alpha: t\n    });\n  }\n}),\n    _r = Ft({\n  less_: function less_(e, t) {\n    var n = Rt(e, \"a\", \"less\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"less\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"Less\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Or = Ft({\n  lessEqual_: function lessEqual_(e, t) {\n    var n = Rt(e, \"a\", \"lessEqual\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"lessEqual\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"LessEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Mr = Ft({\n  localResponseNormalization_: function localResponseNormalization_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 5;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .5;\n    var a = Rt(e, \"x\", \"localResponseNormalization\");\n    l(4 === a.rank || 3 === a.rank, () => \"Error in localResponseNormalization: x must be rank 3 or 4 but got\\n               rank \".concat(a.rank, \".\")), l(f(t), () => \"Error in localResponseNormalization: depthRadius must be an integer but got depthRadius \".concat(t, \".\"));\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Rs(a, [1, a.shape[0], a.shape[1], a.shape[2]]));\n    var u = vt.runKernel(\"LRN\", {\n      x: i\n    }, {\n      depthRadius: t,\n      bias: n,\n      alpha: s,\n      beta: r\n    });\n    return o ? Rs(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    Lr = Ft({\n  log_: function log_(e) {\n    var t = Rt(e, \"x\", \"log\");\n    return vt.runKernel(\"Log\", {\n      x: t\n    });\n  }\n}),\n    zr = Ft({\n  log1p_: function log1p_(e) {\n    var t = Rt(e, \"x\", \"log1p\");\n    return vt.runKernel(\"Log1p\", {\n      x: t\n    });\n  }\n});\n\nfunction Br(e) {\n  return vt.customGrad(e);\n}\n\nvar Pr = Ft({\n  neg_: function neg_(e) {\n    var t = Rt(e, \"x\", \"neg\");\n    return vt.runKernel(\"Neg\", {\n      x: t\n    });\n  }\n}),\n    Wr = Ft({\n  softplus_: function softplus_(e) {\n    var t = Rt(e, \"x\", \"softplus\");\n    return vt.runKernel(\"Softplus\", {\n      x: t\n    });\n  }\n}),\n    Ur = Ft({\n  logSigmoid_: function logSigmoid_(e) {\n    var t = Rt(e, \"x\", \"logSigmoid\");\n    return Br(e => ({\n      value: Pr(Wr(Pr(e))),\n      gradFunc: t => rs(t, _s(Pr(e)))\n    }))(t);\n  }\n}),\n    Vr = Ft({\n  max_: function max_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"max\");\n    return vt.runKernel(\"Max\", {\n      x: s\n    }, {\n      reductionIndices: t,\n      keepDims: n\n    });\n  }\n}),\n    Gr = Ft({\n  sub_: function sub_(e, t) {\n    var n = Rt(e, \"a\", \"sub\"),\n        s = Rt(t, \"b\", \"sub\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Sub\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    Hr = Ft({\n  sum_: function sum_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"sum\");\n    return \"bool\" === s.dtype && (s = fn(s, \"int32\")), vt.runKernel(\"Sum\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    qr = Ft({\n  logSoftmax_: function logSoftmax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    var n = Rt(e, \"logits\", \"logSoftmax\");\n    if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error(\"Log Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(n.rank, \" and axis was \").concat(t));\n    return Br((e, n) => {\n      var s = Vr(e, t, !0),\n          r = Gr(e, s),\n          a = Gr(fn(r, \"float32\"), Lr(Hr(yr(r), t, !0)));\n      return n([a]), {\n        value: a,\n        gradFunc: (e, n) => {\n          var [s] = n,\n              r = yr(s);\n          return Gr(e, rs(Hr(e, t, !0), r));\n        }\n      };\n    })(n);\n  }\n});\n\nfunction jr(e, t) {\n  for (var _n27 = 0; _n27 < e.length; ++_n27) {\n    if (e[e.length - _n27 - 1] !== t - 1 - _n27) return !1;\n  }\n\n  return !0;\n}\n\nfunction Kr(e, t, n) {\n  var s = e.length + t.length,\n      r = [];\n  var a = 0,\n      i = 0;\n\n  for (var _o9 = 0; _o9 < s; _o9++) {\n    -1 === n.indexOf(_o9) ? r.push(e[a++]) : r.push(t[i++]);\n  }\n\n  return r;\n}\n\nfunction Xr(e, t) {\n  var n = [],\n      s = e.length;\n\n  for (var _r27 = 0; _r27 < s; _r27++) {\n    -1 === t.indexOf(_r27) && n.push(e[_r27]);\n  }\n\n  return [n, t.map(t => e[t])];\n}\n\nfunction Yr(e, t) {\n  return Kr(e, t.map(e => 1), t);\n}\n\nfunction Jr(e, t, n) {\n  l(jr(t, n), () => \"\".concat(e, \" supports only inner-most axes for now. Got axes \").concat(t, \" and rank-\").concat(n, \" input.\"));\n}\n\nfunction Zr(e, t) {\n  if (jr(e, t)) return null;\n  var n = [];\n\n  for (var _s33 = 0; _s33 < t; ++_s33) {\n    -1 === e.indexOf(_s33) && n.push(_s33);\n  }\n\n  return e.forEach(e => n.push(e)), n;\n}\n\nfunction Qr(e) {\n  return e.map((e, t) => [t, e]).sort((e, t) => e[1] - t[1]).map(e => e[0]);\n}\n\nfunction ea(e, t) {\n  var n = [];\n\n  for (var _s34 = t - e; _s34 < t; ++_s34) {\n    n.push(_s34);\n  }\n\n  return n;\n}\n\nvar ta = Ft({\n  logSumExp_: function logSumExp_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"logSumExp\"),\n        r = y(t, s.shape),\n        a = Vr(s, r, !0),\n        i = Gr(s, a),\n        o = yr(i),\n        l = Hr(o, r),\n        u = Lr(l),\n        c = ts(Rs(a, u.shape), u);\n\n    if (n) {\n      var _e55 = Yr(c.shape, r);\n\n      return Rs(c, _e55);\n    }\n\n    return c;\n  }\n}),\n    na = Ft({\n  logicalAnd_: function logicalAnd_(e, t) {\n    var n = Rt(e, \"a\", \"logicalAnd\", \"bool\"),\n        s = Rt(t, \"b\", \"logicalAnd\", \"bool\");\n    return hr(n.shape, s.shape), vt.runKernel(\"LogicalAnd\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    sa = Ft({\n  logicalNot_: function logicalNot_(e) {\n    var t = Rt(e, \"x\", \"logicalNot\", \"bool\");\n    return vt.runKernel(\"LogicalNot\", {\n      x: t\n    });\n  }\n}),\n    ra = Ft({\n  logicalOr_: function logicalOr_(e, t) {\n    var n = Rt(e, \"a\", \"logicalOr\", \"bool\"),\n        s = Rt(t, \"b\", \"logicalOr\", \"bool\");\n    return hr(n.shape, s.shape), vt.runKernel(\"LogicalOr\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    aa = Ft({\n  logicalXor_: function logicalXor_(e, t) {\n    var n = Rt(e, \"a\", \"logicalXor\", \"bool\"),\n        s = Rt(t, \"b\", \"logicalXor\", \"bool\");\n    return hr(n.shape, s.shape), na(ra(e, t), sa(na(e, t)));\n  }\n}),\n    ia = Ft({\n  maxPool_: function maxPool_(e, t, n, s, r) {\n    var a = Rt(e, \"x\", \"maxPool\");\n    var i = a,\n        o = !1;\n    3 === a.rank && (o = !0, i = Rs(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === i.rank, () => \"Error in maxPool: input must be rank 4 but got rank \".concat(i.rank, \".\")), l(Ts(n, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '1'\")), null != r && l(f(s), () => \"Error in maxPool: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var u = vt.runKernel(\"MaxPool\", {\n      x: i\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r\n    });\n    return o ? Rs(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    oa = Ft({\n  maxPool3d_: function maxPool3d_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [1, 1, 1];\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NDHWC\";\n    var i = Rt(e, \"x\", \"maxPool3d\");\n    var o = i,\n        u = !1;\n    4 === i.rank && (u = !0, o = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), l(5 === o.rank, () => \"Error in maxPool3d: x must be rank 5 but got rank \".concat(o.rank, \".\")), l(\"NDHWC\" === a, () => \"Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of \".concat(a)), null != r && l(f(s), () => \"Error in maxPool3d: pad must be an integer when using, dimRoundingMode \".concat(r, \" but got pad \").concat(s, \".\"));\n    var c = vt.runKernel(\"MaxPool3D\", {\n      x: o\n    }, {\n      filterSize: t,\n      strides: n,\n      pad: s,\n      dimRoundingMode: r,\n      dataFormat: a\n    });\n    return u ? Rs(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;\n  }\n}),\n    la = Ft({\n  maximum_: function maximum_(e, t) {\n    var n = Rt(e, \"a\", \"maximum\"),\n        s = Rt(t, \"b\", \"maximum\");\n    return [n, s] = gt(n, s), \"bool\" === n.dtype && (n = fn(n, \"int32\"), s = fn(s, \"int32\")), hr(n.shape, s.shape), vt.runKernel(\"Maximum\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ua = Ft({\n  mean_: function mean_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"mean\");\n    return vt.runKernel(\"Mean\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n});\n\nfunction ca(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n\n  if (\"complex64\" === t) {\n    var _t58 = ca(e, \"float32\"),\n        _n28 = ca(e, \"float32\");\n\n    return Dt(_t58, _n28);\n  }\n\n  var n = O(d(e), t);\n  return vt.makeTensor(n, e, t);\n}\n\nfunction ha(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n\n  if (\"complex64\" === t) {\n    var _t59 = ha(e, \"float32\"),\n        _n29 = ca(e, \"float32\");\n\n    return Dt(_t59, _n29);\n  }\n\n  var n = _(d(e), t);\n\n  return vt.makeTensor(n, e, t);\n}\n\nvar da = Ft({\n  min_: function min_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"min\");\n    return vt.runKernel(\"Min\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n}),\n    pa = Ft({\n  minimum_: function minimum_(e, t) {\n    var n = Rt(e, \"a\", \"minimum\"),\n        s = Rt(t, \"b\", \"minimum\");\n    return [n, s] = gt(n, s), \"bool\" === n.dtype && (n = fn(n, \"int32\"), s = fn(s, \"int32\")), hr(n.shape, s.shape), vt.runKernel(\"Minimum\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    fa = Ft({\n  mirrorPad_: function mirrorPad_(e, t, n) {\n    l(\"reflect\" === n || \"symmetric\" === n, () => \"Invalid mode. Mode must be either reflect or symmetric. Got \".concat(n, \".\"));\n    var s = Rt(e, \"x\", \"mirrorPad\");\n    if (0 === s.rank) throw new Error(\"mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad\");\n    l(t.length === s.rank, () => \"Padding doesn't match input. Must be \".concat(s.rank, \". Got \").concat(t.length, \".\"));\n    var r = \"reflect\" === n ? 1 : 0;\n\n    var _loop5 = function _loop5(_e56) {\n      l(2 === t[_e56].length, () => \"Invalid number of paddings. Must be length of 2 each.\"), l(t[_e56][0] >= 0 && t[_e56][0] <= s.shape[_e56] - r && t[_e56][1] >= 0 && t[_e56][1] <= s.shape[_e56] - r, () => \"Padding in dimension \".concat(_e56, \" cannot be greater than or equal to \").concat(s.shape[_e56] - r, \" or less than 0 for input of shape \").concat(s.shape));\n    };\n\n    for (var _e56 = 0; _e56 < s.rank; _e56++) {\n      _loop5(_e56);\n    }\n\n    return vt.runKernel(\"MirrorPad\", {\n      x: s\n    }, {\n      paddings: t,\n      mode: n\n    });\n  }\n}),\n    ga = Ft({\n  mod_: function mod_(e, t) {\n    var n = Rt(e, \"a\", \"mod\"),\n        s = Rt(t, \"b\", \"mod\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Mod\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ma = Ft({\n  square_: function square_(e) {\n    var t = Rt(e, \"x\", \"square\");\n    return vt.runKernel(\"Square\", {\n      x: t\n    }, {});\n  }\n}),\n    ba = Ft({\n  moments_: function moments_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = y(t, (e = Rt(e, \"x\", \"moments\")).shape),\n        r = ua(e, s, n);\n    var a = r.shape;\n    n || (a = Yr(r.shape, s));\n    var i = ma(Gr(fn(e, \"float32\"), Rs(r, a)));\n    return {\n      mean: r,\n      variance: ua(i, s, n)\n    };\n  }\n}),\n    xa = Ft({\n  notEqual_: function notEqual_(e, t) {\n    var n = Rt(e, \"a\", \"notEqual\", \"string_or_numeric\"),\n        s = Rt(t, \"b\", \"notEqual\", \"string_or_numeric\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"NotEqual\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    ya = Ft({\n  onesLike_: function onesLike_(e) {\n    var t = Rt(e, \"x\", \"onesLike\");\n    return vt.runKernel(\"OnesLike\", {\n      x: t\n    });\n  }\n}),\n    ka = Ft({\n  pad_: function pad_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = Rt(e, \"x\", \"pad\");\n    if (0 === s.rank) throw new Error(\"pad(scalar) is not defined. Pass non-scalar to pad\");\n    return vt.runKernel(\"PadV2\", {\n      x: s\n    }, {\n      paddings: t,\n      constantValue: n\n    });\n  }\n}),\n    wa = Ft({\n  spaceToBatchND_: function spaceToBatchND_(e, t, n) {\n    var s = Rt(e, \"x\", \"spaceToBatchND\");\n    return l(s.rank >= 1 + t.length, () => \"input rank \".concat(s.rank, \" should be > than [blockShape] \").concat(t.length)), l(n.length === t.length, () => \"paddings.shape[0] \".concat(n.length, \" must be equal to [blockShape] \").concat(t.length)), l(s.shape.reduce((e, s, r) => r > 0 && r <= t.length ? e && (s + n[r - 1][0] + n[r - 1][1]) % t[r - 1] == 0 : e, !0), () => \"input spatial dimensions \".concat(s.shape.slice(1), \" with paddings \").concat(n.toString(), \" must be divisible by blockShapes \").concat(t.toString())), vt.runKernel(\"SpaceToBatchND\", {\n      x: s\n    }, {\n      blockShape: t,\n      paddings: n\n    });\n  }\n}),\n    va = Ft({\n  pool_: function pool_(e, t, n, s, r, a) {\n    null == r && (r = [1, 1]), null == a && (a = 1), 0 === s && (s = \"valid\");\n    var i = Rt(e, \"x\", \"maxPool\");\n    var o = i,\n        u = !1;\n    3 === i.rank && (u = !0, o = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2]])), l(Ts(a, r), () => \"Error in pool: Either strides or dilations must be 1. Got strides \".concat(a, \" and dilations '\").concat(r, \"'\"));\n    var c = xs(o.shape, t, a, r, s),\n        h = [c.dilationHeight, c.dilationWidth];\n    var d;\n    d = \"same\" === s ? function (e, t) {\n      var n = e.map((e, n) => e + (e - 1) * (t[n] - 1)).map(e => e - 1),\n          s = n.map(e => Math.floor(e / 2)),\n          r = n.map((e, t) => e - s[t]);\n      return n.map((e, t) => [s[t], r[t]]);\n    }([c.filterHeight, c.filterWidth], h) : [[0, 0], [0, 0]];\n\n    var p = 1 === h[0] && 1 === h[1],\n        [f, g] = function (e, t, n) {\n      var s = n.map(e => e[0]),\n          r = n.map(e => e[1]),\n          a = e.concat(s, r),\n          i = t.map((e, t) => (e - a[t] % e) % e),\n          o = r.map((e, t) => e + i[t]);\n      return [t.map((e, t) => [s[t], o[t]]), t.map((e, t) => [0, i[t]])];\n    }([c.inHeight, c.inWidth], h, d),\n        m = p ? s : \"valid\",\n        b = p ? o : wa(o, h, f),\n        x = (\"avg\" === n ? () => As(b, t, a, m) : () => ia(b, t, a, m))(),\n        y = p ? x : Ls(x, h, g);\n\n    return u ? Rs(y, [y.shape[1], y.shape[2], y.shape[3]]) : y;\n  }\n}),\n    Ia = Ft({\n  pow_: function pow_(e, t) {\n    var n = Rt(e, \"base\", \"pow\"),\n        s = Rt(t, \"exp\", \"pow\");\n    return [n, s] = gt(n, s), vt.runKernel(\"Pow\", {\n      a: n,\n      b: s\n    });\n  }\n}),\n    $a = Ft({\n  prelu_: function prelu_(e, t) {\n    var n = Rt(e, \"x\", \"prelu\"),\n        s = Rt(t, \"alpha\", \"prelu\");\n    return vt.runKernel(\"Prelu\", {\n      x: n,\n      alpha: s\n    });\n  }\n}),\n    Sa = Ft({\n  prod_: function prod_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = Rt(e, \"x\", \"prod\");\n    return \"bool\" === s.dtype && (s = fn(s, \"int32\")), vt.runKernel(\"Prod\", {\n      x: s\n    }, {\n      axis: t,\n      keepDims: n\n    });\n  }\n});\n\nfunction Na(e) {\n  var t = {\n    exports: {}\n  };\n  return e(t, t.exports), t.exports;\n}\n\n\"undefined\" != typeof globalThis ? globalThis : \"undefined\" != typeof window ? window : \"undefined\" != typeof global ? global : \"undefined\" != typeof self && self;\n\nvar Ca = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t,\n          n = this,\n          s = (t = 4022871197, function (e) {\n        e = e.toString();\n\n        for (var n = 0; n < e.length; n++) {\n          var s = .02519603282416938 * (t += e.charCodeAt(n));\n          s -= t = s >>> 0, t = (s *= t) >>> 0, t += 4294967296 * (s -= t);\n        }\n\n        return 2.3283064365386963e-10 * (t >>> 0);\n      });\n      n.next = function () {\n        var e = 2091639 * n.s0 + 2.3283064365386963e-10 * n.c;\n        return n.s0 = n.s1, n.s1 = n.s2, n.s2 = e - (n.c = 0 | e);\n      }, n.c = 1, n.s0 = s(\" \"), n.s1 = s(\" \"), n.s2 = s(\" \"), n.s0 -= s(e), n.s0 < 0 && (n.s0 += 1), n.s1 -= s(e), n.s1 < 0 && (n.s1 += 1), n.s2 -= s(e), n.s2 < 0 && (n.s2 += 1), s = null;\n    }\n\n    function r(e, t) {\n      return t.c = e.c, t.s0 = e.s0, t.s1 = e.s1, t.s2 = e.s2, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = n.next;\n      return i.int32 = function () {\n        return 4294967296 * n.next() | 0;\n      }, i.double = function () {\n        return i() + 11102230246251565e-32 * (2097152 * i() | 0);\n      }, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.alea = a;\n  }(0, e);\n}),\n    Ta = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.next = function () {\n        var e = t.x ^ t.x << 11;\n        return t.x = t.y, t.y = t.z, t.z = t.w, t.w ^= t.w >>> 19 ^ e ^ e >>> 8;\n      }, e === (0 | e) ? t.x = e : n += e;\n\n      for (var s = 0; s < n.length + 64; s++) {\n        t.x ^= 0 | n.charCodeAt(s), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xor128 = a;\n  }(0, e);\n}),\n    Ea = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.next = function () {\n        var e = t.x ^ t.x >>> 2;\n        return t.x = t.y, t.y = t.z, t.z = t.w, t.w = t.v, (t.d = t.d + 362437 | 0) + (t.v = t.v ^ t.v << 4 ^ e ^ e << 1) | 0;\n      }, t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.v = 0, e === (0 | e) ? t.x = e : n += e;\n\n      for (var s = 0; s < n.length + 64; s++) {\n        t.x ^= 0 | n.charCodeAt(s), s == n.length && (t.d = t.x << 10 ^ t.x >>> 4), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t.v = e.v, t.d = e.d, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xorwow = a;\n  }(0, e);\n}),\n    Ra = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this;\n      t.next = function () {\n        var e,\n            n,\n            s = t.x,\n            r = t.i;\n        return e = s[r], n = (e ^= e >>> 7) ^ e << 24, n ^= (e = s[r + 1 & 7]) ^ e >>> 10, n ^= (e = s[r + 3 & 7]) ^ e >>> 3, n ^= (e = s[r + 4 & 7]) ^ e << 7, e = s[r + 7 & 7], s[r] = n ^= (e ^= e << 13) ^ e << 9, t.i = r + 1 & 7, n;\n      }, function (e, t) {\n        var n,\n            s = [];\n        if (t === (0 | t)) s[0] = t;else for (t = \"\" + t, n = 0; n < t.length; ++n) {\n          s[7 & n] = s[7 & n] << 15 ^ t.charCodeAt(n) + s[n + 1 & 7] << 13;\n        }\n\n        for (; s.length < 8;) {\n          s.push(0);\n        }\n\n        for (n = 0; n < 8 && 0 === s[n]; ++n) {\n          ;\n        }\n\n        for (8 == n && (s[7] = -1), e.x = s, e.i = 0, n = 256; n > 0; --n) {\n          e.next();\n        }\n      }(t, e);\n    }\n\n    function r(e, t) {\n      return t.x = e.x.slice(), t.i = e.i, t;\n    }\n\n    function a(e, t) {\n      null == e && (e = +new Date());\n\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (a.x && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xorshift7 = a;\n  }(0, e);\n}),\n    Aa = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this;\n      t.next = function () {\n        var e,\n            n,\n            s = t.w,\n            r = t.X,\n            a = t.i;\n        return t.w = s = s + 1640531527 | 0, n = r[a + 34 & 127], e = r[a = a + 1 & 127], n ^= n << 13, e ^= e << 17, n = r[a] = (n ^= n >>> 15) ^ (e ^= e >>> 12), t.i = a, n + (s ^ s >>> 16) | 0;\n      }, function (e, t) {\n        var n,\n            s,\n            r,\n            a,\n            i,\n            o = [],\n            l = 128;\n\n        for (t === (0 | t) ? (s = t, t = null) : (t += \"\\0\", s = 0, l = Math.max(l, t.length)), r = 0, a = -32; a < l; ++a) {\n          t && (s ^= t.charCodeAt((a + 32) % t.length)), 0 === a && (i = s), s ^= s << 10, s ^= s >>> 15, s ^= s << 4, s ^= s >>> 13, a >= 0 && (r = 0 == (n = o[127 & a] ^= s + (i = i + 1640531527 | 0)) ? r + 1 : 0);\n        }\n\n        for (r >= 128 && (o[127 & (t && t.length || 0)] = -1), r = 127, a = 512; a > 0; --a) {\n          s = o[r + 34 & 127], n = o[r = r + 1 & 127], s ^= s << 13, n ^= n << 17, o[r] = (s ^= s >>> 15) ^ (n ^= n >>> 12);\n        }\n\n        e.w = i, e.X = o, e.i = r;\n      }(t, e);\n    }\n\n    function r(e, t) {\n      return t.i = e.i, t.w = e.w, t.X = e.X.slice(), t;\n    }\n\n    function a(e, t) {\n      null == e && (e = +new Date());\n\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (a.X && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.xor4096 = a;\n  }(0, e);\n}),\n    Fa = Na(function (e) {\n  !function (e, t, n) {\n    function s(e) {\n      var t = this,\n          n = \"\";\n      t.next = function () {\n        var e = t.b,\n            n = t.c,\n            s = t.d,\n            r = t.a;\n        return e = e << 25 ^ e >>> 7 ^ n, n = n - s | 0, s = s << 24 ^ s >>> 8 ^ r, r = r - e | 0, t.b = e = e << 20 ^ e >>> 12 ^ n, t.c = n = n - s | 0, t.d = s << 16 ^ n >>> 16 ^ r, t.a = r - e | 0;\n      }, t.a = 0, t.b = 0, t.c = -1640531527, t.d = 1367130551, e === Math.floor(e) ? (t.a = e / 4294967296 | 0, t.b = 0 | e) : n += e;\n\n      for (var s = 0; s < n.length + 20; s++) {\n        t.b ^= 0 | n.charCodeAt(s), t.next();\n      }\n    }\n\n    function r(e, t) {\n      return t.a = e.a, t.b = e.b, t.c = e.c, t.d = e.d, t;\n    }\n\n    function a(e, t) {\n      var n = new s(e),\n          a = t && t.state,\n          i = function i() {\n        return (n.next() >>> 0) / 4294967296;\n      };\n\n      return i.double = function () {\n        do {\n          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);\n        } while (0 === e);\n\n        return e;\n      }, i.int32 = n.next, i.quick = i, a && (\"object\" == typeof a && r(a, n), i.state = function () {\n        return r(n, {});\n      }), i;\n    }\n\n    t && t.exports ? t.exports = a : this.tychei = a;\n  }(0, e);\n}),\n    Da = {\n  __proto__: null,\n  default: {}\n},\n    _a = Na(function (e) {\n  !function (t, n) {\n    var s,\n        r = this,\n        a = 256,\n        i = n.pow(a, 6),\n        o = n.pow(2, 52),\n        l = 2 * o,\n        u = 255;\n\n    function c(e, u, c) {\n      var m = [],\n          b = f(p((u = 1 == u ? {\n        entropy: !0\n      } : u || {}).entropy ? [e, g(t)] : null == e ? function () {\n        try {\n          var e;\n          return s && (e = s.randomBytes) ? e = e(a) : (e = new Uint8Array(a), (r.crypto || r.msCrypto).getRandomValues(e)), g(e);\n        } catch (e) {\n          var n = r.navigator,\n              i = n && n.plugins;\n          return [+new Date(), r, i, r.screen, g(t)];\n        }\n      }() : e, 3), m),\n          x = new h(m),\n          y = function y() {\n        for (var e = x.g(6), t = i, n = 0; e < o;) {\n          e = (e + n) * a, t *= a, n = x.g(1);\n        }\n\n        for (; e >= l;) {\n          e /= 2, t /= 2, n >>>= 1;\n        }\n\n        return (e + n) / t;\n      };\n\n      return y.int32 = function () {\n        return 0 | x.g(4);\n      }, y.quick = function () {\n        return x.g(4) / 4294967296;\n      }, y.double = y, f(g(x.S), t), (u.pass || c || function (e, t, s, r) {\n        return r && (r.S && d(r, x), e.state = function () {\n          return d(x, {});\n        }), s ? (n.random = e, t) : e;\n      })(y, b, \"global\" in u ? u.global : this == n, u.state);\n    }\n\n    function h(e) {\n      var t,\n          n = e.length,\n          s = this,\n          r = 0,\n          i = s.i = s.j = 0,\n          o = s.S = [];\n\n      for (n || (e = [n++]); r < a;) {\n        o[r] = r++;\n      }\n\n      for (r = 0; r < a; r++) {\n        o[r] = o[i = u & i + e[r % n] + (t = o[r])], o[i] = t;\n      }\n\n      (s.g = function (e) {\n        for (var t, n = 0, r = s.i, i = s.j, o = s.S; e--;) {\n          t = o[r = u & r + 1], n = n * a + o[u & (o[r] = o[i = u & i + t]) + (o[i] = t)];\n        }\n\n        return s.i = r, s.j = i, n;\n      })(a);\n    }\n\n    function d(e, t) {\n      return t.i = e.i, t.j = e.j, t.S = e.S.slice(), t;\n    }\n\n    function p(e, t) {\n      var n,\n          s = [],\n          r = typeof e;\n      if (t && \"object\" == r) for (n in e) {\n        try {\n          s.push(p(e[n], t - 1));\n        } catch (e) {}\n      }\n      return s.length ? s : \"string\" == r ? e : e + \"\\0\";\n    }\n\n    function f(e, t) {\n      for (var n, s = e + \"\", r = 0; r < s.length;) {\n        t[u & r] = u & (n ^= 19 * t[u & r]) + s.charCodeAt(r++);\n      }\n\n      return g(t);\n    }\n\n    function g(e) {\n      return String.fromCharCode.apply(0, e);\n    }\n\n    if (n.seedrandom = c, f(n.random(), t), e.exports) {\n      e.exports = c;\n\n      try {\n        s = Da;\n      } catch (e) {}\n    }\n  }([], Math);\n});\n\n_a.alea = Ca, _a.xor128 = Ta, _a.xorwow = Ea, _a.xorshift7 = Ra, _a.xor4096 = Aa, _a.tychei = Fa;\nvar Oa = _a;\n\nclass Ma {\n  constructor(e, t, n, s, r) {\n    this.mean = e, this.stdDev = t, this.dtype = n, this.nextVal = NaN, this.truncated = s, this.truncated && (this.upper = this.mean + 2 * this.stdDev, this.lower = this.mean - 2 * this.stdDev);\n    var a = r || Math.random();\n    this.random = Oa.alea(a.toString());\n  }\n\n  nextValue() {\n    if (!isNaN(this.nextVal)) {\n      var _e57 = this.nextVal;\n      return this.nextVal = NaN, _e57;\n    }\n\n    var e,\n        t,\n        n = !1;\n\n    for (; !n;) {\n      var _s35 = void 0,\n          _r28 = void 0,\n          _a15 = void 0;\n\n      do {\n        _s35 = 2 * this.random() - 1, _r28 = 2 * this.random() - 1, _a15 = _s35 * _s35 + _r28 * _r28;\n      } while (_a15 >= 1 || 0 === _a15);\n\n      var _i11 = Math.sqrt(-2 * Math.log(_a15) / _a15);\n\n      e = this.mean + this.stdDev * _s35 * _i11, t = this.mean + this.stdDev * _r28 * _i11, this.truncated && !this.isValidTruncated(e) || (n = !0);\n    }\n\n    return this.truncated && !this.isValidTruncated(t) || (this.nextVal = this.convertValue(t)), this.convertValue(e);\n  }\n\n  convertValue(e) {\n    return null == this.dtype || \"float32\" === this.dtype ? e : Math.round(e);\n  }\n\n  isValidTruncated(e) {\n    return e <= this.upper && e >= this.lower;\n  }\n\n}\n\nclass La {\n  constructor() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    if (this.canReturnFloat = () => null == this.dtype || \"float32\" === this.dtype, this.min = e, this.range = t - e, this.dtype = n, null == s && (s = Math.random()), \"number\" == typeof s && (s = s.toString()), !this.canReturnFloat() && this.range <= 1) throw new Error(\"The difference between \".concat(e, \" - \").concat(t, \" <= 1 and dtype is not float\"));\n    this.random = Oa.alea(s);\n  }\n\n  convertValue(e) {\n    return this.canReturnFloat() ? e : Math.round(e);\n  }\n\n  nextValue() {\n    return this.convertValue(this.min + this.range * this.random());\n  }\n\n}\n\nvar za = Ft({\n  randomNormal_: function randomNormal_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    if (null != s && \"bool\" === s) throw new Error(\"Unsupported data type \".concat(s));\n    var a = new Ma(t, n, s, !1, r),\n        i = pn(e, s);\n\n    for (var _e58 = 0; _e58 < i.values.length; _e58++) {\n      i.values[_e58] = a.nextValue();\n    }\n\n    return i.toTensor();\n  }\n}),\n    Ba = Ft({\n  randomUniform_: function randomUniform_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    var a = pn(e, s),\n        i = new La(t, n, null, r);\n\n    for (var _e59 = 0; _e59 < a.values.length; _e59++) {\n      a.values[_e59] = i.nextValue();\n    }\n\n    return a.toTensor();\n  }\n});\n\nfunction Pa(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"float32\";\n  if (0 === n) throw new Error(\"Cannot have a step of zero\");\n  return vt.runKernel(\"Range\", {}, {\n    start: e,\n    stop: t,\n    step: n,\n    dtype: s\n  });\n}\n\nvar Wa = Ft({\n  real_: function real_(e) {\n    var t = Rt(e, \"input\", \"real\");\n    return vt.runKernel(\"Real\", {\n      input: t\n    });\n  }\n}),\n    Ua = Ft({\n  reciprocal_: function reciprocal_(e) {\n    var t = Rt(e, \"x\", \"reciprocal\");\n    return vt.runKernel(\"Reciprocal\", {\n      x: t\n    });\n  }\n}),\n    Va = Ft({\n  relu_: function relu_(e) {\n    var t = Rt(e, \"x\", \"relu\");\n    return vt.runKernel(\"Relu\", {\n      x: t\n    });\n  }\n}),\n    Ga = Ft({\n  relu6_: function relu6_(e) {\n    var t = Rt(e, \"x\", \"relu6\");\n    return vt.runKernel(\"Relu6\", {\n      x: t\n    });\n  }\n}),\n    Ha = Ft({\n  reverse_: function reverse_(e, t) {\n    var n = Rt(e, \"x\", \"reverse\");\n    return vt.runKernel(\"Reverse\", {\n      x: n\n    }, {\n      dims: t\n    });\n  }\n}),\n    qa = Ft({\n  round_: function round_(e) {\n    var t = Rt(e, \"x\", \"round\");\n    return vt.runKernel(\"Round\", {\n      x: t\n    });\n  }\n}),\n    ja = Ft({\n  rsqrt_: function rsqrt_(e) {\n    var t = Rt(e, \"x\", \"rsqrt\");\n    return vt.runKernel(\"Rsqrt\", {\n      x: t\n    });\n  }\n});\n\nfunction Ka(e, t) {\n  if (($(e) && \"string\" !== t || Array.isArray(e)) && \"complex64\" !== t) throw new Error(\"Error creating a new Scalar: value must be a primitive (number|boolean|string)\");\n  if (\"string\" === t && $(e) && !(e instanceof Uint8Array)) throw new Error(\"When making a scalar from encoded string, the value must be `Uint8Array`.\");\n  return _t(e, [], [], t);\n}\n\nvar Xa = Ft({\n  selu_: function selu_(e) {\n    var t = Rt(e, \"x\", \"selu\");\n    return vt.runKernel(\"Selu\", {\n      x: t\n    });\n  }\n}),\n    Ya = Ft({\n  separableConv2d_: function separableConv2d_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : \"NHWC\";\n    var o = Rt(e, \"x\", \"separableConv2d\"),\n        u = Rt(t, \"depthwiseFilter\", \"separableConv2d\"),\n        c = Rt(n, \"pointwiseFilter\", \"separableConv2d\");\n    var h = o,\n        d = !1;\n    if (3 === o.rank && (d = !0, h = Rs(o, [1, o.shape[0], o.shape[1], o.shape[2]])), \"NCHW\" === i) throw new Error(\"separableConv2d currently does not support dataFormat NCHW; only NHWC is supported\");\n    l(4 === h.rank, () => \"Error in separableConv2d: input must be rank 4, but got rank \".concat(h.rank, \".\")), l(4 === u.rank, () => \"Error in separableConv2d: depthwise filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(4 === c.rank, () => \"Error in separableConv2d: pointwise filter must be rank 4, but got rank \".concat(u.rank, \".\")), l(1 === c.shape[0], () => \"Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got \".concat(c.shape[0], \".\")), l(1 === c.shape[1], () => \"Error in separableConv2d: the second dimension of pointwise filter must be 1, but got \".concat(c.shape[1], \".\"));\n    var p = u.shape[2],\n        f = u.shape[3];\n    l(c.shape[2] === p * f, () => \"Error in separableConv2d: the third dimension of pointwise filter must be \".concat(p * f, \", but got \").concat(c.shape[2], \".\"));\n    var g = or(h, u, s, r, i, a),\n        m = Ys(g, c, 1, \"valid\", i);\n    return d ? Rs(m, [m.shape[1], m.shape[2], m.shape[3]]) : m;\n  }\n}),\n    Ja = Ft({\n  sign_: function sign_(e) {\n    var t = Rt(e, \"x\", \"sign\");\n    return vt.runKernel(\"Sign\", {\n      x: t\n    });\n  }\n}),\n    Za = Ft({\n  sin_: function sin_(e) {\n    var t = Rt(e, \"x\", \"sin\");\n    return vt.runKernel(\"Sin\", {\n      x: t\n    });\n  }\n}),\n    Qa = Ft({\n  sinh_: function sinh_(e) {\n    var t = Rt(e, \"x\", \"sinh\");\n    return vt.runKernel(\"Sinh\", {\n      x: t\n    });\n  }\n}),\n    ei = Ft({\n  slice1d_: function slice1d_(e, t, n) {\n    var s = Rt(e, \"x\", \"slice1d\");\n    return l(1 === s.rank, () => \"slice1d expects a rank-1 tensor, but got a rank-\".concat(s.rank, \" tensor\")), Os(s, [t], [n]);\n  }\n}),\n    ti = Ft({\n  slice2d_: function slice2d_(e, t, n) {\n    var s = Rt(e, \"x\", \"slice2d\");\n    return l(2 === s.rank, () => \"slice2d expects a rank-2 tensor, but got a rank-\".concat(s.rank, \" tensor\")), Os(s, t, n);\n  }\n}),\n    ni = Ft({\n  slice3d_: function slice3d_(e, t, n) {\n    var s = Rt(e, \"x\", \"slice3d\");\n    return l(3 === s.rank, () => \"slice3d expects a rank-3 tensor, but got a rank-\".concat(s.rank, \" tensor\")), Os(s, t, n);\n  }\n}),\n    si = Ft({\n  slice4d_: function slice4d_(e, t, n) {\n    var s = Rt(e, \"x\", \"slice4d\");\n    return l(4 === s.rank, () => \"slice4d expects a rank-4 tensor, but got a rank-\".concat(s.rank, \" tensor\")), Os(s, t, n);\n  }\n}),\n    ri = Ft({\n  softmax_: function softmax_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    var n = Rt(e, \"logits\", \"softmax\", \"float32\");\n    if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error(\"Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(n.rank, \" and dim was \").concat(t));\n    return vt.runKernel(\"Softmax\", {\n      logits: n\n    }, {\n      dim: t\n    });\n  }\n}),\n    ai = Ft({\n  fft_: function fft_(e) {\n    return l(\"complex64\" === e.dtype, () => \"The dtype for tf.spectral.fft() must be complex64 but got \".concat(e.dtype, \".\")), vt.runKernel(\"FFT\", {\n      input: e\n    });\n  }\n}),\n    ii = Ft({\n  ifft_: function ifft_(e) {\n    return l(\"complex64\" === e.dtype, () => \"The dtype for tf.spectral.ifft() must be complex64 but got \".concat(e.dtype, \".\")), vt.runKernel(\"IFFT\", {\n      input: e\n    });\n  }\n}),\n    oi = Ft({\n  irfft_: function irfft_(e) {\n    var t = e.shape[e.shape.length - 1],\n        n = e.size / t;\n    var s;\n\n    if (t <= 2) {\n      var _r29 = Rs(e, [n, t]);\n\n      s = ii(_r29);\n    } else {\n      var _r30 = [n, 2 * (t - 1)],\n          _a16 = Rs(Wa(e), [n, t]),\n          _i12 = Rs(Er(e), [n, t]),\n          _o10 = Ha(Os(_a16, [0, 1], [n, t - 2]), 1),\n          _l5 = rs(Ha(Os(_i12, [0, 1], [n, t - 2]), 1), Ka(-1)),\n          _u4 = Ds([_a16, _o10], 1),\n          _c3 = Ds([_i12, _l5], 1),\n          _h2 = Rs(Dt(_u4, _c3), [_r30[0], _r30[1]]);\n\n      s = ii(_h2);\n    }\n\n    if (s = Wa(s), 3 === e.rank && 0 !== e.shape[0]) {\n      var _t60 = s,\n          _n30 = e.shape[0];\n      s = Rs(s, [_n30, s.shape[0] / _n30, s.shape[1]]), _t60.dispose();\n    }\n\n    return s;\n  }\n}),\n    li = Ft({\n  split_: function split_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = Rt(e, \"x\", \"split\");\n    return vt.runKernel(\"SplitV\", {\n      x: s\n    }, {\n      numOrSizeSplits: t,\n      axis: n\n    });\n  }\n}),\n    ui = Ft({\n  rfft_: function rfft_(e, t) {\n    l(\"float32\" === e.dtype, () => \"The dtype for rfft() must be real value but got \".concat(e.dtype));\n    var n = e.shape[e.shape.length - 1];\n    var s = e.size / n;\n    var r;\n\n    if (null != t && t < n) {\n      var _s36 = e.shape.map(e => 0),\n          _a17 = e.shape.map(e => e);\n\n      _a17[e.shape.length - 1] = t, r = Os(e, _s36, _a17), n = t;\n    } else if (null != t && t > n) {\n      var _s37 = e.shape.map(e => e);\n\n      _s37[e.shape.length - 1] = t - n, r = Ds([e, ca(_s37)], e.shape.length - 1), n = t;\n    } else r = e;\n\n    var a = fr(r),\n        i = Rs(Dt(r, a), [s, n]),\n        o = ai(i),\n        u = Math.floor(n / 2) + 1,\n        c = Wa(o),\n        h = Er(o),\n        d = li(c, [u, n - u], c.shape.length - 1),\n        p = li(h, [u, n - u], h.shape.length - 1),\n        f = r.shape.slice();\n    return f[r.shape.length - 1] = u, Rs(Dt(d[0], p[0]), f);\n  }\n}),\n    ci = Ft({\n  sqrt_: function sqrt_(e) {\n    var t = Rt(e, \"x\", \"sqrt\");\n    return vt.runKernel(\"Sqrt\", {\n      x: t\n    });\n  }\n}),\n    hi = Ft({\n  squaredDifference_: function squaredDifference_(e, t) {\n    var n = Rt(e, \"a\", \"squaredDifference\"),\n        s = Rt(t, \"b\", \"squaredDifference\");\n    return [n, s] = gt(n, s), hr(n.shape, s.shape), vt.runKernel(\"SquaredDifference\", {\n      a: n,\n      b: s\n    }, {});\n  }\n}),\n    di = Ft({\n  squeeze_: function squeeze_(e, t) {\n    var n = Rt(e, \"x\", \"squeeze\");\n    return Rs(n, k(n.shape, t).newShape);\n  }\n}),\n    pi = Ft({\n  stack_: function stack_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = At(e, \"tensors\", \"stack\", \"string_or_numeric\");\n    return l(n.length >= 1, () => \"Pass at least one tensor to tf.stack\"), n.length > 0 && l(t <= n[0].rank, () => \"Axis must be <= rank of the tensor\"), vt.runKernel(\"Pack\", n, {\n      axis: t\n    });\n  }\n}),\n    fi = Ft({\n  step_: function step_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"step\");\n    return vt.runKernel(\"Step\", {\n      x: n\n    }, {\n      alpha: t\n    });\n  }\n}),\n    gi = Ft({\n  stridedSlice_: function stridedSlice_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;\n    var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 0;\n    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : 0;\n    var u = Rt(e, \"x\", \"stridedSlice\", \"string_or_numeric\");\n    return vt.runKernel(\"StridedSlice\", {\n      x: u\n    }, {\n      begin: t,\n      end: n,\n      strides: s,\n      beginMask: r,\n      endMask: a,\n      ellipsisMask: i,\n      newAxisMask: o,\n      shrinkAxisMask: l\n    });\n  }\n}),\n    mi = Ft({\n  tan_: function tan_(e) {\n    var t = Rt(e, \"x\", \"tan\");\n    return vt.runKernel(\"Tan\", {\n      x: t\n    });\n  }\n});\n\nfunction bi(e, t) {\n  c(e);\n  var n = Ct(e, t);\n  if (1 !== n.length) throw new Error(\"tensor1d() requires values to be a flat/TypedArray\");\n  return _t(e, null, n, t);\n}\n\nfunction xi(e, t, n) {\n  if (c(e), null != t && 2 !== t.length) throw new Error(\"tensor2d() requires shape to have two numbers\");\n  var s = Ct(e, n);\n  if (2 !== s.length && 1 !== s.length) throw new Error(\"tensor2d() requires values to be number[][] or flat/TypedArray\");\n  if (1 === s.length && null == t) throw new Error(\"tensor2d() requires shape to be provided when `values` are a flat/TypedArray\");\n  return _t(e, t, s, n);\n}\n\nvar yi = Ft({\n  topk_: function topk_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = Rt(e, \"x\", \"topk\");\n    if (0 === s.rank) throw new Error(\"topk() expects the input to be of rank 1 or higher\");\n    var r = s.shape[s.shape.length - 1];\n    if (t < 0) throw new Error(\"'k' passed to topk() must be >= 0 but got \".concat(t));\n    if (t > r) throw new Error(\"'k' passed to topk() must be <= the last dimension (\".concat(r, \") but got \").concat(t));\n    var a = {\n      x: s\n    },\n        i = {\n      k: t,\n      sorted: n\n    },\n        [o, l] = vt.runKernel(\"TopK\", a, i);\n    return {\n      values: o,\n      indices: l\n    };\n  }\n}),\n    ki = Ft({\n  truncatedNormal_: function truncatedNormal_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    if (null != s && \"bool\" === s) throw new Error(\"Unsupported data type $ { dtype }\");\n    var a = new Ma(t, n, s, !0, r),\n        i = pn(e, s);\n\n    for (var _e60 = 0; _e60 < i.values.length; _e60++) {\n      i.values[_e60] = a.nextValue();\n    }\n\n    return i.toTensor();\n  }\n}),\n    wi = Ft({\n  unique_: function unique_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"unique\", \"string_or_numeric\");\n    l(n.rank > 0, () => \"The input tensor must be at least 1D\");\n    var s = {\n      x: n\n    },\n        r = {\n      axis: t\n    },\n        [a, i] = vt.runKernel(\"Unique\", s, r);\n    return {\n      values: a,\n      indices: i\n    };\n  }\n}),\n    vi = Ft({\n  unsortedSegmentSum_: function unsortedSegmentSum_(e, t, n) {\n    var s = Rt(e, \"x\", \"unsortedSegmentSum\"),\n        r = Rt(t, \"segmentIds\", \"unsortedSegmentSum\", \"int32\");\n    return l(f(n), () => \"numSegments must be of dtype int\"), vt.runKernel(\"UnsortedSegmentSum\", {\n      x: s,\n      segmentIds: r\n    }, {\n      numSegments: n\n    });\n  }\n}),\n    Ii = Ft({\n  unstack_: function unstack_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    var n = Rt(e, \"x\", \"unstack\", \"string_or_numeric\");\n    return l(t >= -n.shape.length && t < n.shape.length, () => \"Axis = \".concat(t, \" is not in [-\").concat(n.shape.length, \", \").concat(n.shape.length, \")\")), vt.runKernel(\"Unpack\", {\n      value: n\n    }, {\n      axis: t\n    });\n  }\n});\n\nfunction $i(e, t) {\n  var n = [];\n\n  for (var _e61 = 0; _e61 < t.length; _e61++) {\n    t[_e61] && n.push(_e61);\n  }\n\n  var s = pn(e, \"int32\"),\n      r = pn([n.length, e.length], \"int32\");\n\n  for (var _t61 = 0; _t61 < n.length; _t61++) {\n    var _a18 = s.indexToLoc(n[_t61]);\n\n    r.values.set(_a18, _t61 * e.length);\n  }\n\n  return r.toTensor();\n}\n\nfunction Si(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  if (0 === e.rank) return as(e);\n  if (1 !== e.rank && null === n) return Si(Rs(e, [-1]), t, n);\n\n  if (1 === e.rank || \"number\" == typeof n || Array.isArray(n) && 1 === n.length) {\n    if (1 === t) return Hr(as(e), n);\n    if (Infinity === t) return Vr(as(e), n);\n    if (-Infinity === t) return da(as(e), n);\n    if (\"euclidean\" === t || 2 === t) return ci(Hr(Ia(as(e), Ka(2, \"int32\")), n));\n    throw new Error(\"Error in norm: invalid ord value: \".concat(t));\n  }\n\n  if (Array.isArray(n) && 2 === n.length) {\n    if (1 === t) return Vr(Hr(as(e), n[0]), n[1] - 1);\n    if (Infinity === t) return Vr(Hr(as(e), n[1]), n[0]);\n    if (-Infinity === t) return da(Hr(as(e), n[1]), n[0]);\n    if (\"fro\" === t || \"euclidean\" === t) return ci(Hr(ma(e), n));\n    throw new Error(\"Error in norm: invalid ord value: \".concat(t));\n  }\n\n  throw new Error(\"Error in norm: invalid axis: \".concat(n));\n}\n\nvar Ni = Ft({\n  norm_: function norm_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"euclidean\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Si(e = Rt(e, \"x\", \"norm\"), t, n);\n    var a = r.shape;\n\n    if (s) {\n      var _t62 = y(n, e.shape);\n\n      a = Yr(r.shape, _t62);\n    }\n\n    return Rs(r, a);\n  }\n}),\n    Ci = Ft({\n  dropout_: function dropout_(e, t, n, s) {\n    var r = Rt(e, \"x\", \"dropout\");\n    if (l(\"float32\" === r.dtype, () => \"x has to be a floating point tensor since it's going to be scaled, but got a \".concat(r.dtype, \" tensor instead.\")), l(t >= 0 && t < 1, () => \"rate must be a float in the range [0, 1), but got \".concat(t, \".\")), 0 === t) return e instanceof rt ? r.clone() : r;\n\n    var a = function (e, t) {\n      if (null == t) return e.shape.slice();\n      if (p(e.shape, t)) return t;\n\n      if (e.shape.length === t.length) {\n        var _n31 = [];\n\n        for (var _s38 = 0; _s38 < e.shape.length; _s38++) {\n          _n31.push(null == t[_s38] && null != e.shape[_s38] ? e.shape[_s38] : t[_s38]);\n        }\n\n        return _n31;\n      }\n\n      return t;\n    }(r, n),\n        i = 1 - t,\n        o = ss(Sr(ts(Ba(a, 0, 1, \"float32\", s), i)), i);\n\n    return rs(r, o);\n  }\n});\n\nfunction Ti(e, t, n) {\n  var s = 1 - e % 2,\n      r = new Float32Array(e);\n\n  for (var _a19 = 0; _a19 < e; ++_a19) {\n    var _i13 = 2 * Math.PI * _a19 / (e + s - 1);\n\n    r[_a19] = t - n * Math.cos(_i13);\n  }\n\n  return bi(r, \"float32\");\n}\n\nvar Ei = Ft({\n  conv2DBackpropFilter_: function conv2DBackpropFilter_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : \"NHWC\";\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = e;\n    3 === e.rank && (o = Rs(e, [1, e.shape[0], e.shape[1], e.shape[2]]));\n    var u = t;\n    3 === u.rank && (u = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2]])), l(4 === o.rank, () => \"Error in conv2dDerFilter: input must be rank 4, but got shape \".concat(o.shape, \".\")), l(4 === u.rank, () => \"Error in conv2dDerFilter: dy must be rank 4, but got shape \".concat(u.shape, \".\")), l(4 === n.length, () => \"Error in conv2dDerFilter: filterShape must be length 4, but got \".concat(n, \".\"));\n    var c = \"NHWC\" === a ? o.shape[3] : o.shape[1],\n        h = \"NHWC\" === a ? u.shape[3] : u.shape[1];\n    return l(c === n[2], () => \"Error in conv2dDerFilter: depth of input \".concat(c, \") must match input depth in filter (\").concat(n[2], \".\")), l(h === n[3], () => \"Error in conv2dDerFilter: depth of dy (\".concat(h, \") must match output depth for filter (\").concat(n[3], \").\")), null != i && l(f(r), () => \"Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(r, \".\")), vt.runKernel(\"Conv2DBackpropFilter\", {\n      x: o,\n      dy: u\n    }, {\n      strides: s,\n      pad: r,\n      dataFormat: a,\n      dimRoundingMode: i,\n      filterShape: n\n    });\n  }\n});\n\nfunction Ri(e, t, n) {\n  if (null == n || \"linear\" === n) return e;\n  if (\"relu\" === n) return rs(e, fi(t));\n  throw new Error(\"Cannot compute gradient for fused activation \".concat(n, \".\"));\n}\n\nfunction Ai(e, t) {\n  var n = t;\n  var s = cr(e.shape, t.shape);\n  return s.length > 0 && (n = Hr(n, s)), Rs(n, e.shape);\n}\n\nfunction Fi(e, t, n, s) {\n  if (\"linear\" === t) return e;\n  if (\"relu\" === t) return Va(e);\n  if (\"elu\" === t) return br(e);\n  if (\"relu6\" === t) return Ga(e);\n  if (\"prelu\" === t) return $a(e, n);\n  if (\"leakyrelu\" === t) return Dr(e, s);\n  if (\"sigmoid\" === t) return _s(e);\n  throw new Error(\"Unknown fused activation \".concat(t, \".\"));\n}\n\nvar Di = (e, t) => !(e > 0) || \"linear\" === t,\n    _i = Ft({\n  fusedConv2d_: function fusedConv2d_(_ref3) {\n    var {\n      x: e,\n      filter: t,\n      strides: n,\n      pad: s,\n      dataFormat: r = \"NHWC\",\n      dilations: a = [1, 1],\n      dimRoundingMode: i,\n      bias: o,\n      activation: u = \"linear\",\n      preluActivationWeights: c,\n      leakyreluAlpha: h\n    } = _ref3;\n\n    if (!1 === Di(vt.state.gradientDepth, u = u || \"linear\")) {\n      var _l6 = Ys(e, t, n, s, r, a, i);\n\n      return null != o && (_l6 = ts(_l6, o)), Fi(_l6, u, c, h);\n    }\n\n    var d = Rt(e, \"x\", \"conv2d\"),\n        p = Rt(t, \"filter\", \"conv2d\");\n    var g = d,\n        m = !1;\n    3 === d.rank && (m = !0, g = Rs(d, [1, d.shape[0], d.shape[1], d.shape[2]])), l(4 === g.rank, () => \"Error in fused conv2d: input must be rank 4, but got rank \".concat(g.rank, \".\")), l(4 === p.rank, () => \"Error in fused conv2d: filter must be rank 4, but got rank \".concat(p.rank, \".\")), null != i && l(f(s), () => \"Error in fused conv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(s, \".\")), l(g.shape[3] === p.shape[2], () => \"Error in conv2d: depth of input (\".concat(g.shape[3], \") must match input depth for filter \").concat(p.shape[2], \".\")), l(Ts(n, a), () => \"Error in conv2D: Either strides or dilations must be 1. Got strides \".concat(n, \" and dilations '\").concat(a, \"'\")), l(\"NHWC\" === r, () => \"Error in conv2d: got dataFormat of \".concat(r, \" but only NHWC is currently supported.\"));\n    var b = ks(g.shape, p.shape, n, a, s, i);\n    var x, y;\n    null != o && (x = Rt(o, \"bias\", \"fused conv2d\"), [x] = gt(x, d), hr(b.outShape, x.shape)), null != c && (y = Rt(c, \"prelu weights\", \"fused conv2d\"));\n\n    var k = (e, t) => {\n      var [r, i, o, c] = t,\n          h = Ri(e, o, u);\n      l(Cs(a), () => \"Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(a, \"'\"));\n      var d = [Zs(i.shape, h, r, n, s), Ei(i, h, r.shape, n, s)];\n\n      if (null != c) {\n        var _e62 = Ai(c, h);\n\n        d.push(_e62);\n      }\n\n      return d;\n    },\n        w = {\n      x: g,\n      filter: p,\n      bias: x,\n      preluActivationWeights: y\n    },\n        v = {\n      strides: n,\n      pad: s,\n      dataFormat: r,\n      dilations: a,\n      dimRoundingMode: i,\n      activation: u,\n      leakyreluAlpha: h\n    };\n\n    return null == o ? Br((e, t, n) => {\n      var s = vt.runKernel(\"FusedConv2D\", w, v);\n      return n([t, e, s]), m && (s = Rs(s, [s.shape[1], s.shape[2], s.shape[3]])), {\n        value: s,\n        gradFunc: k\n      };\n    })(g, p) : Br((e, t, n, s) => {\n      var r = vt.runKernel(\"FusedConv2D\", w, v);\n      return s([t, e, r, n]), m && (r = Rs(r, [r.shape[1], r.shape[2], r.shape[3]])), {\n        value: r,\n        gradFunc: k\n      };\n    })(g, p, x);\n  }\n}),\n    Oi = Ft({\n  depthwiseConv2dNativeBackpropFilter_: function depthwiseConv2dNativeBackpropFilter_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = e;\n    3 === e.rank && (o = Rs(e, [1, e.shape[0], e.shape[1], e.shape[2]]));\n    var l = t;\n    return 3 === l.rank && (l = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2]])), vt.runKernel(\"DepthwiseConv2dNativeBackpropFilter\", {\n      x: o,\n      dy: l\n    }, {\n      strides: s,\n      pad: r,\n      dimRoundingMode: i,\n      dilations: a,\n      filterShape: n\n    });\n  }\n}),\n    Mi = Ft({\n  depthwiseConv2dNativeBackpropInput_: function depthwiseConv2dNativeBackpropInput_(e, t, n, s, r) {\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n    var i = arguments.length > 6 ? arguments[6] : undefined;\n    var o = t,\n        l = !1;\n    3 === t.rank && (l = !0, o = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2]]));\n    var u = vt.runKernel(\"DepthwiseConv2dNativeBackpropInput\", {\n      dy: o,\n      filter: n\n    }, {\n      strides: s,\n      pad: r,\n      dimRoundingMode: i,\n      dilations: a,\n      inputShape: e\n    });\n    return l ? Rs(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;\n  }\n}),\n    Li = Ft({\n  fusedMatMul_: function fusedMatMul_(_ref4) {\n    var {\n      a: e,\n      b: t,\n      transposeA: n = !1,\n      transposeB: s = !1,\n      bias: r,\n      activation: a = \"linear\",\n      preluActivationWeights: i,\n      leakyreluAlpha: o\n    } = _ref4;\n\n    if (!1 === Di(vt.state.gradientDepth, a)) {\n      var _l7 = In(e, t, n, s);\n\n      return null != r && (_l7 = ts(_l7, r)), Fi(_l7, a, i, o);\n    }\n\n    var u = Rt(e, \"a\", \"fused matMul\"),\n        c = Rt(t, \"b\", \"fused matMul\");\n    [u, c] = gt(u, c);\n    var h = n ? u.shape[u.rank - 2] : u.shape[u.rank - 1],\n        f = s ? c.shape[c.rank - 1] : c.shape[c.rank - 2],\n        g = n ? u.shape[u.rank - 1] : u.shape[u.rank - 2],\n        m = s ? c.shape[c.rank - 2] : c.shape[c.rank - 1],\n        b = u.shape.slice(0, -2),\n        x = c.shape.slice(0, -2),\n        y = d(b),\n        k = d(x);\n    l(u.rank >= 2 && c.rank >= 2 && u.rank === c.rank, () => \"Error in fused matMul: inputs must have the same rank of at least 2, got ranks \".concat(u.rank, \" and \").concat(c.rank, \".\")), l(p(b, x), () => \"Error in fused matMul: outer dimensions (\".concat(b, \") and (\").concat(x, \") of Tensors with shapes \").concat(u.shape, \" and \").concat(c.shape, \" must match.\")), l(h === f, () => \"Error in fused matMul: inner shapes (\".concat(h, \") and (\").concat(f, \") of Tensors with shapes \").concat(u.shape, \" and \").concat(c.shape, \" and transposeA=\").concat(n, \" and transposeB=\").concat(s, \" must match.\"));\n    var w = u.shape.slice(0, -2).concat([g, m]),\n        v = Rs(u, n ? [y, h, g] : [y, g, h]),\n        I = Rs(c, s ? [k, m, f] : [k, f, m]);\n    var $, S;\n    null != r && ($ = Rt(r, \"bias\", \"fused matMul\"), [$] = gt($, u), hr(w, $.shape)), null != i && (S = Rt(i, \"prelu weights\", \"fused matMul\"));\n\n    var N = (e, t) => {\n      var [i, o, l, u] = t,\n          c = Ri(Rs(e, l.shape), l, a);\n      var h, d;\n      return n || s ? !n && s ? (h = In(c, o, !1, !1), d = In(c, i, !0, !1)) : n && !s ? (h = In(o, c, !1, !0), d = In(i, c, !1, !1)) : (h = In(o, c, !0, !0), d = In(c, i, !0, !0)) : (h = In(c, o, !1, !0), d = In(i, c, !0, !1)), null != r ? [h, d, Ai(u, c)] : [h, d];\n    },\n        C = {\n      a: v,\n      b: I,\n      bias: $,\n      preluActivationWeights: S\n    },\n        T = {\n      transposeA: n,\n      transposeB: s,\n      activation: a,\n      leakyreluAlpha: o\n    };\n\n    return null == r ? Br((e, t, n) => {\n      var s = vt.runKernel(\"_FusedMatMul\", C, T);\n      return n([e, t, s]), {\n        value: Rs(s, w),\n        gradFunc: N\n      };\n    })(v, I) : Br((e, t, n, s) => {\n      var r = vt.runKernel(\"_FusedMatMul\", C, T);\n      return s([e, t, r, n]), {\n        value: Rs(r, w),\n        gradFunc: N\n      };\n    })(v, I, $);\n  }\n});\n\nFt({\n  hammingWindow_: function hammingWindow_(e) {\n    return Ti(e, .54, .46);\n  }\n});\nvar zi = Ft({\n  hannWindow_: function hannWindow_(e) {\n    return Ti(e, .5, .5);\n  }\n}),\n    Bi = Ft({\n  frame_: function frame_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = 0;\n    var i = [];\n\n    for (; a + t <= e.size;) {\n      i.push(Os(e, a, t)), a += n;\n    }\n\n    if (s) for (; a < e.size;) {\n      var _s39 = a + t - e.size,\n          _o11 = Ds([Os(e, a, t - _s39), $r([_s39], r)]);\n\n      i.push(_o11), a += n;\n    }\n    return 0 === i.length ? xi([], [0, t]) : Rs(Ds(i), [i.length, t]);\n  }\n});\nFt({\n  stft_: function stft_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : zi;\n    null == s && (s = Math.floor(Math.pow(2, Math.ceil(Math.log(t) / Math.log(2)))));\n    var a = Bi(e, t, n),\n        i = rs(a, r(t));\n    return ui(i, s);\n  }\n});\nvar Pi = Ft({\n  cropAndResize_: function cropAndResize_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"bilinear\";\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = Rt(e, \"image\", \"cropAndResize\"),\n        o = Rt(t, \"boxes\", \"cropAndResize\", \"float32\"),\n        u = Rt(n, \"boxInd\", \"cropAndResize\", \"int32\"),\n        c = o.shape[0];\n    return l(4 === i.rank, () => \"Error in cropAndResize: image must be rank 4,but got rank \".concat(i.rank, \".\")), l(2 === o.rank && 4 === o.shape[1], () => \"Error in cropAndResize: boxes must be have size [\".concat(c, \",4] but had shape \").concat(o.shape, \".\")), l(1 === u.rank && u.shape[0] === c, () => \"Error in cropAndResize: boxInd must be have size [\".concat(c, \"] but had shape \").concat(o.shape, \".\")), l(2 === s.length, () => \"Error in cropAndResize: cropSize must be of length 2, but got length \".concat(s.length, \".\")), l(s[0] >= 1 && s[1] >= 1, () => \"cropSize must be atleast [1,1], but was \".concat(s)), l(\"bilinear\" === r || \"nearest\" === r, () => \"method must be bilinear or nearest, but was \".concat(r)), vt.runKernel(\"CropAndResize\", {\n      image: i,\n      boxes: o,\n      boxInd: u\n    }, {\n      method: r,\n      extrapolationValue: a,\n      cropSize: s\n    });\n  }\n}),\n    Wi = Ft({\n  flipLeftRight_: function flipLeftRight_(e) {\n    var t = Rt(e, \"image\", \"flipLeftRight\", \"float32\");\n    return l(4 === t.rank, () => \"Error in flipLeftRight: image must be rank 4,but got rank \".concat(t.rank, \".\")), vt.runKernel(\"FlipLeftRight\", {\n      image: t\n    }, {});\n  }\n}),\n    Ui = Ft({\n  grayscaleToRGB_: function grayscaleToRGB_(e) {\n    var t = Rt(e, \"image\", \"grayscaleToRGB\"),\n        n = t.rank - 1,\n        s = t.shape[n];\n    l(t.rank >= 2, () => \"Error in grayscaleToRGB: images must be at least rank 2, but got rank \".concat(t.rank, \".\")), l(1 === s, () => \"Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size \".concat(s, \".\"));\n    var r = new Array(t.rank);\n    return r.fill(1, 0, n), r[n] = 3, vr(t, r);\n  }\n}),\n    Vi = Ft({\n  rotateWithOffset_: function rotateWithOffset_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = Rt(e, \"image\", \"rotateWithOffset\", \"float32\");\n    return l(4 === r.rank, () => \"Error in rotateWithOffset: image must be rank 4,but got rank \".concat(r.rank, \".\")), vt.runKernel(\"RotateWithOffset\", {\n      image: r\n    }, {\n      radians: t,\n      fillValue: n,\n      center: s\n    });\n  }\n});\n\nfunction Gi(e, t, n, s, r, a) {\n  null == s && (s = .5), null == r && (r = Number.NEGATIVE_INFINITY), null == a && (a = 0);\n  var i = e.shape[0];\n  return n = Math.min(n, i), l(0 <= s && s <= 1, () => \"iouThreshold must be in [0, 1], but was '\".concat(s, \"'\")), l(2 === e.rank, () => \"boxes must be a 2D tensor, but was of rank '\".concat(e.rank, \"'\")), l(4 === e.shape[1], () => \"boxes must have 4 columns, but 2nd dimension was \".concat(e.shape[1])), l(1 === t.rank, () => \"scores must be a 1D tensor\"), l(t.shape[0] === i, () => \"scores has incompatible shape with boxes. Expected \".concat(i, \", but was \").concat(t.shape[0])), l(0 <= a && a <= 1, () => \"softNmsSigma must be in [0, 1], but was '\".concat(a, \"'\")), {\n    maxOutputSize: n,\n    iouThreshold: s,\n    scoreThreshold: r,\n    softNmsSigma: a\n  };\n}\n\nvar Hi = Ft({\n  nonMaxSuppression_: function nonMaxSuppression_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = Rt(e, \"boxes\", \"nonMaxSuppression\"),\n        i = Rt(t, \"scores\", \"nonMaxSuppression\"),\n        o = Gi(a, i, n, s, r);\n    return vt.runKernel(\"NonMaxSuppressionV3\", {\n      boxes: a,\n      scores: i\n    }, {\n      maxOutputSize: n = o.maxOutputSize,\n      iouThreshold: s = o.iouThreshold,\n      scoreThreshold: r = o.scoreThreshold\n    });\n  }\n});\n\nfunction qi(e, t, n) {\n  var s = function (e, t, n) {\n    return function (e, t, n) {\n      var s = 0,\n          r = e.length,\n          a = 0,\n          i = !1;\n\n      for (; s < r;) {\n        a = s + (r - s >>> 1);\n\n        var _o12 = n(t, e[a]);\n\n        _o12 > 0 ? s = a + 1 : (r = a, i = !_o12);\n      }\n\n      return i ? s : -s - 1;\n    }(e, t, n || ji);\n  }(e, t, n);\n\n  e.splice(s < 0 ? -(s + 1) : s, 0, t);\n}\n\nfunction ji(e, t) {\n  return e > t ? 1 : e < t ? -1 : 0;\n}\n\nfunction Ki(e, t, n, s, r) {\n  return Ji(e, t, n, s, r, 0);\n}\n\nfunction Xi(e, t, n, s, r, a) {\n  return Ji(e, t, n, s, r, 0, !1, a, !0);\n}\n\nfunction Yi(e, t, n, s, r, a) {\n  return Ji(e, t, n, s, r, a, !0);\n}\n\nfunction Ji(e, t, n, s, r, a) {\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;\n  var u = [];\n\n  for (var _e63 = 0; _e63 < t.length; _e63++) {\n    t[_e63] > r && u.push({\n      score: t[_e63],\n      boxIndex: _e63,\n      suppressBeginIndex: 0\n    });\n  }\n\n  u.sort(eo);\n  var c = a > 0 ? -.5 / a : 0,\n      h = [],\n      d = [];\n\n  for (; h.length < n && u.length > 0;) {\n    var _t63 = u.pop(),\n        {\n      score: _n32,\n      boxIndex: _a20,\n      suppressBeginIndex: _i14\n    } = _t63;\n\n    if (_n32 < r) break;\n\n    var _o13 = !1;\n\n    for (var _n33 = h.length - 1; _n33 >= _i14; --_n33) {\n      var _i15 = Zi(e, _a20, h[_n33]);\n\n      if (_i15 >= s) {\n        _o13 = !0;\n        break;\n      }\n\n      if (_t63.score = _t63.score * Qi(s, c, _i15), _t63.score <= r) break;\n    }\n\n    _t63.suppressBeginIndex = h.length, _o13 || (_t63.score === _n32 ? (h.push(_a20), d.push(_t63.score)) : _t63.score > r && qi(u, _t63, eo));\n  }\n\n  var p = h.length,\n      f = n - p;\n  o && f > 0 && (h.push(...new Array(f).fill(0)), d.push(...new Array(f).fill(0)));\n  var g = {\n    selectedIndices: h\n  };\n  return i && (g.selectedScores = d), l && (g.validOutputs = p), g;\n}\n\nfunction Zi(e, t, n) {\n  var s = e.subarray(4 * t, 4 * t + 4),\n      r = e.subarray(4 * n, 4 * n + 4),\n      a = Math.min(s[0], s[2]),\n      i = Math.min(s[1], s[3]),\n      o = Math.max(s[0], s[2]),\n      l = Math.max(s[1], s[3]),\n      u = Math.min(r[0], r[2]),\n      c = Math.min(r[1], r[3]),\n      h = Math.max(r[0], r[2]),\n      d = Math.max(r[1], r[3]),\n      p = (o - a) * (l - i),\n      f = (h - u) * (d - c);\n  if (p <= 0 || f <= 0) return 0;\n  var g = Math.max(a, u),\n      m = Math.max(i, c),\n      b = Math.min(o, h),\n      x = Math.min(l, d),\n      y = Math.max(b - g, 0) * Math.max(x - m, 0);\n  return y / (p + f - y);\n}\n\nfunction Qi(e, t, n) {\n  var s = Math.exp(t * n * n);\n  return n <= e ? s : 0;\n}\n\nfunction eo(e, t) {\n  return e.score - t.score || e.score === t.score && t.boxIndex - e.boxIndex;\n}\n\nvar to = Ft({\n  nonMaxSuppressionWithScore_: function nonMaxSuppressionWithScore_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n    var i = Rt(e, \"boxes\", \"nonMaxSuppression\"),\n        o = Rt(t, \"scores\", \"nonMaxSuppression\"),\n        l = Gi(i, o, n, s, r, a),\n        u = vt.runKernel(\"NonMaxSuppressionV5\", {\n      boxes: i,\n      scores: o\n    }, {\n      maxOutputSize: n = l.maxOutputSize,\n      iouThreshold: s = l.iouThreshold,\n      scoreThreshold: r = l.scoreThreshold,\n      softNmsSigma: a = l.softNmsSigma\n    });\n    return {\n      selectedIndices: u[0],\n      selectedScores: u[1]\n    };\n  }\n}),\n    no = Ft({\n  nonMaxSuppressionPadded_: function nonMaxSuppressionPadded_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n    var i = Rt(e, \"boxes\", \"nonMaxSuppression\"),\n        o = Rt(t, \"scores\", \"nonMaxSuppression\"),\n        l = Gi(i, o, n, s, r, null),\n        u = vt.runKernel(\"NonMaxSuppressionV4\", {\n      boxes: i,\n      scores: o\n    }, {\n      maxOutputSize: l.maxOutputSize,\n      iouThreshold: l.iouThreshold,\n      scoreThreshold: l.scoreThreshold,\n      padToMaxOutputSize: a\n    });\n    return {\n      selectedIndices: u[0],\n      validOutputs: u[1]\n    };\n  }\n}),\n    so = Ft({\n  resizeBilinear_: function resizeBilinear_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Rt(e, \"images\", \"resizeBilinear\");\n    l(3 === r.rank || 4 === r.rank, () => \"Error in resizeBilinear: x must be rank 3 or 4, but got rank \".concat(r.rank, \".\")), l(2 === t.length, () => \"Error in resizeBilinear: new shape must 2D, but got shape \".concat(t, \".\")), l(!1 === s || !1 === n, () => \"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.\");\n    var a = r,\n        i = !1;\n    3 === r.rank && (i = !0, a = Rs(r, [1, r.shape[0], r.shape[1], r.shape[2]]));\n    var o = vt.runKernel(\"ResizeBilinear\", {\n      images: a\n    }, {\n      alignCorners: n,\n      halfPixelCenters: s,\n      size: t\n    });\n    return i ? Rs(o, [o.shape[1], o.shape[2], o.shape[3]]) : o;\n  }\n}),\n    ro = Ft({\n  resizeNearestNeighbor_: function resizeNearestNeighbor_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = Rt(e, \"images\", \"resizeNearestNeighbor\");\n    l(3 === r.rank || 4 === r.rank, () => \"Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank \".concat(r.rank, \".\")), l(2 === t.length, () => \"Error in resizeNearestNeighbor: new shape must 2D, but got shape \".concat(t, \".\")), l(\"float32\" === r.dtype || \"int32\" === r.dtype, () => \"`images` must have `int32` or `float32` as dtype\"), l(!1 === s || !1 === n, () => \"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.\");\n    var a = r,\n        i = !1;\n    3 === r.rank && (i = !0, a = Rs(r, [1, r.shape[0], r.shape[1], r.shape[2]]));\n    var o = vt.runKernel(\"ResizeNearestNeighbor\", {\n      images: a\n    }, {\n      alignCorners: n,\n      halfPixelCenters: s,\n      size: t\n    });\n    return i ? Rs(o, [o.shape[1], o.shape[2], o.shape[3]]) : o;\n  }\n}),\n    ao = Ft({\n  threshold_: function threshold_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"binary\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n    var r = Rt(e, \"image\", \"threshold\"),\n        a = r.shape[0] * r.shape[1];\n    var i,\n        o,\n        u,\n        c,\n        h = rs(bi([s]), 255);\n\n    if (l(3 === r.rank, () => \"Error in threshold: image must be rank 3,but got rank \".concat(r.rank, \".\")), l(3 === r.shape[2] || 1 === r.shape[2], () => \"Error in threshold: image color channel must be equal to 3 or 1but got \".concat(r.shape[2], \".\")), l(\"int32\" === r.dtype || \"float32\" === r.dtype, () => \"Error in dtype: image dtype must be int32 or float32,but got dtype \".concat(r.dtype, \".\")), l(\"otsu\" === t || \"binary\" === t, () => \"Method must be binary or otsu, but was \".concat(t)), 3 === r.shape[2]) {\n      [i, o, u] = li(r, [1, 1, 1], -1);\n\n      var _e64 = rs(i, .2989),\n          _t64 = rs(o, .587),\n          _n34 = rs(u, .114);\n\n      c = ts(ts(_e64, _t64), _n34);\n    } else c = e;\n\n    \"otsu\" === t && (h = function (e, t) {\n      var n,\n          s,\n          r,\n          a,\n          i,\n          o,\n          l = bi([-1]),\n          u = bi([0]),\n          c = bi([0]);\n\n      for (var _h3 = 0; _h3 < e.size - 1; _h3++) {\n        n = Os(e, 0, _h3 + 1), s = Os(e, _h3 + 1), i = ss(Hr(n), t), o = ss(Hr(s), t);\n\n        var _d4 = Hr(rs(n, Pa(0, n.size)));\n\n        r = ss(_d4, Hr(n));\n\n        var _p4 = $r(s.shape, n.size),\n            _f3 = ts(Pa(0, s.size), _p4),\n            _g4 = rs(s, _f3);\n\n        a = ss(Hr(_g4), Hr(s));\n\n        var _m3 = Gr(r, a),\n            _b3 = Gr(r, a),\n            _x9 = rs(i, o);\n\n        c = rs(rs(_x9, _m3), _b3);\n\n        var _y3 = Cr(c, u);\n\n        u = pr(_y3, c, u), l = pr(_y3, bi([_h3]), l);\n      }\n\n      return l;\n    }(Us(fn(qa(c), \"int32\"), Ot([]), 256), a));\n    var d = n ? Or(c, h) : Cr(c, h);\n    return fn(rs(d, 255), \"int32\");\n  }\n}),\n    io = Ft({\n  transform_: function transform_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"nearest\";\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"constant\";\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    var a = arguments.length > 5 ? arguments[5] : undefined;\n    var i = Rt(e, \"image\", \"transform\", \"float32\"),\n        o = Rt(t, \"transforms\", \"transform\", \"float32\");\n    return l(4 === i.rank, () => \"Error in transform: image must be rank 4,but got rank \".concat(i.rank, \".\")), l(2 === o.rank && (o.shape[0] === i.shape[0] || 1 === o.shape[0]) && 8 === o.shape[1], () => \"Error in transform: Input transform should be batch x 8 or 1 x 8\"), l(null == a || 2 === a.length, () => \"Error in transform: outputShape must be [height, width] or null, but got \".concat(a, \".\")), vt.runKernel(\"Transform\", {\n      image: i,\n      transforms: o\n    }, {\n      interpolation: n,\n      fillMode: s,\n      fillValue: r,\n      outputShape: a\n    });\n  }\n}),\n    oo = Ft({\n  bandPart_: function bandPart_(e, t, n) {\n    l(t % 1 == 0, () => \"bandPart(): numLower must be an integer, got \".concat(t, \".\")), l(n % 1 == 0, () => \"bandPart(): numUpper must be an integer, got \".concat(n, \".\"));\n    var s = Rt(e, \"a\", \"bandPart\");\n    l(s.rank >= 2, () => \"bandPart(): Rank must be at least 2, got \".concat(s.rank, \".\"));\n    var r = s.shape,\n        [a, i] = s.shape.slice(-2);\n    if (!(t <= a)) throw new Error(\"bandPart(): numLower (\".concat(t, \") must not be greater than the number of rows (\").concat(a, \").\"));\n    if (!(n <= i)) throw new Error(\"bandPart(): numUpper (\".concat(n, \") must not be greater than the number of columns (\").concat(i, \").\"));\n    t < 0 && (t = a), n < 0 && (n = i);\n    var o = Rs(Pa(0, a, 1, \"int32\"), [-1, 1]),\n        u = Pa(0, i, 1, \"int32\"),\n        c = Gr(o, u),\n        h = na(Or(c, Ka(+t, \"int32\")), Tr(c, Ka(-n, \"int32\"))),\n        d = ca([a, i], s.dtype);\n    return Rs(pi(Ii(Rs(s, [-1, a, i])).map(e => pr(h, e, d))), r);\n  }\n}),\n    lo = Ft({\n  gramSchmidt_: function gramSchmidt_(e) {\n    var t;\n\n    if (Array.isArray(e)) {\n      (function () {\n        t = !1, l(null != e && e.length > 0, () => \"Gram-Schmidt process: input must not be null, undefined, or empty\");\n        var n = e[0].shape[0];\n\n        var _loop6 = function _loop6(_t65) {\n          l(e[_t65].shape[0] === n, () => \"Gram-Schmidt: Non-unique lengths found in the input vectors: (\".concat(e[_t65].shape[0], \" vs. \").concat(n, \")\"));\n        };\n\n        for (var _t65 = 1; _t65 < e.length; ++_t65) {\n          _loop6(_t65);\n        }\n      })();\n    } else t = !0, e = li(e, e.shape[0], 0).map(e => di(e, [0]));\n\n    l(e.length <= e[0].shape[0], () => \"Gram-Schmidt: Number of vectors (\".concat(e.length, \") exceeds number of dimensions (\").concat(e[0].shape[0], \").\"));\n    var n = [],\n        s = e;\n\n    var _loop7 = function _loop7(_t66) {\n      n.push(vt.tidy(() => {\n        var e = s[_t66];\n        if (_t66 > 0) for (var _s40 = 0; _s40 < _t66; ++_s40) {\n          var _t67 = rs(Hr(rs(n[_s40], e)), n[_s40]);\n\n          e = Gr(e, _t67);\n        }\n        return ss(e, Ni(e, \"euclidean\"));\n      }));\n    };\n\n    for (var _t66 = 0; _t66 < e.length; ++_t66) {\n      _loop7(_t66);\n    }\n\n    return t ? pi(n, 0) : n;\n  }\n});\n\nfunction uo(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  return vt.tidy(() => {\n    l(2 === e.shape.length, () => \"qr2d() requires a 2D Tensor, but got a \".concat(e.shape.length, \"D Tensor.\"));\n    var n = e.shape[0],\n        s = e.shape[1];\n    var r = Ir(n),\n        a = gn(e);\n    var i = xi([[1]], [1, 1]);\n    var o = gn(i);\n    var u = n >= s ? s : n;\n\n    var _loop8 = function _loop8(_e65) {\n      var t = a,\n          l = o,\n          u = r;\n      [o, a, r] = vt.tidy(() => {\n        var t = Os(a, [_e65, _e65], [n - _e65, 1]),\n            l = Ni(t),\n            u = Os(a, [_e65, _e65], [1, 1]),\n            c = pr(Cr(u, 0), xi([[-1]]), xi([[1]])),\n            h = Gr(u, rs(c, l)),\n            d = ss(t, h);\n        o = 1 === d.shape[0] ? gn(i) : Ds([i, Os(d, [1, 0], [d.shape[0] - 1, d.shape[1]])], 0);\n        var p = Pr(ss(In(c, h), l)),\n            f = Os(a, [_e65, 0], [n - _e65, s]),\n            g = rs(p, o),\n            m = Sn(o);\n        if (0 === _e65) a = Gr(f, In(g, In(m, f)));else {\n          var _t68 = Gr(f, In(g, In(m, f)));\n\n          a = Ds([Os(a, [0, 0], [_e65, s]), _t68], 0);\n        }\n        var b = Sn(g),\n            x = Os(r, [0, _e65], [n, r.shape[1] - _e65]);\n        if (0 === _e65) r = Gr(x, In(In(x, o), b));else {\n          var _t69 = Gr(x, In(In(x, o), b));\n\n          r = Ds([Os(r, [0, 0], [n, _e65]), _t69], 1);\n        }\n        return [o, a, r];\n      }), Zn([t, l, u]);\n    };\n\n    for (var _e65 = 0; _e65 < u; ++_e65) {\n      _loop8(_e65);\n    }\n\n    return !t && n > s && (r = Os(r, [0, 0], [n, s]), a = Os(a, [0, 0], [s, s])), [r, a];\n  });\n}\n\nvar co = Ft({\n  qr_: function qr_(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    if (l(e.rank >= 2, () => \"qr() requires input tensor to have a rank >= 2, but got rank \".concat(e.rank)), 2 === e.rank) return uo(e, t);\n    {\n      var _n35 = e.shape.slice(0, e.shape.length - 2).reduce((e, t) => e * t),\n          _s41 = Ii(Rs(e, [_n35, e.shape[e.shape.length - 2], e.shape[e.shape.length - 1]]), 0),\n          _r31 = [],\n          _a21 = [];\n\n      return _s41.forEach(e => {\n        var [n, s] = uo(e, t);\n        _r31.push(n), _a21.push(s);\n      }), [Rs(pi(_r31, 0), e.shape), Rs(pi(_a21, 0), e.shape)];\n    }\n  }\n});\nvar ho;\n!function (e) {\n  e[e.NONE = 0] = \"NONE\", e[e.MEAN = 1] = \"MEAN\", e[e.SUM = 2] = \"SUM\", e[e.SUM_BY_NONZERO_WEIGHTS = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n}(ho || (ho = {}));\nvar po = Ft({\n  computeWeightedLoss_: function computeWeightedLoss_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var s = Rt(e, \"losses\", \"computeWeightedLoss\");\n    var r = null;\n    null != t && (r = Rt(t, \"weights\", \"computeWeightedLoss\"));\n    var a = null == r ? s : rs(s, r);\n    if (n === ho.NONE) return a;\n    if (n === ho.SUM) return Hr(a);\n\n    if (n === ho.MEAN) {\n      if (null == r) return ua(a);\n      {\n        var _e66 = s.size / r.size,\n            _t70 = ss(Hr(a), Hr(r));\n\n        return _e66 > 1 ? ss(_t70, Ka(_e66)) : _t70;\n      }\n    }\n\n    if (n === ho.SUM_BY_NONZERO_WEIGHTS) {\n      if (null == r) return ss(Hr(a), Ka(s.size));\n      {\n        var _e67 = rs(r, ha(s.shape)),\n            _t71 = fn(Hr(xa(_e67, Ka(0))), \"float32\");\n\n        return ss(Hr(a), _t71);\n      }\n    }\n\n    throw Error(\"Unknown reduction: \".concat(n));\n  }\n});\nFt({\n  absoluteDifference_: function absoluteDifference_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var r = Rt(e, \"labels\", \"absoluteDifference\"),\n        a = Rt(t, \"predictions\", \"absoluteDifference\");\n    var i = null;\n    null != n && (i = Rt(n, \"weights\", \"absoluteDifference\")), u(r.shape, a.shape, \"Error in absoluteDifference: \");\n    var o = as(Gr(r, a));\n    return po(o, i, s);\n  }\n}), Ft({\n  cosineDistance_: function cosineDistance_(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var a = Rt(e, \"labels\", \"cosineDistance\"),\n        i = Rt(t, \"predictions\", \"cosineDistance\");\n    var o = null;\n    null != s && (o = Rt(s, \"weights\", \"cosineDistance\")), u(a.shape, i.shape, \"Error in cosineDistance: \");\n    var l = Ka(1),\n        c = Gr(l, Hr(rs(a, i), n, !0));\n    return po(c, o, r);\n  }\n}), Ft({\n  hingeLoss_: function hingeLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var r = Rt(e, \"labels\", \"hingeLoss\");\n    var a = Rt(t, \"predictions\", \"hingeLoss\");\n    var i = null;\n    null != n && (i = Rt(n, \"weights\", \"hingeLoss\")), u(r.shape, a.shape, \"Error in hingeLoss: \");\n    var o = Ka(1);\n    r = Gr(rs(Ka(2), r), o);\n    var l = Va(Gr(o, rs(r, a)));\n    return po(l, i, s);\n  }\n}), Ft({\n  huberLoss_: function huberLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var a = Rt(e, \"labels\", \"huberLoss\"),\n        i = Rt(t, \"predictions\", \"huberLoss\");\n    var o = null;\n    null != n && (o = Rt(n, \"weights\", \"huberLoss\")), u(a.shape, i.shape, \"Error in huberLoss: \");\n    var l = Ka(s),\n        c = as(Gr(i, a)),\n        h = pa(c, l),\n        d = Gr(c, h),\n        p = ts(rs(Ka(.5), ma(h)), rs(l, d));\n    return po(p, o, r);\n  }\n}), Ft({\n  logLoss_: function logLoss_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1e-7;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var a = Rt(e, \"labels\", \"logLoss\"),\n        i = Rt(t, \"predictions\", \"logLoss\");\n    var o = null;\n    null != n && (o = Rt(n, \"weights\", \"logLoss\")), u(a.shape, i.shape, \"Error in logLoss: \");\n    var l = Ka(1),\n        c = Ka(s),\n        h = Pr(rs(a, Lr(ts(i, c)))),\n        d = rs(Gr(l, a), Lr(ts(Gr(l, i), c))),\n        p = Gr(h, d);\n    return po(p, o, r);\n  }\n}), Ft({\n  meanSquaredError_: function meanSquaredError_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var r = Rt(e, \"labels\", \"meanSquaredError\"),\n        a = Rt(t, \"predictions\", \"meanSquaredError\");\n    var i = null;\n    null != n && (i = Rt(n, \"weights\", \"meanSquaredError\")), u(r.shape, a.shape, \"Error in meanSquaredError: \");\n    var o = hi(r, a);\n    return po(o, i, s);\n  }\n}), Ft({\n  sigmoidCrossEntropy_: function sigmoidCrossEntropy_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var a = Rt(e, \"multiClassLabels\", \"sigmoidCrossEntropy\");\n    var i = Rt(t, \"logits\", \"sigmoidCrossEntropy\");\n    var o = null;\n\n    if (null != n && (o = Rt(n, \"weights\", \"sigmoidCrossEntropy\")), u(a.shape, i.shape, \"Error in sigmoidCrossEntropy: \"), s > 0) {\n      var _e68 = Ka(s),\n          _t72 = Ka(1),\n          _n36 = Ka(.5);\n\n      a = ts(rs(a, Gr(_t72, _e68)), rs(_n36, _e68));\n    }\n\n    var l = function (e, t) {\n      var n = Rt(e, \"labels\", \"sigmoidCrossEntropyWithLogits\"),\n          s = Rt(t, \"logits\", \"sigmoidCrossEntropyWithLogits\");\n      u(n.shape, s.shape, \"Error in sigmoidCrossEntropyWithLogits: \");\n      var r = Va(s),\n          a = rs(s, n),\n          i = zr(yr(Pr(as(s))));\n      return ts(Gr(r, a), i);\n    }(a, i);\n\n    return po(l, o, r);\n  }\n}), Ft({\n  softmaxCrossEntropy_: function softmaxCrossEntropy_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : ho.SUM_BY_NONZERO_WEIGHTS;\n    var a = Rt(e, \"onehotLabels\", \"softmaxCrossEntropy\");\n    var i = Rt(t, \"logits\", \"softmaxCrossEntropy\");\n    var o = null;\n\n    if (null != n && (o = Rt(n, \"weights\", \"softmaxCrossEntropy\")), u(a.shape, i.shape, \"Error in softmaxCrossEntropy: \"), s > 0) {\n      var _e69 = Ka(s),\n          _t73 = Ka(1),\n          _n37 = Ka(a.shape[1]);\n\n      a = ts(rs(a, Gr(_t73, _e69)), ss(_e69, _n37));\n    }\n\n    var l = function (e, t) {\n      var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;\n      if (-1 === n && (n = t.rank - 1), n !== t.rank - 1) throw Error(\"Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank \".concat(t.rank, \" and dim was \").concat(n));\n      return Br((e, t, s) => {\n        var r = ta(t, [n], !0),\n            a = Gr(fn(t, \"float32\"), r);\n        s([e, a]);\n        var i = Pr(rs(a, e));\n        return {\n          value: Hr(i, [n]),\n          gradFunc: (e, t) => {\n            var [s, r] = t,\n                a = Yr(e.shape, [n]);\n            return [rs(Rs(e, a), Gr(fn(s, \"float32\"), yr(r))), rs(Rs(e, a), Gr(yr(r), fn(s, \"float32\")))];\n          }\n        };\n      })(e, t);\n    }(a, i);\n\n    return po(l, o, r);\n  }\n}), Ft({\n  sparseFillEmptyRows_: function sparseFillEmptyRows_(e, t, n, s) {\n    var r = Rt(e, \"indices\", \"sparseFillEmptyRows\"),\n        a = Rt(t, \"values\", \"sparseFillEmptyRows\"),\n        i = Rt(n, \"denseShape\", \"sparseFillEmptyRows\"),\n        o = Rt(s, \"defaultValue\", \"sparseFillEmptyRows\", a.dtype);\n    if (2 !== r.rank) throw new Error(\"Indices should be Tensor2D but received shape\\n        \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Values should be Tensor1D but received shape \".concat(a.shape));\n    if (1 !== i.rank) throw new Error(\"Dense shape should be Tensor1D but received shape \".concat(i.shape));\n    if (0 !== o.rank) throw new Error(\"Default value should be a scalar but received shape \".concat(o.shape));\n    var l = vt.runKernel(\"SparseFillEmptyRows\", {\n      indices: r,\n      values: a,\n      denseShape: i,\n      defaultValue: o\n    });\n    return {\n      outputIndices: l[0],\n      outputValues: l[1],\n      emptyRowIndicator: l[2],\n      reverseIndexMap: l[3]\n    };\n  }\n}), Ft({\n  sparseReshape_: function sparseReshape_(e, t, n) {\n    var s = Rt(e, \"inputIndices\", \"sparseReshape\"),\n        r = Rt(t, \"inputShape\", \"sparseReshape\"),\n        a = Rt(n, \"newShape\", \"sparseReshape\");\n    if (2 !== s.rank) throw new Error(\"Input indices should be Tensor2D but received shape\\n        \".concat(s.shape));\n    if (1 !== r.rank) throw new Error(\"Input shape should be Tensor1D but received shape \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"New shape should be Tensor1D but received shape \".concat(a.shape));\n    var i = vt.runKernel(\"SparseReshape\", {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    });\n    return {\n      outputIndices: i[0],\n      outputShape: i[1]\n    };\n  }\n}), Ft({\n  sparseSegmentMean_: function sparseSegmentMean_(e, t, n) {\n    var s = Rt(e, \"data\", \"sparseSegmentMean\"),\n        r = Rt(t, \"indices\", \"sparseSegmentMean\"),\n        a = Rt(n, \"segmentIds\", \"sparseSegmentMean\");\n    if (s.rank < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.rank) throw new Error(\"Indices should be Tensor1D but received shape\\n          \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Segment ids should be Tensor1D but received shape\\n          \".concat(a.shape));\n    return vt.runKernel(\"SparseSegmentMean\", {\n      data: s,\n      indices: r,\n      segmentIds: a\n    });\n  }\n}), Ft({\n  sparseSegmentSum_: function sparseSegmentSum_(e, t, n) {\n    var s = Rt(e, \"data\", \"sparseSegmentSum\"),\n        r = Rt(t, \"indices\", \"sparseSegmentSum\"),\n        a = Rt(n, \"segmentIds\", \"sparseSegmentSum\");\n    if (s.rank < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.rank) throw new Error(\"Indices should be Tensor1D but received shape\\n         \".concat(r.shape));\n    if (1 !== a.rank) throw new Error(\"Segment ids should be Tensor1D but received shape\\n         \".concat(a.shape));\n    return vt.runKernel(\"SparseSegmentSum\", {\n      data: s,\n      indices: r,\n      segmentIds: a\n    });\n  }\n}), Ft({\n  stringNGrams_: function stringNGrams_(e, t, n, s, r, a, i, o) {\n    var l = Rt(e, \"data\", \"stringNGrams\", \"string\");\n    if (\"string\" !== l.dtype) throw new Error(\"Data must be of datatype string\");\n    if (1 !== l.shape.length) throw new Error(\"Data must be a vector, saw: \".concat(l.shape));\n    var u = Rt(t, \"dataSplits\", \"stringNGrams\");\n    if (\"int32\" !== u.dtype) throw new Error(\"Data splits must be of datatype int32\");\n    var c = vt.runKernel(\"StringNGrams\", {\n      data: l,\n      dataSplits: u\n    }, {\n      separator: n,\n      nGramWidths: s,\n      leftPad: r,\n      rightPad: a,\n      padWidth: i,\n      preserveShortSequences: o\n    });\n    return {\n      nGrams: c[0],\n      nGramsSplits: c[1]\n    };\n  }\n}), Ft({\n  stringSplit_: function stringSplit_(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = Rt(e, \"input\", \"stringSplit\", \"string\"),\n        r = Rt(t, \"delimiter\", \"stringSplit\", \"string\");\n    if (1 !== s.rank) throw new Error(\"Input should be Tensor1D but received shape \".concat(s.shape));\n    if (0 !== r.rank) throw new Error(\"Delimiter should be a scalar but received shape \".concat(r.shape));\n    var a = vt.runKernel(\"StringSplit\", {\n      input: s,\n      delimiter: r\n    }, {\n      skipEmpty: n\n    });\n    return {\n      indices: a[0],\n      values: a[1],\n      shape: a[2]\n    };\n  }\n}), Ft({\n  stringToHashBucketFast_: function stringToHashBucketFast_(e, t) {\n    var n = Rt(e, \"input\", \"stringToHashBucketFast\", \"string\"),\n        s = {\n      numBuckets: t\n    };\n    if (t <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    return vt.runKernel(\"StringToHashBucketFast\", {\n      input: n\n    }, s);\n  }\n});\nvar fo = {\n  flipLeftRight: Wi,\n  grayscaleToRGB: Ui,\n  resizeNearestNeighbor: ro,\n  resizeBilinear: so,\n  rotateWithOffset: Vi,\n  cropAndResize: Pi,\n  nonMaxSuppression: Hi,\n  nonMaxSuppressionAsync: function () {\n    var _nonMaxSuppressionAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = Rt(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          i = Rt(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          o = Gi(a, i, n, s, r);\n      n = o.maxOutputSize, s = o.iouThreshold, r = o.scoreThreshold;\n      var l = yield Promise.all([a.data(), i.data()]),\n          u = l[0],\n          c = l[1],\n          {\n        selectedIndices: h\n      } = Ki(u, c, n, s, r);\n      return a !== e && a.dispose(), i !== t && i.dispose(), bi(h, \"int32\");\n    });\n\n    function nonMaxSuppressionAsync(_x10, _x11, _x12) {\n      return _nonMaxSuppressionAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionAsync;\n  }(),\n  nonMaxSuppressionWithScore: to,\n  nonMaxSuppressionWithScoreAsync: function () {\n    var _nonMaxSuppressionWithScoreAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n      var i = Rt(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          o = Rt(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          l = Gi(i, o, n, s, r, a);\n      n = l.maxOutputSize, s = l.iouThreshold, r = l.scoreThreshold, a = l.softNmsSigma;\n      var u = yield Promise.all([i.data(), o.data()]),\n          c = u[0],\n          h = u[1],\n          {\n        selectedIndices: d,\n        selectedScores: p\n      } = Yi(c, h, n, s, r, a);\n      return i !== e && i.dispose(), o !== t && o.dispose(), {\n        selectedIndices: bi(d, \"int32\"),\n        selectedScores: bi(p)\n      };\n    });\n\n    function nonMaxSuppressionWithScoreAsync(_x13, _x14, _x15) {\n      return _nonMaxSuppressionWithScoreAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionWithScoreAsync;\n  }(),\n  nonMaxSuppressionPadded: no,\n  nonMaxSuppressionPaddedAsync: function () {\n    var _nonMaxSuppressionPaddedAsync = _asyncToGenerator(function* (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;\n      var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;\n      var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n      var i = Rt(e, \"boxes\", \"nonMaxSuppressionAsync\"),\n          o = Rt(t, \"scores\", \"nonMaxSuppressionAsync\"),\n          l = Gi(i, o, n, s, r, null),\n          u = l.maxOutputSize,\n          c = l.iouThreshold,\n          h = l.scoreThreshold,\n          [d, p] = yield Promise.all([i.data(), o.data()]),\n          {\n        selectedIndices: f,\n        validOutputs: g\n      } = Xi(d, p, u, c, h, a);\n      return i !== e && i.dispose(), o !== t && o.dispose(), {\n        selectedIndices: bi(f, \"int32\"),\n        validOutputs: Ka(g, \"int32\")\n      };\n    });\n\n    function nonMaxSuppressionPaddedAsync(_x16, _x17, _x18) {\n      return _nonMaxSuppressionPaddedAsync.apply(this, arguments);\n    }\n\n    return nonMaxSuppressionPaddedAsync;\n  }(),\n  threshold: ao,\n  transform: io\n},\n    go = {\n  bandPart: oo,\n  gramSchmidt: lo,\n  qr: co\n};\n\nclass mo extends qn {\n  minimize(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 ? arguments[2] : undefined;\n    var {\n      value: s,\n      grads: r\n    } = this.computeGradients(e, n);\n\n    if (null != n) {\n      var _e70 = n.map(e => ({\n        name: e.name,\n        tensor: r[e.name]\n      }));\n\n      this.applyGradients(_e70);\n    } else this.applyGradients(r);\n\n    return Zn(r), t ? s : (s.dispose(), null);\n  }\n\n  get iterations() {\n    return null == this.iterations_ && (this.iterations_ = 0), this.iterations_;\n  }\n\n  incrementIterations() {\n    this.iterations_ = this.iterations + 1;\n  }\n\n  computeGradients(e, t) {\n    return function (e, t) {\n      l(E(e), () => \"The f passed in variableGrads(f) must be a function\"), l(null == t || Array.isArray(t) && t.every(e => e instanceof it), () => \"The varList passed in variableGrads(f, varList) must be an array of variables\");\n      var n = null != t;\n\n      if (!n) {\n        t = [];\n\n        for (var _e71 in vt.registeredVariables) {\n          t.push(vt.registeredVariables[_e71]);\n        }\n      }\n\n      var s = n ? t.filter(e => !e.trainable) : null,\n          r = t.length;\n      l((t = t.filter(e => e.trainable)).length > 0, () => \"variableGrads() expects at least one of the input variables to be trainable, but none of the \".concat(r, \" variables is trainable.\"));\n      var {\n        value: a,\n        grads: i\n      } = vt.gradients(e, t, null, !0);\n      l(i.some(e => null != e), () => \"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().\"), l(0 === a.rank, () => \"The f passed in variableGrads(f) must return a scalar, but it returned a rank-\".concat(a.rank, \" tensor\"));\n      var o = {};\n      return t.forEach((e, t) => {\n        null != i[t] && (o[e.name] = i[t]);\n      }), null != s && s.forEach(e => o[e.name] = null), {\n        value: a,\n        grads: o\n      };\n    }(e, t);\n  }\n\n  dispose() {\n    null != this.iterations_ && Zn(this.iterations_);\n  }\n\n  saveIterations() {\n    var _this23 = this;\n\n    return _asyncToGenerator(function* () {\n      return null == _this23.iterations_ && (_this23.iterations_ = 0), {\n        name: \"iter\",\n        tensor: Ka(_this23.iterations_, \"int32\")\n      };\n    })();\n  }\n\n  getWeights() {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"getWeights() is not implemented for this optimizer yet.\");\n    })();\n  }\n\n  setWeights(e) {\n    var _this24 = this;\n\n    return _asyncToGenerator(function* () {\n      throw new Error(\"setWeights() is not implemented for this optimizer class \".concat(_this24.getClassName()));\n    })();\n  }\n\n  extractIterations(e) {\n    var _this25 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this25.iterations_ = (yield e[0].tensor.data())[0], e.slice(1);\n    })();\n  }\n\n}\n\nObject.defineProperty(mo, Symbol.hasInstance, {\n  value: e => null != e.minimize && null != e.computeGradients && null != e.applyGradients\n});\n\nclass bo extends mo {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    super(), this.learningRate = e, this.rho = t, this.epsilon = n, this.accumulatedGrads = [], this.accumulatedUpdates = [], null == n && (this.epsilon = vt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = vt.registeredVariables[t];\n      null == this.accumulatedGrads[n] && (this.accumulatedGrads[n] = {\n        originalName: \"\".concat(t, \"/accum_grad\"),\n        variable: Jn(() => fr(s).variable(!1))\n      }), null == this.accumulatedUpdates[n] && (this.accumulatedUpdates[n] = {\n        originalName: \"\".concat(t, \"/accum_var\"),\n        variable: Jn(() => fr(s).variable(!1))\n      });\n      var r = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == r) return;\n      var a = this.accumulatedGrads[n].variable,\n          i = this.accumulatedUpdates[n].variable;\n      Jn(() => {\n        var e = ts(rs(a, this.rho), rs(ma(r), 1 - this.rho)),\n            t = rs(ss(ci(ts(i, this.epsilon)), ci(ts(a, this.epsilon))), r),\n            n = ts(rs(i, this.rho), rs(ma(t), 1 - this.rho));\n        a.assign(e), i.assign(n);\n        var o = ts(rs(t, -this.learningRate), s);\n        s.assign(o);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedUpdates && (Zn(this.accumulatedGrads.map(e => e.variable)), Zn(this.accumulatedUpdates.map(e => e.variable)));\n  }\n\n  getWeights() {\n    var _this26 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this26.accumulatedGrads, ..._this26.accumulatedUpdates];\n      return [yield _this26.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this27 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = (e = yield _this27.extractIterations(e)).length / 2;\n      _this27.accumulatedGrads = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      })), _this27.accumulatedUpdates = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      rho: this.rho,\n      epsilon: this.epsilon\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.rho, t.epsilon);\n  }\n\n}\n\nbo.className = \"Adadelta\", Kn(bo);\n\nclass xo extends mo {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;\n    super(), this.learningRate = e, this.initialAccumulatorValue = t, this.accumulatedGrads = [];\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = vt.registeredVariables[t];\n\n      if (null == this.accumulatedGrads[n]) {\n        var _e72 = !1;\n\n        this.accumulatedGrads[n] = {\n          originalName: \"\".concat(t, \"/accumulator\"),\n          variable: Jn(() => $r(s.shape, this.initialAccumulatorValue).variable(_e72))\n        };\n      }\n\n      var r = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == r) return;\n      var a = this.accumulatedGrads[n].variable;\n      Jn(() => {\n        var e = ts(a, ma(r));\n        a.assign(e);\n        var t = ts(rs(ss(r, ci(ts(e, vt.backend.epsilon()))), -this.learningRate), s);\n        s.assign(t);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedGrads && Zn(this.accumulatedGrads.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this28 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this28.saveIterations()].concat(_this28.accumulatedGrads.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this29 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this29.extractIterations(e), _this29.accumulatedGrads = e.map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      initialAccumulatorValue: this.initialAccumulatorValue\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.initialAccumulatorValue);\n  }\n\n}\n\nxo.className = \"Adagrad\", Kn(xo);\n\nclass yo extends mo {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = s, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], Jn(() => {\n      this.accBeta1 = Ka(t).variable(), this.accBeta2 = Ka(n).variable();\n    }), null == s && (this.epsilon = vt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n    Jn(() => {\n      var n = Gr(1, this.accBeta1),\n          s = Gr(1, this.accBeta2);\n      t.forEach((t, r) => {\n        var a = vt.registeredVariables[t];\n        null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {\n          originalName: \"\".concat(t, \"/m\"),\n          variable: Jn(() => fr(a).variable(!1))\n        }), null == this.accumulatedSecondMoment[r] && (this.accumulatedSecondMoment[r] = {\n          originalName: \"\".concat(t, \"/v\"),\n          variable: Jn(() => fr(a).variable(!1))\n        });\n        var i = Array.isArray(e) ? e[r].tensor : e[t];\n        if (null == i) return;\n        var o = this.accumulatedFirstMoment[r].variable,\n            l = this.accumulatedSecondMoment[r].variable,\n            u = ts(rs(o, this.beta1), rs(i, 1 - this.beta1)),\n            c = ts(rs(l, this.beta2), rs(ma(i), 1 - this.beta2)),\n            h = ss(u, n),\n            d = ss(c, s);\n        o.assign(u), l.assign(c);\n        var p = ts(rs(ss(h, ts(ci(d), this.epsilon)), -this.learningRate), a);\n        a.assign(p);\n      }), this.accBeta1.assign(rs(this.accBeta1, this.beta1)), this.accBeta2.assign(rs(this.accBeta2, this.beta2));\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.accBeta1.dispose(), this.accBeta2.dispose(), null != this.accumulatedFirstMoment && Zn(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedSecondMoment && Zn(this.accumulatedSecondMoment.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this30 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this30.accumulatedFirstMoment, ..._this30.accumulatedSecondMoment];\n      return [yield _this30.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this31 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this31.extractIterations(e), Jn(() => {\n        _this31.accBeta1.assign(Ia(_this31.beta1, _this31.iterations_ + 1)), _this31.accBeta2.assign(Ia(_this31.beta2, _this31.iterations_ + 1));\n      });\n      var t = e.length / 2;\n      _this31.accumulatedFirstMoment = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      })), _this31.accumulatedSecondMoment = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      beta1: this.beta1,\n      beta2: this.beta2,\n      epsilon: this.epsilon\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon);\n  }\n\n}\n\nyo.className = \"Adam\", Kn(yo);\n\nclass ko extends mo {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = s, this.decay = r, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], Jn(() => {\n      this.iteration = Ka(0).variable(), this.accBeta1 = Ka(t).variable();\n    }), null == s && (this.epsilon = vt.backend.epsilon());\n  }\n\n  applyGradients(e) {\n    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);\n    Jn(() => {\n      var n = Gr(1, this.accBeta1),\n          s = ss(-this.learningRate, ts(rs(this.iteration, this.decay), 1));\n      t.forEach((t, r) => {\n        var a = vt.registeredVariables[t];\n        null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {\n          originalName: \"\".concat(t, \"/m\"),\n          variable: fr(a).variable(!1)\n        }), null == this.accumulatedWeightedInfNorm[r] && (this.accumulatedWeightedInfNorm[r] = {\n          originalName: \"\".concat(t, \"/v\"),\n          variable: fr(a).variable(!1)\n        });\n        var i = Array.isArray(e) ? e[r].tensor : e[t];\n        if (null == i) return;\n        var o = this.accumulatedFirstMoment[r].variable,\n            l = this.accumulatedWeightedInfNorm[r].variable,\n            u = ts(rs(o, this.beta1), rs(i, 1 - this.beta1)),\n            c = rs(l, this.beta2),\n            h = as(i),\n            d = la(c, h);\n        o.assign(u), l.assign(d);\n        var p = ts(rs(ss(s, n), ss(u, ts(d, this.epsilon))), a);\n        a.assign(p);\n      }), this.iteration.assign(ts(this.iteration, 1)), this.accBeta1.assign(rs(this.accBeta1, this.beta1));\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.accBeta1.dispose(), this.iteration.dispose(), null != this.accumulatedFirstMoment && Zn(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedWeightedInfNorm && Zn(this.accumulatedWeightedInfNorm.map(e => e.variable));\n  }\n\n  getWeights() {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"getWeights() is not implemented for Adamax yet.\");\n    })();\n  }\n\n  setWeights(e) {\n    return _asyncToGenerator(function* () {\n      throw new Error(\"setWeights() is not implemented for Adamax yet.\");\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      beta1: this.beta1,\n      beta2: this.beta2,\n      epsilon: this.epsilon,\n      decay: this.decay\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon, t.decay);\n  }\n\n}\n\nko.className = \"Adamax\", Kn(ko);\n\nclass wo extends mo {\n  constructor(e) {\n    super(), this.learningRate = e, this.setLearningRate(e);\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == s) return;\n      var r = vt.registeredVariables[t];\n      Jn(() => {\n        var e = ts(rs(this.c, s), r);\n        r.assign(e);\n      });\n    }), this.incrementIterations();\n  }\n\n  setLearningRate(e) {\n    this.learningRate = e, null != this.c && this.c.dispose(), this.c = Qn(Ka(-e));\n  }\n\n  dispose() {\n    this.c.dispose();\n  }\n\n  getWeights() {\n    var _this32 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this32.saveIterations()];\n    })();\n  }\n\n  setWeights(e) {\n    var _this33 = this;\n\n    return _asyncToGenerator(function* () {\n      if (0 !== (e = yield _this33.extractIterations(e)).length) throw new Error(\"SGD optimizer does not have settable weights.\");\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate);\n  }\n\n}\n\nwo.className = \"SGD\", Kn(wo);\n\nclass vo extends wo {\n  constructor(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    super(e), this.learningRate = e, this.momentum = t, this.useNesterov = n, this.accumulations = [], this.m = Ka(this.momentum);\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = vt.registeredVariables[t];\n\n      if (null == this.accumulations[n]) {\n        var _e73 = !1;\n\n        this.accumulations[n] = {\n          originalName: \"\".concat(t, \"/momentum\"),\n          variable: Jn(() => fr(s).variable(_e73))\n        };\n      }\n\n      var r = this.accumulations[n].variable,\n          a = Array.isArray(e) ? e[n].tensor : e[t];\n      null != a && Jn(() => {\n        var e;\n        var t = ts(rs(this.m, r), a);\n        e = ts(rs(this.c, this.useNesterov ? ts(a, rs(t, this.m)) : t), s), r.assign(t), s.assign(e);\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    this.m.dispose(), null != this.accumulations && Zn(this.accumulations.map(e => e.variable));\n  }\n\n  setMomentum(e) {\n    this.momentum = e;\n  }\n\n  getWeights() {\n    var _this34 = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this34.saveIterations()].concat(_this34.accumulations.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this35 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this35.extractIterations(e), _this35.accumulations = e.map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(!1)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      momentum: this.momentum,\n      useNesterov: this.useNesterov\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.momentum, t.useNesterov);\n  }\n\n}\n\nvo.className = \"Momentum\", Kn(vo);\n\nclass Io extends mo {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (super(), this.learningRate = e, this.decay = t, this.momentum = n, this.epsilon = s, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = r, null == s && (this.epsilon = vt.backend.epsilon()), null == e) throw new Error(\"learningRate for RMSPropOptimizer must be defined.\");\n  }\n\n  applyGradients(e) {\n    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {\n      var s = vt.registeredVariables[t],\n          r = !1;\n      null == this.accumulatedMeanSquares[n] && (this.accumulatedMeanSquares[n] = {\n        originalName: \"\".concat(t, \"/rms\"),\n        variable: Jn(() => fr(s).variable(r))\n      }), null == this.accumulatedMoments[n] && (this.accumulatedMoments[n] = {\n        originalName: \"\".concat(t, \"/momentum\"),\n        variable: Jn(() => fr(s).variable(r))\n      }), null == this.accumulatedMeanGrads[n] && this.centered && (this.accumulatedMeanGrads[n] = {\n        originalName: \"\".concat(t, \"/mg\"),\n        variable: Jn(() => fr(s).variable(r))\n      });\n      var a = Array.isArray(e) ? e[n].tensor : e[t];\n      if (null == a) return;\n      var i = this.accumulatedMeanSquares[n].variable,\n          o = this.accumulatedMoments[n].variable;\n      Jn(() => {\n        var e = ts(rs(i, this.decay), rs(ma(a), 1 - this.decay));\n\n        if (this.centered) {\n          var _t74 = this.accumulatedMeanGrads[n].variable,\n              _r32 = ts(rs(_t74, this.decay), rs(a, 1 - this.decay)),\n              _l8 = ss(rs(a, this.learningRate), ci(Gr(e, ts(ma(_r32), this.epsilon)))),\n              _u5 = ts(rs(o, this.momentum), _l8);\n\n          i.assign(e), _t74.assign(_r32), o.assign(_u5);\n\n          var _c4 = Gr(s, _u5);\n\n          s.assign(_c4);\n        } else {\n          var _e74 = ts(rs(i, this.decay), rs(ma(a), 1 - this.decay)),\n              _t75 = ts(rs(o, this.momentum), ss(rs(a, this.learningRate), ci(ts(_e74, this.epsilon))));\n\n          i.assign(_e74), o.assign(_t75);\n\n          var _n38 = Gr(s, _t75);\n\n          s.assign(_n38);\n        }\n      });\n    }), this.incrementIterations();\n  }\n\n  dispose() {\n    null != this.accumulatedMeanSquares && Zn(this.accumulatedMeanSquares.map(e => e.variable)), null != this.accumulatedMeanGrads && this.centered && Zn(this.accumulatedMeanGrads.map(e => e.variable)), null != this.accumulatedMoments && Zn(this.accumulatedMoments.map(e => e.variable));\n  }\n\n  getWeights() {\n    var _this36 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [..._this36.accumulatedMeanSquares, ..._this36.accumulatedMoments];\n      return _this36.centered && e.push(..._this36.accumulatedMeanGrads), [yield _this36.saveIterations()].concat(e.map(e => ({\n        name: e.originalName,\n        tensor: e.variable\n      })));\n    })();\n  }\n\n  setWeights(e) {\n    var _this37 = this;\n\n    return _asyncToGenerator(function* () {\n      e = yield _this37.extractIterations(e);\n      var t = _this37.centered ? e.length / 3 : e.length / 2,\n          n = !1;\n      _this37.accumulatedMeanSquares = e.slice(0, t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })), _this37.accumulatedMoments = e.slice(t, 2 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })), _this37.centered && (_this37.accumulatedMeanGrads = e.slice(2 * t, 3 * t).map(e => ({\n        originalName: e.name,\n        variable: e.tensor.variable(n)\n      })));\n    })();\n  }\n\n  getConfig() {\n    return {\n      learningRate: this.learningRate,\n      decay: this.decay,\n      momentum: this.momentum,\n      epsilon: this.epsilon,\n      centered: this.centered\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e(t.learningRate, t.decay, t.momentum, t.epsilon, t.centered);\n  }\n\n}\n\nIo.className = \"RMSProp\", Kn(Io);\n\nclass $o {\n  static sgd(e) {\n    return new wo(e);\n  }\n\n  static momentum(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    return new vo(e, t, n);\n  }\n\n  static rmsprop(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    return new Io(e, t, n, s, r);\n  }\n\n  static adam() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    return new yo(e, t, n, s);\n  }\n\n  static adadelta() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .95;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    return new bo(e, t, n);\n  }\n\n  static adamax() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .002;\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n    return new ko(e, t, n, s, r);\n  }\n\n  static adagrad(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;\n    return new xo(e, t);\n  }\n\n}\n\nvar So = {\n  sgd: $o.sgd,\n  momentum: $o.momentum,\n  adadelta: $o.adadelta,\n  adagrad: $o.adagrad,\n  rmsprop: $o.rmsprop,\n  adamax: $o.adamax,\n  adam: $o.adam\n},\n    No = \"undefined\" != typeof requestAnimationFrame ? requestAnimationFrame : \"undefined\" != typeof setImmediate ? setImmediate : e => e();\n\nfunction Co() {\n  return new Promise(e => No(() => e()));\n}\n\nfunction To(e, t) {\n  var n = e[0].length;\n  e.forEach((e, t) => {\n    l(e.length === n, () => \"Error in concat\".concat(n, \"D: rank of tensors[\").concat(t, \"] must be the same as the rank of the rest (\").concat(n, \")\"));\n  }), l(t >= 0 && t < n, () => \"Error in concat\".concat(n, \"D: axis must be between 0 and \").concat(n - 1, \".\"));\n  var s = e[0];\n  e.forEach((e, r) => {\n    for (var _a22 = 0; _a22 < n; _a22++) {\n      l(_a22 === t || e[_a22] === s[_a22], () => \"Error in concat\".concat(n, \"D: Shape of tensors[\").concat(r, \"] (\").concat(e, \") does not match the shape of the rest (\").concat(s, \") along the non-concatenated axis \").concat(r, \".\"));\n    }\n  });\n}\n\nfunction Eo(e, t) {\n  var n = e[0].slice();\n\n  for (var _s42 = 1; _s42 < e.length; _s42++) {\n    n[t] += e[_s42][t];\n  }\n\n  return n;\n}\n\nfunction Ro(e) {\n  return e <= 30 ? e : R(e, Math.floor(Math.sqrt(e)));\n}\n\nfunction Ao(e, t, n) {\n  return [n * (\"number\" == typeof e ? e : e[0]), t * (\"number\" == typeof e ? e : e[1])];\n}\n\nfunction Fo(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = [];\n  if (s) r = r.concat(t.slice(0)), r.push(e[0] / n), r = r.concat(e.slice(1));else {\n    r = r.concat(e[0]);\n    var _n39 = t.length;\n\n    for (var _s43 = 0; _s43 < _n39; ++_s43) {\n      r = r.concat([e[_s43 + 1] / t[_s43], t[_s43]]);\n    }\n\n    r = r.concat(e.slice(_n39 + 1));\n  }\n  return r;\n}\n\nfunction Do(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n  var s = [];\n\n  if (n) {\n    s.push(t);\n\n    for (var _n40 = t + 1; _n40 < e; ++_n40) {\n      _n40 <= 2 * t ? (s.push(_n40), s.push(_n40 - (t + 1))) : s.push(_n40);\n    }\n  } else {\n    var _n41 = [],\n        _r33 = [];\n\n    for (var _s44 = 1; _s44 < e; ++_s44) {\n      _s44 >= 2 * t + 1 || _s44 % 2 == 1 ? _r33.push(_s44) : _n41.push(_s44);\n    }\n\n    s.push(..._n41), s.push(0), s.push(..._r33);\n  }\n\n  return s;\n}\n\nfunction _o(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = [];\n  r.push(s ? e[0] / n : e[0] * n);\n\n  for (var _n42 = 1; _n42 < e.length; ++_n42) {\n    r.push(_n42 <= t.length ? s ? t[_n42 - 1] * e[_n42] : e[_n42] / t[_n42 - 1] : e[_n42]);\n  }\n\n  return r;\n}\n\nfunction Oo(e, t) {\n  var n = [0];\n\n  for (var _s45 = 0; _s45 < t; ++_s45) {\n    n.push(e[_s45][0]);\n  }\n\n  return n;\n}\n\nfunction Mo(e, t, n) {\n  var s = e.slice(0, 1);\n\n  for (var _r34 = 0; _r34 < n; ++_r34) {\n    s.push(e[_r34 + 1] - t[_r34][0] - t[_r34][1]);\n  }\n\n  return s;\n}\n\nfunction Lo(e, t) {\n  if (e.length !== t.length) throw new Error(\"Cannot merge real and imag arrays of different lengths. real:\".concat(e.length, \", imag: \").concat(t.length, \".\"));\n  var n = new Float32Array(2 * e.length);\n\n  for (var _s46 = 0; _s46 < n.length; _s46 += 2) {\n    n[_s46] = e[_s46 / 2], n[_s46 + 1] = t[_s46 / 2];\n  }\n\n  return n;\n}\n\nfunction zo(e) {\n  var t = new Float32Array(e.length / 2),\n      n = new Float32Array(e.length / 2);\n\n  for (var _s47 = 0; _s47 < e.length; _s47 += 2) {\n    t[_s47 / 2] = e[_s47], n[_s47 / 2] = e[_s47 + 1];\n  }\n\n  return {\n    real: t,\n    imag: n\n  };\n}\n\nfunction Bo(e) {\n  var t = Math.ceil(e.length / 4),\n      n = new Float32Array(t),\n      s = new Float32Array(t);\n\n  for (var _t76 = 0; _t76 < e.length; _t76 += 4) {\n    n[Math.floor(_t76 / 4)] = e[_t76], s[Math.floor(_t76 / 4)] = e[_t76 + 1];\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Po(e) {\n  var t = Math.floor(e.length / 4),\n      n = new Float32Array(t),\n      s = new Float32Array(t);\n\n  for (var _t77 = 2; _t77 < e.length; _t77 += 4) {\n    n[Math.floor(_t77 / 4)] = e[_t77], s[Math.floor(_t77 / 4)] = e[_t77 + 1];\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Wo(e, t) {\n  return {\n    real: e[2 * t],\n    imag: e[2 * t + 1]\n  };\n}\n\nfunction Uo(e, t, n, s) {\n  e[2 * s] = t, e[2 * s + 1] = n;\n}\n\nfunction Vo(e, t) {\n  var n = new Float32Array(e / 2),\n      s = new Float32Array(e / 2);\n\n  for (var _r35 = 0; _r35 < Math.ceil(e / 2); _r35++) {\n    var _a23 = (t ? 2 : -2) * Math.PI * (_r35 / e);\n\n    n[_r35] = Math.cos(_a23), s[_r35] = Math.sin(_a23);\n  }\n\n  return {\n    real: n,\n    imag: s\n  };\n}\n\nfunction Go(e, t, n) {\n  var s = (n ? 2 : -2) * Math.PI * (e / t);\n  return {\n    real: Math.cos(s),\n    imag: Math.sin(s)\n  };\n}\n\nvar Ho = /->/g;\n\nfunction qo(e, t) {\n  var n = ((e = e.replace(/\\s/g, \"\")).length - e.replace(Ho, \"\").length) / \"->\".length;\n  if (n < 1) throw new Error(\"Equations without an arrow are not supported.\");\n  if (n > 1) throw new Error('Equation must contain exactly one arrow (\"->\").');\n  var [s, r] = e.split(\"->\");\n  l(-1 === s.indexOf(\"...\"), () => 'The ellipsis notation (\"...\") is not supported yet.');\n  var a = s.split(\",\"),\n      i = a.length;\n  if (t !== i) throw new Error(\"Expected \".concat(i, \" input tensors, received \").concat(t));\n  if (i > 2) throw new Error(\"Support for more than 2 input tensors is not implemented yet.\");\n  var o = [];\n\n  var _loop9 = function _loop9(_e75) {\n    var t = r[_e75];\n    if (!a.some(e => -1 !== e.indexOf(t))) throw new Error(\"Output subscripts contain the label \".concat(t, \" not present in the input subscripts.\"));\n    -1 === o.indexOf(t) && o.push(t);\n  };\n\n  for (var _e75 = 0; _e75 < r.length; ++_e75) {\n    _loop9(_e75);\n  }\n\n  for (var _e76 = 0; _e76 < s.length; ++_e76) {\n    var _t78 = s[_e76];\n    -1 === o.indexOf(_t78) && \",\" !== _t78 && o.push(_t78);\n  }\n\n  var u = new Array(a.length);\n\n  for (var _e77 = 0; _e77 < i; ++_e77) {\n    if (new Set(a[_e77].split(\"\")).size !== a[_e77].length) throw new Error(\"Found duplicate axes in input component \".concat(a[_e77], \". Support for duplicate axes in input is not implemented yet.\"));\n    u[_e77] = [];\n\n    for (var _t79 = 0; _t79 < a[_e77].length; ++_t79) {\n      u[_e77].push(o.indexOf(a[_e77][_t79]));\n    }\n  }\n\n  var c = o.length,\n      h = [];\n\n  for (var _e78 = r.length; _e78 < c; ++_e78) {\n    h.push(_e78);\n  }\n\n  return {\n    allDims: o,\n    summedDims: h,\n    idDims: u\n  };\n}\n\nfunction jo(e, t) {\n  var n = new Array(e);\n  n.fill(-1);\n\n  for (var _e79 = 0; _e79 < t.length; ++_e79) {\n    n[t[_e79]] = _e79;\n  }\n\n  var s = [];\n\n  for (var _t80 = 0; _t80 < e; ++_t80) {\n    -1 === n[_t80] && s.push(_t80);\n  }\n\n  return n = n.filter(e => -1 !== e), {\n    permutationIndices: n,\n    expandDims: s\n  };\n}\n\nfunction Ko(e, t, n) {\n  var s = new Array(e);\n\n  var _loop10 = function _loop10(_e80) {\n    var r = n[_e80].shape;\n\n    var _loop11 = function _loop11(_n43) {\n      void 0 === s[t[_e80][_n43]] ? s[t[_e80][_n43]] = r[_n43] : l(s[t[_e80][_n43]] === r[_n43], () => \"Expected dimension \".concat(s[t[_e80][_n43]], \" at axis \").concat(_n43, \" of input shaped \").concat(JSON.stringify(r), \", but got dimension \").concat(r[_n43]));\n    };\n\n    for (var _n43 = 0; _n43 < t[_e80].length; ++_n43) {\n      _loop11(_n43);\n    }\n  };\n\n  for (var _e80 = 0; _e80 < n.length; ++_e80) {\n    _loop10(_e80);\n  }\n}\n\nfunction Xo(e, t) {\n  var n = e,\n      s = [];\n  var r = 0;\n  0 === e.length && n.push(-1), r = e.length + 1;\n\n  for (var _e81 = 0; _e81 < r; ++_e81) {\n    s.push([]);\n  }\n\n  var a = [];\n\n  for (var _e82 = 0; _e82 < n.length; ++_e82) {\n    var _r36 = Jo(t, n[_e82]);\n\n    for (var _t81 of _r36) {\n      -1 === a.indexOf(_t81) && (s[_e82].push(_t81), a.push(_t81));\n    }\n  }\n\n  return {\n    path: n,\n    steps: s\n  };\n}\n\nfunction Yo(e) {\n  return e.every((e, t) => e === t);\n}\n\nfunction Jo(e, t) {\n  var n = [];\n\n  for (var _s48 = 0; _s48 < e.length; ++_s48) {\n    0 !== e[_s48].length && -1 === e[_s48].indexOf(t) && -1 !== t || n.push(_s48);\n  }\n\n  return n;\n}\n\nfunction Zo(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = [];\n  if (\"number\" == typeof t) l(e.shape[n] % t == 0, () => \"Number of splits must evenly divide the axis.\"), s = new Array(t).fill(e.shape[n] / t);else {\n    l(t.reduce((e, t) => (-1 === t && (e += 1), e), 0) <= 1, () => \"There should be only one negative value in split array.\");\n\n    var _r37 = t.indexOf(-1);\n\n    if (-1 !== _r37) {\n      var _s49 = t.reduce((e, t) => t > 0 ? e + t : e);\n\n      t[_r37] = e.shape[n] - _s49;\n    }\n\n    l(e.shape[n] === t.reduce((e, t) => e + t), () => \"The sum of sizes must match the size of the axis dimension.\"), s = t;\n  }\n  return s;\n}\n\nfunction Qo(e, t) {\n  var n,\n      s = !1;\n\n  for (e <= 30 ? (n = e, s = !0) : n = R(e, Math.floor(Math.sqrt(e))); !s;) {\n    n > t || n === e ? s = !0 : n = R(e, n + 1);\n  }\n\n  return n;\n}\n\nfunction el(e, t, n) {\n  var s = [],\n      r = e.length;\n\n  for (var _a24 = 0; _a24 < r; _a24++) {\n    s.push(_a24 !== t ? e[_a24] : n);\n  }\n\n  return s;\n}\n\nfunction tl(e, t, n, s) {\n  var r = t.shape.length,\n      a = e.shape.length;\n  if (0 !== s && (s < -r || s > r)) throw new Error(\"Expect batchDims in the range of [-\".concat(r, \", \").concat(r, \"], but got \").concat(s));\n  if (s < 0 && (s += r), s > a) throw new Error(\"batchDims (\".concat(s, \") must be less than rank(x) (\\n    \").concat(a, \").\"));\n  if (n < s) throw new Error(\"batchDims (\".concat(s, \") must be less than or equal to axis (\").concat(n, \").\"));\n\n  for (var _n44 = 0; _n44 < s; ++_n44) {\n    if (e.shape[_n44] !== t.shape[_n44]) throw new Error(\"x.shape[\".concat(_n44, \"]: \").concat(e.shape[_n44], \" should be equal to indices.shape[\").concat(_n44, \"]: \").concat(t.shape[_n44], \".\"));\n  }\n\n  var i = e.shape[n],\n      o = [];\n  var l = 1,\n      u = 1,\n      c = 1;\n\n  for (var _t82 = 0; _t82 < s; ++_t82) {\n    o.push(e.shape[_t82]), l *= e.shape[_t82];\n  }\n\n  for (var _t83 = s; _t83 < n; _t83++) {\n    o.push(e.shape[_t83]), u *= e.shape[_t83];\n  }\n\n  for (var _e83 = s; _e83 < r; _e83++) {\n    o.push(t.shape[_e83]);\n  }\n\n  for (var _t84 = n + 1; _t84 < a; _t84++) {\n    o.push(e.shape[_t84]), c *= e.shape[_t84];\n  }\n\n  return {\n    batchSize: l,\n    sliceSize: c,\n    outerSize: u,\n    dimSize: i,\n    outputShape: o\n  };\n}\n\nfunction nl(e) {\n  try {\n    return e.map(e => qe(e));\n  } catch (e) {\n    throw new Error(\"Failed to decode encoded string bytes into utf-8, error: \".concat(e));\n  }\n}\n\nfunction sl(e) {\n  return e.map(e => He(e));\n}\n\nvar rl = {\n  __proto__: null,\n  slice_util: Hn,\n  segment_util: {\n    __proto__: null,\n    segOpComputeOptimalWindowSize: Qo,\n    computeOutShape: el,\n    collectGatherOpShapeInfo: tl\n  },\n  fromUint8ToStringArray: nl,\n  fromStringArrayToUint8: sl,\n  upcastType: pt,\n  axesAreInnerMostDims: jr,\n  combineLocations: Kr,\n  computeOutAndReduceShapes: Xr,\n  expandShapeToKeepDim: Yr,\n  assertAxesAreInnerMostDims: Jr,\n  getAxesPermutation: Zr,\n  getUndoAxesPermutation: Qr,\n  getInnerMostAxes: ea,\n  getBroadcastDims: ur,\n  getReductionAxes: cr,\n  assertAndGetBroadcastShape: hr,\n  assertParamsConsistent: To,\n  computeOutShape: Eo,\n  computeDilation2DInfo: bs,\n  computePool2DInfo: xs,\n  computePool3DInfo: ys,\n  computeConv2DInfo: ks,\n  computeConv3DInfo: ws,\n  computeDefaultPad: vs,\n  tupleValuesAreOne: Cs,\n  eitherStridesOrDilationsAreOne: Ts,\n  convertConv2DDataFormat: Es,\n  getFusedDyActivation: Ri,\n  getFusedBiasGradient: Ai,\n  applyActivation: Fi,\n  shouldFuse: Di,\n  PARALLELIZE_THRESHOLD: 30,\n  computeOptimalWindowSize: Ro,\n  getImageCenter: Ao,\n  getReshaped: Fo,\n  getPermuted: Do,\n  getReshapedPermuted: _o,\n  getSliceBeginCoords: Oo,\n  getSliceSize: Mo,\n  prepareAndValidate: Nn,\n  validateUpdateShape: Cn,\n  validateInput: function validateInput(e, t, n) {\n    if (t.rank < 1) throw new Error(\"tf.scatterND() expects the indices to be rank 1 or higher, but the rank was \".concat(t.rank, \".\"));\n    if (e.rank < 1) throw new Error(\"tf.scatterND() expects the updates to be rank 1 or higher, but the rank was \".concat(e.rank, \".\"));\n    if (\"int32\" !== t.dtype) throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \".concat(t.dtype));\n    if (n.length < 1) throw new Error(\"Output rank must be greater or equal to 1, but got shape: \".concat(n));\n\n    if (0 === n.length) {\n      if (0 === t.size) throw new Error(\"Indices specified for empty output. indices shape: \".concat(t.shape));\n      if (0 === e.size) throw new Error(\"Updates specified for empty output. updates shape: \".concat(e.shape));\n    }\n\n    Cn(n, t, e);\n  },\n  calculateShapes: Tn,\n  SELU_SCALEALPHA: 1.7580993408473768,\n  SELU_SCALE: 1.0507009873554805,\n  ERF_P: .3275911,\n  ERF_A1: .254829592,\n  ERF_A2: -.284496736,\n  ERF_A3: 1.421413741,\n  ERF_A4: -1.453152027,\n  ERF_A5: 1.061405429,\n  warn: W,\n  log: function log() {\n    G().getBool(\"IS_TEST\") || G().getBool(\"PROD\") || console.log(...arguments);\n  },\n  mergeRealAndImagArrays: Lo,\n  splitRealAndImagArrays: zo,\n  complexWithEvenIndex: Bo,\n  complexWithOddIndex: Po,\n  getComplexWithIndex: Wo,\n  assignToTypedArray: Uo,\n  exponents: Vo,\n  exponent: Go,\n  decodeEinsumEquation: qo,\n  getEinsumPermutation: jo,\n  checkEinsumDimSizes: Ko,\n  getEinsumComputePath: Xo,\n  isIdentityPermutation: Yo,\n  prepareSplitSize: Zo\n};\nvar al = {\n  kernelName: \"Abs\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, fi(fn(n, \"float32\"), -1))\n    };\n  }\n},\n    il = {\n  kernelName: \"Acos\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ma(fn(n, \"float32\")),\n            s = ci(Gr(Ka(1), t));\n        return Pr(ss(e, s));\n      }\n    };\n  }\n},\n    ol = {\n  kernelName: \"Acosh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ci(Gr(ma(fn(n, \"float32\")), 1));\n        return ss(e, t);\n      }\n    };\n  }\n},\n    ll = {\n  kernelName: \"Add\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = e;\n        var s = cr(n.shape, r);\n        return s.length > 0 && (t = Hr(t, s)), Rs(t, n.shape);\n      },\n      b: () => {\n        var t = e;\n        var n = cr(s.shape, r);\n        return n.length > 0 && (t = Hr(t, n)), Rs(t, s.shape);\n      }\n    };\n  }\n},\n    ul = {\n  kernelName: \"ArgMax\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => fr(n)\n    };\n  }\n},\n    cl = {\n  kernelName: \"ArgMin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => fr(n)\n    };\n  }\n},\n    hl = {\n  kernelName: \"Asin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ci(Gr(Ka(1), ma(fn(n, \"float32\")))))\n    };\n  }\n},\n    dl = {\n  kernelName: \"Asinh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = ci(ts(Ka(1), ma(fn(n, \"float32\"))));\n        return ss(e, t);\n      }\n    };\n  }\n},\n    pl = {\n  kernelName: \"Atan2\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ts(ma(n), ma(s));\n        var a = rs(e, ss(s, t));\n        var i = cr(n.shape, r);\n        return i.length > 0 && (a = Hr(a, i)), Rs(a, n.shape);\n      },\n      b: () => {\n        var t = ts(ma(n), ma(s));\n        var a = Pr(rs(e, ss(n, t)));\n        var i = cr(s.shape, r);\n        return i.length > 0 && (a = Hr(a, i)), Rs(a, s.shape);\n      }\n    };\n  }\n},\n    fl = {\n  kernelName: \"Atan\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ts(ma(fn(n, \"float32\")), 1))\n    };\n  }\n},\n    gl = {\n  kernelName: \"Atanh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, Gr(Ka(1), ma(fn(n, \"float32\"))))\n    };\n  }\n},\n    ml = Ft({\n  avgPool3dGrad_: function avgPool3dGrad_(e, t, n, s, r, a) {\n    var i = Rt(e, \"dy\", \"avgPool3dGrad\"),\n        o = Rt(t, \"input\", \"avgPool3dGrad\");\n    var u = i,\n        c = o,\n        h = !1;\n    4 === o.rank && (h = !0, u = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]]), c = Rs(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), l(5 === u.rank, () => \"Error in avgPool3dGrad: dy must be rank 5 but got rank \".concat(u.rank, \".\")), l(5 === c.rank, () => \"Error in avgPool3dGrad: input must be rank 5 but got rank \".concat(c.rank, \".\")), null != a && l(f(r), () => \"Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode \".concat(a, \" but got pad \").concat(r, \".\"));\n    var d = vt.runKernel(\"AvgPool3DGrad\", {\n      dy: u,\n      input: c\n    }, {\n      filterSize: n,\n      strides: s,\n      pad: r,\n      dimRoundingMode: a\n    });\n    return h ? Rs(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;\n  }\n}),\n    bl = {\n  kernelName: \"AvgPool3D\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      dimRoundingMode: o\n    } = n;\n    return {\n      x: () => ml(e, s, r, a, i, o)\n    };\n  }\n},\n    xl = Ft({\n  avgPoolGrad_: function avgPoolGrad_(e, t, n, s, r) {\n    var a = Rt(e, \"dy\", \"avgPoolGrad\"),\n        i = Rt(t, \"input\", \"avgPoolGrad\");\n    l(i.rank === a.rank, () => \"Rank of input (\".concat(i.rank, \") does not match rank of dy (\").concat(a.rank, \")\"));\n    var o = i,\n        u = a,\n        c = !1;\n    3 === i.rank && (c = !0, o = Rs(i, [1, i.shape[0], i.shape[1], i.shape[2]]), u = Rs(a, [1, a.shape[0], a.shape[1], a.shape[2]])), l(4 === u.rank, () => \"Error in avgPoolGrad: dy must be rank 4 but got rank \".concat(u.rank, \".\")), l(4 === o.rank, () => \"Error in avgPoolGrad: input must be rank 4 but got rank \".concat(o.rank, \".\"));\n    var h = vt.runKernel(\"AvgPoolGrad\", {\n      dy: u,\n      input: o\n    }, {\n      filterSize: n,\n      strides: s,\n      pad: r\n    });\n    return c ? Rs(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;\n  }\n}),\n    yl = {\n  kernelName: \"AvgPool\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i\n    } = n;\n    return {\n      x: () => xl(e, s, r, a, i)\n    };\n  }\n},\n    kl = {\n  kernelName: \"BatchMatMul\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      transposeA: a,\n      transposeB: i\n    } = n;\n    return a || i ? !a && i ? {\n      a: () => In(e, r, !1, !1),\n      b: () => In(e, s, !0, !1)\n    } : a && !i ? {\n      a: () => In(r, e, !1, !0),\n      b: () => In(s, e, !1, !1)\n    } : {\n      a: () => In(r, e, !0, !0),\n      b: () => In(e, s, !0, !0)\n    } : {\n      a: () => In(e, r, !1, !0),\n      b: () => In(s, e, !0, !1)\n    };\n  }\n},\n    wl = {\n  kernelName: \"BatchToSpaceND\",\n  gradFunc: (e, t, n) => {\n    var {\n      blockShape: s,\n      crops: r\n    } = n;\n    return {\n      x: () => wa(e, s, r)\n    };\n  }\n},\n    vl = {\n  kernelName: \"BroadcastTo\",\n  gradFunc: (e, t, n) => {\n    var s = n.inputShape,\n        r = n.shape,\n        a = Array.from(r);\n\n    for (var _e84 = s.length - 1; _e84 >= 0; _e84--) {\n      if (s[_e84] === r[_e84]) a[_e84] = 1;else if (1 !== s[_e84]) throw new Error(\"broadcastTo(): [\".concat(s, \"] cannot be broadcast to [\").concat(r, \"].\"));\n    }\n\n    var i = [];\n\n    for (var _e85 = 0; _e85 < a.length; _e85++) {\n      a[_e85] > 1 && i.push(_e85);\n    }\n\n    return {\n      x: () => Hr(e, i, !0)\n    };\n  }\n},\n    Il = {\n  kernelName: \"Ceil\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n},\n    $l = {\n  kernelName: \"ClipByValue\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      clipValueMin: r,\n      clipValueMax: a\n    } = n;\n    return {\n      x: () => pr(na(Tr(s, r), Or(s, a)), e, fr(e))\n    };\n  }\n},\n    Sl = {\n  kernelName: \"ComplexAbs\",\n  inputsToSave: [\"x\"],\n  gradFunc: al.gradFunc\n},\n    Nl = {\n  kernelName: \"Concat\",\n  saveAllInputs: !0,\n  gradFunc: (e, t, n) => {\n    var s = t.map(e => e.shape),\n        {\n      axis: r\n    } = n,\n        a = y(r, t[0].shape)[0],\n        i = s.map(e => e[a]);\n    return li(e, i, a).map(e => () => e);\n  }\n},\n    Cl = {\n  kernelName: \"Conv2D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      dilations: a,\n      strides: i,\n      pad: o,\n      dataFormat: u\n    } = n;\n    return l(Cs(a), () => \"Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(a, \"'\")), {\n      x: () => Zs(s.shape, e, r, i, o, u),\n      filter: () => Ei(s, e, r.shape, i, o, u)\n    };\n  }\n},\n    Tl = {\n  kernelName: \"Conv2DBackpropInput\",\n  inputsToSave: [\"dy\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      strides: a,\n      pad: i,\n      dataFormat: o,\n      dimRoundingMode: l\n    } = n;\n    return {\n      dy: () => Ys(e, r, a, i, o, 1, l),\n      filter: () => Ei(e, s, r.shape, a, i, o, l)\n    };\n  }\n},\n    El = Ft({\n  conv3DBackpropFilter_: function conv3DBackpropFilter_(e, t, n, s, r) {\n    var a = e;\n    4 === e.rank && (a = Rs(e, [1, e.shape[0], e.shape[1], e.shape[2], e.shape[3]]));\n    var i = t;\n    return 4 === i.rank && (i = Rs(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), l(5 === a.rank, () => \"Error in conv3dDerFilter: input must be rank 5, but got shape \".concat(a.shape, \".\")), l(5 === i.rank, () => \"Error in conv3dDerFilter: dy must be rank 5, but got shape \".concat(i.shape, \".\")), l(5 === n.length, () => \"Error in conv3dDerFilter: filterShape must be length 5, but got \".concat(n, \".\")), l(a.shape[4] === n[3], () => \"Error in conv3dDerFilter: depth of input \".concat(a.shape[4], \") must match input depth in filter (\").concat(n[3], \".\")), l(i.shape[4] === n[4], () => \"Error in conv3dDerFilter: depth of dy (\".concat(i.shape[4], \") must match output depth for filter (\").concat(n[4], \").\")), vt.runKernel(\"Conv3DBackpropFilterV2\", {\n      x: a,\n      dy: i\n    }, {\n      strides: s,\n      pad: r,\n      filterShape: n\n    });\n  }\n}),\n    Rl = {\n  kernelName: \"Conv3D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var {\n      dilations: s,\n      strides: r,\n      pad: a\n    } = n;\n    l(Cs(s), () => \"Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\".concat(s, \"'\"));\n    var [i, o] = t;\n    return {\n      x: () => tr(i.shape, e, o, r, a),\n      filter: () => El(i, e, o.shape, r, a)\n    };\n  }\n},\n    Al = {\n  kernelName: \"Cos\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(Pr(Za(fn(n, \"float32\"))), e)\n    };\n  }\n},\n    Fl = {\n  kernelName: \"Cosh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(Qa(fn(n, \"float32\")), e)\n    };\n  }\n},\n    Dl = {\n  kernelName: \"Cumsum\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r,\n      exclusive: a,\n      reverse: i\n    } = n;\n    return {\n      x: () => {\n        var t = Zr([r], s.rank);\n        var n = ar(e, r, a, !i);\n        return null != t && (n = Sn(n, t)), n;\n      }\n    };\n  }\n},\n    _l = {\n  kernelName: \"DepthwiseConv2dNative\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var {\n      dilations: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    } = n,\n        o = null == s ? [1, 1] : s;\n    l(Cs(o), () => \"Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '\".concat(o, \"'\"));\n    var [u, c] = t;\n    return l(4 === u.rank, () => \"Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank \".concat(u.rank, \".\")), l(4 === c.rank, () => \"Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank \".concat(c.rank, \".\")), l(u.shape[3] === c.shape[2], () => \"Error in gradient of depthwiseConv2d: number of input channels (\".concat(u.shape[3], \") must match the inChannels dimension in filter \").concat(c.shape[2], \".\")), l(Ts(r, o), () => \"Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides \".concat(r, \" and dilations '\").concat(o, \"'.\")), null != i && l(f(a), () => \"Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\")), {\n      x: () => Mi(u.shape, e, c, r, a, o, i),\n      filter: () => Oi(u, e, c.shape, r, a, o, i)\n    };\n  }\n},\n    Ol = {\n  kernelName: \"Dilation2D\",\n  inputsToSave: [\"x\", \"filter\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        a = {\n      x: s,\n      filter: r,\n      dy: e\n    },\n        i = {\n      x: s,\n      filter: r,\n      dy: e\n    };\n    return {\n      x: () => vt.runKernel(\"Dilation2DBackpropInput\", a, n),\n      filter: () => vt.runKernel(\"Dilation2DBackpropFilter\", i, n)\n    };\n  }\n},\n    Ml = {\n  kernelName: \"Elu\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = {\n      dy: e,\n      y: n\n    };\n    return {\n      x: () => vt.runKernel(\"EluGrad\", s)\n    };\n  }\n},\n    Ll = {\n  kernelName: \"Erf\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = rs(yr(Pr(ma(n))), 2 / Math.sqrt(Math.PI));\n    return {\n      x: () => rs(e, s)\n    };\n  }\n},\n    zl = {\n  kernelName: \"Exp\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, n)\n    };\n  }\n},\n    Bl = {\n  kernelName: \"ExpandDims\",\n  inputsToSave: [\"input\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      input: () => Rs(e, n.shape)\n    };\n  }\n},\n    Pl = {\n  kernelName: \"Expm1\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, yr(n))\n    };\n  }\n},\n    Wl = {\n  kernelName: \"Floor\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n},\n    Ul = {\n  kernelName: \"FloorDiv\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ss(e, fn(s, \"float32\")),\n            a = cr(n.shape, r);\n        return a.length > 0 ? Rs(Hr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = rs(e, fn(n, \"float32\"));\n        var a = cr(s.shape, r);\n        a.length > 0 && (t = Rs(Hr(t, a), s.shape));\n        var i = ma(s);\n        return Pr(ss(t, fn(i, \"float32\")));\n      }\n    };\n  }\n},\n    Vl = {\n  kernelName: \"FusedBatchNorm\",\n  inputsToSave: [\"x\", \"mean\", \"variance\", \"scale\"],\n  gradFunc: (e, t, n) => {\n    var {\n      varianceEpsilon: s\n    } = n,\n        [r, a, i, o] = t,\n        l = null == o ? Ka(1) : o,\n        u = cr(a.shape, r.shape),\n        c = [];\n\n    if (1 === a.rank) {\n      for (var _e86 = 0; _e86 < r.shape.length - 1; ++_e86) {\n        c.push(r.shape[_e86]);\n      }\n\n      c.push(1);\n    }\n\n    var h = Gr(r, a),\n        d = rs(e, l),\n        p = ja(ts(i, Ka(s))),\n        f = rs(rs(rs(p, p), p), Ka(-.5));\n    return {\n      x: () => Rs(rs(rs(e, 1 === a.rank ? vr(Rs(p, [1, 1, 1, a.shape[0]]), c) : p), l), r.shape),\n      mean: () => {\n        var e = rs(rs(p, Ka(-1)), d);\n        return 1 === a.rank && (e = Hr(e, u)), Rs(e, a.shape);\n      },\n      variance: () => {\n        var e = rs(rs(f, h), d);\n        return 1 === a.rank && (e = Hr(e, u)), Rs(e, a.shape);\n      },\n      scale: () => {\n        var t = rs(h, p);\n        var n = rs(e, t);\n        return 1 === a.rank && (n = Hr(n, u)), Rs(n, a.shape);\n      },\n      offset: () => {\n        var t = e;\n        return 1 === a.rank && (t = Hr(t, u)), Rs(t, a.shape);\n      }\n    };\n  }\n},\n    Gl = {\n  kernelName: \"GatherV2\",\n  inputsToSave: [\"x\", \"indices\"],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      axis: a\n    } = n,\n        i = y(a, s.shape)[0];\n    return {\n      x: () => {\n        var t = s.shape,\n            n = r.size,\n            o = t.slice(0, i),\n            l = o.length,\n            u = t.slice(a, t.length).slice(1),\n            c = u.length,\n            h = Hl(0, l),\n            d = Hl(l + 1, l + 1 + c),\n            p = ql([o, [n], u]),\n            f = Rs(e, p),\n            g = Rs(r, [n]),\n            m = ql([[l], h, d]),\n            b = Sn(f, m);\n        var x = vi(b, g, s.shape[i]);\n        var y = Qr(m);\n        return x = Sn(x, y), x;\n      },\n      indices: () => r\n    };\n  }\n};\n\nfunction Hl(e, t) {\n  var n = [];\n\n  for (var _s50 = e; _s50 < t; ++_s50) {\n    n.push(_s50);\n  }\n\n  return n;\n}\n\nfunction ql(e) {\n  var t = [];\n\n  for (var _n45 = 0; _n45 < e.length; ++_n45) {\n    for (var _s51 = 0; _s51 < e[_n45].length; ++_s51) {\n      t.push(e[_n45][_s51]);\n    }\n  }\n\n  return t;\n}\n\nvar jl = {\n  kernelName: \"GreaterEqual\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => fr(n),\n      b: () => fr(s)\n    };\n  }\n},\n    Kl = {\n  kernelName: \"Identity\",\n  gradFunc: e => ({\n    x: () => fn(e, \"float32\")\n  })\n},\n    Xl = {\n  kernelName: \"IsFinite\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n},\n    Yl = {\n  kernelName: \"IsInf\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n},\n    Jl = {\n  kernelName: \"IsNan\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n},\n    Zl = {\n  kernelName: \"LeakyRelu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      alpha: r\n    } = n,\n        a = Cr(s, 0);\n    return {\n      x: () => pr(a, e, rs(e, r))\n    };\n  }\n},\n    Ql = {\n  kernelName: \"Log1p\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ts(n, 1))\n    };\n  }\n},\n    eu = {\n  kernelName: \"Log\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, fn(n, \"float32\"))\n    };\n  }\n},\n    tu = {\n  kernelName: \"LogSoftmax\",\n  inputsToSave: [],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r\n    } = n;\n    return {\n      logits: () => {\n        var t = yr(s);\n        return Gr(e, rs(Hr(e, r, !0), t));\n      }\n    };\n  }\n},\n    nu = Ft({\n  localResponseNormalizationBackprop_: function localResponseNormalizationBackprop_(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 5;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : .5;\n    return vt.runKernel(\"LRNGrad\", {\n      x: e,\n      y: t,\n      dy: n\n    }, {\n      depthRadius: s,\n      bias: r,\n      alpha: a,\n      beta: i\n    });\n  }\n}),\n    su = {\n  kernelName: \"LRN\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = n;\n    return {\n      x: () => nu(s, r, e, a, i, o, l)\n    };\n  }\n};\n\nfunction ru(e, t, n, s) {\n  return t.rank < n.rank && (t = Rs(t, Yr(t.shape, s))), e.rank < n.rank && (e = Rs(e, Yr(e.shape, s))), {\n    x: () => rs(e, fn(dr(n, t), e.dtype))\n  };\n}\n\nvar au = {\n  kernelName: \"Max\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      reductionIndices: r\n    } = s,\n        a = t[0],\n        i = ru(e, t[1], a, y(r, a.shape));\n    return {\n      x: () => i.x()\n    };\n  }\n},\n    iu = {\n  kernelName: \"Maximum\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => rs(e, fn(Tr(n, s), \"float32\")),\n      b: () => rs(e, fn(_r(n, s), \"float32\"))\n    };\n  }\n},\n    ou = Ft({\n  maxPool3dGrad_: function maxPool3dGrad_(e, t, n, s, r, a, i) {\n    var o = Rt(e, \"dy\", \"maxPool3dGrad\"),\n        u = Rt(t, \"input\", \"maxPool3dGrad\"),\n        c = Rt(n, \"output\", \"maxPool3dGrad\");\n    var h = o,\n        d = u,\n        p = c,\n        g = !1;\n    4 === u.rank && (g = !0, h = Rs(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]]), d = Rs(u, [1, u.shape[0], u.shape[1], u.shape[2], u.shape[3]]), p = Rs(c, [1, c.shape[0], c.shape[1], c.shape[2], c.shape[3]])), l(5 === h.rank, () => \"Error in maxPool3dGrad: dy must be rank 5 but got rank \".concat(h.rank, \".\")), l(5 === d.rank, () => \"Error in maxPool3dGrad: input must be rank 5 but got rank \".concat(d.rank, \".\")), l(5 === p.rank, () => \"Error in maxPool3dGrad: output must be rank 5 but got rank \".concat(p.rank, \".\")), null != i && l(f(a), () => \"Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\"));\n    var m = vt.runKernel(\"MaxPool3DGrad\", {\n      dy: h,\n      input: d,\n      output: p\n    }, {\n      filterSize: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    });\n    return g ? Rs(m, [m.shape[1], m.shape[2], m.shape[3], m.shape[4]]) : m;\n  }\n}),\n    lu = {\n  kernelName: \"MaxPool3D\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l\n    } = n;\n    return {\n      x: () => ou(e, s, r, a, i, o, l)\n    };\n  }\n},\n    uu = Ft({\n  maxPoolGrad_: function maxPoolGrad_(e, t, n, s, r, a, i) {\n    var o = Rt(e, \"dy\", \"maxPoolGrad\"),\n        u = Rt(t, \"input\", \"maxPoolGrad\"),\n        c = Rt(n, \"output\", \"maxPoolGrad\");\n    return l(u.rank === o.rank, () => \"Rank of input (\".concat(u.rank, \") does not match rank of dy (\").concat(o.rank, \")\")), l(4 === o.rank, () => \"Error in maxPoolGrad: dy must be rank 4 but got rank \".concat(o.rank, \".\")), l(4 === u.rank, () => \"Error in maxPoolGrad: input must be rank 4 but got rank \".concat(u.rank, \".\")), null != i && l(f(a), () => \"Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode \".concat(i, \" but got pad \").concat(a, \".\")), vt.runKernel(\"MaxPoolGrad\", {\n      dy: o,\n      input: u,\n      output: c\n    }, {\n      filterSize: s,\n      strides: r,\n      pad: a,\n      dimRoundingMode: i\n    });\n  }\n}),\n    cu = {\n  kernelName: \"PadV2\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var s = t[0],\n        {\n      paddings: r\n    } = n,\n        a = r.map(e => e[0]);\n    return {\n      x: () => Os(e, a, s.shape)\n    };\n  }\n},\n    hu = {\n  kernelName: \"SpaceToBatchND\",\n  gradFunc: (e, t, n) => {\n    var {\n      blockShape: s,\n      paddings: r\n    } = n;\n    return {\n      x: () => Ls(e, s, r)\n    };\n  }\n},\n    du = {\n  kernelName: \"SplitV\",\n  gradFunc: (e, t, n) => {\n    var {\n      axis: s\n    } = n;\n    return {\n      x: () => Ds(e, s)\n    };\n  }\n},\n    pu = [al, il, ol, ll, {\n  kernelName: \"AddN\",\n  saveAllInputs: !0,\n  gradFunc: (e, t) => {\n    var n = {};\n    return t.forEach((t, s) => {\n      n[s] = () => e.clone();\n    }), n;\n  }\n}, ul, cl, hl, dl, pl, fl, gl, bl, yl, kl, wl, vl, {\n  kernelName: \"Cast\",\n  gradFunc: e => ({\n    x: () => e.clone()\n  })\n}, Il, $l, Sl, Nl, Tl, Cl, Rl, Al, Fl, Dl, _l, Ol, {\n  kernelName: \"RealDiv\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = ss(e, fn(s, \"float32\")),\n            a = cr(n.shape, r);\n        return a.length > 0 ? Rs(Hr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = rs(e, fn(n, \"float32\"));\n        var a = cr(s.shape, r);\n        a.length > 0 && (t = Rs(Hr(t, a), s.shape));\n        var i = ma(s);\n        return Pr(ss(t, fn(i, \"float32\")));\n      }\n    };\n  }\n}, Ml, Ll, zl, Bl, Pl, Ul, Wl, Vl, Gl, jl, Kl, Xl, Yl, Jl, Zl, Ql, eu, tu, su, au, au, iu, lu, {\n  kernelName: \"MaxPool\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s, r] = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o\n    } = n;\n    return {\n      x: () => uu(e, s, r, a, i, o)\n    };\n  }\n}, {\n  kernelName: \"Mean\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      axis: r\n    } = n,\n        a = y(r, s.shape),\n        i = d(Xr(s.shape, a)[1]);\n    return {\n      x: () => {\n        var t = s.shape.slice();\n        a.forEach(e => {\n          t[e] = 1;\n        });\n        var n = Rs(e, t);\n        return ss(rs(n, ha(s.shape, \"float32\")), i);\n      }\n    };\n  }\n}, {\n  kernelName: \"Min\",\n  inputsToSave: [\"x\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      axis: r\n    } = s,\n        [a, i] = t,\n        o = ru(e, i, a, y(r, a.shape));\n    return {\n      x: () => o.x()\n    };\n  }\n}, {\n  kernelName: \"Minimum\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t;\n    return {\n      a: () => rs(e, fn(Or(n, s), \"float32\")),\n      b: () => rs(e, fn(Cr(n, s), \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"MirrorPad\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var s = t[0],\n        {\n      paddings: r\n    } = n,\n        a = r.map(e => e[0]);\n    return {\n      x: () => Os(e, a, s.shape)\n    };\n  }\n}, {\n  kernelName: \"Mod\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = cr(n.shape, r);\n        return t.length > 0 ? Rs(Hr(e, t), n.shape) : e;\n      },\n      b: () => {\n        var t = rs(e, Pr(Sr(ss(n, s)))),\n            a = cr(s.shape, r);\n        return a.length > 0 ? Rs(Hr(t, a), s.shape) : t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Multiply\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = rs(e, fn(s, \"float32\")),\n            a = cr(n.shape, r);\n        return a.length > 0 ? Rs(Hr(t, a), n.shape) : t;\n      },\n      b: () => {\n        var t = rs(e, fn(n, \"float32\")),\n            a = cr(s.shape, r);\n        return a.length > 0 ? Rs(Hr(t, a), s.shape) : t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Neg\",\n  gradFunc: e => ({\n    x: () => Pr(e)\n  })\n}, {\n  kernelName: \"OneHot\",\n  inputsToSave: [\"indices\"],\n  gradFunc: (e, t) => {\n    var n = t[0];\n    return {\n      indices: () => ca(n.shape, \"float32\")\n    };\n  }\n}, {\n  kernelName: \"OnesLike\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n}, {\n  kernelName: \"Pack\",\n  saveAllInputs: !0,\n  gradFunc: (e, t, n) => {\n    var {\n      axis: s\n    } = n;\n    return Ii(e, s).map(e => () => e);\n  }\n}, cu, cu, {\n  kernelName: \"Pow\",\n  inputsToSave: [\"a\", \"b\"],\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n, s, r] = t,\n        _a25 = n,\n        i = s,\n        o = hr(_a25.shape, i.shape);\n    return {\n      a: () => {\n        var t = fn(i, \"float32\");\n        var n = rs(e, rs(t, Ia(_a25, Gr(t, Ka(1)))));\n        var s = cr(_a25.shape, o);\n        return s.length > 0 && (n = Hr(n, s)), Rs(n, _a25.shape);\n      },\n      b: () => {\n        var t = Cr(_a25, 0),\n            n = pr(t, Lr(_a25), fr(_a25));\n        var s = rs(e, rs(r, n));\n        var l = cr(i.shape, o);\n        return l.length > 0 && (s = Hr(s, l)), Rs(s, i.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Prelu\",\n  inputsToSave: [\"x\", \"alpha\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = Cr(n, 0);\n    return {\n      x: () => pr(r, e, rs(e, s)),\n      alpha: () => {\n        var t = pr(r, fr(e), rs(e, n));\n        var a = cr(s.shape, e.shape);\n        return a.length > 0 && (t = Hr(t, a)), Rs(t, s.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Reciprocal\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, Pr(ma(n)))\n    };\n  }\n}, {\n  kernelName: \"Relu6\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t,\n        s = rs(Or(n, 6), fi(n));\n    return {\n      x: () => rs(e, fn(s, \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"Relu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, fn(fi(n), \"float32\"))\n    };\n  }\n}, {\n  kernelName: \"Reshape\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => Rs(e, n.shape)\n    };\n  }\n}, {\n  kernelName: \"ResizeBilinear\",\n  inputsToSave: [\"images\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = {\n      dy: e,\n      images: s\n    };\n    return {\n      images: () => vt.runKernel(\"ResizeBilinearGrad\", r, n)\n    };\n  }\n}, {\n  kernelName: \"ResizeNearestNeighbor\",\n  inputsToSave: [\"images\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = {\n      dy: e,\n      images: s\n    };\n    return {\n      images: () => vt.runKernel(\"ResizeNearestNeighborGrad\", r, n)\n    };\n  }\n}, {\n  kernelName: \"Reverse\",\n  gradFunc: (e, t, n) => {\n    var {\n      dims: s\n    } = n,\n        r = y(s, e.shape);\n    return {\n      x: () => Ha(e, r)\n    };\n  }\n}, {\n  kernelName: \"Round\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n}, {\n  kernelName: \"Rsqrt\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => Pr(ss(e, rs(Ia(n, 1.5), 2)))\n    };\n  }\n}, {\n  kernelName: \"Select\",\n  inputsToSave: [\"condition\"],\n  gradFunc: (_e87, t) => {\n    var [n] = t;\n    return {\n      condition: () => fn(fr(n), \"float32\"),\n      t: () => rs(_e87, fn(n, _e87.dtype)),\n      e: () => rs(_e87, fn(sa(n), _e87.dtype))\n    };\n  }\n}, {\n  kernelName: \"Selu\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => {\n        var t = Cr(n, Ka(0)),\n            s = Ka(1.7580993408473768),\n            r = Ka(1.0507009873554805),\n            a = rs(e, r),\n            i = rs(rs(e, s), yr(fn(n, \"float32\")));\n        return pr(t, a, i);\n      }\n    };\n  }\n}, {\n  kernelName: \"Sigmoid\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, rs(n, Gr(Ka(1), n)))\n    };\n  }\n}, {\n  kernelName: \"Sign\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n}, {\n  kernelName: \"Sin\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(sr(fn(n, \"float32\")), e)\n    };\n  }\n}, {\n  kernelName: \"Sinh\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(rr(fn(n, \"float32\")), e)\n    };\n  }\n}, {\n  kernelName: \"Slice\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      begin: r,\n      size: a\n    } = n,\n        i = s.shape,\n        [o, l] = Vn(s, r, a),\n        u = [];\n\n    for (var _t85 = 0; _t85 < e.rank; _t85++) {\n      u.push([o[_t85], i[_t85] - o[_t85] - l[_t85]]);\n    }\n\n    return {\n      x: () => ka(e, u)\n    };\n  }\n}, {\n  kernelName: \"Softmax\",\n  outputsToSave: [!0],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      dim: r\n    } = n,\n        a = rs(e, s);\n    return {\n      logits: () => Gr(a, rs(Hr(a, [r], !0), s))\n    };\n  }\n}, {\n  kernelName: \"Softplus\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, _s(n))\n    };\n  }\n}, hu, hu, du, du, {\n  kernelName: \"Sqrt\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, rs(ci(fn(n, \"float32\")), 2))\n    };\n  }\n}, {\n  kernelName: \"SquaredDifference\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = Ka(2);\n    return {\n      a: () => rs(e, rs(r, Gr(n, s))),\n      b: () => rs(e, rs(r, Gr(s, n)))\n    };\n  }\n}, {\n  kernelName: \"Square\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(e, rs(fn(n, \"float32\"), 2))\n    };\n  }\n}, {\n  kernelName: \"Step\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n}, {\n  kernelName: \"Sub\",\n  inputsToSave: [\"a\", \"b\"],\n  gradFunc: (e, t) => {\n    var [n, s] = t,\n        r = hr(n.shape, s.shape);\n    return {\n      a: () => {\n        var t = e;\n        var s = cr(n.shape, r);\n        return s.length > 0 && (t = Hr(t, s)), Rs(t, n.shape);\n      },\n      b: () => {\n        var t = e;\n        var n = cr(s.shape, r);\n        return n.length > 0 && (t = Hr(t, n)), Rs(Pr(t), s.shape);\n      }\n    };\n  }\n}, {\n  kernelName: \"Sum\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        r = s.shape.slice(),\n        {\n      axis: a\n    } = n;\n    y(a, s.shape).forEach(e => {\n      r[e] = 1;\n    });\n    var i = Rs(e, r),\n        o = rs(i, ha(s.shape, \"float32\"));\n    return {\n      x: () => o\n    };\n  }\n}, {\n  kernelName: \"Tan\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => ss(e, ma(sr(n)))\n    };\n  }\n}, {\n  kernelName: \"Tanh\",\n  outputsToSave: [!0],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => rs(Gr(Ka(1), ma(n)), e)\n    };\n  }\n}, {\n  kernelName: \"Tile\",\n  inputsToSave: [\"x\"],\n  gradFunc: (e, t, n) => {\n    var [s] = t,\n        {\n      reps: r\n    } = n;\n    return {\n      x: () => {\n        var t = fr(s);\n        if (1 === s.rank) for (var _n46 = 0; _n46 < r[0]; ++_n46) {\n          t = ts(t, Os(e, [_n46 * s.shape[0]], [s.shape[0]]));\n        } else if (2 === s.rank) for (var _n47 = 0; _n47 < r[0]; ++_n47) {\n          for (var _a26 = 0; _a26 < r[1]; ++_a26) {\n            t = ts(t, Os(e, [_n47 * s.shape[0], _a26 * s.shape[1]], [s.shape[0], s.shape[1]]));\n          }\n        } else if (3 === s.rank) for (var _n48 = 0; _n48 < r[0]; ++_n48) {\n          for (var _a27 = 0; _a27 < r[1]; ++_a27) {\n            for (var _i16 = 0; _i16 < r[2]; ++_i16) {\n              t = ts(t, Os(e, [_n48 * s.shape[0], _a27 * s.shape[1], _i16 * s.shape[2]], [s.shape[0], s.shape[1], s.shape[2]]));\n            }\n          }\n        } else {\n          if (4 !== s.rank) throw new Error(\"Gradient for tile operation is not implemented for rank-\".concat(s.rank, \" tensors yet.\"));\n\n          for (var _n49 = 0; _n49 < r[0]; ++_n49) {\n            for (var _a28 = 0; _a28 < r[1]; ++_a28) {\n              for (var _i17 = 0; _i17 < r[2]; ++_i17) {\n                for (var _o14 = 0; _o14 < r[3]; ++_o14) {\n                  t = ts(t, Os(e, [_n49 * s.shape[0], _a28 * s.shape[1], _i17 * s.shape[2], _o14 * s.shape[3]], [s.shape[0], s.shape[1], s.shape[2], s.shape[3]]));\n                }\n              }\n            }\n          }\n        }\n        return t;\n      }\n    };\n  }\n}, {\n  kernelName: \"Transpose\",\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      perm: r\n    } = s,\n        a = Qr(r);\n    return {\n      x: () => Sn(e, a)\n    };\n  }\n}, {\n  kernelName: \"Unpack\",\n  gradFunc: (e, t, n) => {\n    var s = n,\n        {\n      axis: r\n    } = s;\n    return {\n      value: () => pi(e, r)\n    };\n  }\n}, {\n  kernelName: \"UnsortedSegmentSum\",\n  inputsToSave: [\"segmentIds\"],\n  gradFunc: (e, t) => {\n    var [n] = t;\n    return {\n      x: () => function (e, t) {\n        var n = la(t, fr(t)),\n            s = Nr(e, n);\n        var r = Tr(t, Ka(0, \"int32\"));\n        var a = s.rank - r.rank;\n\n        for (var _e88 = 0; _e88 < a; ++_e88) {\n          r = kr(r, _e88 + 1);\n        }\n\n        r = na(r, ha(s.shape, \"bool\"));\n        var i = fr(s);\n        return pr(r, s, i);\n      }(e, n)\n    };\n  }\n}, {\n  kernelName: \"ZerosLike\",\n  gradFunc: e => ({\n    x: () => fr(e)\n  })\n}];\n\nfor (var _e89 of pu) {\n  te(_e89);\n}\n\nvar fu;\n\nfunction gu() {\n  return null == fu && (fu = vt.backend.epsilon()), fu;\n}\n\nat().prototype.abs = function () {\n  return this.throwIfDisposed(), as(this);\n}, at().prototype.acos = function () {\n  return this.throwIfDisposed(), is(this);\n}, at().prototype.acosh = function () {\n  return this.throwIfDisposed(), os(this);\n}, at().prototype.add = function (e) {\n  return this.throwIfDisposed(), ts(this, e);\n}, at().prototype.all = function (e, t) {\n  return this.throwIfDisposed(), ls(this, e, t);\n}, at().prototype.any = function (e, t) {\n  return this.throwIfDisposed(), us(this, e, t);\n}, at().prototype.argMax = function (e) {\n  return this.throwIfDisposed(), cs(this, e);\n}, at().prototype.argMin = function (e) {\n  return this.throwIfDisposed(), hs(this, e);\n}, at().prototype.asScalar = function () {\n  return this.throwIfDisposed(), l(1 === this.size, () => \"The array must have only 1 element.\"), Rs(this, []);\n}, at().prototype.asType = function (e) {\n  return this.throwIfDisposed(), fn(this, e);\n}, at().prototype.as1D = function () {\n  return this.throwIfDisposed(), Rs(this, [this.size]);\n}, at().prototype.as2D = function (e, t) {\n  return this.throwIfDisposed(), Rs(this, [e, t]);\n}, at().prototype.as3D = function (e, t, n) {\n  return this.throwIfDisposed(), Rs(this, [e, t, n]);\n}, at().prototype.as4D = function (e, t, n, s) {\n  return this.throwIfDisposed(), Rs(this, [e, t, n, s]);\n}, at().prototype.as5D = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), Rs(this, [e, t, n, s, r]);\n}, at().prototype.asin = function () {\n  return this.throwIfDisposed(), ds(this);\n}, at().prototype.asinh = function () {\n  return this.throwIfDisposed(), ps(this);\n}, at().prototype.atan = function () {\n  return this.throwIfDisposed(), fs(this);\n}, at().prototype.atan2 = function (e) {\n  return this.throwIfDisposed(), gs(this, e);\n}, at().prototype.atanh = function () {\n  return this.throwIfDisposed(), ms(this);\n}, at().prototype.avgPool = function (e, t, n, s) {\n  return this.throwIfDisposed(), As(this, e, t, n, s);\n}, at().prototype.batchToSpaceND = function (e, t) {\n  return this.throwIfDisposed(), Ls(this, e, t);\n}, at().prototype.batchNorm = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), zs(this, e, t, n, s, r);\n}, at().prototype.broadcastTo = function (e) {\n  return this.throwIfDisposed(), Vs(this, e);\n}, at().prototype.cast = function (e) {\n  return this.throwIfDisposed(), fn(this, e);\n}, at().prototype.ceil = function () {\n  return this.throwIfDisposed(), Gs(this);\n}, at().prototype.clipByValue = function (e, t) {\n  return this.throwIfDisposed(), Hs(this, e, t);\n}, at().prototype.concat = function (e, t) {\n  return this.throwIfDisposed(), e instanceof rt && (e = [e]), Ds([this, ...e], t);\n}, at().prototype.conv1d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Js(this, e, t, n, s, r, a);\n}, at().prototype.conv2dTranspose = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), Qs(this, e, t, n, s, r);\n}, at().prototype.conv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Ys(this, e, t, n, s, r, a);\n}, at().prototype.cos = function () {\n  return this.throwIfDisposed(), sr(this);\n}, at().prototype.cosh = function () {\n  return this.throwIfDisposed(), rr(this);\n}, at().prototype.cumsum = function (e, t, n) {\n  return this.throwIfDisposed(), ar(this, e, t, n);\n}, at().prototype.depthToSpace = function (e, t) {\n  return this.throwIfDisposed(), ir(this, e, t);\n}, at().prototype.depthwiseConv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), or(this, e, t, n, s, r, a);\n}, at().prototype.dilation2d = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), lr(this, e, t, n, s, r);\n}, at().prototype.divNoNan = function (e) {\n  return this.throwIfDisposed(), gr(this, e);\n}, at().prototype.div = function (e) {\n  return this.throwIfDisposed(), ss(this, e);\n}, at().prototype.dot = function (e) {\n  return this.throwIfDisposed(), mr(this, e);\n}, at().prototype.elu = function () {\n  return this.throwIfDisposed(), br(this);\n}, at().prototype.equal = function (e) {\n  return this.throwIfDisposed(), dr(this, e);\n}, at().prototype.erf = function () {\n  return this.throwIfDisposed(), xr(this);\n}, at().prototype.exp = function () {\n  return this.throwIfDisposed(), yr(this);\n}, at().prototype.expandDims = function (e) {\n  return this.throwIfDisposed(), kr(this, e);\n}, at().prototype.expm1 = function () {\n  return this.throwIfDisposed(), wr(this);\n}, at().prototype.fft = function () {\n  return this.throwIfDisposed(), ai(this);\n}, at().prototype.flatten = function () {\n  return this.throwIfDisposed(), Rs(this, [this.size]);\n}, at().prototype.floor = function () {\n  return this.throwIfDisposed(), Sr(this);\n}, at().prototype.floorDiv = function (e) {\n  return this.throwIfDisposed(), ns(this, e);\n}, at().prototype.gather = function (e, t) {\n  return this.throwIfDisposed(), Nr(this, e, t);\n}, at().prototype.greaterEqual = function (e) {\n  return this.throwIfDisposed(), Tr(this, e);\n}, at().prototype.greater = function (e) {\n  return this.throwIfDisposed(), Cr(this, e);\n}, at().prototype.ifft = function () {\n  return this.throwIfDisposed(), ii(this);\n}, at().prototype.irfft = function () {\n  return this.throwIfDisposed(), oi(this);\n}, at().prototype.isFinite = function () {\n  return this.throwIfDisposed(), Rr(this);\n}, at().prototype.isInf = function () {\n  return this.throwIfDisposed(), Ar(this);\n}, at().prototype.isNaN = function () {\n  return this.throwIfDisposed(), Fr(this);\n}, at().prototype.leakyRelu = function (e) {\n  return this.throwIfDisposed(), Dr(this, e);\n}, at().prototype.lessEqual = function (e) {\n  return this.throwIfDisposed(), Or(this, e);\n}, at().prototype.less = function (e) {\n  return this.throwIfDisposed(), _r(this, e);\n}, at().prototype.localResponseNormalization = function (e, t, n, s) {\n  return this.throwIfDisposed(), Mr(this, e, t, n, s);\n}, at().prototype.logSigmoid = function () {\n  return this.throwIfDisposed(), Ur(this);\n}, at().prototype.logSoftmax = function (e) {\n  return this.throwIfDisposed(), qr(this, e);\n}, at().prototype.logSumExp = function (e, t) {\n  return this.throwIfDisposed(), ta(this, e, t);\n}, at().prototype.log = function () {\n  return this.throwIfDisposed(), Lr(this);\n}, at().prototype.log1p = function () {\n  return this.throwIfDisposed(), zr(this);\n}, at().prototype.logicalAnd = function (e) {\n  return this.throwIfDisposed(), na(this, e);\n}, at().prototype.logicalNot = function () {\n  return this.throwIfDisposed(), sa(this);\n}, at().prototype.logicalOr = function (e) {\n  return this.throwIfDisposed(), ra(this, e);\n}, at().prototype.logicalXor = function (e) {\n  return this.throwIfDisposed(), aa(this, e);\n}, at().prototype.matMul = function (e, t, n) {\n  return this.throwIfDisposed(), In(this, e, t, n);\n}, at().prototype.maxPool = function (e, t, n, s) {\n  return this.throwIfDisposed(), ia(this, e, t, n, s);\n}, at().prototype.max = function (e, t) {\n  return this.throwIfDisposed(), Vr(this, e, t);\n}, at().prototype.maximum = function (e) {\n  return this.throwIfDisposed(), la(this, e);\n}, at().prototype.mean = function (e, t) {\n  return this.throwIfDisposed(), ua(this, e, t);\n}, at().prototype.min = function (e, t) {\n  return this.throwIfDisposed(), da(this, e, t);\n}, at().prototype.minimum = function (e) {\n  return this.throwIfDisposed(), pa(this, e);\n}, at().prototype.mirrorPad = function (e, t) {\n  return this.throwIfDisposed(), fa(this, e, t);\n}, at().prototype.mod = function (e) {\n  return this.throwIfDisposed(), ga(this, e);\n}, at().prototype.mul = function (e) {\n  return this.throwIfDisposed(), rs(this, e);\n}, at().prototype.neg = function () {\n  return this.throwIfDisposed(), Pr(this);\n}, at().prototype.norm = function (e, t, n) {\n  return this.throwIfDisposed(), Ni(this, e, t, n);\n}, at().prototype.notEqual = function (e) {\n  return this.throwIfDisposed(), xa(this, e);\n}, at().prototype.oneHot = function (e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  return this.throwIfDisposed(), $n(this, e, t, n);\n}, at().prototype.onesLike = function () {\n  return this.throwIfDisposed(), ya(this);\n}, at().prototype.pad = function (e, t) {\n  return this.throwIfDisposed(), ka(this, e, t);\n}, at().prototype.pool = function (e, t, n, s, r) {\n  return this.throwIfDisposed(), va(this, e, t, n, s, r);\n}, at().prototype.pow = function (e) {\n  return this.throwIfDisposed(), Ia(this, e);\n}, at().prototype.prelu = function (e) {\n  return this.throwIfDisposed(), $a(this, e);\n}, at().prototype.prod = function (e, t) {\n  return this.throwIfDisposed(), Sa(this, e, t);\n}, at().prototype.reciprocal = function () {\n  return this.throwIfDisposed(), Ua(this);\n}, at().prototype.relu = function () {\n  return this.throwIfDisposed(), Va(this);\n}, at().prototype.relu6 = function () {\n  return this.throwIfDisposed(), Ga(this);\n}, at().prototype.reshapeAs = function (e) {\n  return this.throwIfDisposed(), Rs(this, e.shape);\n}, at().prototype.reshape = function (e) {\n  return this.throwIfDisposed(), Rs(this, e);\n}, at().prototype.resizeBilinear = function (e, t, n) {\n  return this.throwIfDisposed(), so(this, e, t, n);\n}, at().prototype.resizeNearestNeighbor = function (e, t, n) {\n  return this.throwIfDisposed(), ro(this, e, t, n);\n}, at().prototype.reverse = function (e) {\n  return this.throwIfDisposed(), Ha(this, e);\n}, at().prototype.rfft = function () {\n  return this.throwIfDisposed(), ui(this);\n}, at().prototype.round = function () {\n  return this.throwIfDisposed(), qa(this);\n}, at().prototype.rsqrt = function () {\n  return this.throwIfDisposed(), ja(this);\n}, at().prototype.selu = function () {\n  return this.throwIfDisposed(), Xa(this);\n}, at().prototype.separableConv2d = function (e, t, n, s, r, a) {\n  return this.throwIfDisposed(), Ya(this, e, t, n, s, r, a);\n}, at().prototype.sigmoid = function () {\n  return this.throwIfDisposed(), _s(this);\n}, at().prototype.sign = function () {\n  return this.throwIfDisposed(), Ja(this);\n}, at().prototype.sin = function () {\n  return this.throwIfDisposed(), Za(this);\n}, at().prototype.sinh = function () {\n  return this.throwIfDisposed(), Qa(this);\n}, at().prototype.slice = function (e, t) {\n  return this.throwIfDisposed(), Os(this, e, t);\n}, at().prototype.softmax = function (e) {\n  return this.throwIfDisposed(), ri(this, e);\n}, at().prototype.softplus = function () {\n  return this.throwIfDisposed(), Wr(this);\n}, at().prototype.spaceToBatchND = function (e, t) {\n  return this.throwIfDisposed(), wa(this, e, t);\n}, at().prototype.split = function (e, t) {\n  return this.throwIfDisposed(), li(this, e, t);\n}, at().prototype.sqrt = function () {\n  return this.throwIfDisposed(), ci(this);\n}, at().prototype.square = function () {\n  return this.throwIfDisposed(), ma(this);\n}, at().prototype.squaredDifference = function (e) {\n  return this.throwIfDisposed(), hi(this, e);\n}, at().prototype.squeeze = function (e) {\n  return this.throwIfDisposed(), di(this, e);\n}, at().prototype.stack = function (e, t) {\n  this.throwIfDisposed();\n  var n = e instanceof rt ? [this, e] : [this, ...e];\n  return pi(n, t);\n}, at().prototype.step = function (e) {\n  return this.throwIfDisposed(), fi(this, e);\n}, at().prototype.stridedSlice = function (e, t, n, s, r, a, i, o) {\n  return this.throwIfDisposed(), gi(this, e, t, n, s, r, a, i, o);\n}, at().prototype.sub = function (e) {\n  return this.throwIfDisposed(), Gr(this, e);\n}, at().prototype.sum = function (e, t) {\n  return this.throwIfDisposed(), Hr(this, e, t);\n}, at().prototype.tan = function () {\n  return this.throwIfDisposed(), mi(this);\n}, at().prototype.tanh = function () {\n  return this.throwIfDisposed(), Ms(this);\n}, at().prototype.tile = function (e) {\n  return this.throwIfDisposed(), vr(this, e);\n}, at().prototype.toBool = function () {\n  return this.throwIfDisposed(), fn(this, \"bool\");\n}, at().prototype.toFloat = function () {\n  return this.throwIfDisposed(), fn(this, \"float32\");\n}, at().prototype.toInt = function () {\n  return this.throwIfDisposed(), fn(this, \"int32\");\n}, at().prototype.topk = function (e, t) {\n  return this.throwIfDisposed(), yi(this, e, t);\n}, at().prototype.transpose = function (e) {\n  return this.throwIfDisposed(), Sn(this, e);\n}, at().prototype.unique = function (e) {\n  return this.throwIfDisposed(), wi(this, e);\n}, at().prototype.unsortedSegmentSum = function (e, t) {\n  return this.throwIfDisposed(), vi(this, e, t);\n}, at().prototype.unstack = function (e) {\n  return this.throwIfDisposed(), Ii(this, e);\n}, at().prototype.where = function (e, t) {\n  return this.throwIfDisposed(), pr(e, this, t);\n}, at().prototype.zerosLike = function () {\n  return this.throwIfDisposed(), fr(this);\n};\n\nclass mu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, mu.prototype);\n  }\n\n}\n\nclass bu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, bu.prototype);\n  }\n\n}\n\nclass xu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, xu.prototype);\n  }\n\n}\n\nclass yu extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, yu.prototype);\n  }\n\n}\n\nclass ku extends Error {\n  constructor(e) {\n    super(e), Object.setPrototypeOf(this, ku.prototype);\n  }\n\n}\n\nfunction wu(e, t) {\n  if (Array.isArray(e)) {\n    var _n50 = [];\n\n    for (var _s52 = 0; _s52 < t; _s52++) {\n      _n50 = _n50.concat(e);\n    }\n\n    return _n50;\n  }\n\n  {\n    var _n51 = new Array(t);\n\n    return _n51.fill(e), _n51;\n  }\n}\n\nfunction vu(e, t) {\n  if (!e) throw new ku(t);\n}\n\nfunction Iu(e, t) {\n  var n = 0;\n\n  for (var _s53 of e) {\n    _s53 === t && n++;\n  }\n\n  return n;\n}\n\nfunction $u(e) {\n  return 1 === e.length ? e[0] : e;\n}\n\nfunction Su(e) {\n  return Array.isArray(e) ? e : [e];\n}\n\nfunction Nu(e) {\n  var t = e.replace(/(.)([A-Z][a-z0-9]+)/g, \"$1_$2\").replace(/([a-z])([A-Z])/g, \"$1_$2\").toLowerCase();\n  return \"_\" !== t[0] ? t : \"private\" + t;\n}\n\nfunction Cu(e) {\n  return e.length <= 1 || -1 === e.indexOf(\"_\") ? e : e.replace(/[_]+(\\w|$)/g, (e, t) => t.toUpperCase());\n}\n\nvar Tu = {};\n\nfunction Eu(e) {\n  if (null == e) return null;\n  var t = {};\n  return t.className = e.getClassName(), t.config = e.getConfig(), t;\n}\n\nfunction Ru(e) {\n  if (null != e && \"object\" == typeof e) if (Array.isArray(e)) e.forEach(e => Ru(e));else {\n    var _t86 = Object.keys(e);\n\n    for (var _n52 of _t86) {\n      var _t87 = e[_n52];\n      null != _t87 && \"object\" == typeof _t87 && (Array.isArray(_t87) || \"ndarray\" !== _t87.type || \"number\" != typeof _t87.value ? Ru(_t87) : e[_n52] = _t87.value);\n    }\n  }\n}\n\nfunction Au(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"object\";\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n\n  if (\"string\" == typeof e) {\n    var _r38 = e;\n\n    var _a29;\n\n    if (_r38 in n) _a29 = n[_r38];else if (_r38 in Tu) _a29 = Tu[_r38];else if (_a29 = t[_r38], null == _a29) throw new xu(\"Unknown \".concat(s, \": \").concat(e, \". This may be due to one of the following reasons:\\n1. The \").concat(s, \" is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\\n2. The custom \").concat(s, \" is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().\"));\n    return _a29;\n  }\n\n  {\n    var _a30 = e;\n    if (null == _a30.className || null == _a30.config) throw new xu(\"\".concat(s, \": Improper config format: \").concat(JSON.stringify(_a30), \".\\n'className' and 'config' must set.\"));\n    var _i18 = _a30.className;\n\n    var _o15, _l9;\n\n    if (_i18 in n ? [_o15, _l9] = n[_i18] : _i18 in Tu ? [_o15, _l9] = Tu.className : _i18 in t && ([_o15, _l9] = t[_i18]), null == _o15) throw new xu(\"Unknown \".concat(s, \": \").concat(_i18, \". This may be due to one of the following reasons:\\n1. The \").concat(s, \" is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\\n2. The custom \").concat(s, \" is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().\"));\n\n    if (null != _l9) {\n      var _e90 = {};\n\n      for (var _t89 of Object.keys(Tu)) {\n        _e90[_t89] = Tu[_t89];\n      }\n\n      for (var _t90 of Object.keys(n)) {\n        _e90[_t90] = n[_t90];\n      }\n\n      _a30.config.customObjects = _e90;\n\n      var _t88 = Object.assign({}, Tu);\n\n      for (var _e91 of Object.keys(n)) {\n        Tu[_e91] = n[_e91];\n      }\n\n      Ru(_a30.config);\n\n      var _s54 = _l9(_o15, _a30.config, n, r);\n\n      return Tu = Object.assign({}, _t88), _s54;\n    }\n\n    {\n      var _e92 = Object.assign({}, Tu);\n\n      for (var _e93 of Object.keys(n)) {\n        Tu[_e93] = n[_e93];\n      }\n\n      var _t91 = new _o15(_a30.config);\n\n      return Tu = Object.assign({}, _e92), _t91;\n    }\n  }\n}\n\nfunction Fu(e, t) {\n  return -1 * function (e, t) {\n    return e < t ? -1 : e > t ? 1 : 0;\n  }(e, t);\n}\n\nfunction Du(e) {\n  if (null == e) return e;\n  var t = [];\n\n  for (var _n53 of e) {\n    -1 === t.indexOf(_n53) && t.push(_n53);\n  }\n\n  return t;\n}\n\nfunction _u(e) {\n  if (null == e) throw new xu(\"Invalid value in obj: \".concat(JSON.stringify(e)));\n\n  for (var _t92 in e) {\n    if (e.hasOwnProperty(_t92)) return !1;\n  }\n\n  return !0;\n}\n\nfunction Ou(e, t, n) {\n  if (null != n && e.indexOf(n) < 0) throw new xu(\"\".concat(n, \" is not a valid \").concat(t, \".  Valid values are \").concat(e, \" or null/undefined.\"));\n}\n\nfunction Mu(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Infinity;\n  return vu(n >= 0), vu(s >= n), Array.isArray(e) && e.length >= n && e.length <= s && e.every(e => typeof e === t);\n}\n\nfunction Lu(e, t) {\n  Array.isArray(e) ? (l(e.length > 0, () => \"\".concat(t, \" is unexpectedly an empty array.\")), e.forEach((e, n) => Lu(e, \"element \".concat(n + 1, \" of \").concat(t)))) : l(Number.isInteger(e) && e > 0, () => \"Expected \".concat(t, \" to be a positive integer, but got \").concat(zu(e), \".\"));\n}\n\nfunction zu(e) {\n  return null === e ? \"null\" : Array.isArray(e) ? \"[\" + e.map(e => zu(e)).join(\",\") + \"]\" : \"string\" == typeof e ? \"\\\"\".concat(e, \"\\\"\") : \"\".concat(e);\n}\n\nfunction Bu(e) {\n  return \"relu\" === e ? \"relu\" : \"linear\" === e ? \"linear\" : \"elu\" === e ? \"elu\" : null;\n}\n\nfunction Pu(e, t) {\n  return Jn(() => ci(Hr(rs(e, e), t, !0)));\n}\n\nclass Wu extends qn {\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass Uu extends Wu {\n  constructor(e) {\n    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Jn(() => {\n      var t = Pu(e, this.axis),\n          n = Hs(t, 0, this.maxValue);\n      return rs(e, ss(n, ts(gu(), t)));\n    });\n  }\n\n  getConfig() {\n    return {\n      maxValue: this.maxValue,\n      axis: this.axis\n    };\n  }\n\n}\n\nUu.className = \"MaxNorm\", Kn(Uu);\n\nclass Vu extends Wu {\n  constructor(e) {\n    super(), this.defaultAxis = 0, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Jn(() => ss(e, ts(gu(), Pu(e, this.axis))));\n  }\n\n  getConfig() {\n    return {\n      axis: this.axis\n    };\n  }\n\n}\n\nVu.className = \"UnitNorm\", Kn(Vu);\n\nclass Gu extends Wu {\n  apply(e) {\n    return Va(e);\n  }\n\n}\n\nGu.className = \"NonNeg\", Kn(Gu);\n\nclass Hu extends Wu {\n  constructor(e) {\n    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = null != e.minValue ? e.minValue : this.defaultMinValue, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.rate = null != e.rate ? e.rate : this.defaultRate, this.axis = null != e.axis ? e.axis : this.defaultAxis;\n  }\n\n  apply(e) {\n    return Jn(() => {\n      var t = Pu(e, this.axis),\n          n = ts(rs(this.rate, Hs(t, this.minValue, this.maxValue)), rs(1 - this.rate, t));\n      return rs(e, ss(n, ts(gu(), t)));\n    });\n  }\n\n  getConfig() {\n    return {\n      minValue: this.minValue,\n      maxValue: this.maxValue,\n      rate: this.rate,\n      axis: this.axis\n    };\n  }\n\n}\n\nHu.className = \"MinMaxNorm\", Kn(Hu);\nvar qu = {\n  maxNorm: \"MaxNorm\",\n  minMaxNorm: \"MinMaxNorm\",\n  nonNeg: \"NonNeg\",\n  unitNorm: \"UnitNorm\"\n};\n\nfunction ju(e) {\n  return Eu(e);\n}\n\nfunction Ku(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Au(e, jn.getMap().classNameMap, t, \"constraint\");\n}\n\nfunction Xu(e) {\n  return null == e ? null : \"string\" == typeof e ? Ku({\n    className: e in qu ? qu[e] : e,\n    config: {}\n  }) : e instanceof Wu ? e : Ku(e);\n}\n\nvar Yu = [\"channelsFirst\", \"channelsLast\"],\n    Ju = [\"nearest\", \"bilinear\"],\n    Zu = [\"valid\", \"same\", \"causal\"],\n    Qu = [\"max\", \"avg\"],\n    ec = [\"sum\", \"mul\", \"concat\", \"ave\"],\n    tc = new Map();\n\nfunction nc(e) {\n  Ou(Yu, \"DataFormat\", e);\n}\n\nfunction sc(e) {\n  Ou(Zu, \"PaddingMode\", e);\n}\n\nfunction rc(e) {\n  Ou(Qu, \"PoolMode\", e);\n}\n\nvar ac = [];\n\nfunction ic(e, t) {\n  ac.push(e);\n\n  try {\n    var _e94 = t();\n\n    return ac.pop(), _e94;\n  } catch (e) {\n    throw ac.pop(), e;\n  }\n}\n\nfunction oc(e) {\n  if (!cc(e)) throw new Error(\"Not a valid tensor name: '\" + e + \"'\");\n  return (0 === ac.length ? \"\" : ac.join(\"/\") + \"/\") + e;\n}\n\nfunction lc(e) {\n  if (!cc(e)) throw new Error(\"Not a valid tensor name: '\" + e + \"'\");\n  tc.has(e) || tc.set(e, 0);\n  var t = tc.get(e);\n\n  if (tc.set(e, tc.get(e) + 1), t > 0) {\n    var _n54 = \"\".concat(e, \"_\").concat(t);\n\n    return tc.set(_n54, 1), _n54;\n  }\n\n  return e;\n}\n\nvar uc = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\\._\\/]*$/);\n\nfunction cc(e) {\n  return !!e.match(uc);\n}\n\nfunction hc(e, t, n) {\n  null == t && (t = 0), null == n && (n = e.length);\n  var s = 1;\n\n  for (var _r39 = t; _r39 < n; ++_r39) {\n    s *= e[_r39];\n  }\n\n  return s;\n}\n\nfunction dc(e) {\n  if (0 === e.length) return Number.NaN;\n  var t = Number.POSITIVE_INFINITY;\n\n  for (var _n55 = 0; _n55 < e.length; _n55++) {\n    var _s55 = e[_n55];\n    _s55 < t && (t = _s55);\n  }\n\n  return t;\n}\n\nfunction pc(e) {\n  if (0 === e.length) return Number.NaN;\n  var t = Number.NEGATIVE_INFINITY;\n\n  for (var _n56 = 0; _n56 < e.length; _n56++) {\n    var _s56 = e[_n56];\n    _s56 > t && (t = _s56);\n  }\n\n  return t;\n}\n\nfunction fc(e, t) {\n  if (t < e) throw new xu(\"end (\".concat(t, \") < begin (\").concat(e, \") is forbidden.\"));\n  var n = [];\n\n  for (var _s57 = e; _s57 < t; ++_s57) {\n    n.push(_s57);\n  }\n\n  return n;\n}\n\nfunction gc(e, t) {\n  return fn(e, t);\n}\n\nfunction mc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var n = e.shape.slice();\n  return t < 0 && (t = n.length + t + 1), n.splice(t, 0, 1), Rs(e, n);\n}\n\nfunction bc(e, t, n) {\n  return Jn(() => {\n    switch (e.rank) {\n      case 1:\n        return ei(e, t, n);\n\n      case 2:\n        return ti(e, [t, 0], [n, e.shape[1]]);\n\n      case 3:\n        return ni(e, [t, 0, 0], [n, e.shape[1], e.shape[2]]);\n\n      case 4:\n        return si(e, [t, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3]]);\n\n      case 5:\n        return Os(e, [t, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4]]);\n\n      case 6:\n        return Os(e, [t, 0, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4], e.shape[5]]);\n\n      default:\n        throw new xu(\"sliceAlongFirstAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction xc(e, t, n) {\n  return Jn(() => {\n    switch (e.rank) {\n      case 1:\n        return ei(e, t, n);\n\n      case 2:\n        return ti(e, [0, t], [e.shape[0], n]);\n\n      case 3:\n        return ni(e, [0, 0, t], [e.shape[0], e.shape[1], n]);\n\n      case 4:\n        return si(e, [0, 0, 0, t], [e.shape[0], e.shape[1], e.shape[2], n]);\n\n      default:\n        throw new xu(\"sliceAlongLastAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction yc(e, t, n, s) {\n  return Jn(() => {\n    switch (e.rank) {\n      case 1:\n        return ei(e, t, n);\n\n      case 2:\n        switch (s) {\n          case 1:\n            return bc(e, t, n);\n\n          case 2:\n            return xc(e, t, n);\n\n          default:\n            throw new xu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      case 3:\n        switch (s) {\n          case 1:\n            return bc(e, t, n);\n\n          case 2:\n            return ni(e, [0, t, 0], [e.shape[0], n, e.shape[2]]);\n\n          case 3:\n            return xc(e, t, n);\n\n          default:\n            throw new xu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      case 4:\n        switch (s) {\n          case 1:\n            return bc(e, t, n);\n\n          case 2:\n            return si(e, [0, t, 0, 0], [e.shape[0], n, e.shape[2], e.shape[3]]);\n\n          case 3:\n            return si(e, [0, 0, t, 0], [e.shape[0], e.shape[1], n, e.shape[3]]);\n\n          case 4:\n            return xc(e, t, n);\n\n          default:\n            throw new xu(\"The axis is not within the rank of the tensor \".concat(s));\n        }\n\n      default:\n        throw new xu(\"sliceAlongLastAxis() received an unsupported tensor rank: \".concat(e.rank));\n    }\n  });\n}\n\nfunction kc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var n;\n  return t < 0 && (n = e[0].rank, t = 0 !== n ? n : 0), t === e[0].rank && (t = -1), Ds(e, t);\n}\n\nfunction wc(e, t) {\n  switch (e.rank) {\n    case 1:\n      return qs([e, t]);\n\n    case 2:\n      return js([e, t], 0);\n\n    case 3:\n      return Ks([e, t], 0);\n\n    case 4:\n      return Xs([e, t], 0);\n\n    default:\n      throw new xu(\"concatAlongFirstAxis() received an unsupported tensor rank: \".concat(e.rank));\n  }\n}\n\nfunction vc(e, t) {\n  if (Array.isArray(t) || (t = [t]), e.rank !== t.length) throw new xu(\"The length of input n (\".concat(t.length, \") does not match the number of dimensions in input x (\").concat(e.rank, \")\"));\n  return vr(e, t);\n}\n\nfunction Ic(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  var s = arguments.length > 3 ? arguments[3] : undefined;\n  var r = arguments.length > 4 ? arguments[4] : undefined;\n  return za(e, t, n, s, r);\n}\n\nfunction $c(e, t, n, s) {\n  if (e.rank < 2 || t.rank < 2) throw new yu(\"dot requires both inputs to be rank >= 2 but got x shape = \".concat(e.shape, \" and y shape = \").concat(t.shape));\n  if (t.rank >= 3 && e.shape.slice(-1)[0] !== t.shape.slice(-2)[0]) throw new yu(\"If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = \".concat(e.shape, \" and  y shape = \").concat(t.shape));\n  if (2 === e.rank && 2 === t.rank) return Li({\n    a: e,\n    b: t,\n    transposeA: !1,\n    transposeB: !1,\n    bias: s ? Cc(e.rank, s, \"channelsLast\") : null,\n    activation: n\n  });\n  {\n    var _r40 = e.shape.slice(),\n        _a31 = _r40.pop();\n\n    e = Rs(e, [-1, _a31]);\n\n    var _i19 = t.shape.slice(),\n        _o16 = _i19.pop(),\n        _l10 = _i19.pop(),\n        _u6 = [..._i19, _o16],\n        _c5 = Array.from({\n      length: t.rank\n    }, (e, n) => 0 === n ? t.rank - 2 : n <= t.rank - 2 ? n - 1 : n);\n\n    t = Rs(Sn(t, _c5), [_l10, -1]);\n    var _h4 = [..._r40, ..._u6];\n    return Rs(Li({\n      a: e,\n      b: t,\n      transposeA: !1,\n      transposeB: !1,\n      bias: s ? Cc(e.rank, s, \"channelsLast\") : null,\n      activation: n\n    }), _h4);\n  }\n}\n\nfunction Sc(e, t, n) {\n  return Jn(() => (t = Array.isArray(t) ? bi(t, \"int32\") : fn(t, \"int32\"), Nr(e, t, n)));\n}\n\nfunction Nc(e) {\n  return rs(e, e);\n}\n\nfunction Cc(e, t, n) {\n  var s = t.shape;\n  if (1 !== t.rank && t.rank !== e) throw new xu(\"Unexpected bias dimensions: \".concat(t.rank, \"; expected it to be 1 or \").concat(e));\n\n  if (5 === e) {\n    if (\"channelsFirst\" === n) return Rs(t, 1 === s.length ? [1, s[0], 1, 1, 1] : [1, s[3], s[0], s[1], s[2]]);\n    if (\"channelsLast\" === n) return Rs(t, 1 === s.length ? [1, 1, 1, 1, s[0]] : [1].concat(s));\n  } else if (4 === e) {\n    if (\"channelsFirst\" === n) return Rs(t, 1 === s.length ? [1, s[0], 1, 1] : [1, s[2], s[0], s[1]]);\n    if (\"channelsLast\" === n) return Rs(t, 1 === s.length ? [1, 1, 1, s[0]] : [1].concat(s));\n  } else if (3 === e) {\n    if (\"channelsFirst\" === n) return Rs(t, 1 === s.length ? [1, s[0], 1] : [1, s[1], s[0]]);\n    if (\"channelsLast\" === n) return Rs(t, 1 === s.length ? [1, 1, s[0]] : [1].concat(s));\n  } else if (e < 3) return t;\n\n  throw new xu(\"Unsupported input rank by biasAdd: \".concat(t.rank));\n}\n\nfunction Tc(e, t, n) {\n  return Jn(() => (null == n && (n = \"channelsLast\"), nc(n), ts(e, Cc(e.rank, t, n))));\n}\n\nfunction Ec(e, t, n, s) {\n  return Jn(() => Ci(e, t, n, s));\n}\n\nfunction Rc(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return n ? e() : t();\n}\n\nvar Ac = [\"fanIn\", \"fanOut\", \"fanAvg\"],\n    Fc = [\"normal\", \"uniform\", \"truncatedNormal\"];\n\nclass Dc extends qn {\n  fromConfigUsesCustomObjects() {\n    return !1;\n  }\n\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass _c extends Dc {\n  apply(e, t) {\n    return ca(e, t);\n  }\n\n}\n\n_c.className = \"Zeros\", Kn(_c);\n\nclass Oc extends Dc {\n  apply(e, t) {\n    return ha(e, t);\n  }\n\n}\n\nOc.className = \"Ones\", Kn(Oc);\n\nclass Mc extends Dc {\n  constructor(e) {\n    if (super(), \"object\" != typeof e) throw new xu(\"Expected argument of type ConstantConfig but got \".concat(e));\n    if (void 0 === e.value) throw new xu(\"config must have value set but got \".concat(e));\n    this.value = e.value;\n  }\n\n  apply(e, t) {\n    return Jn(() => rs(Ka(this.value), ha(e, t)));\n  }\n\n  getConfig() {\n    return {\n      value: this.value\n    };\n  }\n\n}\n\nMc.className = \"Constant\", Kn(Mc);\n\nclass Lc extends Dc {\n  constructor(e) {\n    super(), this.DEFAULT_MINVAL = -.05, this.DEFAULT_MAXVAL = .05, this.minval = e.minval || this.DEFAULT_MINVAL, this.maxval = e.maxval || this.DEFAULT_MAXVAL, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    return Ba(e, this.minval, this.maxval, t);\n  }\n\n  getConfig() {\n    return {\n      minval: this.minval,\n      maxval: this.maxval,\n      seed: this.seed\n    };\n  }\n\n}\n\nLc.className = \"RandomUniform\", Kn(Lc);\n\nclass zc extends Dc {\n  constructor(e) {\n    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new yu(\"randomNormal does not support dType \".concat(t, \".\"));\n    return Ic(e, this.mean, this.stddev, t, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n\nzc.className = \"RandomNormal\", Kn(zc);\n\nclass Bc extends Dc {\n  constructor(e) {\n    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new yu(\"truncatedNormal does not support dType \".concat(t, \".\"));\n    return ki(e, this.mean, this.stddev, t, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n\nBc.className = \"TruncatedNormal\", Kn(Bc);\n\nclass Pc extends Dc {\n  constructor(e) {\n    super(), this.gain = null != e.gain ? e.gain : 1;\n  }\n\n  apply(e, t) {\n    return Jn(() => {\n      if (2 !== e.length || e[0] !== e[1]) throw new xu(\"Identity matrix initializer can only be used for 2D square matrices.\");\n      return rs(this.gain, Ir(e[0]));\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain\n    };\n  }\n\n}\n\nPc.className = \"Identity\", Kn(Pc);\n\nclass Wc extends Dc {\n  constructor(e) {\n    if (super(), e.scale < 0) throw new xu(\"scale must be a positive float. Got: \".concat(e.scale));\n    this.scale = null == e.scale ? 1 : e.scale, this.mode = null == e.mode ? \"fanIn\" : e.mode, Ou(Ac, \"FanMode\", this.mode), this.distribution = null == e.distribution ? \"normal\" : e.distribution, Ou(Fc, \"Distribution\", this.distribution), this.seed = e.seed;\n  }\n\n  apply(e, t) {\n    var n = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"channelsLast\";\n      var n, s;\n      if (nc(t), 2 === e.length) n = e[0], s = e[1];else if (-1 !== [3, 4, 5].indexOf(e.length)) {\n        if (\"channelsFirst\" === t) {\n          var _t93 = hc(e, 2);\n\n          n = e[1] * _t93, s = e[0] * _t93;\n        } else if (\"channelsLast\" === t) {\n          var _t94 = hc(e, 0, e.length - 2);\n\n          n = e[e.length - 2] * _t94, s = e[e.length - 1] * _t94;\n        }\n      } else {\n        var _t95 = hc(e);\n\n        n = Math.sqrt(_t95), s = Math.sqrt(_t95);\n      }\n      return [n, s];\n    }(e),\n        s = n[0],\n        r = n[1];\n\n    var a = this.scale;\n\n    if (a /= \"fanIn\" === this.mode ? Math.max(1, s) : \"fanOut\" === this.mode ? Math.max(1, r) : Math.max(1, (s + r) / 2), \"normal\" === this.distribution) {\n      var _n57 = Math.sqrt(a);\n\n      if (\"float32\" !== (t = t || \"float32\") && \"int32\" !== t) throw new yu(\"\".concat(this.getClassName(), \" does not support dType \").concat(t, \".\"));\n      return ki(e, 0, _n57, t, this.seed);\n    }\n\n    {\n      var _n58 = Math.sqrt(3 * a);\n\n      return Ba(e, -_n58, _n58, t);\n    }\n  }\n\n  getConfig() {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n\n}\n\nWc.className = \"VarianceScaling\", Kn(Wc);\n\nclass Uc extends Wc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanAvg\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\nUc.className = \"GlorotUniform\", Kn(Uc);\n\nclass Vc extends Wc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanAvg\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\nVc.className = \"GlorotNormal\", Kn(Vc);\n\nclass Gc extends Wc {\n  constructor(e) {\n    super({\n      scale: 2,\n      mode: \"fanIn\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\nGc.className = \"HeNormal\", Kn(Gc);\n\nclass Hc extends Wc {\n  constructor(e) {\n    super({\n      scale: 2,\n      mode: \"fanIn\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\nHc.className = \"HeUniform\", Kn(Hc);\n\nclass qc extends Wc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanIn\",\n      distribution: \"normal\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\nqc.className = \"LeCunNormal\", Kn(qc);\n\nclass jc extends Wc {\n  constructor(e) {\n    super({\n      scale: 1,\n      mode: \"fanIn\",\n      distribution: \"uniform\",\n      seed: null == e ? null : e.seed\n    });\n  }\n\n  getClassName() {\n    return Wc.className;\n  }\n\n}\n\njc.className = \"LeCunNormal\", Kn(jc);\n\nclass Kc extends Dc {\n  constructor(e) {\n    if (super(), this.DEFAULT_GAIN = 1, this.gain = null == e.gain ? this.DEFAULT_GAIN : e.gain, this.seed = e.seed, null != this.seed) throw new yu(\"Random seed is not implemented for Orthogonal Initializer yet.\");\n  }\n\n  apply(e, t) {\n    return Jn(() => {\n      if (e.length < 2) throw new yu(\"Shape must be at least 2D.\");\n      e[0] * e[1] > 2e3 && console.warn(\"Orthogonal initializer is being called on a matrix with more than 2000 (\".concat(e[0] * e[1], \") elements: Slowness may result.\"));\n      var t = Ic(e[0] > e[1] ? [e[1], e[0]] : e, 0, 1, \"float32\");\n      var n = go.gramSchmidt(t);\n      return e[0] > e[1] && (n = Sn(n)), rs(this.gain, n);\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain,\n      seed: this.seed\n    };\n  }\n\n}\n\nKc.className = \"Orthogonal\", Kn(Kc);\nvar Xc = {\n  constant: \"Constant\",\n  glorotNormal: \"GlorotNormal\",\n  glorotUniform: \"GlorotUniform\",\n  heNormal: \"HeNormal\",\n  heUniform: \"HeUniform\",\n  identity: \"Identity\",\n  leCunNormal: \"LeCunNormal\",\n  leCunUniform: \"LeCunUniform\",\n  ones: \"Ones\",\n  orthogonal: \"Orthogonal\",\n  randomNormal: \"RandomNormal\",\n  randomUniform: \"RandomUniform\",\n  truncatedNormal: \"TruncatedNormal\",\n  varianceScaling: \"VarianceScaling\",\n  zeros: \"Zeros\"\n};\n\nfunction Yc(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Au(e, jn.getMap().classNameMap, t, \"initializer\");\n}\n\nfunction Jc(e) {\n  return Eu(e);\n}\n\nfunction Zc(e) {\n  if (\"string\" == typeof e) {\n    var _t96 = e in Xc ? Xc[e] : e;\n\n    if (\"GlorotNormal\" === _t96) return new Vc();\n    if (\"GlorotUniform\" === _t96) return new Uc();\n    if (\"HeNormal\" === _t96) return new Gc();\n    if (\"HeUniform\" === _t96) return new Hc();\n    if (\"LeCunNormal\" === _t96) return new qc();\n    if (\"LeCunUniform\" === _t96) return new jc();\n    {\n      var _e95 = {};\n      return _e95.className = _t96, _e95.config = {}, Yc(_e95);\n    }\n  }\n\n  return e instanceof Dc ? e : Yc(e);\n}\n\nvar Qc = 0;\n\nfunction eh() {\n  return Qc++;\n}\n\nvar th = {};\n\nfunction nh() {\n  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"\";\n  return e in th || (th[e] = 0), th[e] += 1, e + th[e].toString();\n}\n\nfunction sh(e) {\n  return Array.isArray(e) && Array.isArray(e[0]);\n}\n\nfunction rh(e) {\n  return 0 === e.length ? [] : Array.isArray(e[0]) ? e : [e];\n}\n\nfunction ah(e) {\n  var t;\n\n  if (Array.isArray(e)) {\n    if (1 !== e.length) throw new xu(\"Expected Tensor length to be 1; got \".concat(e.length));\n    t = e[0];\n  } else t = e;\n\n  return t;\n}\n\nfunction ih(e) {\n  if (Array.isArray(e) && Array.isArray(e[0])) {\n    if (1 === e.length) return (e = e)[0];\n    throw new xu(\"Expected exactly 1 Shape; got \".concat(e.length));\n  }\n\n  return e;\n}\n\nfunction oh(e) {\n  var t = 0;\n\n  for (var _n59 of e) {\n    t += 0 === _n59.shape.length ? 1 : _n59.shape.reduce((e, t) => e * t);\n  }\n\n  return t;\n}\n\nclass lh {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"float32\";\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"Variable\";\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n    this.dtype = null == t ? \"float32\" : t, this.shape = e.shape, this.id = eh(), this.originalName = oc(n = null == n ? \"Variable\" : n), this.name = lc(this.originalName), this.trainable_ = s, this.constraint = r, this.val = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n      var n = arguments.length > 2 ? arguments[2] : undefined;\n      var s = arguments.length > 3 ? arguments[3] : undefined;\n      return vt.makeVariable(e, t, n, s);\n    }(e, this.trainable_, this.name, this.dtype);\n  }\n\n  read() {\n    return this.assertNotDisposed(), this.val;\n  }\n\n  write(e) {\n    return this.assertNotDisposed(), function (e, t) {\n      if (e.shape.toString() !== t.shape.toString()) throw new Error(\"Shape mismatch: \" + JSON.stringify(e.shape) + \" vs. \" + JSON.stringify(t.shape));\n    }(this.val, e), this.val.id !== e.id && (this.val.assign(e), null != this.constraint && this.val.assign(this.constraint.apply(this.val))), this;\n  }\n\n  dispose() {\n    this.assertNotDisposed(), this.val.dispose();\n  }\n\n  assertNotDisposed() {\n    if (this.val.isDisposed) throw new Error(\"LayersVariable \".concat(this.name, \" is already disposed.\"));\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this.trainable_ = e, this.val.trainable = e;\n  }\n\n}\n\nfunction uh(e) {\n  return e.map(e => e.read());\n}\n\nfunction ch(e) {\n  e.forEach(e => {\n    e[0].write(e[1]);\n  });\n}\n\nclass hh {\n  constructor(e) {\n    this.dtype = e.dtype, this.shape = e.shape, this.ndim = null != e.shape ? e.shape.length : e.ndim, this.maxNDim = e.maxNDim, this.minNDim = e.minNDim, this.axes = e.axes || {};\n  }\n\n}\n\nclass dh {\n  constructor(e, t, n, s, r, a, i) {\n    this.dtype = e, this.shape = t, this.sourceLayer = n, this.inputs = s, this.callArgs = r, this.outputTensorIndex = i, this.id = eh(), null != a && (this.originalName = oc(a), this.name = lc(this.originalName)), this.rank = t.length;\n  }\n\n}\n\nvar ph = 0;\n\nclass fh {\n  constructor(e, t) {\n    this.callArgs = t, this.id = ph++, this.outboundLayer = e.outboundLayer, this.inboundLayers = e.inboundLayers, this.nodeIndices = e.nodeIndices, this.tensorIndices = e.tensorIndices, this.inputTensors = e.inputTensors, this.outputTensors = e.outputTensors, this.inputMasks = e.inputMasks, this.outputMasks = e.outputMasks, this.inputShapes = e.inputShapes, this.outputShapes = e.outputShapes;\n\n    for (var _t97 of e.inboundLayers) {\n      null != _t97 && _t97.outboundNodes.push(this);\n    }\n\n    e.outboundLayer.inboundNodes.push(this);\n  }\n\n  getConfig() {\n    var e = [];\n\n    for (var _t98 of this.inboundLayers) {\n      e.push(null != _t98 ? _t98.name : null);\n    }\n\n    return {\n      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,\n      inboundLayers: e,\n      nodeIndices: this.nodeIndices,\n      tensorIndices: this.tensorIndices\n    };\n  }\n\n}\n\nvar gh = 0;\n\nclass mh extends qn {\n  constructor() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = !1, this.id = gh++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = !1, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = !1, this.inboundNodes = [], this.outboundNodes = [];\n    var t = e.name;\n\n    if (!t) {\n      var _e96 = this.getClassName();\n\n      t = Nu(_e96) + \"_\" + nh(_e96);\n    }\n\n    if (this.name = t, this.trainable_ = null == e.trainable || e.trainable, null != e.inputShape || null != e.batchInputShape) {\n      var _t99;\n\n      if (null != e.batchInputShape) _t99 = e.batchInputShape;else if (null != e.inputShape) {\n        var _n61 = null;\n        null != e.batchSize && (_n61 = e.batchSize), _t99 = [_n61].concat(e.inputShape);\n      }\n      this.batchInputShape = _t99;\n      var _n60 = e.dtype;\n      null == _n60 && (_n60 = e.inputDType), null == _n60 && (_n60 = \"float32\"), this.dtype = _n60;\n    }\n\n    this.initialWeights = null != e.weights ? e.weights : null, this._refCount = null, this.fastWeightInitDuringBuild = !1;\n  }\n\n  static nodeKey(e, t) {\n    return e.name + \"_ib-\" + t.toString();\n  }\n\n  getNodeAtIndex(e, t) {\n    if (0 === this.inboundNodes.length) throw new bu(\"The layer has never been called and thus has no defined \".concat(t, \".\"));\n    if (this.inboundNodes.length <= e) throw new xu(\"Asked to get \".concat(t, \" at node \").concat(e, \", but the layer has only \").concat(this.inboundNodes.length, \" inbound nodes.\"));\n    return this.inboundNodes[e];\n  }\n\n  getInputAt(e) {\n    return $u(this.getNodeAtIndex(e, \"input\").inputTensors);\n  }\n\n  getOutputAt(e) {\n    return $u(this.getNodeAtIndex(e, \"output\").outputTensors);\n  }\n\n  get input() {\n    if (this.inboundNodes.length > 1) throw new mu(\"Layer \".concat(this.name, \" has multiple inbound nodes, hence the notion of \\\"layer input\\\" is ill-defined. Use `getInputAt(nodeIndex)` instead.\"));\n    if (0 === this.inboundNodes.length) throw new mu(\"Layer \".concat(this.name, \" is not connected, no input to return.\"));\n    return $u(this.getNodeAtIndex(0, \"input\").inputTensors);\n  }\n\n  get output() {\n    if (0 === this.inboundNodes.length) throw new mu(\"Layer \".concat(this.name, \" has no inbound nodes.\"));\n    if (this.inboundNodes.length > 1) throw new mu(\"Layer \".concat(this.name, \" has multiple inbound nodes, hence the notion of \\\"layer output\\\" is ill-defined. Use `getOutputAt(nodeIndex)` instead.\"));\n    return $u(this.getNodeAtIndex(0, \"output\").outputTensors);\n  }\n\n  get losses() {\n    return this._losses;\n  }\n\n  calculateLosses() {\n    return this.losses.map(e => e());\n  }\n\n  get updates() {\n    return this._updates;\n  }\n\n  get built() {\n    return this._built;\n  }\n\n  set built(e) {\n    this._built = e;\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this._trainableWeights.forEach(t => t.trainable = e), this.trainable_ = e;\n  }\n\n  get trainableWeights() {\n    return this.trainable_ ? this._trainableWeights.filter(e => e.trainable) : [];\n  }\n\n  set trainableWeights(e) {\n    this._trainableWeights = e;\n  }\n\n  get nonTrainableWeights() {\n    return this.trainable ? this._trainableWeights.filter(e => !e.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);\n  }\n\n  set nonTrainableWeights(e) {\n    this._nonTrainableWeights = e;\n  }\n\n  get weights() {\n    return this.trainableWeights.concat(this.nonTrainableWeights);\n  }\n\n  get stateful() {\n    return this._stateful;\n  }\n\n  resetStates() {\n    if (!this.stateful) throw new Error(\"Cannot call the resetStates() method of a non-stateful Layer object.\");\n  }\n\n  assertInputCompatibility(e) {\n    if (e = Su(e), null == this.inputSpec || 0 === this.inputSpec.length) return;\n    var t = Su(this.inputSpec);\n    if (e.length !== t.length) throw new xu(\"Layer \".concat(this.name, \" expects \").concat(t.length, \" inputs, but it received \").concat(e.length, \" input tensors. Input received: \").concat(e));\n\n    for (var _n62 = 0; _n62 < e.length; _n62++) {\n      var _s58 = e[_n62],\n          _r41 = t[_n62];\n      if (null == _r41) continue;\n      var _a32 = _s58.rank;\n      if (null != _r41.ndim && _a32 !== _r41.ndim) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected ndim=\").concat(_r41.ndim, \", found ndim=\").concat(_a32));\n      if (null != _r41.maxNDim && _a32 > _r41.maxNDim) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected max_ndim=\").concat(_r41.maxNDim, \", found ndim=\").concat(_a32));\n      if (null != _r41.minNDim && _a32 < _r41.minNDim) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected min_ndim=\").concat(_r41.minNDim, \", found ndim=\").concat(_a32, \".\"));\n      if (null != _r41.dtype && _s58.dtype !== _r41.dtype) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \" : expected dtype=\").concat(_r41.dtype, \", found dtype=\").concat(_s58.dtype, \".\"));\n\n      if (_r41.axes) {\n        var _e97 = _s58.shape;\n\n        for (var _t100 in _r41.axes) {\n          var _s59 = Number(_t100),\n              _a33 = _r41.axes[_t100],\n              _i20 = _s59 >= 0 ? _e97[_s59] : _e97[_e97.length + _s59];\n\n          if (null != _a33 && -1 === [_a33, null].indexOf(_i20)) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected axis \").concat(_s59, \" of input shape to have value \").concat(_a33, \" but got shape \").concat(_e97, \".\"));\n        }\n      }\n\n      if (null != _r41.shape) for (var _e98 = 0; _e98 < _r41.shape.length; ++_e98) {\n        var _t101 = _r41.shape[_e98],\n            _a34 = _s58.shape[_e98];\n        if (null != _t101 && null != _a34 && _t101 !== _a34) throw new xu(\"Input \".concat(_n62, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_r41.shape, \", found shape=\").concat(_s58.shape, \".\"));\n      }\n    }\n  }\n\n  call(e, t) {\n    return e;\n  }\n\n  invokeCallHook(e, t) {\n    null != this._callHook && this._callHook(e, t);\n  }\n\n  setCallHook(e) {\n    this._callHook = e;\n  }\n\n  clearCallHook() {\n    this._callHook = null;\n  }\n\n  apply(e, t) {\n    t = t || {}, this.assertNotDisposed();\n    var n = Su(e);\n    var s = !0;\n\n    for (var _e99 of n) {\n      if (!(_e99 instanceof dh)) {\n        s = !1;\n        break;\n      }\n    }\n\n    var r = !0;\n\n    for (var _e100 of n) {\n      if (_e100 instanceof dh) {\n        r = !1;\n        break;\n      }\n    }\n\n    if (s === r) throw new xu(\"Arguments to apply() must be all SymbolicTensors or all Tensors\");\n    return ic(this.name, () => {\n      if (!this.built) {\n        this.assertInputCompatibility(e);\n        var _t102 = [];\n\n        for (var _n63 of Su(e)) {\n          _t102.push(_n63.shape);\n        }\n\n        this.build($u(_t102)), this.built = !0, this.initialWeights && this.setWeights(this.initialWeights), null === this._refCount && r && (this._refCount = 1);\n      }\n\n      if (this.assertInputCompatibility(e), r) {\n        var _s60 = this.call(e, t);\n\n        var _r42 = Su(_s60),\n            _a35 = [];\n\n        for (var _e101 of _r42) {\n          -1 !== n.indexOf(_e101) && (_e101 = _e101.clone()), _a35.push(_e101);\n        }\n\n        if (_s60 = $u(_a35), null != this.activityRegularizer) throw new yu(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");\n        return _s60;\n      }\n\n      {\n        var _n64 = function (e) {\n          e = Su(e);\n          var t = [];\n\n          for (var _n65 of e) {\n            t.push(_n65.shape);\n          }\n\n          return $u(t);\n        }(e),\n            _s61 = this.computeOutputShape(_n64);\n\n        var _r43;\n\n        var _a36 = \"float32\";\n        if (this.warnOnIncompatibleInputShape(Array.isArray(e) ? _n64[0] : _n64), _r43 = null != _s61 && _s61.length > 0 && Array.isArray(_s61[0]) ? _s61.map((n, s) => new dh(_a36, n, this, Su(e), t, this.name, s)) : new dh(_a36, _s61, this, Su(e), t, this.name), this.addInboundNode(e, _r43, null, null, _n64, _s61, t), this._refCount++, null != this.activityRegularizer) throw new yu(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");\n        return _r43;\n      }\n    });\n  }\n\n  warnOnIncompatibleInputShape(e) {\n    if (null != this.batchInputShape) if (e.length !== this.batchInputShape.length) console.warn(\"The rank of the input tensor provided (shape: \".concat(JSON.stringify(e), \") does not match that of the batchInputShape (\").concat(JSON.stringify(this.batchInputShape), \") of the layer \").concat(this.name));else {\n      var _t103 = !1;\n\n      this.batchInputShape.forEach((n, s) => {\n        null != n && null != e[s] && e[s] !== n && (_t103 = !0);\n      }), _t103 && console.warn(\"The shape of the input tensor (\".concat(JSON.stringify(e), \") does not match the expectation of layer \").concat(this.name, \": \").concat(JSON.stringify(this.batchInputShape)));\n    }\n  }\n\n  get outputShape() {\n    if (null == this.inboundNodes || 0 === this.inboundNodes.length) throw new mu(\"The layer \".concat(this.name, \" has never been called and thus has no defined output shape.\"));\n    var e = [];\n\n    for (var _t104 of this.inboundNodes) {\n      var _n66 = JSON.stringify(_t104.outputShapes);\n\n      -1 === e.indexOf(_n66) && e.push(_n66);\n    }\n\n    if (1 === e.length) {\n      var _e102 = this.inboundNodes[0].outputShapes;\n      return Array.isArray(_e102) && Array.isArray(_e102[0]) && 1 === _e102.length ? _e102[0] : _e102;\n    }\n\n    throw new mu(\"The layer \".concat(this.name, \" has multiple inbound nodes with different output shapes. Hence the notion of \\\"output shape\\\" is ill-defined for the layer.\"));\n  }\n\n  countParams() {\n    if (!this.built) throw new bu(\"You tried to call countParams() on \".concat(this.name, \", but the layer is not built yet. Build it first by calling build(batchInputShape).\"));\n    return oh(this.weights);\n  }\n\n  build(e) {\n    this.built = !0;\n  }\n\n  getWeights() {\n    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;\n    return uh(e ? this.trainableWeights : this.weights);\n  }\n\n  setWeights(e) {\n    Jn(() => {\n      var t = this.weights;\n      if (t.length !== e.length) throw new xu(\"You called setWeights(weights) on layer \\\"\".concat(this.name, \"\\\" with a weight list of length \").concat(e.length, \", but the layer was expecting \").concat(t.length, \" weights. Provided weights: \").concat(e, \"...\"));\n      if (0 === t.length) return;\n      var n = [],\n          s = uh(t);\n\n      for (var _r44 = 0; _r44 < s.length; ++_r44) {\n        var _a37 = s[_r44],\n            _i21 = t[_r44],\n            _o17 = e[_r44];\n        if (!p(_a37.shape, _o17.shape)) throw new xu(\"Layer weight shape \".concat(_a37.shape, \" not compatible with provided weight shape \").concat(_o17.shape));\n        n.push([_i21, _o17]);\n      }\n\n      ch(n);\n    });\n  }\n\n  addWeight(e, t, n, s, r, a, i) {\n    if (-1 !== this._addedWeightNames.indexOf(e)) throw new xu(\"Duplicate weight name \".concat(e, \" for layer \").concat(this.name));\n    this._addedWeightNames.push(e), null == n && (n = \"float32\"), this.fastWeightInitDuringBuild && (s = Zc(\"zeros\"));\n    var o = s.apply(t, n),\n        l = new lh(o, n, e, a, i);\n    return o.dispose(), null != r && this.addLoss(() => r.apply(l.read())), null == a && (a = !0), a ? this._trainableWeights.push(l) : this._nonTrainableWeights.push(l), l;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    this.fastWeightInitDuringBuild = e;\n  }\n\n  addLoss(e) {\n    null == e || Array.isArray(e) && 0 === e.length || (e = Su(e), null != this._losses && this.losses.push(...e));\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  computeMask(e, t) {\n    if (!this.supportsMasking) {\n      if (null != t) {\n        if (!Array.isArray(t)) throw new TypeError(\"Layer \".concat(this.name, \" does not support masking, but was passed an inputMask.\"));\n        t.forEach(e => {\n          if (null != e) throw new TypeError(\"Layer \".concat(this.name, \" does not support masking, but was passed an inputMask.\"));\n        });\n      }\n\n      return null;\n    }\n\n    return t;\n  }\n\n  addInboundNode(e, t, n, s, r, a) {\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    var o = Su(e);\n    t = Su(t), n = Su(n), s = Su(s), r = rh(r), a = rh(a);\n    var l = [],\n        u = [],\n        c = [];\n\n    for (var _e103 of o) {\n      l.push(_e103.sourceLayer), u.push(_e103.nodeIndex), c.push(_e103.tensorIndex);\n    }\n\n    new fh({\n      outboundLayer: this,\n      inboundLayers: l,\n      nodeIndices: u,\n      tensorIndices: c,\n      inputTensors: o,\n      outputTensors: t,\n      inputMasks: n,\n      outputMasks: s,\n      inputShapes: r,\n      outputShapes: a\n    }, i);\n\n    for (var _e104 = 0; _e104 < t.length; _e104++) {\n      t[_e104].sourceLayer = this, t[_e104].nodeIndex = this.inboundNodes.length - 1, t[_e104].tensorIndex = _e104;\n    }\n  }\n\n  getConfig() {\n    var e = {\n      name: this.name,\n      trainable: this.trainable\n    };\n    return null != this.batchInputShape && (e.batchInputShape = this.batchInputShape), null != this.dtype && (e.dtype = this.dtype), e;\n  }\n\n  disposeWeights() {\n    return this.weights.forEach(e => e.dispose()), this.weights.length;\n  }\n\n  assertNotDisposed() {\n    if (0 === this._refCount) throw new Error(\"Layer '\".concat(this.name, \"' is already disposed.\"));\n  }\n\n  dispose() {\n    if (!this.built) throw new Error(\"Cannot dispose Layer \".concat(this.name, \" because it has not been built yet.\"));\n    if (null === this._refCount) throw new Error(\"Cannot dispose Layer \".concat(this.name, \" because it has not been used yet.\"));\n    this.assertNotDisposed();\n    var e = 0;\n    return 0 == --this._refCount && (e = this.disposeWeights()), {\n      refCountAfterDispose: this._refCount,\n      numDisposedVariables: e\n    };\n  }\n\n}\n\nfunction bh(e, t, n) {\n  if ((null == t || null != n && n > 0) && (t = e.sourceLayer, n = e.nodeIndex), 0 === t.inboundNodes.length) return [e];\n  {\n    var _e105 = t.inboundNodes[n];\n    if (0 === _e105.inboundLayers.length) return _e105.inputTensors;\n    {\n      var _t105 = [];\n\n      for (var _n67 = 0; _n67 < _e105.inboundLayers.length; _n67++) {\n        var _s62 = bh(_e105.inputTensors[_n67], _e105.inboundLayers[_n67], _e105.nodeIndices[_n67]);\n\n        for (var _e106 of _s62) {\n          -1 === _t105.indexOf(_e106) && _t105.push(_e106);\n        }\n      }\n\n      return _t105;\n    }\n  }\n}\n\nclass xh extends mh {\n  constructor(e) {\n    if (super({\n      dtype: e.dtype,\n      name: null != e.name ? e.name : nh(\"input\").toString()\n    }), null == e.batchSize && (e.batchSize = null), null == e.sparse && (e.sparse = !1), this.trainable = !1, this.built = !0, this.sparse = e.sparse, null != e.inputShape && null != e.batchInputShape) throw new xu(\"Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.\");\n    var t = e.batchInputShape;\n\n    if (null == t) {\n      if (null == e.inputShape) throw new xu(\"An InputLayer should be passed either a `batchInputShape` or an `inputShape`.\");\n      t = [e.batchSize].concat(e.inputShape);\n    } else if (null != e.batchSize) throw new xu(\"Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.\");\n\n    var n = e.dtype || \"float32\";\n    this.batchInputShape = t, this.dtype = n, this.inputSpec = [{\n      shape: t\n    }];\n    var s = new dh(this.dtype, this.batchInputShape, this, [], {}, this.name);\n    s.nodeIndex = 0, s.tensorIndex = 0, new fh({\n      outboundLayer: this,\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: [s],\n      outputTensors: [s],\n      inputMasks: [null],\n      outputMasks: [null],\n      inputShapes: [t],\n      outputShapes: [t]\n    });\n  }\n\n  apply(e, t) {\n    throw new xu(\"Cannot pass any input to an InputLayer's apply() method. InputLayer name: \".concat(this.name));\n  }\n\n  dispose() {\n    return {\n      refCountAfterDispose: this._refCount,\n      numDisposedVariables: 0\n    };\n  }\n\n  getConfig() {\n    return {\n      batchInputShape: this.batchInputShape,\n      dtype: this.dtype,\n      sparse: this.sparse,\n      name: this.name\n    };\n  }\n\n}\n\nfunction yh(_x19) {\n  return _yh.apply(this, arguments);\n}\n\nfunction _yh() {\n  _yh = _asyncToGenerator(function* (e) {\n    if (null == e) return;\n    var t = [],\n        n = [],\n        s = [];\n\n    for (var _r175 in e) {\n      var _a148 = e[_r175];\n\n      if (\"number\" != typeof _a148) {\n        var _e529 = _a148;\n        t.push(_e529.data()), n.push(_r175), s.push(_e529);\n      }\n    }\n\n    if (t.length > 0) {\n      var _r176 = yield Promise.all(t);\n\n      for (var _t429 = 0; _t429 < _r176.length; ++_t429) {\n        e[n[_t429]] = _r176[_t429][0];\n      }\n\n      Zn(s);\n    }\n  });\n  return _yh.apply(this, arguments);\n}\n\nfunction kh(e) {\n  if (null != e) for (var _t106 in e) {\n    var _n68 = e[_t106];\n    \"number\" != typeof _n68 && _n68.dispose();\n  }\n}\n\nvar wh;\nxh.className = \"InputLayer\", Kn(xh), function (e) {\n  e[e.SILENT = 0] = \"SILENT\", e[e.VERBOSE = 1] = \"VERBOSE\";\n}(wh || (wh = {}));\n\nclass vh {\n  constructor() {\n    this.validationData = null;\n  }\n\n  setParams(e) {\n    this.params = e;\n  }\n\n  onEpochBegin(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onEpochEnd(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onBatchBegin(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onBatchEnd(e, t) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onTrainBegin(e) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  onTrainEnd(e) {\n    return _asyncToGenerator(function* () {})();\n  }\n\n  setModel(e) {}\n\n}\n\nclass Ih {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 10;\n    null == e && (e = []), this.callbacks = e, this.queueLength = t;\n  }\n\n  append(e) {\n    this.callbacks.push(e);\n  }\n\n  setParams(e) {\n    for (var _t107 of this.callbacks) {\n      _t107.setParams(e);\n    }\n  }\n\n  setModel(e) {\n    for (var _t108 of this.callbacks) {\n      _t108.setModel(e);\n    }\n  }\n\n  onEpochBegin(e, t) {\n    var _this38 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n69 of _this38.callbacks) {\n        yield _n69.onEpochBegin(e, t);\n      }\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this39 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n70 of _this39.callbacks) {\n        yield _n70.onEpochEnd(e, t);\n      }\n    })();\n  }\n\n  onBatchBegin(e, t) {\n    var _this40 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n71 of _this40.callbacks) {\n        yield _n71.onBatchBegin(e, t);\n      }\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this41 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n\n      for (var _n72 of _this41.callbacks) {\n        yield _n72.onBatchEnd(e, t);\n      }\n    })();\n  }\n\n  onTrainBegin(e) {\n    var _this42 = this;\n\n    return _asyncToGenerator(function* () {\n      null == e && (e = {});\n\n      for (var _t109 of _this42.callbacks) {\n        yield _t109.onTrainBegin(e);\n      }\n    })();\n  }\n\n  onTrainEnd(e) {\n    var _this43 = this;\n\n    return _asyncToGenerator(function* () {\n      null == e && (e = {});\n\n      for (var _t110 of _this43.callbacks) {\n        yield _t110.onTrainEnd(e);\n      }\n    })();\n  }\n\n}\n\nclass $h extends vh {\n  constructor() {\n    super();\n  }\n\n  onEpochBegin(e) {\n    var _this44 = this;\n\n    return _asyncToGenerator(function* () {\n      _this44.seen = 0, _this44.totals = {};\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this45 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {});\n      var n = null == t.size ? 0 : t.size;\n      _this45.seen += n;\n\n      var _loop12 = function _loop12(_e107) {\n        var s = t[_e107];\n        if (\"number\" == typeof s) _this45.totals.hasOwnProperty(_e107) || (_this45.totals[_e107] = 0), _this45.totals[_e107] = _this45.totals[_e107] + s * n;else {\n          var _t111;\n\n          _e107 in _this45.totals ? _t111 = _this45.totals[_e107] : _this45.totals[_e107] = 0;\n\n          var _r45 = Jn(() => ts(_this45.totals[_e107], rs(s, n)));\n\n          _this45.totals[_e107] = _r45, null != _t111 && _t111.dispose();\n        }\n      };\n\n      for (var _e107 in t) {\n        _loop12(_e107);\n      }\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this46 = this;\n\n    return _asyncToGenerator(function* () {\n      if (null != t) {\n        var _loop13 = function _loop13(_e108) {\n          null != _this46.totals[_e108] && (\"number\" == typeof _this46.totals[_e108] ? t[_e108] = _this46.totals[_e108] / _this46.seen : Jn(() => {\n            var n = rs(ss(1, _this46.seen), _this46.totals[_e108]);\n            t[_e108] = n, _this46.totals[_e108].dispose(), Qn(t[_e108]);\n          }));\n        };\n\n        for (var _e108 of _this46.params.metrics) {\n          _loop13(_e108);\n        }\n      }\n    })();\n  }\n\n}\n\nclass Sh extends vh {\n  onTrainBegin(e) {\n    var _this47 = this;\n\n    return _asyncToGenerator(function* () {\n      _this47.epoch = [], _this47.history = {};\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this48 = this;\n\n    return _asyncToGenerator(function* () {\n      null == t && (t = {}), _this48.epoch.push(e);\n\n      for (var _e109 in t) {\n        null == _this48.history[_e109] && (_this48.history[_e109] = []), _this48.history[_e109].push(t[_e109]);\n      }\n    })();\n  }\n\n  syncData() {\n    var _this49 = this;\n\n    return _asyncToGenerator(function* () {\n      var e = [],\n          t = [],\n          n = [];\n\n      for (var _s63 in _this49.history) {\n        var _r46 = _this49.history[_s63];\n\n        for (var _a38 = 0; _a38 < _r46.length; ++_a38) {\n          \"number\" != typeof _r46[_a38] && (e.push(_r46[_a38].data()), t.push(_s63), n.push(_a38));\n        }\n      }\n\n      var s = yield Promise.all(e);\n\n      for (var _e110 = 0; _e110 < s.length; ++_e110) {\n        _this49.history[t[_e110]][n[_e110]].dispose(), _this49.history[t[_e110]][n[_e110]] = s[_e110][0];\n      }\n    })();\n  }\n\n}\n\nclass Nh extends vh {\n  constructor(e, t) {\n    if (super(), this.currentEpoch = 0, this.yieldEvery = t || \"auto\", \"auto\" === this.yieldEvery && (this.yieldEvery = 125), \"never\" === this.yieldEvery && null != e.onYield) throw new Error(\"yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback\");\n    C(this.yieldEvery) && (this.maybeWait = function (e, t) {\n      var n,\n          s = Ge();\n      return function () {\n        var a = Ge();\n        return a - s < t || (s = a, n = e(...arguments)), n;\n      };\n    }(this.maybeWait.bind(this), this.yieldEvery)), this.trainBegin = e.onTrainBegin, this.trainEnd = e.onTrainEnd, this.epochBegin = e.onEpochBegin, this.epochEnd = e.onEpochEnd, this.batchBegin = e.onBatchBegin, this.batchEnd = e.onBatchEnd, this.yield = e.onYield;\n  }\n\n  maybeWait(e, t, n) {\n    var _this50 = this;\n\n    return _asyncToGenerator(function* () {\n      var s = [];\n      null != _this50.yield && (yield yh(n), s.push(_this50.yield(e, t, n))), s.push(Co()), yield Promise.all(s);\n    })();\n  }\n\n  onEpochBegin(e, t) {\n    var _this51 = this;\n\n    return _asyncToGenerator(function* () {\n      _this51.currentEpoch = e, null != _this51.epochBegin && (yield yh(t), yield _this51.epochBegin(e, t));\n    })();\n  }\n\n  onEpochEnd(e, t) {\n    var _this52 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = [];\n      null != _this52.epochEnd && (yield yh(t), n.push(_this52.epochEnd(e, t))), \"epoch\" === _this52.yieldEvery && n.push(Co()), yield Promise.all(n);\n    })();\n  }\n\n  onBatchBegin(e, t) {\n    var _this53 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this53.batchBegin && (yield yh(t), yield _this53.batchBegin(e, t));\n    })();\n  }\n\n  onBatchEnd(e, t) {\n    var _this54 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = [];\n      null != _this54.batchEnd && (yield yh(t), n.push(_this54.batchEnd(e, t))), \"batch\" === _this54.yieldEvery ? n.push(Co()) : C(_this54.yieldEvery) && n.push(_this54.maybeWait(_this54.currentEpoch, e, t)), yield Promise.all(n);\n    })();\n  }\n\n  onTrainBegin(e) {\n    var _this55 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this55.trainBegin && (yield yh(e), yield _this55.trainBegin(e));\n    })();\n  }\n\n  onTrainEnd(e) {\n    var _this56 = this;\n\n    return _asyncToGenerator(function* () {\n      null != _this56.trainEnd && (yield yh(e), yield _this56.trainEnd(e));\n    })();\n  }\n\n}\n\nfunction Ch(e, t) {\n  return null == e && (e = {}), e instanceof vh ? [e] : Array.isArray(e) && e[0] instanceof vh ? e : Su(e).map(e => new Nh(e, t));\n}\n\nclass Th {\n  constructor() {}\n\n  static registerCallbackConstructor(e, t) {\n    l(e >= 0 && Number.isInteger(e), () => \"Verbosity level is expected to be an integer >= 0, but got \".concat(e)), Th.checkForDuplicate(t), null == Th.constructors[e] && (Th.constructors[e] = []), Th.constructors[e].push(t);\n  }\n\n  static checkForDuplicate(e) {\n    for (var _t112 in Th.constructors) {\n      Th.constructors[+_t112].forEach(t => {\n        if (t === e) throw new xu(\"Duplicate callback constructor.\");\n      });\n    }\n  }\n\n  static clear() {\n    Th.constructors = {};\n  }\n\n  static createCallbacks(e) {\n    var t = [];\n\n    for (var _n73 in Th.constructors) {\n      var _s64 = +_n73;\n\n      e >= _s64 && t.push(...Th.constructors[_s64]);\n    }\n\n    return t.map(e => new e());\n  }\n\n}\n\nfunction Eh(e, t, n, s, r, a, i, o, l) {\n  var u = new Sh(),\n      c = [new $h(), ...Th.createCallbacks(t)];\n  null != e && c.push(...e), c.push(u);\n  var h = new Ih(c);\n  return h.setParams({\n    epochs: n,\n    initialEpoch: s,\n    samples: r,\n    steps: a,\n    batchSize: i,\n    verbose: t,\n    doValidation: o,\n    metrics: l\n  }), {\n    callbackList: h,\n    history: u\n  };\n}\n\nfunction Rh(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Au(e, jn.getMap().classNameMap, t, \"layer\", n);\n}\n\nfunction Ah(e, t) {\n  return Jn(() => {\n    \"float32\" !== e.dtype && (e = fn(e, \"float32\"));\n    var n = Hr(Nc(e), t, !0),\n        s = $r(n.shape, gu()),\n        r = ci(la(n, s));\n    return ss(e, r);\n  });\n}\n\nfunction Fh(e, t) {\n  return Jn(() => ua(Nc(Gr(t, e)), -1));\n}\n\nfunction Dh(e, t) {\n  return Jn(() => ua(as(Gr(t, e)), -1));\n}\n\nfunction _h(e, t) {\n  return Jn(() => {\n    var n = Gr(e, t),\n        s = Hs(as(e), gu(), Number.MAX_VALUE),\n        r = as(ss(n, s));\n    return rs(100, ua(r, -1));\n  });\n}\n\nfunction Oh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Jn(() => {\n    if (n) t = ri(t);else {\n      var _e111 = Hr(t, t.shape.length - 1, !0);\n\n      t = ss(t, _e111);\n    }\n    return t = Hs(t, gu(), 1 - gu()), Pr(Hr(rs(fn(e, \"float32\"), Lr(t)), t.shape.length - 1));\n  });\n}\n\nfunction Mh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  return Jn(() => {\n    var s = fn(Sr(function (e) {\n      var t = [hc(e.shape)];\n      return Rs(e, t);\n    }(e)), \"int32\"),\n        r = (t = Hs(t, gu(), 1 - gu())).shape;\n    return Oh(Rs($n(s, r[r.length - 1]), r), t, n);\n  });\n}\n\nfunction Lh(e, t) {\n  return Jn(() => {\n    var n;\n    return n = Hs(t, gu(), 1 - gu()), n = Lr(ss(n, Gr(1, n))), ua(function (e, t) {\n      if (!p(e.shape, t.shape)) throw new xu(\"logits and labels must have the same shape, but got shapes \".concat(JSON.stringify(e.shape), \" and \").concat(JSON.stringify(t.shape)));\n      return Jn(() => {\n        var n = Va(t),\n            s = Pr(as(t));\n        return ts(Gr(n, rs(t, e)), zr(yr(s)));\n      });\n    }(e, n), -1);\n  });\n}\n\nfunction zh(e, t) {\n  return Jn(() => {\n    var n = Ah(e, -1),\n        s = Ah(t, -1),\n        r = rs(n, s);\n    return Pr(Hr(r, -1));\n  });\n}\n\nTh.constructors = {};\nvar Bh = {\n  meanSquaredError: Fh,\n  meanAbsoluteError: Dh,\n  meanAbsolutePercentageError: _h,\n  meanSquaredLogarithmicError: function meanSquaredLogarithmicError(e, t) {\n    return Jn(() => {\n      var n = Hs(t, gu(), Number.MAX_VALUE),\n          s = Lr(ts(1, n)),\n          r = Hs(e, gu(), Number.MAX_VALUE),\n          a = Lr(ts(1, r));\n      return ua(Nc(Gr(s, a)), -1);\n    });\n  },\n  squaredHinge: function squaredHinge(e, t) {\n    return Jn(() => {\n      var n = la(0, Gr(1, rs(e, t)));\n      return ua(Nc(n), -1);\n    });\n  },\n  hinge: function hinge(e, t) {\n    return Jn(() => {\n      var n = la(0, Gr(1, rs(e, t)));\n      return ua(n, -1);\n    });\n  },\n  categoricalHinge: function categoricalHinge(e, t) {\n    return Jn(() => {\n      var n = Hr(rs(e, t), -1),\n          s = Vr(rs(Gr(1, e), t), -1);\n      return la(0, ts(1, Gr(s, n)));\n    });\n  },\n  logcosh: function logcosh(e, t) {\n    return Jn(() => {\n      var n = Math.log(2),\n          s = Gr(t, e),\n          r = Gr(ts(s, Wr(rs(-2, s))), n);\n      return ua(r, -1);\n    });\n  },\n  categoricalCrossentropy: Oh,\n  sparseCategoricalCrossentropy: Mh,\n  binaryCrossentropy: Lh,\n  kullbackLeiblerDivergence: function kullbackLeiblerDivergence(e, t) {\n    return Jn(() => {\n      var n = Hs(e, gu(), 1),\n          s = Hs(t, gu(), 1);\n      return Hr(rs(e, Lr(ss(n, s))), -1);\n    });\n  },\n  poisson: function poisson(e, t) {\n    return Jn(() => {\n      var n = Lr(ts(gu(), t));\n      return ua(Gr(t, rs(e, n)), -1);\n    });\n  },\n  cosineProximity: zh\n};\n\nfunction Ph(e) {\n  if (\"string\" == typeof e) {\n    if (e in Bh) return Bh[e];\n\n    var _t113 = \"Unknown loss \".concat(e);\n\n    throw e.toLowerCase().includes(\"softmaxcrossentropy\") && (_t113 = \"Unknown loss \".concat(e, \". Use \\\"categoricalCrossentropy\\\" as the string name for tf.losses.softmaxCrossEntropy\")), new xu(_t113);\n  }\n\n  return e;\n}\n\nfunction Wh(e, t) {\n  return Jn(() => {\n    var n = rs(.5, ya(t)),\n        s = gc(Cr(t, n), e.dtype);\n    return ua(dr(e, s), -1);\n  });\n}\n\nfunction Uh(e, t) {\n  return Jn(() => gc(dr(cs(e, -1), cs(t, -1)), \"float32\"));\n}\n\nfunction Vh(e, t) {\n  return Lh(e, t);\n}\n\nfunction Gh(e, t) {\n  return e.rank === t.rank && (e = di(e, [e.rank - 1])), (t = cs(t, -1)).dtype !== e.dtype && (t = fn(t, e.dtype)), fn(dr(e, t), \"float32\");\n}\n\nvar Hh = Oh,\n    qh = Mh,\n    jh = {\n  binaryAccuracy: Wh,\n  categoricalAccuracy: Uh,\n  precision: function precision(e, t) {\n    return Jn(() => {\n      var n = function (e, t) {\n        return Jn(() => fn(Hr(na(dr(e, 1), dr(t, 1))), \"float32\"));\n      }(e, t),\n          s = function (e, t) {\n        return Jn(() => fn(Hr(na(dr(e, 0), dr(t, 1))), \"float32\"));\n      }(e, t),\n          r = ts(n, s);\n\n      return fn(pr(Cr(r, 0), ss(n, r), 0), \"float32\");\n    });\n  },\n  categoricalCrossentropy: Hh,\n  sparseCategoricalCrossentropy: qh,\n  mse: Fh,\n  MSE: Fh,\n  mae: Dh,\n  MAE: Dh,\n  mape: _h,\n  MAPE: _h,\n  cosine: zh\n};\n\nfunction Kh(e) {\n  if (\"string\" == typeof e && e in jh) return jh[e];\n  if (\"string\" != typeof e && null != e) return e;\n  throw new xu(\"Unknown metric \".concat(e));\n}\n\nfunction Xh(e) {\n  if (vu(null !== e, \"Unknown LossOrMetricFn \".concat(e)), \"string\" == typeof e) return e;\n  {\n    var _t114;\n\n    for (var _n74 of Object.keys(Bh)) {\n      if (Bh[_n74] === e) {\n        _t114 = _n74;\n        break;\n      }\n    }\n\n    if (void 0 !== _t114) return _t114;\n\n    for (var _n75 of Object.keys(jh)) {\n      if (jh[_n75] === e) {\n        _t114 = _n75;\n        break;\n      }\n    }\n\n    return void 0 !== _t114 ? _t114 : e.name;\n  }\n}\n\nfunction Yh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n  if (null == e || \"object\" != typeof e || Object.getPrototypeOf(e) !== Object.prototype || !Jh(e)) throw new Error(\"User-defined metadata is expected to be a JSON object, but is not.\");\n\n  if (n) {\n    var _n76 = JSON.stringify(e);\n\n    _n76.length > 1048576 && console.warn(\"User-defined metadata of model \\\"\".concat(t, \"\\\" is too large in size (length=\").concat(_n76.length, \" when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.\"));\n  }\n}\n\nfunction Jh(e) {\n  if (null === e) return !0;\n\n  if (\"object\" == typeof e) {\n    if (Object.getPrototypeOf(e) === Object.prototype) {\n      var _t115 = Object.keys(e);\n\n      for (var _n77 of _t115) {\n        if (\"string\" != typeof _n77) return !1;\n        if (!Jh(e[_n77])) return !1;\n      }\n\n      return !0;\n    }\n\n    if (Array.isArray(e)) {\n      for (var _t116 of e) {\n        if (!Jh(_t116)) return !1;\n      }\n\n      return !0;\n    }\n\n    return !1;\n  }\n\n  {\n    var _t117 = typeof e;\n\n    return \"string\" === _t117 || \"number\" === _t117 || \"boolean\" === _t117;\n  }\n}\n\nfunction Zh(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n  var s = \"\";\n\n  for (var _n78 = 0; _n78 < e.length; ++_n78) {\n    _n78 > 0 && (s = s.slice(0, s.length - 1) + \" \"), s += e[_n78], s = s.slice(0, t[_n78]), s += \" \".repeat(t[_n78] - s.length);\n  }\n\n  n(s);\n}\n\nfunction Qh(e, t, n) {\n  var s;\n\n  try {\n    s = JSON.stringify(e.outputShape);\n  } catch (e) {\n    s = \"multiple\";\n  }\n\n  Zh([\"\".concat(e.name, \" (\").concat(e.getClassName(), \")\"), s, e.countParams().toString()], t, n);\n}\n\nfunction ed(e, t, n, s) {\n  var r;\n\n  try {\n    r = JSON.stringify(e.outputShape);\n  } catch (e) {\n    r = \"multiple\";\n  }\n\n  var a = [];\n\n  for (var _t118 of e.inboundNodes) {\n    if (!(null != n && n.length > 0 && -1 === n.indexOf(_t118))) for (var _e112 = 0; _e112 < _t118.inboundLayers.length; ++_e112) {\n      a.push(\"\".concat(_t118.inboundLayers[_e112].name, \"[\").concat(_t118.nodeIndices[_e112], \"][\").concat(_t118.tensorIndices[_e112], \"]\"));\n    }\n  }\n\n  var i = e.name,\n      o = e.getClassName(),\n      l = 0 === a.length ? \"\" : a[0];\n  Zh([\"\".concat(i, \" (\").concat(o, \")\"), r, e.countParams().toString(), l], t, s);\n\n  for (var _e113 = 1; _e113 < a.length; ++_e113) {\n    Zh([\"\", \"\", \"\", a[_e113]], t, s);\n  }\n}\n\nfunction td(e, t, n) {\n  return (\"inboundNodes\" === e || \"outputLayers\" === e || \"inputLayers\" === e) && 0 === t && \"string\" == typeof n;\n}\n\nfunction nd(e, t) {\n  if (null === e) return null;\n  if (\"string\" == typeof e) return Cu(e);\n  if (\"number\" == typeof e || \"boolean\" == typeof e) return e;\n\n  if (e instanceof Array) {\n    var _n79 = [],\n        _s65 = e.length;\n\n    for (var _r47 = 0; _r47 < _s65; ++_r47) {\n      var _s66 = e[_r47];\n      td(t, _r47, _s66) ? _n79.push(_s66) : _n79.push(nd(_s66, t));\n    }\n\n    return _n79;\n  }\n\n  {\n    var _t119 = {};\n\n    for (var _n80 of Object.keys(e)) {\n      var _s67 = e[_n80];\n      if (\"name\" === _n80 && \"string\" == typeof _s67) _t119[_n80] = _s67;else {\n        var _e114 = Cu(_n80);\n\n        _t119[_e114] = nd(_s67, _e114);\n      }\n    }\n\n    return _t119;\n  }\n}\n\nfunction sd(e, t) {\n  if (null == e) return null;\n  if (\"string\" == typeof e) return Nu(e);\n  if (\"number\" == typeof e || \"boolean\" == typeof e) return e;\n\n  if (e instanceof Array) {\n    var _n81 = [],\n        _s68 = e.length;\n\n    for (var _r48 = 0; _r48 < _s68; ++_r48) {\n      var _s69 = e[_r48];\n      td(t, _r48, _s69) ? _n81.push(_s69) : _n81.push(sd(_s69, t));\n    }\n\n    return _n81;\n  }\n\n  {\n    var _t120 = {};\n\n    for (var _n82 of Object.keys(e)) {\n      var _s70 = e[_n82];\n      _t120[Nu(_n82)] = \"name\" !== _n82 && \"className\" !== _n82 || \"string\" != typeof _s70 ? sd(_s70, _n82) : _s70;\n    }\n\n    return _t120;\n  }\n}\n\nclass rd {\n  constructor(e) {\n    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, e instanceof rd) for (var _t121 in e.id2Value) {\n      this.id2Value[_t121] = e.id2Value[_t121], _t121 in e.id2Mask && (this.id2Mask[_t121] = e.id2Mask[_t121]);\n    } else {\n      if (null == e) return;\n\n      for (var _t122 of e) {\n        this.add(_t122.key, _t122.value);\n      }\n    }\n  }\n\n  add(e, t, n) {\n    if (null != this.id2Value[e.id]) throw new xu(\"Duplicate key: name=\".concat(e.name, \", id=\").concat(e.id));\n    return this.id2Value[e.id] = function (e, t) {\n      if (null == e.dtype || e.dtype === t.dtype) return t;\n\n      try {\n        return fn(t, e.dtype);\n      } catch (n) {\n        throw new xu(\"The dtype of the feed (\".concat(t.dtype, \") can not be cast to the dtype of the key '\").concat(e.name, \"' (\").concat(e.dtype, \").\"));\n      }\n    }(e, t), this.name2Id[e.name] = e.id, null != n && (this.id2Mask[e.id] = n), this;\n  }\n\n  addFeed(e) {\n    this.add(e.key, e.value);\n  }\n\n  hasKey(e) {\n    return null != this.id2Value[e.id];\n  }\n\n  names() {\n    return Object.keys(this.name2Id);\n  }\n\n  getValue(e) {\n    if (e instanceof dh) {\n      if (null == this.id2Value[e.id]) throw new xu(\"Nonexistent key: \".concat(e.name));\n      return this.id2Value[e.id];\n    }\n\n    {\n      var _t123 = this.name2Id[e];\n      if (null == _t123) throw new xu(\"Feed dict has no SymbolicTensor name: \".concat(e));\n      return this.id2Value[_t123];\n    }\n  }\n\n  getMask(e) {\n    if (e instanceof dh) {\n      if (null == this.id2Value[e.id]) throw new xu(\"Nonexistent key: \".concat(e.name));\n      return this.id2Mask[e.id];\n    }\n\n    {\n      var _t124 = this.name2Id[e];\n      if (null == _t124) throw new xu(\"Feed dict has no SymbolicTensor name: \".concat(e));\n      return this.id2Mask[_t124];\n    }\n  }\n\n  disposeMasks() {\n    null != this.id2Mask && Zn(this.id2Mask);\n  }\n\n}\n\nvar ad = {},\n    id = {};\n\nfunction od(e, t, n, s) {\n  var r = null != n && n.training,\n      a = Array.isArray(e),\n      i = a ? e : [e],\n      o = i.map(e => e.name),\n      u = [],\n      c = t.names();\n\n  for (var _e115 of o) {\n    -1 !== c.indexOf(_e115) ? u.push(t.getValue(_e115)) : u.push(null);\n  }\n\n  null != s && (s.maxNumTensors = -Infinity, s.minNumTensors = Infinity);\n  var h = o.join(\",\") + \"|\" + t.names().join(\",\");\n  var d, p;\n\n  if (null == ad[h]) {\n    var _e116 = function (e, t) {\n      l(null != e && e.length > 0, () => \"Expected at least one fetch, got none\");\n      var n = [],\n          s = {};\n\n      if (1 === e.length) {\n        var _r49 = ud(e[0], t);\n\n        n = _r49.sorted, s = _r49.recipientMap;\n      } else {\n        var _r50 = new Set();\n\n        for (var _a39 of e) {\n          var {\n            sorted: _e117,\n            recipientMap: _i22\n          } = ud(_a39, t);\n\n          for (var _t125 of _e117) {\n            _r50.has(_t125.name) || (n.push(_t125), _r50.add(_t125.name));\n          }\n\n          var _loop14 = function _loop14(_e118) {\n            null == s[_e118] && (s[_e118] = new Set()), _i22[_e118].forEach(t => s[_e118].add(t));\n          };\n\n          for (var _e118 in _i22) {\n            _loop14(_e118);\n          }\n        }\n      }\n\n      return {\n        sorted: n,\n        recipientCounts: ld(s)\n      };\n    }(i, t);\n\n    d = _e116.sorted, p = _e116.recipientCounts, ad[h] = d, id[h] = p;\n  }\n\n  d = ad[h], p = {}, r || Object.assign(p, id[h]);\n  var f = new rd(t);\n\n  for (var _e119 = 0; _e119 < d.length; ++_e119) {\n    if (null != s) {\n      var _e120 = Yn().numTensors;\n      _e120 > s.maxNumTensors && (s.maxNumTensors = _e120), _e120 < s.minNumTensors && (s.minNumTensors = _e120);\n    }\n\n    var _a40 = d[_e119],\n        _i23 = _a40.sourceLayer;\n    if (_i23 instanceof xh) continue;\n    var _l11 = [],\n        _c6 = [],\n        _h5 = [];\n\n    var _g5 = !1;\n\n    for (var _e121 of _a40.inputs) {\n      var _n83 = f.getValue(_e121),\n          _s71 = f.getMask(_e121);\n\n      _l11.push(_n83), _c6.push(_s71), null != _s71 && (_g5 = !0), r || (p[_e121.name]--, 0 !== p[_e121.name] || t.hasKey(_e121) || -1 !== o.indexOf(_e121.name) || _n83.isDisposed || !0 === _e121.sourceLayer.stateful || _h5.push(_n83));\n    }\n\n    _g5 && ((n = n || {}).mask = _c6[0]);\n\n    var _m4 = Su(_i23.apply(_l11, n));\n\n    var _b4 = null;\n    _i23.supportsMasking && (_b4 = _i23.computeMask(_l11, _c6));\n\n    var _x20 = cd(_a40),\n        _y4 = Array.isArray(_x20) ? _x20 : [_x20];\n\n    for (var _e122 = 0; _e122 < _y4.length; ++_e122) {\n      f.hasKey(_y4[_e122]) || f.add(_y4[_e122], _m4[_e122], Array.isArray(_b4) ? _b4[0] : _b4);\n\n      var _t126 = o.indexOf(_y4[_e122].name);\n\n      -1 !== _t126 && (u[_t126] = _m4[_e122]);\n    }\n\n    r || Zn(_h5);\n  }\n\n  return f.disposeMasks(), a ? u : u[0];\n}\n\nfunction ld(e) {\n  var t = {};\n\n  for (var _n84 in e) {\n    t[_n84] = e[_n84].size;\n  }\n\n  return t;\n}\n\nfunction ud(e, t) {\n  var n = new Set(),\n      s = [],\n      r = {};\n\n  for (var _e123 of t.names()) {\n    n.add(_e123);\n  }\n\n  var a = [],\n      i = [];\n\n  for (a.push(e); a.length > 0;) {\n    var _e124 = a[a.length - 1];\n\n    if (n.has(_e124.name)) {\n      a.pop();\n      continue;\n    }\n\n    var _t127 = i[i.length - 1] === a.length - 1;\n\n    if (0 === _e124.inputs.length || _t127) a.pop(), s.push(_e124), n.add(_e124.name), _t127 && i.pop();else {\n      i.push(a.length - 1);\n\n      for (var _t128 of _e124.inputs) {\n        null == r[_t128.name] && (r[_t128.name] = new Set()), r[_t128.name].add(_e124.name), n.has(_t128.name) || a.push(_t128);\n      }\n    }\n  }\n\n  return {\n    sorted: s,\n    recipientMap: r\n  };\n}\n\nfunction cd(e) {\n  var t;\n  if (1 === e.sourceLayer.inboundNodes.length) t = e.sourceLayer.output;else {\n    var _n85 = null;\n\n    for (var _t129 = 0; _t129 < e.sourceLayer.inboundNodes.length; ++_t129) {\n      for (var _s72 of e.sourceLayer.inboundNodes[_t129].outputTensors) {\n        if (_s72.id === e.id) {\n          _n85 = _t129;\n          break;\n        }\n      }\n    }\n\n    t = e.sourceLayer.getOutputAt(_n85);\n  }\n  return t;\n}\n\nclass hd extends mh {\n  constructor(e) {\n    if (super({}), this.containerNodes = new Set(), this.name = e.name, null == this.name) {\n      var _e125 = this.getClassName().toLowerCase();\n\n      this.name = nh(_e125);\n    }\n\n    if (this.supportsMasking = !1, this.trainable_ = !0, this.inputs = Array.isArray(e.inputs) ? e.inputs.slice() : [e.inputs], this.outputs = Array.isArray(e.outputs) ? e.outputs.slice() : [e.outputs], Du(this.inputs).length !== this.inputs.length) throw new xu(\"The list of inputs passed to the model is redundant. All inputs should only appear once. Found: \".concat(this.inputs.map(e => e.name)));\n    Du(this.outputs).length !== this.outputs.length && console.warn(\"The list of outputs passed to the model is redundant. All outputs should only appear once. Found: \".concat(this.outputs.map(e => e.name))), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];\n\n    for (var _e126 of this.outputs) {\n      var _t130 = _e126.nodeIndex,\n          _n86 = _e126.tensorIndex;\n      this.outputLayers.push(_e126.sourceLayer), this.outputLayersNodeIndices.push(_t130), this.outputLayersTensorIndices.push(_n86);\n    }\n\n    for (var _e127 of this.inputs) {\n      var _t131 = _e127.sourceLayer,\n          _n87 = _e127.nodeIndex,\n          _s73 = _e127.tensorIndex;\n      vu(0 === _n87, \"input layer has >1 nodes\"), vu(0 === _s73, \"input layer has >1 tensors\"), this.inputLayers.push(_t131), this.inputLayersNodeIndices.push(_n87), this.inputLayersTensorIndices.push(_s73);\n    }\n\n    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];\n\n    for (var _t132 = 0; _t132 < this.inputLayers.length; _t132++) {\n      var _n88 = this.inputLayers[_t132];\n      if (!(_n88 instanceof xh)) throw new TypeError(\"Input layers to a LayersModel must be InputLayer objects. Received inputs: \".concat(e.inputs, \". Input \").concat(_t132, \" (0-based) originates from layer type \").concat(_n88.getClassName(), \".\"));\n      this.inputNames.push(_n88.name), this.feedInputShapes.push(_n88.batchInputShape), this.feedInputNames.push(_n88.name);\n    }\n\n    for (var _e128 of this.outputLayers) {\n      this.outputNames.push(_e128.name);\n    }\n\n    this.internalInputShapes = this.inputs.map(e => e.shape), this.internalOutputShapes = this.outputs.map(e => e.shape);\n\n    var t = {},\n        n = {},\n        s = {},\n        r = {},\n        a = {},\n        i = [],\n        o = (e, t, n, s, r, l) => {\n      null != s && null != r && null != l || (s = e.sourceLayer, r = e.nodeIndex, l = e.tensorIndex);\n      var u = s.inboundNodes[r];\n      if (-1 !== n.indexOf(u)) throw new bu(\"The tensor \".concat(e.name, \" at layer \\\"\").concat(s.name, \"\\\" is part of a cycle.\"));\n      if (-1 !== t.indexOf(u)) return;\n      this.containerNodes.add(hd.nodeKey(s, r)), s.id in a || (a[s.id] = Object.keys(a).length), -1 === n.indexOf(u) && n.push(u);\n      var c = u.inboundLayers.length;\n\n      for (var _e129 = 0; _e129 < c; _e129++) {\n        o(u.inputTensors[_e129], t, n, u.inboundLayers[_e129], u.nodeIndices[_e129], u.tensorIndices[_e129]);\n      }\n\n      for (t.push(u); n.indexOf(u) >= 0;) {\n        n.splice(n.indexOf(u), 1);\n      }\n\n      i.push(u);\n    },\n        l = [],\n        u = [];\n\n    for (var _e130 of this.outputs) {\n      o(_e130, l, u);\n    }\n\n    var c = i.slice().reverse();\n\n    for (var _e131 of c) {\n      n[_e131.id] = _e131, _e131.id in t || (t[_e131.id] = 0);\n      var _a41 = t[_e131.id];\n      _a41 = Math.max(_a41, null == s[_e131.outboundLayer.id] ? 0 : s[_e131.outboundLayer.id]), s[_e131.outboundLayer.id] = _a41, r[_e131.outboundLayer.id] = _e131.outboundLayer, t[_e131.id] = _a41;\n\n      for (var _s74 = 0; _s74 < _e131.inboundLayers.length; _s74++) {\n        var _r51 = _e131.inboundLayers[_s74].inboundNodes[_e131.nodeIndices[_s74]];\n        t[_r51.id] = Math.max(_a41 + 1, null == t[_r51.id] ? 0 : t[_r51.id]), n[_r51.id] = _r51;\n      }\n    }\n\n    var h = {};\n\n    for (var _e132 in t) {\n      var _s75 = t[_e132];\n      _s75 in h || (h[_s75] = []), h[_s75].push(n[_e132]);\n    }\n\n    var d = {};\n\n    for (var _e133 in s) {\n      var _t133 = s[_e133];\n      _t133 in d || (d[_t133] = []), d[_t133].push(r[_e133]);\n    }\n\n    var p = Object.keys(d).map(e => parseInt(e, 10)).sort(Fu);\n    this.layers = [];\n\n    for (var _e134 of p) {\n      var _t134 = d[_e134];\n\n      _t134.sort((e, t) => {\n        var n = a[e.id],\n            s = a[t.id];\n        return n < s ? -1 : n > s ? 1 : 0;\n      });\n\n      for (var _e135 of _t134) {\n        _e135 instanceof hd && this.internalContainerRefs.push(_e135), this.layers.push(_e135);\n      }\n    }\n\n    this.layersByDepth = d, p = Object.keys(h).map(e => parseInt(e, 10)).sort(Fu);\n    var f = this.inputs.slice(),\n        g = [];\n\n    for (var _e136 of p) {\n      for (var _t135 of h[_e136]) {\n        var _e137 = _t135.outboundLayer;\n\n        if (null != _e137) {\n          for (var _n89 of _t135.inputTensors) {\n            if (-1 === f.indexOf(_n89)) throw new bu(\"Graph disconnected: cannot obtain value for tensor \".concat(_n89, \" at layer \\\"\").concat(_e137.name, \"\\\". The following previous layers were accessed without issue: \").concat(g));\n          }\n\n          for (var _e138 of _t135.outputTensors) {\n            f.push(_e138);\n          }\n\n          g.push(_e137.name);\n        }\n      }\n    }\n\n    this.nodesByDepth = h;\n    var m = this.layers.map(e => e.name);\n\n    var _loop15 = function _loop15(_e139) {\n      var t = m.filter(t => t === _e139).length;\n      if (1 !== t) throw new bu(\"The name \\\"\".concat(_e139, \"\\\" is used \").concat(t, \" times in the model. All layer names should be unique. Layer names: \") + JSON.stringify(m));\n    };\n\n    for (var _e139 of m) {\n      _loop15(_e139);\n    }\n\n    this.outboundNodes = [], this.inboundNodes = [], new fh({\n      outboundLayer: this,\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: this.inputs,\n      outputTensors: this.outputs,\n      inputMasks: this.inputs.map(e => null),\n      outputMasks: this.outputs.map(e => null),\n      inputShapes: this.inputs.map(e => e.shape),\n      outputShapes: this.outputs.map(e => e.shape)\n    }), this.built = !0, this._refCount = 1;\n  }\n\n  assertNotDisposed() {\n    if (0 === this._refCount) throw new Error(\"Container '\".concat(this.name, \"' is already disposed.\"));\n  }\n\n  dispose() {\n    this.assertNotDisposed();\n    var e = {\n      refCountAfterDispose: null,\n      numDisposedVariables: 0\n    };\n\n    if (0 == --this._refCount) {\n      for (var _t136 of this.layers) {\n        e.numDisposedVariables += _t136.dispose().numDisposedVariables;\n      }\n\n      for (var _t137 of this.internalContainerRefs) {\n        e.numDisposedVariables += _t137.dispose().numDisposedVariables;\n      }\n    }\n\n    return e.refCountAfterDispose = this._refCount, e;\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(e) {\n    this.layers.forEach(t => {\n      t._trainableWeights.forEach(t => t.trainable = e);\n    }), this.trainable_ = e;\n  }\n\n  get trainableWeights() {\n    if (this._trainableWeights.length > 0) throw new xu(\"Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.\");\n    if (!this.trainable) return [];\n    var e = [];\n\n    for (var _t138 of this.layers) {\n      e = e.concat(_t138.trainableWeights);\n    }\n\n    return e;\n  }\n\n  get nonTrainableWeights() {\n    var e = [];\n\n    for (var _t139 of this.layers) {\n      e.push(..._t139.nonTrainableWeights);\n    }\n\n    if (!this.trainable) {\n      var _t140 = [];\n\n      for (var _e140 of this.layers) {\n        _t140.push(..._e140.trainableWeights);\n      }\n\n      return _t140.concat(e);\n    }\n\n    return e;\n  }\n\n  get weights() {\n    return this.trainableWeights.concat(this.nonTrainableWeights);\n  }\n\n  loadWeights(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = {};\n    var s = 0;\n\n    for (var _e141 of this.layers) {\n      for (var _t141 of _e141.weights) {\n        if (null != n[_t141.originalName]) throw new xu(\"Duplicate weight name: \".concat(_t141.originalName));\n        n[_t141.originalName] = _t141, s++;\n      }\n    }\n\n    var r = [];\n\n    for (var _s76 in e) {\n      var _a42 = _s76;\n\n      if (null == n[_s76]) {\n        var _e142 = _s76.split(\"/\");\n\n        _a42 = _e142.slice(0, -2).concat([_e142[_e142.length - 1]]).join(\"/\");\n      }\n\n      if (null != n[_a42]) r.push([n[_a42], e[_s76]]);else if (t) throw new xu(\"Provided weight data has no target variable: \".concat(_s76));\n      delete n[_a42];\n    }\n\n    if (t) {\n      var _e143 = [];\n\n      for (var _t142 in n) {\n        _e143.push(_t142);\n      }\n\n      if (_e143.length > 0) throw new xu(\"\".concat(_e143.length, \" of \").concat(s, \" weights are not set: \").concat(_e143));\n    }\n\n    ch(r);\n  }\n\n  updatedConfig() {\n    var e = this.getConfig(),\n        t = {};\n    return t.className = this.getClassName(), t.config = e, t.kerasVersion = \"tfjs-layers 3.9.0\", t.backend = \"TensorFlow.js\", t;\n  }\n\n  toJSON(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;\n    var n = sd(this.updatedConfig());\n    return t ? JSON.stringify(n) : n;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      e = Su(e);\n      var n = new rd();\n\n      for (var _t143 = 0; _t143 < this.inputs.length; ++_t143) {\n        n.add(this.inputs[_t143], e[_t143]);\n      }\n\n      return od(this.outputs, n, t);\n    });\n  }\n\n  computeMask(e, t) {\n    return Jn(() => {\n      var n;\n      return e = Su(e), n = null == t ? wu(null, e.length) : Su(t), this.runInternalGraph(e, n)[1];\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = rh(e);\n    if (t.length !== this.inputLayers.length) throw new xu(\"Invalid inputShape argument \".concat(e, \": model has \").concat(this.inputLayers.length, \" tensor inputs.\"));\n    var n = {};\n\n    for (var _e144 = 0; _e144 < t.length; _e144++) {\n      n[this.inputLayers[_e144].name + \"_0_0\"] = t[_e144];\n    }\n\n    var s = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(Fu);\n    if (s.length > 1) for (var _e145 of s) {\n      var _t144 = this.nodesByDepth[_e145];\n\n      for (var _e146 of _t144) {\n        var _t145 = _e146.outboundLayer;\n        if (-1 !== this.inputLayers.map(e => e.id).indexOf(_t145.id)) continue;\n        var _s77 = [];\n\n        for (var _t146 = 0; _t146 < _e146.inboundLayers.length; _t146++) {\n          _s77.push(n[\"\".concat(_e146.inboundLayers[_t146].name, \"_\").concat(_e146.nodeIndices[_t146], \"_\").concat(_e146.tensorIndices[_t146])]);\n        }\n\n        var _r52 = rh(_t145.computeOutputShape($u(_s77))),\n            _a43 = _t145.inboundNodes.indexOf(_e146);\n\n        for (var _e147 = 0; _e147 < _r52.length; _e147++) {\n          n[\"\".concat(_t145.name, \"_\").concat(_a43, \"_\").concat(_e147)] = _r52[_e147];\n        }\n      }\n    }\n    var r = [],\n        a = [];\n\n    for (var _e148 = 0; _e148 < this.outputLayers.length; _e148++) {\n      a.push(\"\".concat(this.outputLayers[_e148].name, \"_\").concat(this.outputLayersNodeIndices[_e148], \"_\").concat(this.outputLayersTensorIndices[_e148]));\n    }\n\n    for (var _e149 = 0; _e149 < a.length; _e149++) {\n      var _t147 = a[_e149];\n      vu(_t147 in n), r.push(n[_t147]);\n    }\n\n    return $u(r);\n  }\n\n  runInternalGraph(e, t) {\n    null == t && (t = wu(null, e.length));\n    var n = {};\n\n    for (var _s78 = 0; _s78 < this.inputs.length; ++_s78) {\n      n[this.inputs[_s78].id] = [e[_s78], t[_s78]];\n    }\n\n    var s = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(Fu);\n\n    for (var _e150 of s) {\n      var _t148 = this.nodesByDepth[_e150];\n\n      for (var _e151 of _t148) {\n        var _t149 = _e151.outboundLayer,\n            _s79 = _e151.inputTensors,\n            _r53 = _e151.outputTensors,\n            _a44 = new Array();\n\n        for (var _e152 of _s79) {\n          _e152.id in n && _a44.push(n[_e152.id]);\n        }\n\n        if (_a44.length === _s79.length) {\n          var _s80 = void 0,\n              _i24 = void 0,\n              _o18 = void 0,\n              _l12 = void 0,\n              _u7 = {};\n\n          if (null != _e151.callArgs && (_u7 = _e151.callArgs), 1 === _a44.length) {\n            var [_e153, _n90] = _a44[0];\n            null == _u7.mask && (_u7.mask = _n90), _o18 = Su(_t149.call(_e153, _u7)), _l12 = Su(_t149.computeMask(_e153, _n90)), _s80 = [_e153], _i24 = [_n90];\n          } else _s80 = _a44.map(e => e[0]), _i24 = _a44.map(e => e[1]), null == _u7.mask && (_u7.mask = _i24), _o18 = Su(_t149.call(_s80, _u7)), _l12 = Su(_t149.computeMask(_s80, _i24));\n\n          if (_t149.activityRegularizer) throw new yu(\"LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.\");\n\n          for (var _e154 = 0; _e154 < _r53.length; ++_e154) {\n            n[_r53[_e154].id] = [_o18[_e154], _l12[_e154]];\n          }\n        }\n      }\n    }\n\n    var r = [],\n        a = [],\n        i = [];\n\n    for (var _e155 of this.outputs) {\n      vu(_e155.id in n, \"Could not compute output \".concat(_e155.name, \" : \").concat(_e155.id));\n      var [_t150, _s81] = n[_e155.id];\n      i.push(_t150.shape), r.push(_t150), a.push(_s81);\n    }\n\n    return [r, a, i];\n  }\n\n  buildNodeConversionMap(e) {\n    var t = {};\n    var n;\n\n    for (var _e156 of this.layers) {\n      n = _e156 instanceof hd ? 1 : 0;\n\n      for (var _s82 = 0; _s82 < _e156.inboundNodes.length; _s82++) {\n        var _r54 = hd.nodeKey(_e156, _s82);\n\n        this.containerNodes.has(_r54) && (t[_r54] = n, n += 1);\n      }\n    }\n\n    return t;\n  }\n\n  getLayer(e, t) {\n    if (null != t) {\n      if (this.layers.length <= t) throw new xu(\"Was asked to retrieve layer at index \".concat(t, \", but model only has \").concat(this.layers.length, \" layer(s).\"));\n      return this.layers[t];\n    }\n\n    if (null == e) throw new xu(\"Provide either a layer name or layer index\");\n\n    for (var _t151 of this.layers) {\n      if (_t151.name === e) return _t151;\n    }\n\n    throw new xu(\"No such layer: \".concat(e));\n  }\n\n  calculateLosses() {\n    return Jn(() => {\n      var e = [];\n\n      for (var _t152 of this.layers) {\n        for (var _n91 = 0; _n91 < _t152.inboundNodes.length; ++_n91) {\n          var _s83 = hd.nodeKey(_t152, _n91);\n\n          this.containerNodes.has(_s83) && e.push(..._t152.calculateLosses());\n        }\n      }\n\n      return e;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      name: this.name\n    },\n        t = this.buildNodeConversionMap(this.layers),\n        n = [];\n\n    for (var _e157 of this.layers) {\n      var _s84 = _e157.getClassName(),\n          _r55 = _e157.getConfig(),\n          _a45 = [];\n\n      for (var _n92 = 0; _n92 < _e157.inboundNodes.length; _n92++) {\n        var _s85 = _e157.inboundNodes[_n92],\n            _r56 = hd.nodeKey(_e157, _n92);\n\n        var _i26 = {};\n\n        if (this.containerNodes.has(_r56)) {\n          if (_s85.callArgs) try {\n            JSON.stringify(_s85.callArgs), _i26 = _s85.callArgs;\n          } catch (t) {\n            console.warn(\"Layer \".concat(_e157.name, \" was passed non-serializable keyword arguments: \").concat(_s85.callArgs, \". They will not be included in the serialized model (and thus will be missing at deserialization time).\")), _i26 = {};\n          }\n\n          if (_s85.inboundLayers.length > 0) {\n            var _e158 = [];\n\n            for (var _n93 = 0; _n93 < _s85.inboundLayers.length; _n93++) {\n              var _r57 = _s85.inboundLayers[_n93],\n                  _a46 = _s85.tensorIndices[_n93];\n              var _o19 = t[hd.nodeKey(_r57, _s85.nodeIndices[_n93])];\n              null == _o19 && (_o19 = 0), _e158.push([_r57.name, _o19, _a46, _i26]);\n            }\n\n            _a45.push(_e158);\n          }\n        }\n      }\n\n      var _i25 = {};\n      _i25.name = _e157.name, _i25.className = _s84, _i25.config = _r55, _i25.inboundNodes = _a45, n.push(_i25);\n    }\n\n    e.layers = n;\n    var s = [];\n\n    for (var _e159 = 0; _e159 < this.inputLayers.length; _e159++) {\n      var _n94 = this.inputLayers[_e159],\n          _r58 = hd.nodeKey(_n94, this.inputLayersNodeIndices[_e159]);\n\n      if (!this.containerNodes.has(_r58)) continue;\n      var _a47 = t[_r58];\n      null == _a47 && (_a47 = 0), s.push([_n94.name, _a47, this.inputLayersTensorIndices[_e159]]);\n    }\n\n    e.inputLayers = s;\n    var r = [];\n\n    for (var _e160 = 0; _e160 < this.outputLayers.length; _e160++) {\n      var _n95 = this.outputLayers[_e160],\n          _s86 = hd.nodeKey(_n95, this.outputLayersNodeIndices[_e160]);\n\n      if (!this.containerNodes.has(_s86)) continue;\n      var _a48 = t[_s86];\n      null == _a48 && (_a48 = 0), r.push([_n95.name, _a48, this.outputLayersTensorIndices[_e160]]);\n    }\n\n    return e.outputLayers = r, e;\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = {},\n        a = {};\n\n    function i(e, t) {\n      e.name in a ? a[e.name].push(t) : a[e.name] = [t];\n    }\n\n    function o(e, t) {\n      var n = [];\n      var s;\n\n      for (var _a49 of t) {\n        var _o20 = _a49[0],\n            _l13 = _a49[1],\n            _u8 = _a49[2];\n        if (s = null == _a49[3] ? {} : _a49[3], !(_o20 in r)) return void i(e, t);\n        var _c7 = r[_o20];\n        if (_c7.inboundNodes.length <= _l13) return void i(e, t);\n        n.push(_c7.inboundNodes[_l13].outputTensors[_u8]);\n      }\n\n      n.length > 0 && e.apply($u(n), s);\n    }\n\n    function l(e) {\n      var n = e.name,\n          a = Rh(e, null != t.customObjects ? t.customObjects : {});\n      a.setFastWeightInitDuringBuild(s), r[n] = a, e.inboundNodes.forEach(e => {\n        if (!(e instanceof Array)) throw new xu(\"Corrupted configuration, expected array for nodeData: \".concat(e));\n        i(a, e);\n      });\n    }\n\n    var u = t.name,\n        c = t.layers;\n\n    for (var _e161 of c) {\n      l(_e161);\n    }\n\n    for (; !_u(a);) {\n      for (var _e162 of c) {\n        var _t153 = r[_e162.name];\n\n        if (_t153.name in a) {\n          var _e163 = a[_t153.name];\n          delete a[_t153.name];\n\n          for (var _n96 of _e163) {\n            o(_t153, _n96);\n          }\n        }\n      }\n    }\n\n    var h = [],\n        d = [],\n        p = t.inputLayers;\n\n    for (var _e164 of p) {\n      var _t154 = _e164[0],\n          _n97 = _e164[1],\n          _s87 = _e164[2];\n      vu(_t154 in r), h.push(r[_t154].inboundNodes[_n97].outputTensors[_s87]);\n    }\n\n    var f = t.outputLayers;\n\n    for (var _e165 of f) {\n      var _t155 = _e165[0],\n          _n98 = _e165[1],\n          _s88 = _e165[2];\n      vu(_t155 in r), d.push(r[_t155].inboundNodes[_n98].outputTensors[_s88]);\n    }\n\n    return new e({\n      inputs: h,\n      outputs: d,\n      name: u\n    });\n  }\n\n  get stateful() {\n    if (this._stateful) throw new xu(\"Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.\");\n\n    for (var _e166 of this.layers) {\n      if (_e166.stateful) return !0;\n    }\n\n    return !1;\n  }\n\n  resetStates() {\n    Jn(() => {\n      this.layers.forEach(e => {\n        e.stateful && e.resetStates();\n      });\n    });\n  }\n\n}\n\nfunction dd(e, t) {\n  return function (e, t, n) {\n    var s = t.length;\n    if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => null);\n    if (1 === s) return Array.isArray(e) && 1 === e.length ? e : \"object\" == typeof e && t[0] in e ? [e[t[0]]] : [e];\n\n    if (Array.isArray(e)) {\n      if (e.length !== s) throw new Error(\"Provided classWeight is an array of \".concat(e.length, \" element(s), but the model has \").concat(s, \" outputs. Make sure a set of weights is provided for each model output.\"));\n      return e;\n    }\n\n    if (\"object\" == typeof e && Object.keys(e).length > 0 && \"object\" == typeof e[Object.keys(e)[0]]) {\n      var _n99 = [];\n      return t.forEach(t => {\n        _n99.push(t in e ? e[t] : null);\n      }), _n99;\n    }\n\n    throw new Error(\"The model has multiple (\".concat(s, \") outputs, so classWeight must be either an array with \").concat(s, \" elements or an object with \").concat(t, \" keys. Provided classWeight not understood: \").concat(JSON.stringify(e)));\n  }(e, t);\n}\n\nfunction pd(_x21, _x22, _x23, _x24) {\n  return _pd.apply(this, arguments);\n}\n\nfunction _pd() {\n  _pd = _asyncToGenerator(function* (e, t, n, s) {\n    if (null != t || null != s) throw new Error(\"Support sampleWeight is not implemented yet\");\n\n    if (null != n) {\n      var _t430 = Jn(() => {\n        if (1 === e.shape.length) return gn(e);\n\n        if (2 === e.shape.length) {\n          if (e.shape[1] > 1) return cs(e, 1);\n          if (1 === e.shape[1]) return Rs(e, [e.shape[0]]);\n          throw new Error(\"Encountered unexpected last-dimension size (\".concat(e.shape[1], \") during handling of class weights. The size is expected to be >= 1.\"));\n        }\n\n        throw new Error(\"Unexpected rank of target (y) tensor (\".concat(e.rank, \") during handling of class weights. The rank is expected to be 1 or 2.\"));\n      }),\n          _s244 = Array.from(yield _t430.data());\n\n      Zn(_t430);\n      var _r177 = [];\n      return _s244.forEach(e => {\n        if (null == n[e]) throw new Error(\"classWeight must contain all classes in the training data. The class \".concat(e, \" exists in the data but not in classWeight\"));\n\n        _r177.push(n[e]);\n      }), bi(_r177, \"float32\");\n    }\n\n    return null;\n  });\n  return _pd.apply(this, arguments);\n}\n\nfunction fd(e, t) {\n  return rs(e, t);\n}\n\nfunction gd(e, t) {\n  var n, s;\n  n = t.xs, s = t.ys, l(null != n && null != s, () => \"A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates \".concat(t));\n  var r = md(\"input\", e.inputNames, n),\n      a = md(\"output\", e.outputNames, s),\n      i = r[0].shape[0];\n  l(r.length === e.inputs.length, () => \"LayersModel has \".concat(e.inputs.length, \" inputs, but the dataset provides \").concat(r.length, \" inputs.  (Expected input keys: \").concat(JSON.stringify(e.inputNames), \")\")), l(a.length === e.outputs.length, () => \"LayersModel has \".concat(e.outputs.length, \" outputs, but the dataset provides \").concat(a.length, \" outputs.  (Expected output keys: \").concat(JSON.stringify(e.outputNames), \")\"));\n\n  var _loop16 = function _loop16(_t156) {\n    l(r[_t156].shape[0] === i, () => \"Batch size mismatch: input \".concat(e.inputNames[_t156], \" has \").concat(r[_t156].shape[0], \"; expected  \").concat(i, \" based on input \").concat(e.inputNames[0], \".\"));\n  };\n\n  for (var _t156 = 0; _t156 < r.length; _t156++) {\n    _loop16(_t156);\n  }\n\n  var _loop17 = function _loop17(_t157) {\n    l(a[_t157].shape[0] === i, () => \"Batch size mismatch: output \".concat(e.outputNames[_t157], \" has \").concat(a[_t157].shape[0], \"; expected  \").concat(i, \" based on input \").concat(e.inputNames[0], \".\"));\n  };\n\n  for (var _t157 = 0; _t157 < a.length; _t157++) {\n    _loop17(_t157);\n  }\n\n  return {\n    xs: r,\n    ys: a\n  };\n}\n\nfunction md(e, t, n) {\n  if (n instanceof rt) return [n];\n  if (Array.isArray(n)) return l(n.length === t.length, () => \"Received an array of \".concat(n.length, \" Tensors, but expected \").concat(t.length, \" to match the \").concat(e, \" keys \").concat(t, \".\")), n;\n  {\n    var _s89 = [];\n\n    for (var _r59 of t) {\n      if (null == n[_r59]) throw new xu(\"The feature data generated by the dataset lacks the required \".concat(e, \" key '\").concat(_r59, \"'.\"));\n\n      _s89.push(n[_r59]);\n    }\n\n    return _s89;\n  }\n}\n\nfunction bd(e) {\n  return \"function\" == typeof e.iterator;\n}\n\nfunction xd(e) {\n  l(e > 0 && Number.isInteger(e), () => \"batchSize is required to be a positive integer, but got \".concat(e));\n}\n\nfunction yd(e, t, n) {\n  return null == e ? [null] : Array.isArray(e) ? e.map(e => bc(e, t, n - t)) : bc(e, t, n - t);\n}\n\nfunction kd(e, t) {\n  return Jn(() => null == e ? null : Array.isArray(e) ? e.map(e => kd(e, t)) : Sc(e, \"int32\" === t.dtype ? t : fn(t, \"int32\")));\n}\n\nfunction wd(e, t) {\n  var n = [];\n  var s = 0,\n      r = null;\n\n  for (; s < e;) {\n    r = s + t, r >= e && (r = e), n.push([s, r]), s = r;\n  }\n\n  return n;\n}\n\nfunction vd(e) {\n  var t = [];\n  e instanceof rt && (e = [e]);\n\n  for (var _n100 = 0; _n100 < e.length; ++_n100) {\n    var _s90 = e[_n100];\n    if (1 === _s90.rank) t.push(mc(_s90, 1));else {\n      if (0 === _s90.rank) throw new Error(\"Expected tensor to be at least 1D, but received a 0D tensor (scalar).\");\n      t.push(_s90);\n    }\n  }\n\n  return t;\n}\n\nfunction Id(e, t) {\n  if (null == e) return;\n  var n = [];\n  if (t instanceof rt) n.push(t.id);else if (Array.isArray(t)) t.forEach(e => n.push(e.id));else if (null != t) for (var _e167 in t) {\n    n.push(t[_e167].id);\n  }\n  var s = [];\n  if (e instanceof rt) -1 === n.indexOf(e.id) && s.push(e);else if (Array.isArray(e)) e.forEach(e => {\n    -1 === n.indexOf(e.id) && s.push(e);\n  });else if (null != e) for (var _t158 in e) {\n    var _r60 = e[_t158];\n    -1 === n.indexOf(_r60.id) && s.push(_r60);\n  }\n  s.forEach(e => {\n    e.isDisposed || e.dispose();\n  });\n}\n\nfunction $d(e) {\n  return Array.isArray(e);\n}\n\nfunction Sd(e) {\n  return !function (e) {\n    return e instanceof rt;\n  }(e) && !$d(e);\n}\n\nfunction Nd(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"\";\n\n  if (null == t || 0 === t.length) {\n    if (null != e) {\n      var _t159 = !1;\n\n      if ($d(e) && e.length > 0) _t159 = !0;else if (Sd(e)) {\n        for (var _n101 in e) {\n          if (e.hasOwnProperty(_n101)) {\n            _t159 = !0;\n            break;\n          }\n        }\n      } else _t159 = !0;\n      if (_t159) throw new xu(\"Error when checking model \".concat(r, \" expected no data, but got \").concat(e));\n    }\n\n    return [];\n  }\n\n  if (null == e) return t.map(e => null);\n  var a;\n\n  if (Sd(e)) {\n    e = e, a = [];\n\n    for (var _n102 of t) {\n      if (null == e[_n102]) throw new xu(\"No data provided for \\\"\".concat(_n102, \"\\\". Need data for each key in: \").concat(t));\n      a.push(e[_n102]);\n    }\n  } else if ($d(e)) {\n    if ((e = e).length !== t.length) throw new xu(\"Error when checking model \".concat(r, \": the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see \").concat(t.length, \" Tensor(s), but instead got the following list of Tensor(s): \").concat(e));\n    a = e;\n  } else {\n    if (e = e, t.length > 1) throw new xu(\"The model \".concat(r, \" expects \").concat(t.length, \" Tensor(s), but only received one Tensor. Found: Tensor with shape \").concat(e.shape));\n    a = [e];\n  }\n\n  if (a = vd(a), null != n) for (var _e168 = 0; _e168 < t.length; ++_e168) {\n    if (null == n[_e168]) continue;\n    var _i27 = a[_e168];\n    if (_i27.shape.length !== n[_e168].length) throw new xu(\"Error when checking \".concat(r, \": expected \").concat(t[_e168], \" to have \").concat(n[_e168].length, \" dimension(s). but got array with shape \").concat(_i27.shape));\n\n    for (var _t160 = 0; _t160 < n[_e168].length; ++_t160) {\n      if (0 === _t160 && !s) continue;\n      var _a50 = _i27.shape[_t160],\n          _o21 = n[_e168][_t160];\n      if (null != _o21 && _o21 >= 0 && _a50 !== _o21) throw new xu(\"\".concat(r, \" expected a batch of elements where each example has shape [\").concat(n[_e168].slice(1, n[_e168].length), \"] (i.e.,tensor shape [*,\").concat(n[_e168].slice(1, n[_e168].length), \"]) but the \").concat(r, \" received an input with \").concat(_i27.shape[0], \" examples, each with shape [\").concat(_i27.shape.slice(1, _i27.shape.length), \"] (tensor shape [\").concat(_i27.shape, \"])\"));\n    }\n  }\n  return a;\n}\n\nfunction Cd(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"\";\n  var a;\n\n  if (Array.isArray(e)) {\n    if (e.length !== t.length) throw new xu(\"Error when checking model \".concat(r, \": the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see \").concat(t.length, \" Tensor(s), but instead got \").concat(e.length, \" Tensors(s).\"));\n    a = e;\n  } else {\n    if (t.length > 1) throw new xu(\"The model expects \".concat(t.length, \" \").concat(r, \" Tensors, but only received one Tensor. Found: array with shape \").concat(JSON.stringify(e.shape), \".\"));\n    a = [e];\n  }\n\n  if (null != n) for (var _e169 = 0; _e169 < t.length; ++_e169) {\n    if (null == n[_e169]) continue;\n    var _i28 = a[_e169];\n    if (_i28.shape.length !== n[_e169].length) throw new xu(\"Error when checking \".concat(r, \": expected \").concat(t[_e169], \" to have \").concat(n[_e169].length, \" dimension(s), but got array with shape \").concat(JSON.stringify(_i28.shape)));\n\n    for (var _a51 = 0; _a51 < n[_e169].length; ++_a51) {\n      if (0 === _a51 && !s) continue;\n      var _o22 = _i28.shape[_a51],\n          _l14 = n[_e169][_a51];\n      if (null != _l14 && _l14 !== _o22) throw new xu(\"Error when checking \".concat(r, \": expected \").concat(t[_e169], \" to have shape \").concat(JSON.stringify(n[_e169]), \" but got array with shape \").concat(JSON.stringify(_i28.shape), \".\"));\n    }\n  }\n}\n\nclass Td extends hd {\n  constructor(e) {\n    super(e), this.isTraining = !1;\n  }\n\n  summary(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n    if (!this.built) throw new xu(\"This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).\");\n    !function (e, t, n) {\n      var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : console.log;\n\n      var r = function (e) {\n        var t = !0;\n        var n = [],\n            s = [];\n\n        for (var _t161 in e.nodesByDepth) {\n          n.push(e.nodesByDepth[_t161]);\n        }\n\n        for (var _e170 of n) {\n          if (_e170.length > 1 || 1 === _e170.length && _e170[0].inboundLayers.length > 1) {\n            t = !1;\n            break;\n          }\n\n          s.push(..._e170);\n        }\n\n        if (t) for (var _n103 of e.layers) {\n          var _e171 = !1;\n\n          for (var _r61 of _n103.inboundNodes) {\n            if (-1 !== s.indexOf(_r61)) {\n              if (_e171) {\n                t = !1;\n                break;\n              }\n\n              _e171 = !0;\n            }\n          }\n\n          if (!t) break;\n        }\n        return t;\n      }(e),\n          a = [\"Layer (type)\", \"Output shape\", \"Param #\"];\n\n      var i;\n\n      if (r ? (t = t || 65, n = n || [.45, .85, 1]) : (t = t || 98, n = n || [.33, .55, .67, 1]), n[n.length - 1] <= 1 && (n = n.map(e => Math.floor(t * e))), !r) {\n        a.push(\"Receives inputs\"), i = [];\n\n        for (var _t162 in e.nodesByDepth) {\n          i.push(...e.nodesByDepth[_t162]);\n        }\n      }\n\n      s(\"_\".repeat(t)), Zh(a, n, s), s(\"=\".repeat(t));\n      var o = e.layers;\n\n      for (var _e172 = 0; _e172 < o.length; ++_e172) {\n        r ? Qh(o[_e172], n, s) : ed(o[_e172], n, i, s), s((_e172 === o.length - 1 ? \"=\" : \"_\").repeat(t));\n      }\n\n      e.checkTrainableWeightsConsistency();\n\n      var l = function (e) {\n        var t;\n        return t = oh(null != e.collectedTrainableWeights ? e.collectedTrainableWeights : e.trainableWeights), t;\n      }(e),\n          u = oh(e.nonTrainableWeights);\n\n      s(\"Total params: \".concat(l + u)), s(\"Trainable params: \".concat(l)), s(\"Non-trainable params: \".concat(u)), s(\"_\".repeat(t));\n    }(this, e, t, n);\n  }\n\n  compile(e) {\n    var _this57 = this;\n\n    if (null == e.loss && (e.loss = []), this.loss = e.loss, \"string\" == typeof e.optimizer) this.optimizer_ = function (e) {\n      var t = {\n        Adagrad: () => So.adagrad(.01),\n        Adadelta: () => So.adadelta(1, .95, gu()),\n        Adam: () => So.adam(.001, .9, .999, gu()),\n        Adamax: () => So.adamax(.002, .9, .999, gu(), 0),\n        RMSProp: () => So.rmsprop(.001, .9, 0, gu()),\n        SGD: () => So.sgd(.01)\n      };\n      if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, e in t) return t[e]();\n      throw new xu(\"Unknown Optimizer \".concat(e));\n    }(e.optimizer), this.isOptimizerOwned = !0;else {\n      if (!(e.optimizer instanceof mo)) throw new xu(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n      this.optimizer_ = e.optimizer, this.isOptimizerOwned = !1;\n    }\n    var t = [];\n    if (Array.isArray(e.loss) || \"string\" == typeof e.loss || \"function\" == typeof e.loss) {\n      if (Array.isArray(e.loss)) {\n        if (e.loss.length !== this.outputs.length) throw new xu(\"When passing an Array as loss, it should have one entry per model output. The model has \".concat(this.outputs.length, \" output(s), but you passed loss=\").concat(e.loss, \".\"));\n        t = e.loss.map(e => Ph(e));\n      } else {\n        var _n104 = Ph(e.loss);\n\n        this.outputs.forEach(e => {\n          t.push(_n104);\n        });\n      }\n    } else {\n      e.loss = e.loss;\n\n      for (var _t163 in e.loss) {\n        if (-1 === this.outputNames.indexOf(_t163)) throw new xu(\"Unknown entry in loss dictionary: \\\"\".concat(_t163, \"\\\". Only expected the following keys: \").concat(this.outputNames));\n      }\n\n      for (var _n105 of this.outputNames) {\n        null == e.loss[_n105] && console.warn(\"Output \\\"\".concat(_n105, \"\\\" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to \").concat(_n105, \" during training\")), t.push(Ph(e.loss[_n105]));\n      }\n    }\n    this.lossFunctions = t, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];\n\n    for (var _e173 = 0; _e173 < this.outputs.length; ++_e173) {\n      var _t164 = this.internalOutputShapes[_e173];\n      this.feedOutputNames.push(this.outputNames[_e173]), this.feedOutputShapes.push(_t164), this.feedLossFns.push(this.lossFunctions[_e173]);\n    }\n\n    var n = [];\n    this.metrics = e.metrics, this.metricsNames = [\"loss\"], this.metricsTensors = [], ic(\"loss\", () => {\n      for (var _e174 = 0; _e174 < this.outputs.length; ++_e174) {\n        if (-1 !== n.indexOf(_e174)) continue;\n        var _t165 = this.lossFunctions[_e174];\n        this.outputs.length > 1 && (this.metricsTensors.push([_t165, _e174]), this.metricsNames.push(this.outputNames[_e174] + \"_loss\"));\n      }\n    });\n\n    var s = function (e, t) {\n      if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => []);\n      var n;\n      if (\"string\" == typeof e || \"function\" == typeof e) n = [e];else {\n        if (!Array.isArray(e) && \"object\" != typeof e) throw new TypeError(\"Type of metrics argument not understood. Expected an string,function, Array, or Object, found: \".concat(e));\n        n = e;\n      }\n      if (Array.isArray(n)) return t.map(e => n);\n      {\n        var _e175 = [];\n\n        for (var _s91 of t) {\n          var _t166 = n.hasOwnProperty(_s91) ? n[_s91] : [];\n\n          Array.isArray(_t166) || (_t166 = [_t166]), _e175.push(_t166);\n        }\n\n        return _e175;\n      }\n    }(e.metrics, this.outputNames),\n        r = (e, t, n) => {\n      this.outputNames.length > 1 && (t = this.outputNames[e] + \"_\" + t), this.metricsNames.push(t), this.metricsTensors.push([n, e]);\n    };\n\n    ic(\"metric\", () => {\n      var _loop18 = function _loop18(_e176) {\n        -1 === n.indexOf(_e176) && (t => {\n          var n, s, a;\n\n          for (var _i29 of t) {\n            if (\"string\" == typeof _i29 && -1 !== [\"accuracy\", \"acc\", \"crossentropy\", \"ce\"].indexOf(_i29)) {\n              var _t168 = _this57.internalOutputShapes[_e176];\n\n              var _r62 = void 0;\n\n              1 === _t168[_t168.length - 1] || _this57.lossFunctions[_e176] === Lh ? -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Wh : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = Vh) : _this57.lossFunctions[_e176] === Mh ? -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Gh : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = qh) : -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? s = Uh : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (s = Hh), -1 !== [\"accuracy\", \"acc\"].indexOf(_i29) ? _r62 = \"acc\" : -1 !== [\"crossentropy\", \"ce\"].indexOf(_i29) && (_r62 = \"ce\"), a = s, n = \"\" + _r62;\n            } else {\n              var _e177 = Kh(_i29);\n\n              a = _e177, n = \"\" + Xh(_i29);\n            }\n\n            var _t167 = void 0;\n\n            ic(n, () => {\n              _t167 = a;\n            }), r(_e176, n, _t167);\n          }\n        })(s[_e176]);\n      };\n\n      for (var _e176 = 0; _e176 < this.outputs.length; ++_e176) {\n        _loop18(_e176);\n      }\n    }), this.collectedTrainableWeights = this.trainableWeights;\n  }\n\n  checkTrainableWeightsConsistency() {\n    null != this.collectedTrainableWeights && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn(\"Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?\");\n  }\n\n  evaluate(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = null == n.batchSize ? 32 : n.batchSize;\n    xd(s);\n    var r = this.standardizeUserDataXY(e, t, !0, s);\n\n    try {\n      var _a52 = r[0].concat(r[1]);\n\n      return this.makeTestFunction(), $u(this.testLoop(this.testFunction, _a52, s, n.verbose, n.steps));\n    } finally {\n      Id(r[0], e), Id(r[1], t);\n    }\n  }\n\n  evaluateDataset(e, t) {\n    var _this58 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this58.makeTestFunction(), function () {\n        var _ref5 = _asyncToGenerator(function* (e, t, n) {\n          var s = null != (n = n || {}).batches,\n              r = e.testFunction;\n          var a = [];\n          if (n.verbose > 0) throw new yu(\"Verbose mode is not implemented yet.\");\n          l(!s || n.batches > 0 && Number.isInteger(n.batches), () => \"Test loop expects `batches` to be a positive integer, but received \".concat(JSON.stringify(n.batches)));\n          var i = \"function\" == typeof t.next ? t : yield t.iterator();\n          var o = 0,\n              u = 0;\n\n          var _loop19 = function* _loop19() {\n            var t = yield i.next();\n\n            if (a = Jn(() => {\n              if (t.value) {\n                (function () {\n                  var {\n                    xs: n,\n                    ys: s\n                  } = gd(e, t.value),\n                      i = n.concat(s),\n                      l = Jn(() => r(i));\n                  if (Zn(i), 0 === u) for (var _e179 = 0; _e179 < l.length; ++_e179) {\n                    a.push(Ka(0));\n                  }\n                  var c = i[0].shape[0];\n\n                  var _loop20 = function _loop20(_e180) {\n                    var t = l[_e180],\n                        n = a[_e180];\n                    a[_e180] = Jn(() => ts(a[_e180], rs(c, t))), u > 0 && Zn(n);\n                  };\n\n                  for (var _e180 = 0; _e180 < l.length; ++_e180) {\n                    _loop20(_e180);\n                  }\n\n                  Zn(l), o += c, ++u;\n                })();\n              }\n\n              return a;\n            }), t.done) {\n              s && console.warn(\"Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least `batches` batches (in this case, \".concat(n.batches, \" batches). You may need to use the repeat() function when building your dataset.\"));\n              return \"break\";\n            }\n          };\n\n          for (; !s || u < n.batches;) {\n            var _ret = yield* _loop19();\n\n            if (_ret === \"break\") break;\n          }\n\n          for (var _e178 = 0; _e178 < a.length; ++_e178) {\n            var _t169 = a[_e178];\n            a[_e178] = ss(a[_e178], o), Zn(_t169);\n          }\n\n          return $u(a);\n        });\n\n        return function (_x25, _x26, _x27) {\n          return _ref5.apply(this, arguments);\n        };\n      }()(_this58, e, t);\n    })();\n  }\n\n  checkNumSamples(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"steps\";\n    var r;\n\n    if (null != n) {\n      if (r = null, null != t) throw new xu(\"If \".concat(s, \" is set, batchSize must be null or undefined.Got batchSize = \").concat(t));\n    } else {\n      if (null == e) throw new xu(\"Either the input data should have a defined shape, or \".concat(s, \" shoud be specified.\"));\n      r = Array.isArray(e) ? e[0].shape[0] : e.shape[0];\n    }\n\n    return r;\n  }\n\n  execute(e, t) {\n    if (Array.isArray(t) && 0 === t.length) throw new xu(\"`outputs` is an empty Array, which is not allowed.\");\n    var n = Array.isArray(t),\n        s = this.retrieveSymbolicTensors(n ? t : [t]),\n        r = new rd();\n\n    if (e instanceof rt && (e = [e]), Array.isArray(e)) {\n      if (e.length !== this.inputs.length) throw new xu(\"The number of inputs provided (\".concat(e.length, \") does not match the number of inputs of this model (\").concat(this.inputs.length, \").\"));\n\n      for (var _t170 = 0; _t170 < this.inputs.length; ++_t170) {\n        r.add(this.inputs[_t170], e[_t170]);\n      }\n    } else for (var _t171 of this.inputs) {\n      var _n106 = e[_t171.name];\n      if (null == _n106) throw new xu(\"No value is provided for the model's input \".concat(_t171.name));\n      r.add(_t171, _n106);\n    }\n\n    var a = od(s, r);\n    return n ? a : a[0];\n  }\n\n  retrieveSymbolicTensors(e) {\n    var t = wu(null, e.length);\n    var n = e.length;\n\n    for (var _s92 of this.layers) {\n      var _r63 = Array.isArray(_s92.output) ? _s92.output : [_s92.output],\n          _a53 = _r63.map(e => e.name);\n\n      for (var _s93 = 0; _s93 < e.length; ++_s93) {\n        var _i30 = _a53.indexOf(e[_s93]);\n\n        if (-1 !== _i30 && (t[_s93] = _r63[_i30], n--), 0 === n) break;\n      }\n\n      if (0 === n) break;\n    }\n\n    if (n > 0) {\n      var _n107 = [];\n      throw t.forEach((t, s) => {\n        null == t && _n107.push(e[s]);\n      }), new xu(\"Cannot find SymbolicTensors for output name(s): \".concat(JSON.stringify(_n107)));\n    }\n\n    return t;\n  }\n\n  predictLoop(e) {\n    var _this59 = this;\n\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    return Jn(() => {\n      var s = this.checkNumSamples(e);\n      if (n) throw new yu(\"Verbose predictLoop() is not implemented yet.\");\n      var r = wd(s, t),\n          a = this.outputs.map(e => []);\n\n      var _loop21 = function _loop21(_t172) {\n        Jn(() => {\n          var n = yd(e, r[_t172][0], r[_t172][1]),\n              s = [];\n          if (Array.isArray(n)) for (var _e181 = 0; _e181 < n.length; ++_e181) {\n            s.push({\n              key: _this59.inputs[_e181],\n              value: n[_e181]\n            });\n          } else s.push({\n            key: _this59.inputs[0],\n            value: n\n          });\n          var a = new rd(s);\n          return od(_this59.outputs, a);\n        }).forEach((e, t) => a[t].push(e));\n      };\n\n      for (var _t172 = 0; _t172 < r.length; ++_t172) {\n        _loop21(_t172);\n      }\n\n      return $u(a.map(e => Ds(e, 0)));\n    });\n  }\n\n  predict(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    var n = vd(e);\n    Cd(n, this.inputNames, this.feedInputShapes, !1);\n\n    try {\n      var _s94 = null == t.batchSize ? 32 : t.batchSize;\n\n      return xd(_s94), this.predictLoop(n, _s94);\n    } finally {\n      Id(n, e);\n    }\n  }\n\n  predictOnBatch(e) {\n    Cd(e, this.inputNames, this.feedInputShapes, !0);\n    var t = (Array.isArray(e) ? e[0] : e).shape[0];\n    return this.predictLoop(e, t);\n  }\n\n  standardizeUserDataXY(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    if (null == this.optimizer_) throw new bu(\"You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).\");\n    var r = [];\n\n    for (var _e182 = 0; _e182 < this.feedOutputShapes.length; ++_e182) {\n      var _t173 = this.feedOutputShapes[_e182];\n      r.push(this.feedLossFns[_e182] === Mh ? _t173.slice(0, _t173.length - 1).concat([1]) : _t173);\n    }\n\n    if (function (e, t, n) {\n      var s = Du(e.map(e => e.shape[0]));\n      s.sort();\n      var r = Du(t.map(e => e.shape[0]));\n      if (r.sort(), s.length > 1) throw new xu(\"All input Tensors (x) should have the same number of samples. Got array shapes: \".concat(JSON.stringify(e.map(e => e.shape))));\n      if (r.length > 1) throw new xu(\"All target Tensors (y) should have the same number of samples. Got array shapes: \".concat(JSON.stringify(t.map(e => e.shape))));\n      if (s.length > 0 && r.length > 0 && !p(s, r)) throw new xu(\"Input Tensors should have the same number of samples as target Tensors. Found \".concat(s[0], \" input sample(s) and \").concat(r[0], \" target sample(s).\"));\n    }(e = Nd(e, this.feedInputNames, this.feedInputShapes, !1, \"input\"), t = Nd(t, this.feedOutputNames, r, !1, \"target\")), function (e, t, n) {\n      var s = [Fh, Lh, Oh];\n\n      for (var _r64 = 0; _r64 < e.length; ++_r64) {\n        var _a54 = e[_r64],\n            _i31 = t[_r64],\n            _o23 = n[_r64];\n\n        if (null != _i31) {\n          if (_i31 === Oh && 1 === _a54.shape[_a54.shape.length - 1]) throw new xu(\"You are passing a target array of shape \".concat(_a54.shape, \" while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].\"));\n\n          if (-1 !== s.indexOf(_i31)) {\n            var _e183 = _a54.shape.slice(1),\n                _t174 = _o23.slice(1);\n\n            for (var _n108 = 0; _n108 < _e183.length; ++_n108) {\n              var _s95 = _e183[_n108],\n                  _r65 = _t174[_n108];\n              if (null != _r65 && _s95 !== _r65) throw new xu(\"A target Tensor with shape \".concat(_a54.shape, \" was passed for an output of shape \").concat(_o23, \", while using a loss function that expects targets to have the same shape as the output.\"));\n            }\n          }\n        }\n      }\n    }(t, this.feedLossFns, this.feedOutputShapes), this.stateful && null != s && s > 0 && e[0].shape[0] % s != 0) throw new xu(\"In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size \".concat(s, \". Found: \").concat(e[0].shape[0], \" sample(s).\"));\n    return [e, t];\n  }\n\n  standardizeUserData(e, t, n, s) {\n    var _arguments = arguments,\n        _this60 = this;\n\n    return _asyncToGenerator(function* () {\n      var r = _arguments.length > 4 && _arguments[4] !== undefined ? _arguments[4] : !0;\n      var a = _arguments.length > 5 ? _arguments[5] : undefined;\n\n      var [i, o] = _this60.standardizeUserDataXY(e, t, r, a);\n\n      if (null != n) throw new Error(\"sample weight is not supported yet.\");\n      var l = null;\n\n      if (null != s) {\n        var _e184 = dd(s, _this60.outputNames);\n\n        l = [];\n\n        for (var _t175 = 0; _t175 < _e184.length; ++_t175) {\n          l.push(yield pd(o[_t175], null, _e184[_t175]));\n        }\n      }\n\n      return [i, o, l];\n    })();\n  }\n\n  testLoop(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    var r = arguments.length > 4 ? arguments[4] : undefined;\n    return Jn(() => {\n      var a = this.checkNumSamples(t, n, r, \"steps\"),\n          i = [];\n      if (s > 0) throw new yu(\"Verbose mode is not implemented yet.\");\n      if (null != r) throw new yu(\"steps mode in testLoop() is not implemented yet\");\n      {\n        var _s96 = wd(a, n),\n            _r66 = bi(fc(0, a));\n\n        for (var _n109 = 0; _n109 < _s96.length; ++_n109) {\n          var _a55 = _s96[_n109][0],\n              _o24 = _s96[_n109][1],\n              _l15 = bc(_r66, _a55, _o24 - _a55),\n              _u9 = kd(t, _l15),\n              _c8 = e(_u9);\n\n          if (0 === _n109) for (var _e185 = 0; _e185 < _c8.length; ++_e185) {\n            i.push(Ka(0));\n          }\n\n          for (var _e186 = 0; _e186 < _c8.length; ++_e186) {\n            i[_e186] = ts(i[_e186], rs(_o24 - _a55, _c8[_e186]));\n          }\n        }\n\n        for (var _e187 = 0; _e187 < i.length; ++_e187) {\n          i[_e187] = ss(i[_e187], a);\n        }\n      }\n      return i;\n    });\n  }\n\n  getDedupedMetricsNames() {\n    var e = this.metricsNames,\n        t = [];\n\n    for (var _n110 = 0; _n110 < e.length; ++_n110) {\n      var _s97 = e[_n110];\n      var _r67 = _s97;\n      Iu(e, _s97) > 1 && (_r67 += \"_\".concat(Iu(e.slice(0, _n110), _s97))), t.push(_r67);\n    }\n\n    return t;\n  }\n\n  makeTrainFunction() {\n    return e => {\n      var t = [],\n          n = e.slice(0, this.inputs.length),\n          s = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),\n          r = e.slice(this.inputs.length + this.outputs.length, this.inputs.length + 2 * this.outputs.length),\n          a = [],\n          i = this.collectedTrainableWeights.map(e => e.read());\n      return [this.optimizer_.minimize(() => {\n        var e = [];\n\n        for (var _t176 = 0; _t176 < this.inputs.length; ++_t176) {\n          e.push({\n            key: this.inputs[_t176],\n            value: n[_t176]\n          });\n        }\n\n        var i = new rd(e),\n            o = od(this.outputs, i, {\n          training: !0\n        });\n        var l;\n\n        for (var _e188 = 0; _e188 < this.lossFunctions.length; ++_e188) {\n          var _n111 = (0, this.lossFunctions[_e188])(s[_e188], o[_e188]);\n\n          null != r[_e188] && (_n111 = fd(_n111, r[_e188]));\n\n          var _a56 = ua(_n111);\n\n          t.push(_a56), l = 0 === _e188 ? _n111 : ts(l, _n111);\n        }\n\n        for (var _e189 = 0; _e189 < this.metricsTensors.length; ++_e189) {\n          var _n112 = void 0;\n\n          if (this.outputs.length > 1 && _e189 < this.outputs.length) _n112 = t[_e189];else {\n            var _t177 = this.metricsTensors[_e189][1];\n            _n112 = ua((0, this.metricsTensors[_e189][0])(s[_t177], o[_t177]));\n          }\n          Qn(_n112), a.push(_n112);\n        }\n\n        return l = ua(l), this.calculateLosses().forEach(e => {\n          l = ts(l, e);\n        }), l;\n      }, !0, i)].concat(a);\n    };\n  }\n\n  makeTestFunction() {\n    this.testFunction = e => Jn(() => {\n      var t = [];\n      var n;\n      var s = e.slice(0, this.inputs.length),\n          r = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),\n          a = [];\n\n      for (var _e190 = 0; _e190 < this.inputs.length; ++_e190) {\n        a.push({\n          key: this.inputs[_e190],\n          value: s[_e190]\n        });\n      }\n\n      var i = new rd(a),\n          o = od(this.outputs, i);\n\n      for (var _e191 = 0; _e191 < this.lossFunctions.length; ++_e191) {\n        var _s98 = ua((0, this.lossFunctions[_e191])(r[_e191], o[_e191]));\n\n        n = 0 === _e191 ? _s98 : ts(n, _s98), t.push(n);\n      }\n\n      for (var _e192 = 0; _e192 < this.metricsTensors.length; ++_e192) {\n        var _n113 = this.metricsTensors[_e192][1],\n            _s99 = ua((0, this.metricsTensors[_e192][0])(r[_n113], o[_n113]));\n\n        t.push(_s99);\n      }\n\n      return t;\n    });\n  }\n\n  fit(e, t) {\n    var _arguments2 = arguments,\n        _this61 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = _arguments2.length > 2 && _arguments2[2] !== undefined ? _arguments2[2] : {};\n      return function () {\n        var _ref6 = _asyncToGenerator(function* (e, t, n) {\n          var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n          if (e.isTraining) throw new Error(\"Cannot start training because another fit() call is ongoing.\");\n          var a, i, o, l, u, c, h;\n          e.isTraining = !0;\n\n          try {\n            var _d5 = null == s.batchSize ? 32 : s.batchSize;\n\n            xd(_d5);\n\n            var _p5 = !1,\n                _f4 = yield e.standardizeUserData(t, n, s.sampleWeight, s.classWeight, _p5, _d5);\n\n            a = _f4[0], i = _f4[1], h = _f4[2];\n\n            var _g6,\n                _m5 = !1;\n\n            if (null != s.validationData && s.validationData.length > 0) {\n              if (_m5 = !0, 2 !== s.validationData.length) throw 3 === s.validationData.length ? new yu(\"validationData including sample weights is not supported yet.\") : new xu(\"When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; \".concat(s.validationData, \" is invalid.\"));\n              o = s.validationData[0], l = s.validationData[1];\n\n              var _t178 = !0,\n                  _n114 = yield e.standardizeUserData(o, l, null, null, _t178, _d5);\n\n              u = _n114[0], c = _n114[1], _g6 = u.concat(c);\n            } else if (null != s.validationSplit && s.validationSplit > 0 && s.validationSplit < 1) {\n              _m5 = !0;\n\n              var _e193 = Math.floor(a[0].shape[0] * (1 - s.validationSplit)),\n                  _t179 = a[0].shape[0];\n\n              u = yd(a, _e193, _t179), a = yd(a, 0, _e193), c = yd(i, _e193, _t179), i = yd(i, 0, _e193), _g6 = u.concat(c);\n            } else null != s.validationSteps && (_m5 = !0);\n\n            var _b5 = a.concat(i).concat(h);\n\n            e.checkTrainableWeightsConsistency();\n\n            var _x31 = e.makeTrainFunction(),\n                _y5 = e.getDedupedMetricsNames();\n\n            var _k3, _w2;\n\n            _m5 ? (e.makeTestFunction(), _k3 = e.testFunction, _w2 = _y5.slice().concat(_y5.map(e => \"val_\" + e))) : (_k3 = null, _g6 = [], _w2 = _y5.slice());\n\n            var _v2 = Ch(s.callbacks, s.yieldEvery);\n\n            return yield function () {\n              var _ref7 = _asyncToGenerator(function* (e, t, n, s, a, i, o, l, u, c, h, d, p, f, g) {\n                null == a && (a = 32), null == i && (i = 1), null == h && (h = !0), null == p && (p = 0);\n                var m = !1;\n                null != u && null != c && (m = !0);\n                var b = e.checkNumSamples(n, a, null, \"steps_per_epoch\");\n                var x;\n                null != b && (x = fc(0, b)), null == o && (o = 1);\n                var {\n                  callbackList: y,\n                  history: k\n                } = Eh(l, o, i, p, b, null, a, m, d);\n                y.setModel(e), e.history = k, yield y.onTrainBegin(), e.stopTraining_ = !1;\n\n                var _loop22 = function* _loop22(_o25) {\n                  yield y.onEpochBegin(_o25);\n                  var i = {};\n                  {\n                    yield* function* () {\n                      if (\"batch\" === h) throw new yu(\"batch shuffling is not implemneted yet\");\n                      h && r(x);\n                      var o = bi(x),\n                          l = wd(b, a);\n\n                      var _loop23 = function* _loop23(_r68) {\n                        var h = {};\n                        if (yield y.onBatchBegin(_r68, h), Jn(() => {\n                          var d = l[_r68][0],\n                              p = l[_r68][1],\n                              f = bc(o, d, p - d);\n                          h.batch = _r68, h.size = p - d;\n                          var g = kd(n, f),\n                              b = t(g);\n\n                          for (var _e194 = 0; _e194 < s.length; ++_e194) {\n                            var _t180 = b[_e194];\n                            h[s[_e194]] = _t180, Qn(_t180);\n                          }\n\n                          if (_r68 === l.length - 1 && m) {\n                            var _t181 = e.testLoop(u, c, a);\n\n                            for (var _e195 = 0; _e195 < s.length; ++_e195) {\n                              var _n115 = s[_e195],\n                                  _r69 = _t181[_e195];\n                              Qn(_r69), i[\"val_\" + _n115] = _r69;\n                            }\n                          }\n                        }), yield y.onBatchEnd(_r68, h), kh(h), e.stopTraining_) return \"break\";\n                      };\n\n                      for (var _r68 = 0; _r68 < l.length; ++_r68) {\n                        var _ret3 = yield* _loop23(_r68);\n\n                        if (_ret3 === \"break\") break;\n                      }\n\n                      o.dispose();\n                    }();\n                  }\n                  if (yield y.onEpochEnd(_o25, i), e.stopTraining_) return \"break\";\n                };\n\n                for (var _o25 = p; _o25 < i; ++_o25) {\n                  var _ret2 = yield* _loop22(_o25);\n\n                  if (_ret2 === \"break\") break;\n                }\n\n                return yield y.onTrainEnd(), yield e.history.syncData(), e.history;\n              });\n\n              return function (_x32, _x33, _x34, _x35, _x36, _x37, _x38, _x39, _x40, _x41, _x42, _x43, _x44, _x45, _x46) {\n                return _ref7.apply(this, arguments);\n              };\n            }()(e, _x31, _b5, _y5, _d5, s.epochs, s.verbose, _v2, _k3, _g6, s.shuffle, _w2, s.initialEpoch);\n          } finally {\n            e.isTraining = !1, Id(a, t), Id(i, n), Id(u, o), Id(c, l), null != h && Zn(h);\n          }\n        });\n\n        return function (_x28, _x29, _x30) {\n          return _ref6.apply(this, arguments);\n        };\n      }()(_this61, e, t, n);\n    })();\n  }\n\n  fitDataset(e, t) {\n    var _this62 = this;\n\n    return _asyncToGenerator(function* () {\n      return function () {\n        var _ref8 = _asyncToGenerator(function* (e, t, n) {\n          var s = null != n.batchesPerEpoch;\n          if (l(null != e.optimizer, () => \"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).\"), l(null != n, () => \"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.\"), l(null != n.epochs && n.epochs > 0 && Number.isInteger(n.epochs), () => \"For fitDataset(), config.epochs is expected to be a positive integer, but got \".concat(n.epochs)), l(!s || n.batchesPerEpoch > 0 && Number.isInteger(n.batchesPerEpoch), () => \"For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got \".concat(n.batchesPerEpoch)), l(null == n.validationSplit, () => \"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.\"), e.isTraining) throw new Error(\"Cannot start training because another fit() call is ongoing.\");\n          e.isTraining = !0;\n\n          try {\n            var _r70 = null != n.validationData;\n\n            var _a57, _i32;\n\n            if (_r70) if (bd(n.validationData)) l(null == n.validationBatches || n.validationBatches > 0 && Number.isInteger(n.validationBatches), () => \"For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got \".concat(n.validationBatches));else {\n              var _e196 = function (e) {\n                if (3 === e.length) throw new yu(\"Validation with sample weights is not implemented yet.\");\n                return {\n                  xs: e[0],\n                  ys: e[1]\n                };\n              }(n.validationData);\n\n              _a57 = _e196.xs, _i32 = _e196.ys;\n            }\n\n            var _o26 = e.makeTrainFunction(),\n                _u10 = e.getDedupedMetricsNames();\n\n            var _c9;\n\n            _c9 = _r70 ? _u10.slice().concat(_u10.map(e => \"val_\" + e)) : _u10.slice();\n\n            var _h6 = Ch(n.callbacks, n.yieldEvery),\n                _d6 = null == n.verbose ? 1 : n.verbose,\n                {\n              callbackList: _p6,\n              history: _f5\n            } = Eh(_h6, _d6, n.epochs, null, null, function (e, t) {\n              var n = null;\n              return null != t.batchesPerEpoch ? n = t.batchesPerEpoch : Number.isFinite(e.size) && (n = e.size), n;\n            }(t, n), null, _r70, _c9);\n\n            _p6.setModel(e), e.history = _f5, yield _p6.onTrainBegin(), e.stopTraining_ = !1;\n\n            var _g7 = null == n.initialEpoch ? 0 : n.initialEpoch,\n                _m6 = yield t.iterator();\n\n            for (; _g7 < n.epochs;) {\n              var _l16 = {};\n              yield _p6.onEpochBegin(_g7);\n              var _c10 = 0,\n                  _h7 = 0;\n\n              for (s || (_m6 = yield t.iterator()); !s || _c10 < n.batchesPerEpoch;) {\n                var _t182 = yield _m6.next();\n\n                if (s && _t182.done) {\n                  console.warn(\"You provided `batchesPerEpoch` as \".concat(n.batchesPerEpoch, \", but your dataset iterator ran out of data after \").concat(_c10, \" batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, \") + n.batchesPerEpoch * n.epochs + \" batches). You may need to use the repeat() function when building your dataset.\");\n                  break;\n                }\n\n                if (null != _t182.value) {\n                  var {\n                    xs: _s100,\n                    ys: _r71\n                  } = gd(e, _t182.value),\n                      _a58 = {};\n                  _a58.batch = _h7, _a58.size = _s100[0].shape[0], yield _p6.onBatchBegin(_h7, _a58);\n                  var _i33 = [];\n\n                  if (null != n.classWeight) {\n                    var _t183 = dd(n.classWeight, e.outputNames);\n\n                    for (var _e197 = 0; _e197 < _t183.length; ++_e197) {\n                      _i33.push(yield pd(_r71[_e197], null, _t183[_e197]));\n                    }\n                  }\n\n                  var _l17 = _s100.concat(_r71).concat(_i33),\n                      _d7 = _o26(_l17);\n\n                  Zn(_l17);\n\n                  for (var _e198 = 0; _e198 < _u10.length; ++_e198) {\n                    var _t184 = _d7[_e198];\n                    _a58[_u10[_e198]] = _t184, Qn(_t184);\n                  }\n\n                  yield _p6.onBatchEnd(_h7, _a58), kh(_a58), _h7++, _c10++;\n                }\n\n                if (s ? _c10 >= n.batchesPerEpoch : _t182.done) {\n                  if (_r70) {\n                    var _t185 = void 0;\n\n                    _t185 = bd(n.validationData) ? Su(yield e.evaluateDataset(n.validationData, {\n                      batches: n.validationBatches\n                    })) : Su(e.evaluate(_a57, _i32, {\n                      batchSize: null == n.validationBatchSize ? 32 : n.validationBatchSize,\n                      verbose: 0\n                    }));\n\n                    for (var _n116 = 0; _n116 < e.metricsNames.length; ++_n116) {\n                      _l16[\"val_\".concat(e.metricsNames[_n116])] = _t185[_n116];\n                    }\n                  }\n\n                  break;\n                }\n\n                if (e.stopTraining_) break;\n              }\n\n              if (yield _p6.onEpochEnd(_g7, _l16), _g7++, e.stopTraining_) break;\n            }\n\n            return yield _p6.onTrainEnd(), yield e.history.syncData(), e.history;\n          } finally {\n            e.isTraining = !1;\n          }\n        });\n\n        return function (_x47, _x48, _x49) {\n          return _ref8.apply(this, arguments);\n        };\n      }()(_this62, e, t);\n    })();\n  }\n\n  trainOnBatch(e, t) {\n    var _this63 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = yield _this63.standardizeUserData(e, t),\n          s = n[0],\n          r = n[1],\n          a = _this63.makeTrainFunction()(s.concat(r)),\n          i = [];\n\n      for (var _e199 of a) {\n        var _t186 = yield _e199.data();\n\n        i.push(_t186[0]);\n      }\n\n      return Zn(a), $u(i);\n    })();\n  }\n\n  getNamedWeights(e) {\n    var t = [],\n        n = null != e && e.trainableOnly,\n        s = n ? this.trainableWeights : this.weights,\n        r = this.getWeights(n);\n\n    for (var _e200 = 0; _e200 < s.length; ++_e200) {\n      n && !s[_e200].trainable || t.push({\n        name: s[_e200].originalName,\n        tensor: r[_e200]\n      });\n    }\n\n    return t;\n  }\n\n  set stopTraining(e) {\n    this.stopTraining_ = e;\n  }\n\n  get stopTraining() {\n    return this.stopTraining_;\n  }\n\n  get optimizer() {\n    return this.optimizer_;\n  }\n\n  set optimizer(e) {\n    this.optimizer_ !== e && (this.optimizer_ = e, this.isOptimizerOwned = !1);\n  }\n\n  dispose() {\n    var e = super.dispose();\n\n    if (0 === e.refCountAfterDispose && null != this.optimizer && this.isOptimizerOwned) {\n      var _t187 = Yn().numTensors;\n      this.optimizer_.dispose(), e.numDisposedVariables += _t187 - Yn().numTensors;\n    }\n\n    return e;\n  }\n\n  getLossIdentifiers() {\n    var e;\n    if (\"string\" == typeof this.loss) e = Nu(this.loss);else if (Array.isArray(this.loss)) {\n      for (var _e201 of this.loss) {\n        if (\"string\" != typeof _e201) throw new Error(\"Serialization of non-string loss is not supported.\");\n      }\n\n      e = this.loss.map(e => Nu(e));\n    } else {\n      var _t188 = Object.keys(this.loss);\n\n      e = {};\n      var _n117 = this.loss;\n\n      for (var _s101 of _t188) {\n        if (\"string\" != typeof _n117[_s101]) throw new Error(\"Serialization of non-string loss is not supported.\");\n        e[_s101] = Nu(_n117[_s101]);\n      }\n    }\n    return e;\n  }\n\n  getMetricIdentifiers() {\n    if (\"string\" == typeof this.metrics || \"function\" == typeof this.metrics) return [Nu(Xh(this.metrics))];\n    if (Array.isArray(this.metrics)) return this.metrics.map(e => Nu(Xh(e)));\n    {\n      var _e202 = {};\n\n      for (var _t189 in this.metrics) {\n        _e202[_t189] = Nu(Xh(this.metrics[_t189]));\n      }\n\n      return _e202;\n    }\n  }\n\n  getTrainingConfig() {\n    return {\n      loss: this.getLossIdentifiers(),\n      metrics: this.getMetricIdentifiers(),\n      optimizer_config: {\n        class_name: this.optimizer.getClassName(),\n        config: this.optimizer.getConfig()\n      }\n    };\n  }\n\n  loadTrainingConfig(e) {\n    if (null != e.weighted_metrics) throw new Error(\"Loading weight_metrics is not supported yet.\");\n    if (null != e.loss_weights) throw new Error(\"Loading loss_weights is not supported yet.\");\n    if (null != e.sample_weight_mode) throw new Error(\"Loading sample_weight_mode is not supported yet.\");\n    var t = Rh(nd(e.optimizer_config));\n    var n, s;\n    if (\"string\" == typeof e.loss) n = Cu(e.loss);else if (Array.isArray(e.loss)) n = e.loss.map(e => Cu(e));else if (null != e.loss) {\n      n = {};\n\n      for (var _t190 in e.loss) {\n        n[_t190] = Cu(e.loss[_t190]);\n      }\n    }\n    if (Array.isArray(e.metrics)) s = e.metrics.map(e => Cu(e));else if (null != e.metrics) {\n      s = {};\n\n      for (var _t191 in e.metrics) {\n        s[_t191] = Cu(e.metrics[_t191]);\n      }\n    }\n    this.compile({\n      loss: n,\n      metrics: s,\n      optimizer: t\n    });\n  }\n\n  save(e, t) {\n    var _this64 = this;\n\n    return _asyncToGenerator(function* () {\n      if (\"string\" == typeof e) {\n        var _t192 = Ht.getSaveHandlers(e);\n\n        if (0 === _t192.length) throw new xu(\"Cannot find any save handlers for URL '\".concat(e, \"'\"));\n        if (_t192.length > 1) throw new xu(\"Found more than one (\".concat(_t192.length, \") save handlers for URL '\").concat(e, \"'\"));\n        e = _t192[0];\n      }\n\n      if (null == e.save) throw new xu(\"LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.\");\n      var n = yield Lt(_this64.getNamedWeights(t)),\n          s = {\n        modelTopology: _this64.toJSON(null, !1),\n        format: \"layers-model\",\n        generatedBy: \"TensorFlow.js tfjs-layers v3.9.0\",\n        convertedBy: null\n      };\n\n      if (null != t && t.includeOptimizer && null != _this64.optimizer) {\n        s.trainingConfig = _this64.getTrainingConfig();\n        var _e203 = \"optimizer\",\n            {\n          data: _t193,\n          specs: _r72\n        } = yield Lt(yield _this64.optimizer.getWeights(), _e203);\n        n.specs.push(..._r72), n.data = Wt([n.data, _t193]);\n      }\n\n      return null != _this64.userDefinedMetadata && (Yh(_this64.userDefinedMetadata, _this64.name, !0), s.userDefinedMetadata = _this64.userDefinedMetadata), s.weightData = n.data, s.weightSpecs = n.specs, e.save(s);\n    })();\n  }\n\n  setUserDefinedMetadata(e) {\n    Yh(e, this.name), this.userDefinedMetadata = e;\n  }\n\n  getUserDefinedMetadata() {\n    return this.userDefinedMetadata;\n  }\n\n}\n\nTd.className = \"Model\", Kn(Td);\n\nclass Ed extends Td {}\n\nEd.className = \"Functional\", Kn(Ed);\n\nclass Rd extends Td {\n  constructor(e) {\n    if (super({\n      inputs: [],\n      outputs: []\n    }), e = e || {}, this.trainable = !0, this.built = !1, this.name = null != e.name ? e.name : nh(\"sequential_\"), null != e.layers) for (var _t194 of e.layers) {\n      this.add(_t194);\n    }\n  }\n\n  checkShape(e) {\n    if (e.inboundNodes[0].outputTensors[0].shape.some(e => e < 0)) throw new xu(\"Negative dimension size caused by adding layer \".concat(e.name, \" with input shape [\").concat(e.inboundNodes[0].inputTensors[0].shape, \"]\"));\n  }\n\n  add(e) {\n    var t = e instanceof Rd || e instanceof Td;\n    var n;\n\n    if (t) {\n      if (n = e, 1 !== n.outputs.length) throw new xu(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n      if (1 !== n.inputs.length) throw new xu(\"All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.\");\n    }\n\n    if (0 === this.outputs.length) {\n      if (0 === e.inboundNodes.length) {\n        if (null == e.batchInputShape) throw new xu(\"The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.\");\n\n        var _t195 = function (e) {\n          if (null == e.batchShape && null == e.shape) throw new Error(\"Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.\");\n          if (null != e.batchShape && null != e.shape) throw new xu(\"Please provide either a `shape` or `batchShape` argument to Input, but not both.\");\n          var t = e.batchShape;\n          null != e.shape && null == t && (t = [null].concat(e.shape));\n          var n = e.dtype;\n          return null == n && (n = \"float32\"), new xh({\n            batchInputShape: t,\n            name: e.name,\n            dtype: n,\n            sparse: e.sparse\n          }).inboundNodes[0].outputTensors[0];\n        }({\n          batchShape: e.batchInputShape,\n          dtype: e.dtype,\n          name: e.name + \"_input\"\n        });\n\n        e.apply(_t195);\n      }\n\n      if (t) this.outputs = n.outputs, this.inputs = n.inputs;else {\n        if (1 !== e.inboundNodes.length) throw new xu(\"A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer \".concat(e.name, \" which has \").concat(e.inboundNodes.length, \" pre-existing inbound connections.\"));\n        if (1 !== e.inboundNodes[0].outputTensors.length) throw new xu(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n        this.checkShape(e), this.outputs = [e.inboundNodes[0].outputTensors[0]], this.inputs = bh(this.outputs[0]);\n      }\n      this.inboundNodes = [], new fh({\n        outboundLayer: this,\n        inboundLayers: [],\n        nodeIndices: [],\n        tensorIndices: [],\n        inputTensors: this.inputs,\n        outputTensors: this.outputs,\n        inputMasks: wu(null, this.inputs.length),\n        outputMasks: [null],\n        inputShapes: this.inputs.map(e => e.shape),\n        outputShapes: this.outputs[0].shape\n      });\n    } else {\n      var _t196 = e.apply(this.outputs[0]);\n\n      if (Array.isArray(_t196)) throw new TypeError(\"All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\");\n      this.checkShape(e), this.outputs = [_t196], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n\n    this.layers.push(e), this.built = !1;\n  }\n\n  pop() {\n    if (0 === this.layers.length) throw new TypeError(\"There are no layers in the model.\");\n    if (this.layers.pop(), 0 === this.layers.length) this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];else {\n      var _e204 = this.layers.length - 1;\n\n      this.layers[_e204].outboundNodes = [], this.outputs = [this.layers[_e204].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n  }\n\n  call(e, t) {\n    return null == this.model && this.build(), this.model.call(e, t);\n  }\n\n  build(e) {\n    if (ih(e), 0 === this.inputs.length || 0 === this.outputs.length) throw new TypeError(\"Sequential model cannot be built: model is empty. Add some layers first.\");\n    this.model = new Td({\n      inputs: this.inputs,\n      outputs: this.outputs[0],\n      name: this.name + \"_model\"\n    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = !0;\n  }\n\n  countParams() {\n    return this.built || this.build(), super.countParams();\n  }\n\n  summary(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n    this.built || this.build(), super.summary(e, t, n);\n  }\n\n  setWeights(e) {\n    null == this.model && this.build(), this.model.setWeights(e);\n  }\n\n  evaluate(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    if (!this.built) throw new bu(\"The model needs to be compiled before being used.\");\n    return this.model.evaluate(e, t, n);\n  }\n\n  evaluateDataset(e, t) {\n    var _this65 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!_this65.built) throw new bu(\"The model needs to be compiled before being used.\");\n      return _this65.model.evaluateDataset(e, t);\n    })();\n  }\n\n  predict(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    return null == this.model && this.build(), this.model.predict(e, t);\n  }\n\n  predictOnBatch(e) {\n    return null == this.model && this.build(), this.model.predictOnBatch(e);\n  }\n\n  compile(e) {\n    this.build(), this.model.compile(e), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;\n  }\n\n  get optimizer() {\n    return null == this.model ? void 0 : this.model.optimizer;\n  }\n\n  set optimizer(e) {\n    this.model.optimizer = e;\n  }\n\n  fit(e, t) {\n    var _arguments3 = arguments,\n        _this66 = this;\n\n    return _asyncToGenerator(function* () {\n      var n = _arguments3.length > 2 && _arguments3[2] !== undefined ? _arguments3[2] : {};\n      if (!_this66.built) throw new bu(\"The model needs to be compiled before being used.\");\n      return _this66.model.fit(e, t, n);\n    })();\n  }\n\n  fitDataset(e, t) {\n    var _this67 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!_this67.built) throw new bu(\"The model needs to be compiled before being used.\");\n      return _this67.model.fitDataset(e, t);\n    })();\n  }\n\n  trainOnBatch(e, t) {\n    var _this68 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this68.model.trainOnBatch(e, t);\n    })();\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r,\n        a = {};\n\n    if (t instanceof Array) {\n      if (null == t[0].className || \"Merge\" === t[0].className) throw new xu(\"Legacy serialization format not supported yet.\");\n      r = t;\n    } else l(null != t.layers, () => \"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.\"), r = t.layers, delete t.layers, a = t;\n\n    var i = new e(a);\n    if (!(i instanceof Rd)) throw new yu(\"Sequential.fromConfig called on non-Sequential input: \".concat(i));\n\n    for (var _e205 of r) {\n      var _t197 = Rh(_e205, void 0, s);\n\n      s && _t197.setFastWeightInitDuringBuild(!0), i.add(_t197);\n    }\n\n    return i;\n  }\n\n  set stopTraining(e) {\n    if (null == this.model) throw new xu(\"Cannot set the stopTraining property of a sequential model before it is compiled.\");\n    this.model.stopTraining = e;\n  }\n\n  get stopTraining() {\n    if (null == this.model) throw new xu(\"Cannot get the stopTraining property of a sequential model before it is compiled.\");\n    return this.model.stopTraining;\n  }\n\n  getConfig() {\n    var e = [];\n\n    for (var _t198 of this.layers) {\n      var _n118 = {};\n      _n118.className = _t198.getClassName(), _n118.config = _t198.getConfig(), e.push(_n118);\n    }\n\n    return {\n      name: this.name,\n      layers: e\n    };\n  }\n\n}\n\nRd.className = \"Sequential\", Kn(Rd);\n\nclass Ad extends qn {\n  getConfig() {\n    return {};\n  }\n\n}\n\nclass Fd extends Ad {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n      if (1 !== t) throw new yu(\"Support for alpha values other than 1 (\".concat(t, \") is not implemented yet.\"));\n      return br(e);\n    }(e, t);\n  }\n\n}\n\nFd.className = \"elu\", Kn(Fd);\n\nclass Dd extends Ad {\n  apply(e) {\n    return Xa(e);\n  }\n\n}\n\nDd.className = \"selu\", Kn(Dd);\n\nclass _d extends Ad {\n  apply(e) {\n    return Va(e);\n  }\n\n}\n\n_d.className = \"relu\", Kn(_d);\n\nclass Od extends Ad {\n  apply(e) {\n    return Jn(() => pa(6, Va(e)));\n  }\n\n}\n\nOd.className = \"relu6\", Kn(Od);\n\nclass Md extends Ad {\n  apply(e) {\n    return e;\n  }\n\n}\n\nMd.className = \"linear\", Kn(Md);\n\nclass Ld extends Ad {\n  apply(e) {\n    return _s(e);\n  }\n\n}\n\nLd.className = \"sigmoid\", Kn(Ld);\n\nclass zd extends Ad {\n  apply(e) {\n    return function (e) {\n      return Jn(() => {\n        var t = ts(.5, rs(.2, e));\n        return Hs(t, 0, 1);\n      });\n    }(e);\n  }\n\n}\n\nzd.className = \"hardSigmoid\", Kn(zd);\n\nclass Bd extends Ad {\n  apply(e) {\n    return Wr(e);\n  }\n\n}\n\nBd.className = \"softplus\", Kn(Bd);\n\nclass Pd extends Ad {\n  apply(e) {\n    return function (e) {\n      return Jn(() => ss(e, ts(as(e), 1)));\n    }(e);\n  }\n\n}\n\nPd.className = \"softsign\", Kn(Pd);\n\nclass Wd extends Ad {\n  apply(e) {\n    return Ms(e);\n  }\n\n}\n\nWd.className = \"tanh\", Kn(Wd);\n\nclass Ud extends Ad {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    return ri(e, t);\n  }\n\n}\n\nUd.className = \"softmax\", Kn(Ud);\n\nclass Vd extends Ad {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    return qr(e, t);\n  }\n\n}\n\nVd.className = \"logSoftmax\", Kn(Vd);\n\nclass Gd extends Ad {\n  apply(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return Jn(() => rs(_s(rs(e, t)), e));\n  }\n\n}\n\nGd.className = \"swish\", Kn(Gd);\n\nclass Hd extends Ad {\n  apply(e) {\n    return Jn(() => rs(e, Ms(Wr(e))));\n  }\n\n}\n\nfunction qd(e) {\n  return e.getClassName();\n}\n\nfunction jd(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Au(e, jn.getMap().classNameMap, t, \"activation\");\n}\n\nfunction Kd(e) {\n  if (null == e) return jd({\n    className: \"linear\",\n    config: {}\n  });\n\n  if (\"string\" == typeof e) {\n    var _t199 = {};\n    return _t199.className = e, _t199.config = {}, jd(_t199);\n  }\n\n  return e instanceof Ad ? e : jd(e);\n}\n\nHd.className = \"mish\", Kn(Hd);\n\nclass Xd extends qn {}\n\nclass Yd extends Xd {\n  constructor(e) {\n    super(), function (e) {\n      if (null != e && \"object\" != typeof e) throw new Error(\"Argument to L1L2 regularizer's constructor is expected to be an object, but received: \".concat(e));\n    }(e), this.l1 = null == e || null == e.l1 ? .01 : e.l1, this.l2 = null == e || null == e.l2 ? .01 : e.l2, this.hasL1 = 0 !== this.l1, this.hasL2 = 0 !== this.l2;\n  }\n\n  apply(e) {\n    return Jn(() => {\n      var t = ca([1]);\n      return this.hasL1 && (t = ts(t, Hr(rs(this.l1, as(e))))), this.hasL2 && (t = ts(t, Hr(rs(this.l2, Nc(e))))), Rs(t, []);\n    });\n  }\n\n  getConfig() {\n    return {\n      l1: this.l1,\n      l2: this.l2\n    };\n  }\n\n  static fromConfig(e, t) {\n    return new e({\n      l1: t.l1,\n      l2: t.l2\n    });\n  }\n\n}\n\nYd.className = \"L1L2\", Kn(Yd);\nvar Jd = {\n  l1l2: \"L1L2\"\n};\n\nfunction Zd(e) {\n  return Eu(e);\n}\n\nfunction Qd(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return Au(e, jn.getMap().classNameMap, t, \"regularizer\");\n}\n\nfunction ep(e) {\n  return null == e ? null : \"string\" == typeof e ? Qd({\n    className: e in Jd ? Jd[e] : e,\n    config: {}\n  }) : e instanceof Xd ? e : Qd(e);\n}\n\nclass tp extends mh {\n  constructor(e) {\n    super(null == e ? {} : e), this.supportsMasking = !0, null != e && (this.maxValue = e.maxValue);\n  }\n\n  call(e, t) {\n    e = ah(e);\n    var n = Va(e);\n    return null != this.maxValue && (n = Hs(n, 0, this.maxValue)), n;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      maxValue: this.maxValue\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\ntp.className = \"ReLU\", Kn(tp);\n\nclass np extends mh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_ALPHA = .3, null == e && (e = {}), this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;\n  }\n\n  call(e, t) {\n    var n = ah(e);\n    return Dr(n, this.alpha);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      alpha: this.alpha\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nnp.className = \"LeakyReLU\", Kn(np);\n\nclass sp extends mh {\n  constructor(e) {\n    if (super(null == e ? {} : e), this.DEFAULT_ALPHA_INITIALIZER = \"zeros\", null == e && (e = {}), this.supportsMasking = !0, this.alphaInitializer = Zc(e.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = ep(e.alphaRegularizer), this.alphaConstraint = Xu(e.alphaConstraint), null == e.sharedAxes) this.sharedAxes = null;else if (Array.isArray(e.sharedAxes)) this.sharedAxes = e.sharedAxes;else {\n      if (\"number\" != typeof e.sharedAxes) throw new xu(\"Expected sharedAxes to be a number or an array of numbers, but got \".concat(e.sharedAxes));\n      this.sharedAxes = [e.sharedAxes];\n    }\n  }\n\n  build(e) {\n    var t = (e = ih(e)).slice(1);\n    if (null != this.sharedAxes) for (var _e206 of this.sharedAxes) {\n      t[_e206 - 1] = 1;\n    }\n    this.alpha = this.addWeight(\"alpha\", t, \"float32\", this.alphaInitializer, this.alphaRegularizer, !0, this.alphaConstraint);\n    var n = {};\n    if (null != this.sharedAxes) for (var _t200 = 1; _t200 < e.length; ++_t200) {\n      n[_t200] = e[_t200];\n    }\n    this.inputSpec = [new hh({\n      ndim: e.length,\n      axes: n\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return e = ah(e), $a(e, this.alpha.read());\n  }\n\n  getConfig() {\n    var e = {\n      alphaInitializer: Jc(this.alphaInitializer),\n      alphaRegularizer: Zd(this.alphaRegularizer),\n      alphaConstraint: ju(this.alphaConstraint),\n      sharedAxes: this.sharedAxes\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nsp.className = \"PReLU\", Kn(sp);\n\nclass rp extends mh {\n  constructor(e) {\n    if (super(null == e ? {} : e), this.DEFAULT_ALPHA = 1, null == e && (e = {}), null != e.alpha && e.alpha !== this.DEFAULT_ALPHA) throw new yu(\"Non-default alpha value (\".concat(e.alpha, \") is not supported by the ELU layer yet.\"));\n    this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;\n  }\n\n  call(e, t) {\n    var n = ah(e);\n    return br(n);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      alpha: this.alpha\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nrp.className = \"ELU\", Kn(rp);\n\nclass ap extends mh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_THETA = 1, null == e && (e = {}), this.theta = null == e.theta ? this.DEFAULT_THETA : e.theta;\n  }\n\n  call(e, t) {\n    var n = ah(e);\n    return rs(n, fn(Cr(n, this.theta), \"float32\"));\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      theta: this.theta\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nap.className = \"ThresholdedReLU\", Kn(ap);\n\nclass ip extends mh {\n  constructor(e) {\n    super(null == e ? {} : e), this.DEFAULT_AXIS = 1, null == e && (e = {}), this.softmax = new Ud().apply, this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis;\n  }\n\n  call(e, t) {\n    var n = ah(e);\n    return this.softmax(n, this.axis);\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction op(e, t, n) {\n  if (\"number\" == typeof e) return wu(e, t);\n  if (e.length !== t) throw new xu(\"The \".concat(n, \" argument must be an integer or tuple of \").concat(t, \" integers. Received: \").concat(e.length, \" elements.\"));\n\n  for (var _r73 = 0; _r73 < t; ++_r73) {\n    var _a59 = e[_r73];\n    if ((s = _a59) !== parseInt(s.toString(), 10)) throw new xu(\"The \".concat(n, \" argument must be an integer or tuple of \").concat(t, \" integers. Received: \").concat(JSON.stringify(e), \" including a non-integer number \").concat(_a59));\n  }\n\n  return e;\n  var s;\n}\n\nfunction lp(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;\n  if (null == e) return e;\n  var a;\n  return a = \"same\" === n ? e : e - (t + (t - 1) * (r - 1)) + 1, Math.floor((a + s - 1) / s);\n}\n\nfunction up(e, t, n, s) {\n  if (null == e) return null;\n  if (\"valid\" === s) e = e * t + pc([n - t, 0]);else {\n    if (\"same\" !== s) throw new xu(\"Unsupport padding mode: \".concat(s, \".\"));\n    e *= t;\n  }\n  return e;\n}\n\nfunction cp(e, t) {\n  return Jn(() => (nc(t), \"channelsFirst\" === t ? Sn(e, [0, 2, 3, 1]) : e));\n}\n\nfunction hp(e, t) {\n  return Jn(() => (nc(t), \"channelsFirst\" === t ? Sn(e, [0, 2, 3, 4, 1]) : e));\n}\n\nfunction dp(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1];\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  var i = arguments.length > 6 ? arguments[6] : undefined;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : null;\n  return Jn(() => {\n    if (null == a && (a = \"channelsLast\"), nc(a), 3 !== e.rank && 4 !== e.rank) throw new xu(\"conv2dWithBiasActivation expects input to be of rank 3 or 4, but received \".concat(e.rank, \".\"));\n    if (3 !== t.rank && 4 !== t.rank) throw new xu(\"conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received \".concat(e.rank, \".\"));\n    var l = cp(e, a);\n    if (\"causal\" === r) throw new yu(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");\n    return l = _i({\n      x: l,\n      filter: t,\n      strides: s,\n      pad: \"same\" === r ? \"same\" : \"valid\",\n      dilations: i,\n      dataFormat: \"NHWC\",\n      bias: n,\n      activation: o\n    }), \"channelsFirst\" === a && (l = Sn(l, [0, 3, 1, 2])), l;\n  });\n}\n\nip.className = \"Softmax\", Kn(ip);\n\nclass pp extends mh {\n  constructor(e, t) {\n    if (super(t), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", pp.verifyArgs(t), this.rank = e, Lu(this.rank, \"rank\"), 1 !== this.rank && 2 !== this.rank && 3 !== this.rank) throw new yu(\"Convolution layer for rank other than 1, 2, or 3 (\".concat(this.rank, \") is not implemented yet.\"));\n    if (this.kernelSize = op(t.kernelSize, e, \"kernelSize\"), this.strides = op(null == t.strides ? 1 : t.strides, e, \"strides\"), this.padding = null == t.padding ? \"valid\" : t.padding, sc(this.padding), this.dataFormat = null == t.dataFormat ? \"channelsLast\" : t.dataFormat, nc(this.dataFormat), this.activation = Kd(t.activation), this.useBias = null == t.useBias || t.useBias, this.biasInitializer = Zc(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = Xu(t.biasConstraint), this.biasRegularizer = ep(t.biasRegularizer), this.activityRegularizer = ep(t.activityRegularizer), this.dilationRate = op(null == t.dilationRate ? 1 : t.dilationRate, e, \"dilationRate\"), 1 === this.rank && Array.isArray(this.dilationRate) && 1 !== this.dilationRate.length) throw new xu(\"dilationRate must be a number or an array of a single number for 1D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n\n    if (2 === this.rank) {\n      if (\"number\" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate];else if (2 !== this.dilationRate.length) throw new xu(\"dilationRate must be a number or array of two numbers for 2D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n    } else if (3 === this.rank) if (\"number\" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];else if (3 !== this.dilationRate.length) throw new xu(\"dilationRate must be a number or array of three numbers for 3D convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n  }\n\n  static verifyArgs(e) {\n    if (vu(\"kernelSize\" in e, \"required key 'kernelSize' not in config\"), \"number\" != typeof e.kernelSize && !Mu(e.kernelSize, \"number\", 1, 3)) throw new xu(\"BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n  getConfig() {\n    var e = {\n      kernelSize: this.kernelSize,\n      strides: this.strides,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      activation: qd(this.activation),\n      useBias: this.useBias,\n      biasInitializer: Jc(this.biasInitializer),\n      biasRegularizer: Zd(this.biasRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      biasConstraint: ju(this.biasConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass fp extends pp {\n  constructor(e, t) {\n    super(e, t), this.kernel = null, fp.verifyArgs(t), this.filters = t.filters, Lu(this.filters, \"filters\"), this.kernelInitializer = Zc(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = Xu(t.kernelConstraint), this.kernelRegularizer = ep(t.kernelRegularizer);\n  }\n\n  build(e) {\n    e = ih(e);\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new xu(\"The channel dimension of the input should be defined. Found \".concat(e[t]));\n    var n = e[t],\n        s = this.kernelSize.concat([n, this.filters]);\n    this.kernel = this.addWeight(\"kernel\", s, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [{\n      ndim: this.rank + 2,\n      axes: {\n        [t]: n\n      }\n    }], this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t;\n      e = ah(e);\n      var n = null == this.bias ? null : this.bias.read(),\n          s = Bu(this.activation.getClassName());\n      if (null != s && 2 === this.rank) t = dp(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate, s);else {\n        if (1 === this.rank) t = function (e, t, n) {\n          var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n          var a = arguments.length > 5 ? arguments[5] : undefined;\n          var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 1;\n          return Jn(() => {\n            if (null == a && (a = \"channelsLast\"), nc(a), 3 !== e.shape.length) throw new xu(\"The input of a conv1dWithBias operation should be 3, but is \".concat(e.shape.length, \" instead.\"));\n            if (3 !== t.shape.length) throw new xu(\"The kernel for a conv1dWithBias operation should be 3, but is \".concat(t.shape.length, \" instead\"));\n            if (null != n && 1 !== n.shape.length) throw new xu(\"The bias for a conv1dWithBias operation should be 1, but is \".concat(t.shape.length, \" instead\"));\n            if (\"channelsFirst\" === a && (e = Sn(e, [0, 2, 1])), \"causal\" === r) throw new yu(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");\n            var o = Js(e, t, s, \"same\" === r ? \"same\" : \"valid\", \"NWC\", i);\n            return null != n && (o = Tc(o, n)), o;\n          });\n        }(e, this.kernel.read(), n, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);else if (2 === this.rank) t = dp(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);else {\n          if (3 !== this.rank) throw new yu(\"convolutions greater than 3D are not implemented yet.\");\n\n          t = function (e, t, n) {\n            var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1, 1];\n            var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"valid\";\n            var a = arguments.length > 5 ? arguments[5] : undefined;\n            var i = arguments.length > 6 ? arguments[6] : undefined;\n            return Jn(() => {\n              if (null == a && (a = \"channelsLast\"), nc(a), 4 !== e.rank && 5 !== e.rank) throw new xu(\"conv3dWithBias expects input to be of rank 4 or 5, but received \".concat(e.rank, \".\"));\n              if (4 !== t.rank && 5 !== t.rank) throw new xu(\"conv3dWithBias expects kernel to be of rank 4 or 5, but received \".concat(e.rank, \".\"));\n              var o = hp(e, a);\n              if (\"causal\" === r) throw new yu(\"The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.\");\n              return o = er(o, t, s, \"same\" === r ? \"same\" : \"valid\", \"NDHWC\", i), null != n && (o = Tc(o, n)), \"channelsFirst\" === a && (o = Sn(o, [0, 4, 1, 2, 3])), o;\n            });\n          }(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);\n        }\n        null != this.activation && (t = this.activation.apply(t));\n      }\n      return t;\n    });\n  }\n\n  computeOutputShape(e) {\n    e = ih(e);\n    var t = [],\n        n = \"channelsLast\" === this.dataFormat ? e.slice(1, e.length - 1) : e.slice(2);\n\n    for (var _e207 = 0; _e207 < n.length; ++_e207) {\n      var _s102 = lp(n[_e207], this.kernelSize[_e207], this.padding, this.strides[_e207], \"number\" == typeof this.dilationRate ? this.dilationRate : this.dilationRate[_e207]);\n\n      t.push(_s102);\n    }\n\n    var s = [e[0]];\n    return \"channelsLast\" === this.dataFormat ? (s = s.concat(t), s.push(this.filters)) : (s.push(this.filters), s = s.concat(t)), s;\n  }\n\n  getConfig() {\n    var e = {\n      filters: this.filters,\n      kernelInitializer: Jc(this.kernelInitializer),\n      kernelRegularizer: Zd(this.kernelRegularizer),\n      kernelConstraint: ju(this.kernelConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  static verifyArgs(e) {\n    if (!(\"filters\" in e) || \"number\" != typeof e.filters || e.filters < 1) throw new xu(\"Convolution layer expected config.filters to be a 'number' > 0 but got \".concat(JSON.stringify(e.filters)));\n  }\n\n}\n\nclass gp extends fp {\n  constructor(e) {\n    super(2, e), gp.verifyArgs(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && !Mu(e.kernelSize, \"number\", 1, 2)) throw new xu(\"Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\ngp.className = \"Conv2D\", Kn(gp);\n\nclass mp extends fp {\n  constructor(e) {\n    super(3, e), mp.verifyArgs(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && (!Array.isArray(e.kernelSize) || 1 !== e.kernelSize.length && 3 !== e.kernelSize.length)) throw new xu(\"Conv3D expects config.kernelSize to be number or [number, number, number], but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\nmp.className = \"Conv3D\", Kn(mp);\n\nclass bp extends gp {\n  constructor(e) {\n    if (super(e), this.inputSpec = [new hh({\n      ndim: 4\n    })], \"same\" !== this.padding && \"valid\" !== this.padding) throw new xu(\"Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode \".concat(this.padding));\n  }\n\n  build(e) {\n    if (4 !== (e = ih(e)).length) throw new xu(\"Input should have rank 4; Received input shape: \" + JSON.stringify(e));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new xu(\"The channel dimension of the inputs should be defined. Found `None`.\");\n    var n = e[t],\n        s = this.kernelSize.concat([this.filters, n]);\n    this.kernel = this.addWeight(\"kernel\", s, \"float32\", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new hh({\n      ndim: 4,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      if (4 !== t.shape.length) throw new xu(\"Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-\".concat(t.shape.length));\n      var n = t.shape;\n      var s, r;\n      \"channelsFirst\" === this.dataFormat ? (s = 2, r = 3) : (s = 1, r = 2);\n      var a = n[r],\n          i = this.kernelSize[1],\n          o = this.strides[1],\n          l = [n[0], up(n[s], this.strides[0], this.kernelSize[0], this.padding), up(a, o, i, this.padding), this.filters];\n      \"channelsLast\" !== this.dataFormat && (t = Sn(t, [0, 2, 3, 1]));\n      var u = Qs(t, this.kernel.read(), l, this.strides, this.padding);\n      return \"channelsLast\" !== this.dataFormat && (u = Sn(u, [0, 3, 1, 2])), null != this.bias && (u = Tc(u, this.bias.read(), this.dataFormat)), null != this.activation && (u = this.activation.apply(u)), u;\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ih(e)).slice();\n    var n, s, r;\n    \"channelsFirst\" === this.dataFormat ? (n = 1, s = 2, r = 3) : (n = 3, s = 1, r = 2);\n    var a = this.kernelSize[0],\n        i = this.kernelSize[1],\n        o = this.strides[0],\n        l = this.strides[1];\n    return t[n] = this.filters, t[s] = up(t[s], o, a, this.padding), t[r] = up(t[r], l, i, this.padding), t;\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.dilationRate, e;\n  }\n\n}\n\nbp.className = \"Conv2DTranspose\", Kn(bp);\n\nclass xp extends mp {\n  constructor(e) {\n    if (super(e), this.inputSpec = [new hh({\n      ndim: 5\n    })], \"same\" !== this.padding && \"valid\" !== this.padding) throw new xu(\"Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode \".concat(this.padding));\n  }\n\n  build(e) {\n    if (5 !== (e = ih(e)).length) throw new xu(\"Input should have rank 5; Received input shape: \" + JSON.stringify(e));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t]) throw new xu(\"The channel dimension of the inputs should be defined. Found `None`.\");\n    var n = e[t],\n        s = this.kernelSize.concat([this.filters, n]);\n    this.kernel = this.addWeight(\"kernel\", s, \"float32\", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new hh({\n      ndim: 5,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      if (5 !== t.shape.length) throw new xu(\"Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-\".concat(t.shape.length));\n      var n = t.shape;\n      var s, r, a;\n      \"channelsFirst\" === this.dataFormat ? (a = 2, s = 3, r = 4) : (a = 1, s = 2, r = 3);\n      var i = n[s],\n          o = n[r],\n          l = this.kernelSize[1],\n          u = this.kernelSize[2],\n          c = this.strides[1],\n          h = this.strides[2],\n          d = [n[0], up(n[a], this.strides[0], this.kernelSize[0], this.padding), up(i, c, l, this.padding), up(o, h, u, this.padding), this.filters];\n      \"channelsLast\" !== this.dataFormat && (t = Sn(t, [0, 2, 3, 4, 1]));\n      var p = nr(t, this.kernel.read(), d, this.strides, this.padding);\n      return \"channelsLast\" !== this.dataFormat && (p = Sn(p, [0, 4, 1, 2, 3])), null !== this.bias && (p = Tc(p, this.bias.read(), this.dataFormat)), null !== this.activation && (p = this.activation.apply(p)), p;\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ih(e)).slice();\n    var n, s, r, a;\n    \"channelsFirst\" === this.dataFormat ? (n = 1, s = 2, r = 3, a = 4) : (n = 4, s = 1, r = 2, a = 3);\n    var i = this.kernelSize[0],\n        o = this.kernelSize[1],\n        l = this.kernelSize[2],\n        u = this.strides[0],\n        c = this.strides[1],\n        h = this.strides[2];\n    return t[n] = this.filters, t[s] = up(t[s], u, i, this.padding), t[r] = up(t[r], c, o, this.padding), t[a] = up(t[a], h, l, this.padding), t;\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.dilationRate, e;\n  }\n\n}\n\nxp.className = \"Conv3DTranspose\", Kn(xp);\n\nclass yp extends fp {\n  constructor(e, t) {\n    if (super(e, t), this.DEFAULT_DEPTHWISE_INITIALIZER = \"glorotUniform\", this.DEFAULT_POINTWISE_INITIALIZER = \"glorotUniform\", this.depthwiseKernel = null, this.pointwiseKernel = null, null == t.filters) throw new xu(\"The `filters` configuration field is required by SeparableConv, but is unspecified.\");\n    if (null != t.kernelInitializer || null != t.kernelRegularizer || null != t.kernelConstraint) throw new xu(\"Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.\");\n    if (null != t.padding && \"same\" !== t.padding && \"valid\" !== t.padding) throw new xu(\"SeparableConv\".concat(this.rank, \"D supports only padding modes: 'same' and 'valid', but received \").concat(JSON.stringify(t.padding)));\n    this.depthMultiplier = null == t.depthMultiplier ? 1 : t.depthMultiplier, this.depthwiseInitializer = Zc(t.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = ep(t.depthwiseRegularizer), this.depthwiseConstraint = Xu(t.depthwiseConstraint), this.pointwiseInitializer = Zc(t.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = ep(t.pointwiseRegularizer), this.pointwiseConstraint = Xu(t.pointwiseConstraint);\n  }\n\n  build(e) {\n    if ((e = ih(e)).length < this.rank + 2) throw new xu(\"Inputs to SeparableConv\".concat(this.rank, \"D should have rank \").concat(this.rank + 2, \", but received input shape: \").concat(JSON.stringify(e)));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[t] || e[t] < 0) throw new xu(\"The channel dimension of the inputs should be defined, but found \".concat(JSON.stringify(e[t])));\n    var n = e[t],\n        s = this.kernelSize.concat([n, this.depthMultiplier]),\n        r = [];\n\n    for (var _e208 = 0; _e208 < this.rank; ++_e208) {\n      r.push(1);\n    }\n\n    r.push(n * this.depthMultiplier, this.filters);\n    var a = !0;\n    this.depthwiseKernel = this.addWeight(\"depthwise_kernel\", s, \"float32\", this.depthwiseInitializer, this.depthwiseRegularizer, a, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight(\"pointwise_kernel\", r, \"float32\", this.pointwiseInitializer, this.pointwiseRegularizer, a, this.pointwiseConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [this.filters], \"float32\", this.biasInitializer, this.biasRegularizer, a, this.biasConstraint) : null, this.inputSpec = [new hh({\n      ndim: this.rank + 2,\n      axes: {\n        [t]: n\n      }\n    })], this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t;\n      if (e = ah(e), 1 === this.rank) throw new yu(\"1D separable convolution is not implemented yet.\");\n      return 2 === this.rank && (\"channelsFirst\" === this.dataFormat && (e = Sn(e, [0, 2, 3, 1])), t = Ya(e, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, \"NHWC\")), this.useBias && (t = Tc(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), \"channelsFirst\" === this.dataFormat && (t = Sn(t, [0, 3, 1, 2])), t;\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, delete e.kernelInitializer, delete e.kernelRegularizer, delete e.kernelConstraint, e.depthwiseInitializer = Jc(this.depthwiseInitializer), e.pointwiseInitializer = Jc(this.pointwiseInitializer), e.depthwiseRegularizer = Zd(this.depthwiseRegularizer), e.pointwiseRegularizer = Zd(this.pointwiseRegularizer), e.depthwiseConstraint = ju(this.depthwiseConstraint), e.pointwiseConstraint = ju(this.pointwiseConstraint), e;\n  }\n\n}\n\nyp.className = \"SeparableConv\";\n\nclass kp extends yp {\n  constructor(e) {\n    super(2, e);\n  }\n\n}\n\nkp.className = \"SeparableConv2D\", Kn(kp);\n\nclass wp extends fp {\n  constructor(e) {\n    super(1, e), wp.verifyArgs(e), this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return delete e.rank, delete e.dataFormat, e;\n  }\n\n  static verifyArgs(e) {\n    if (\"number\" != typeof e.kernelSize && !Mu(e.kernelSize, \"number\", 1, 1)) throw new xu(\"Conv1D expects config.kernelSize to be number or number[] with length 1, but received \".concat(JSON.stringify(e.kernelSize), \".\"));\n  }\n\n}\n\nwp.className = \"Conv1D\", Kn(wp);\n\nclass vp extends mh {\n  constructor(e) {\n    super(e), this.cropping = \"number\" == typeof e.cropping ? [[e.cropping, e.cropping], [e.cropping, e.cropping]] : \"number\" == typeof e.cropping[0] ? [[e.cropping[0], e.cropping[0]], [e.cropping[1], e.cropping[1]]] : e.cropping, this.dataFormat = void 0 === e.dataFormat ? \"channelsLast\" : e.dataFormat, this.inputSpec = [{\n      ndim: 4\n    }];\n  }\n\n  computeOutputShape(e) {\n    return \"channelsFirst\" === this.dataFormat ? [e[0], e[1], e[2] - this.cropping[0][0] - this.cropping[0][1], e[3] - this.cropping[1][0] - this.cropping[1][1]] : [e[0], e[1] - this.cropping[0][0] - this.cropping[0][1], e[2] - this.cropping[1][0] - this.cropping[1][1], e[3]];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (e = ah(e), \"channelsLast\" === this.dataFormat) {\n        var _t201 = yc(e, this.cropping[0][0], e.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);\n\n        return yc(_t201, this.cropping[1][0], e.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);\n      }\n\n      {\n        var _t202 = yc(e, this.cropping[0][0], e.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);\n\n        return yc(_t202, this.cropping[1][0], e.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);\n      }\n    });\n  }\n\n  getConfig() {\n    var e = {\n      cropping: this.cropping,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nvp.className = \"Cropping2D\", Kn(vp);\n\nclass Ip extends mh {\n  constructor(e) {\n    super(e), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{\n      ndim: 4\n    }], this.size = null == e.size ? this.DEFAULT_SIZE : e.size, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, nc(this.dataFormat), this.interpolation = null == e.interpolation ? \"nearest\" : e.interpolation, Ou(Ju, \"InterpolationFormat\", this.interpolation);\n  }\n\n  computeOutputShape(e) {\n    return \"channelsFirst\" === this.dataFormat ? [e[0], e[1], null == e[2] ? null : this.size[0] * e[2], null == e[3] ? null : this.size[1] * e[3]] : [e[0], null == e[1] ? null : this.size[0] * e[1], null == e[2] ? null : this.size[1] * e[2], e[3]];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      var n = t.shape;\n\n      if (\"channelsFirst\" === this.dataFormat) {\n        t = Sn(t, [0, 2, 3, 1]);\n\n        var _e209 = this.size[0] * n[2],\n            _s103 = this.size[1] * n[3],\n            _r74 = \"nearest\" === this.interpolation ? fo.resizeNearestNeighbor(t, [_e209, _s103]) : fo.resizeBilinear(t, [_e209, _s103]);\n\n        return Sn(_r74, [0, 3, 1, 2]);\n      }\n\n      {\n        var _e210 = this.size[0] * n[1],\n            _s104 = this.size[1] * n[2];\n\n        return \"nearest\" === this.interpolation ? fo.resizeNearestNeighbor(t, [_e210, _s104]) : fo.resizeBilinear(t, [_e210, _s104]);\n      }\n    });\n  }\n\n  getConfig() {\n    var e = {\n      size: this.size,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nIp.className = \"UpSampling2D\", Kn(Ip);\n\nclass $p extends pp {\n  constructor(e) {\n    super(2, e), this.depthwiseKernel = null, this.depthMultiplier = null == e.depthMultiplier ? 1 : e.depthMultiplier, this.depthwiseInitializer = Zc(e.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = Xu(e.depthwiseConstraint), this.depthwiseRegularizer = ep(e.depthwiseRegularizer);\n  }\n\n  build(e) {\n    if ((e = ih(e)).length < 4) throw new xu(\"Inputs to DepthwiseConv2D should have rank 4. Received input shape: \".concat(JSON.stringify(e), \".\"));\n    var t = \"channelsFirst\" === this.dataFormat ? 1 : 3;\n    if (null == e[t] || e[t] < 0) throw new xu(\"The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (\".concat(e[t], \").\"));\n    var n = e[t];\n    this.depthwiseKernel = this.addWeight(\"depthwise_kernel\", [this.kernelSize[0], this.kernelSize[1], n, this.depthMultiplier], null, this.depthwiseInitializer, this.depthwiseRegularizer, !0, this.depthwiseConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [n * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = function (e, t) {\n        var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1];\n        var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : \"valid\";\n        var r = arguments.length > 4 ? arguments[4] : undefined;\n        var a = arguments.length > 5 ? arguments[5] : undefined;\n        return Jn(() => {\n          null == r && (r = \"channelsLast\"), nc(r);\n          var i = cp(e, r);\n          if (4 !== e.rank) throw new xu(\"Input for depthwiseConv2d is required to be 4-D, but is instead \".concat(e.rank, \"-D\"));\n          if (4 !== t.rank) throw new xu(\"depthwiseKernel is required to be 4-D, but is instead \".concat(t.rank, \"-D\"));\n          return i = or(i, t, n, \"same\" === s ? \"same\" : \"valid\", \"NHWC\", a), \"channelsFirst\" === r && (i = Sn(i, [0, 3, 1, 2])), i;\n        });\n      }(e = ah(e), this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);\n\n      return this.useBias && (t = Tc(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), t;\n    });\n  }\n\n  computeOutputShape(e) {\n    e = ih(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[3] : e[2],\n        n = \"channelsFirst\" === this.dataFormat ? e[1] * this.depthMultiplier : e[3] * this.depthMultiplier,\n        s = lp(\"channelsFirst\" === this.dataFormat ? e[2] : e[1], this.kernelSize[0], this.padding, this.strides[0]),\n        r = lp(t, this.kernelSize[1], this.padding, this.strides[1]);\n    return \"channelsFirst\" === this.dataFormat ? [e[0], n, s, r] : [e[0], s, r, n];\n  }\n\n  getConfig() {\n    var e = super.getConfig();\n    return e.depthMultiplier = this.depthMultiplier, e.depthwiseInitializer = Jc(this.depthwiseInitializer), e.depthwiseRegularizer = Zd(this.depthwiseRegularizer), e.depthwiseConstraint = ju(this.depthwiseRegularizer), e;\n  }\n\n}\n\nfunction Sp(e, t, n, s) {\n  if (Array.isArray(e)) {\n    if (null != t || null != n) throw new xu(\"When inputs is an array, neither initialState or constants should be provided\");\n    null != s && (n = e.slice(e.length - s, e.length), e = e.slice(0, e.length - s)), e.length > 1 && (t = e.slice(1, e.length)), e = e[0];\n  }\n\n  function r(e) {\n    return null == e || Array.isArray(e) ? e : [e];\n  }\n\n  return {\n    inputs: e,\n    initialState: t = r(t),\n    constants: n = r(n)\n  };\n}\n\nfunction Np(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = arguments.length > 4 ? arguments[4] : undefined;\n  var a = arguments.length > 5 ? arguments[5] : undefined;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;\n  var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n  return Jn(() => {\n    var l = t.shape.length;\n    if (l < 3) throw new xu(\"Input should be at least 3D, but is \".concat(l, \"D.\"));\n    var u = [1, 0].concat(fc(2, l));\n    if (t = Sn(t, u), null != a) throw new yu(\"The rnn() functoin of the deeplearn.js backend does not support constants yet.\");\n    i && console.warn(\"Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend.\"), null != r && ((r = fn(fn(r, \"bool\"), \"float32\")).rank === l - 1 && (r = kr(r, -1)), r = Sn(r, u)), s && (t = Ha(t, 0), null != r && (r = Ha(r, 0)));\n    var c = [];\n    var h,\n        d = n;\n    var p = t.shape[0],\n        f = Ii(t);\n    var g, m;\n    null != r && (g = Ii(r));\n\n    var _loop24 = function _loop24(_t203) {\n      var n = f[_t203],\n          s = Jn(() => e(n, d));\n      if (null == r) h = s[0], d = s[1];else {\n        var _e211 = Jn(() => {\n          var e = g[_t203],\n              n = Gr(ya(e), e);\n          return {\n            output: ts(rs(s[0], e), rs(d[0], n)),\n            newStates: d.map((t, r) => ts(rs(s[1][r], e), rs(t, n)))\n          };\n        });\n\n        h = _e211.output, d = _e211.newStates;\n      }\n      o && c.push(h);\n    };\n\n    for (var _t203 = 0; _t203 < p; ++_t203) {\n      _loop24(_t203);\n    }\n\n    return o && (m = pi(c, 1)), [h, m, d];\n  });\n}\n\n$p.className = \"DepthwiseConv2D\", Kn($p);\n\nclass Cp extends mh {\n  constructor(e) {\n    var t;\n    if (super(e), null == e.cell) throw new xu(\"cell property is missing for the constructor of RNN.\");\n    if (t = Array.isArray(e.cell) ? new Op({\n      cells: e.cell\n    }) : e.cell, null == t.stateSize) throw new xu(\"The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).\");\n    this.cell = t, this.returnSequences = null != e.returnSequences && e.returnSequences, this.returnState = null != e.returnState && e.returnState, this.goBackwards = null != e.goBackwards && e.goBackwards, this._stateful = null != e.stateful && e.stateful, this.unroll = null != e.unroll && e.unroll, this.supportsMasking = !0, this.inputSpec = [new hh({\n      ndim: 3\n    })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];\n  }\n\n  getStates() {\n    return null == this.states_ ? fc(0, Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1).map(e => null) : this.states_;\n  }\n\n  setStates(e) {\n    this.states_ = e;\n  }\n\n  computeOutputShape(e) {\n    sh(e) && (e = e[0]), e = e;\n    var t = this.cell.stateSize;\n    Array.isArray(t) || (t = [t]);\n    var n = t[0];\n    var s;\n\n    if (s = this.returnSequences ? [e[0], e[1], n] : [e[0], n], this.returnState) {\n      var _n119 = [];\n\n      for (var _s105 of t) {\n        _n119.push([e[0], _s105]);\n      }\n\n      return [s].concat(_n119);\n    }\n\n    return s;\n  }\n\n  computeMask(e, t) {\n    return Jn(() => {\n      Array.isArray(t) && (t = t[0]);\n      var e = this.returnSequences ? t : null;\n\n      if (this.returnState) {\n        var _t204 = this.states.map(e => null);\n\n        return [e].concat(_t204);\n      }\n\n      return e;\n    });\n  }\n\n  get states() {\n    if (null == this.states_) {\n      var _e212 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1,\n          _t205 = [];\n\n      for (var _n120 = 0; _n120 < _e212; ++_n120) {\n        _t205.push(null);\n      }\n\n      return _t205;\n    }\n\n    return this.states_;\n  }\n\n  set states(e) {\n    this.states_ = e;\n  }\n\n  build(e) {\n    if (null != this.numConstants) throw new yu(\"Constants support is not implemented in RNN yet.\");\n    sh(e) && (e = e[0]), e = e;\n    var t = this.stateful ? e[0] : null,\n        n = e.slice(2);\n    this.inputSpec[0] = new hh({\n      shape: [t, null, ...n]\n    });\n    var s = [e[0]].concat(e.slice(2));\n    var r;\n\n    if (this.cell.build(s), r = Array.isArray(this.cell.stateSize) ? this.cell.stateSize : [this.cell.stateSize], null != this.stateSpec) {\n      if (!p(this.stateSpec.map(e => e.shape[e.shape.length - 1]), r)) throw new xu(\"An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=\".concat(this.stateSpec, \"; However cell.stateSize is \").concat(this.cell.stateSize));\n    } else this.stateSpec = r.map(e => new hh({\n      shape: [null, e]\n    }));\n\n    this.stateful && this.resetStates();\n  }\n\n  resetStates(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    Jn(() => {\n      if (!this.stateful) throw new mu(\"Cannot call resetStates() on an RNN Layer that is not stateful.\");\n      var n = this.inputSpec[0].shape[0];\n      if (null == n) throw new xu(\"If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \\n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.\");\n      if (null == this.states_) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => ca([n, e])) : [ca([n, this.cell.stateSize])];else if (null == e) Zn(this.states_), null != this.keptStates && (Zn(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(e => ca([n, e])) : this.states_[0] = ca([n, this.cell.stateSize]);else {\n        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new xu(\"Layer \".concat(this.name, \" expects \").concat(this.states_.length, \" state(s), but it received \").concat(e.length, \" state value(s). Input received: \").concat(e));\n        !0 === t ? this.keptStates.push(this.states_.slice()) : Zn(this.states_);\n\n        for (var _t206 = 0; _t206 < this.states_.length; ++_t206) {\n          var _s106 = e[_t206],\n              _r75 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[_t206] : this.cell.stateSize,\n              _a60 = [n, _r75];\n\n          if (!p(_s106.shape, _a60)) throw new xu(\"State \".concat(_t206, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_a60, \", received shape=\").concat(_s106.shape));\n          this.states_[_t206] = _s106;\n        }\n      }\n      this.states_ = this.states_.map(e => Qn(e.clone()));\n    });\n  }\n\n  apply(e, t) {\n    var n = null == t ? null : t.initialState,\n        s = null == t ? null : t.constants;\n    null == t && (t = {});\n    var r = Sp(e, n, s, this.numConstants);\n    e = r.inputs, n = r.initialState, s = r.constants;\n    var a = [],\n        i = [];\n\n    if (null != n) {\n      t.initialState = n, a = a.concat(n), this.stateSpec = [];\n\n      for (var _e213 of n) {\n        this.stateSpec.push(new hh({\n          shape: _e213.shape\n        }));\n      }\n\n      i = i.concat(this.stateSpec);\n    }\n\n    if (null != s && (t.constants = s, a = a.concat(s), this.numConstants = s.length), a[0] instanceof dh) {\n      var _n121 = [e].concat(a),\n          _s107 = this.inputSpec.concat(i),\n          _r76 = this.inputSpec;\n\n      this.inputSpec = _s107;\n\n      var _o27 = super.apply(_n121, t);\n\n      return this.inputSpec = _r76, _o27;\n    }\n\n    return super.apply(e, t);\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var n = null == t ? null : t.mask,\n          s = null == t ? null : t.training;\n      var r = null == t ? null : t.initialState;\n      e = ah(e), null == r && (r = this.stateful ? this.states_ : this.getInitialState(e));\n      var a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n      if (r.length !== a) throw new xu(\"RNN Layer has \".concat(a, \" state(s) but was passed \").concat(r.length, \" initial state(s).\"));\n      this.unroll && console.warn(\"Ignoring unroll = true for RNN layer, due to imperative backend.\");\n      var i = {\n        training: s\n      },\n          o = Np((e, t) => {\n        var n = this.cell.call([e].concat(t), i);\n        return [n[0], n.slice(1)];\n      }, e, r, this.goBackwards, n, null, this.unroll, this.returnSequences),\n          l = o[0],\n          u = o[1],\n          c = o[2];\n      this.stateful && this.resetStates(c, s);\n      var h = this.returnSequences ? u : l;\n      return this.returnState ? [h].concat(c) : h;\n    });\n  }\n\n  getInitialState(e) {\n    return Jn(() => {\n      var t = ca(e.shape);\n      return t = Hr(t, [1, 2]), t = mc(t), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => e > 1 ? vc(t, [1, e]) : t) : this.cell.stateSize > 1 ? [vc(t, [1, this.cell.stateSize])] : [t];\n    });\n  }\n\n  get trainableWeights() {\n    return this.trainable ? this.cell.trainableWeights : [];\n  }\n\n  get nonTrainableWeights() {\n    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.cell && this.cell.setFastWeightInitDuringBuild(e);\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      returnSequences: this.returnSequences,\n      returnState: this.returnState,\n      goBackwards: this.goBackwards,\n      stateful: this.stateful,\n      unroll: this.unroll\n    };\n    null != this.numConstants && (t.numConstants = this.numConstants);\n    var n = this.cell.getConfig();\n    return this.getClassName() === Cp.className && (t.cell = {\n      className: this.cell.getClassName(),\n      config: n\n    }), Object.assign({}, n, e, t);\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = Rh(t.cell, n);\n    return new e(Object.assign(t, {\n      cell: s\n    }));\n  }\n\n}\n\nCp.className = \"RNN\", Kn(Cp);\n\nclass Tp extends mh {}\n\nclass Ep extends Tp {\n  constructor(e) {\n    super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", this.units = e.units, Lu(this.units, \"units\"), this.activation = Kd(null == e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Zc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Zc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Zc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = ep(e.kernelRegularizer), this.recurrentRegularizer = ep(e.recurrentRegularizer), this.biasRegularizer = ep(e.biasRegularizer), this.kernelConstraint = Xu(e.kernelConstraint), this.recurrentConstraint = Xu(e.recurrentConstraint), this.biasConstraint = Xu(e.biasConstraint), this.dropout = dc([1, pc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = dc([1, pc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    e = ih(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (2 !== (e = e).length) throw new xu(\"SimpleRNNCell expects 2 input Tensors, got \".concat(e.length, \".\"));\n      var n = e[1];\n      e = e[0];\n      var s = null != t.training && t.training;\n      var r;\n      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Mp({\n        ones: () => ya(e),\n        rate: this.dropout,\n        training: s\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Mp({\n        ones: () => ya(n),\n        rate: this.recurrentDropout,\n        training: s\n      }));\n      var a = this.dropoutMask,\n          i = this.recurrentDropoutMask;\n      r = $c(null != a ? rs(e, a) : e, this.kernel.read()), null != this.bias && (r = Tc(r, this.bias.read())), null != i && (n = rs(n, i));\n      var o = ts(r, $c(n, this.recurrentKernel.read()));\n      return null != this.activation && (o = this.activation.apply(o)), [o, o];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: qd(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: Jc(this.kernelInitializer),\n      recurrentInitializer: Jc(this.recurrentInitializer),\n      biasInitializer: Jc(this.biasInitializer),\n      kernelRegularizer: Zd(this.kernelRegularizer),\n      recurrentRegularizer: Zd(this.recurrentRegularizer),\n      biasRegularizer: Zd(this.biasRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nEp.className = \"SimpleRNNCell\", Kn(Ep);\n\nclass Rp extends Cp {\n  constructor(e) {\n    e.cell = new Ep(e), super(e);\n  }\n\n  call(e, t) {\n    return Jn(() => (null != this.cell.dropoutMask && (Zn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Zn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nRp.className = \"SimpleRNN\", Kn(Rp);\n\nclass Ap extends Tp {\n  constructor(e) {\n    if (super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_RECURRENT_ACTIVATION = \"hardSigmoid\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", e.resetAfter) throw new xu(\"GRUCell does not support reset_after parameter set to true.\");\n    this.units = e.units, Lu(this.units, \"units\"), this.activation = Kd(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = Kd(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Zc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Zc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Zc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = ep(e.kernelRegularizer), this.recurrentRegularizer = ep(e.recurrentRegularizer), this.biasRegularizer = ep(e.biasRegularizer), this.kernelConstraint = Xu(e.kernelConstraint), this.recurrentConstraint = Xu(e.recurrentConstraint), this.biasConstraint = Xu(e.biasConstraint), this.dropout = dc([1, pc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = dc([1, pc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    e = ih(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], 3 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, 3 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight(\"bias\", [3 * this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (2 !== (e = e).length) throw new xu(\"GRUCell expects 2 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var n = null != t.training && t.training;\n      var s = e[1];\n      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Mp({\n        ones: () => ya(e),\n        rate: this.dropout,\n        training: n,\n        count: 3\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Mp({\n        ones: () => ya(s),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 3\n      }));\n      var r = this.recurrentDropoutMask;\n      var a, i, o;\n      0 < this.dropout && this.dropout < 1 && (e = rs(e, this.dropoutMask[0]));\n      var l = $c(e, this.kernel.read());\n      this.useBias && (l = Tc(l, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = rs(s, r[0]));\n      var u = this.recurrentKernel.read(),\n          [c, h] = li(u, [2 * this.units, this.units], u.rank - 1),\n          d = $c(s, c),\n          [p, f, g] = li(l, 3, l.rank - 1),\n          [m, b] = li(d, 2, d.rank - 1);\n      a = this.recurrentActivation.apply(ts(p, m)), i = this.recurrentActivation.apply(ts(f, b));\n      var x = $c(rs(i, s), h);\n      o = this.activation.apply(ts(g, x));\n      var y = ts(rs(a, s), rs(ts(1, Pr(a)), o));\n      return [y, y];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: qd(this.activation),\n      recurrentActivation: qd(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: Jc(this.kernelInitializer),\n      recurrentInitializer: Jc(this.recurrentInitializer),\n      biasInitializer: Jc(this.biasInitializer),\n      kernelRegularizer: Zd(this.kernelRegularizer),\n      recurrentRegularizer: Zd(this.recurrentRegularizer),\n      biasRegularizer: Zd(this.biasRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation,\n      resetAfter: !1\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nAp.className = \"GRUCell\", Kn(Ap);\n\nclass Fp extends Cp {\n  constructor(e) {\n    0 === e.implementation && console.warn(\"`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.\"), e.cell = new Ap(e), super(e);\n  }\n\n  call(e, t) {\n    return Jn(() => (null != this.cell.dropoutMask && (Zn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Zn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return 0 === t.implmentation && (t.implementation = 1), new e(t);\n  }\n\n}\n\nFp.className = \"GRU\", Kn(Fp);\n\nclass Dp extends Tp {\n  constructor(e) {\n    super(e), this.DEFAULT_ACTIVATION = \"tanh\", this.DEFAULT_RECURRENT_ACTIVATION = \"hardSigmoid\", this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_RECURRENT_INITIALIZER = \"orthogonal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", this.units = e.units, Lu(this.units, \"units\"), this.activation = Kd(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = Kd(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = Zc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Zc(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Zc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = e.unitForgetBias, this.kernelRegularizer = ep(e.kernelRegularizer), this.recurrentRegularizer = ep(e.recurrentRegularizer), this.biasRegularizer = ep(e.biasRegularizer), this.kernelConstraint = Xu(e.kernelConstraint), this.recurrentConstraint = Xu(e.recurrentConstraint), this.biasConstraint = Xu(e.biasConstraint), this.dropout = dc([1, pc([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = dc([1, pc([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;\n  }\n\n  build(e) {\n    var t;\n    var n;\n\n    if (e = ih(e), this.kernel = this.addWeight(\"kernel\", [e[e.length - 1], 4 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight(\"recurrent_kernel\", [this.units, 4 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {\n      if (this.unitForgetBias) {\n        var _e214 = this.biasInitializer,\n            _s108 = this.units;\n        n = new ((t = class extends Dc {\n          apply(t, n) {\n            var r = _e214.apply([_s108]),\n                a = new Oc().apply([_s108]),\n                i = _e214.apply([2 * _s108]);\n\n            return wc(wc(r, a), i);\n          }\n\n        }).className = \"CustomInit\", t)();\n      } else n = this.biasInitializer;\n\n      this.bias = this.addWeight(\"bias\", [4 * this.units], null, n, this.biasRegularizer, !0, this.biasConstraint);\n    } else this.bias = null;\n\n    this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var n = null != t.training && t.training;\n      if (3 !== (e = e).length) throw new xu(\"LSTMCell expects 3 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var s = e[1];\n      var r = e[2];\n      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Mp({\n        ones: () => ya(e),\n        rate: this.dropout,\n        training: n,\n        count: 4\n      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Mp({\n        ones: () => ya(s),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 4\n      }));\n      var a = this.recurrentDropoutMask;\n      var i, o, l, u;\n      0 < this.dropout && this.dropout < 1 && (e = rs(e, this.dropoutMask[0]));\n      var c = $c(e, this.kernel.read());\n      0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = rs(s, a[0])), c = ts(c, $c(s, this.recurrentKernel.read())), this.useBias && (c = Tc(c, this.bias.read()));\n      var [h, d, p, f] = li(c, 4, c.rank - 1);\n      i = this.recurrentActivation.apply(h), o = this.recurrentActivation.apply(d), l = ts(rs(o, r), rs(i, this.activation.apply(p))), u = this.recurrentActivation.apply(f);\n      var g = rs(u, this.activation.apply(l));\n      return [g, g, l];\n    });\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      units: this.units,\n      activation: qd(this.activation),\n      recurrentActivation: qd(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: Jc(this.kernelInitializer),\n      recurrentInitializer: Jc(this.recurrentInitializer),\n      biasInitializer: Jc(this.biasInitializer),\n      unitForgetBias: this.unitForgetBias,\n      kernelRegularizer: Zd(this.kernelRegularizer),\n      recurrentRegularizer: Zd(this.recurrentRegularizer),\n      biasRegularizer: Zd(this.biasRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      recurrentConstraint: ju(this.recurrentConstraint),\n      biasConstraint: ju(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation\n    };\n    return Object.assign({}, e, t);\n  }\n\n}\n\nDp.className = \"LSTMCell\", Kn(Dp);\n\nclass _p extends Cp {\n  constructor(e) {\n    0 === e.implementation && console.warn(\"`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.\"), e.cell = new Dp(e), super(e);\n  }\n\n  call(e, t) {\n    return Jn(() => (null != this.cell.dropoutMask && (Zn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Zn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {\n      mask: null == t ? null : t.mask,\n      training: null == t ? null : t.training,\n      initialState: null == t ? null : t.initialState\n    })));\n  }\n\n  static fromConfig(e, t) {\n    return 0 === t.implmentation && (t.implementation = 1), new e(t);\n  }\n\n}\n\n_p.className = \"LSTM\", Kn(_p);\n\nclass Op extends Tp {\n  constructor(e) {\n    super(e), this.cells = e.cells;\n  }\n\n  get stateSize() {\n    var e = [];\n\n    for (var _t207 of this.cells.slice().reverse()) {\n      Array.isArray(_t207.stateSize) ? e.push(..._t207.stateSize) : e.push(_t207.stateSize);\n    }\n\n    return e;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var n = (e = e).slice(1);\n      var s = [];\n\n      for (var _e215 of this.cells.slice().reverse()) {\n        Array.isArray(_e215.stateSize) ? s.push(n.splice(0, _e215.stateSize.length)) : s.push(n.splice(0, 1));\n      }\n\n      s.reverse();\n      var r = [];\n      var a;\n\n      for (var _i34 = 0; _i34 < this.cells.length; ++_i34) {\n        var _o28 = this.cells[_i34];\n        n = s[_i34], a = 0 === _i34 ? [e[0]].concat(n) : [a[0]].concat(n), a = _o28.call(a, t), r.push(a.slice(1));\n      }\n\n      n = [];\n\n      for (var _e216 of r.slice().reverse()) {\n        n.push(..._e216);\n      }\n\n      return [a[0]].concat(n);\n    });\n  }\n\n  build(e) {\n    var t;\n    sh(e) && (e = e[0]), e = e, this.cells.forEach((n, s) => {\n      ic(\"RNNCell_\".concat(s), () => {\n        n.build(e), t = Array.isArray(n.stateSize) ? n.stateSize[0] : n.stateSize, e = [e[0], t];\n      });\n    }), this.built = !0;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = this.cells.map(e => ({\n      className: e.getClassName(),\n      config: e.getConfig()\n    }));\n    return Object.assign({}, e, {\n      cells: t\n    });\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = [];\n\n    for (var _e217 of t.cells) {\n      s.push(Rh(_e217, n));\n    }\n\n    return new e({\n      cells: s\n    });\n  }\n\n  get trainableWeights() {\n    if (!this.trainable) return [];\n    var e = [];\n\n    for (var _t208 of this.cells) {\n      e.push(..._t208.trainableWeights);\n    }\n\n    return e;\n  }\n\n  get nonTrainableWeights() {\n    var e = [];\n\n    for (var _t209 of this.cells) {\n      e.push(..._t209.nonTrainableWeights);\n    }\n\n    if (!this.trainable) {\n      var _t210 = [];\n\n      for (var _e218 of this.cells) {\n        _t210.push(..._e218.trainableWeights);\n      }\n\n      return _t210.concat(e);\n    }\n\n    return e;\n  }\n\n  getWeights() {\n    var e = [];\n\n    for (var _t211 of this.cells) {\n      e.push(..._t211.weights);\n    }\n\n    return uh(e);\n  }\n\n  setWeights(e) {\n    var t = [];\n\n    for (var _n122 of this.cells) {\n      var _s109 = e.splice(_n122.weights.length);\n\n      for (var _e219 = 0; _e219 < _n122.weights.length; ++_e219) {\n        t.push([_n122.weights[_e219], _s109[_e219]]);\n      }\n    }\n\n    ch(t);\n  }\n\n}\n\nfunction Mp(e) {\n  var {\n    ones: t,\n    rate: n,\n    training: s = !1,\n    count: r = 1\n  } = e,\n      a = () => Ec(t(), n),\n      i = () => Rc(a, t, s);\n\n  return !r || r <= 1 ? Qn(i().clone()) : Array(r).fill(void 0).map(i).map(e => Qn(e.clone()));\n}\n\nvar Lp, zp, Bp;\nOp.className = \"StackedRNNCells\", Kn(Op);\n\nclass Pp extends Cp {\n  constructor(e) {\n    if (e.unroll) throw new yu(\"Unrolling is not possible with convolutional RNNs.\");\n    if (Array.isArray(e.cell)) throw new yu(\"It is not possible at the moment to stack convolutional cells.\");\n    super(e), this.inputSpec = [new hh({\n      ndim: 5\n    })];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (null != this.cell.dropoutMask && (Zn(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (Zn(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), t && t.constants) throw new xu(\"ConvRNN2D cell does not support constants\");\n      return super.call(e, {\n        mask: null == t ? null : t.mask,\n        training: null == t ? null : t.training,\n        initialState: null == t ? null : t.initialState\n      });\n    });\n  }\n\n  computeOutputShape(e) {\n    var t = this.computeSingleOutputShape(e);\n    return this.returnSequences || (t = [t[0], ...t.slice(2)]), this.returnState && (t = [t, ...Array(2).fill([e[0], ...t.slice(-3)])]), t;\n  }\n\n  getInitialState(e) {\n    return Jn(() => {\n      var {\n        stateSize: t\n      } = this.cell,\n          n = this.computeSingleOutputShape(e.shape),\n          s = ca([n[0], ...n.slice(2)]);\n      return Array.isArray(t) ? Array(t.length).fill(s) : [s];\n    });\n  }\n\n  resetStates(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    Jn(() => {\n      if (!this.stateful) throw new mu(\"Cannot call resetStates() on an RNN Layer that is not stateful.\");\n      var n = this.inputSpec[0].shape,\n          s = this.computeSingleOutputShape(n),\n          r = [s[0], ...s.slice(2)];\n      if (null == n[0]) throw new xu(\"If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \\n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.\");\n      if (null == this.getStates()) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(() => ca(r)) : [ca(r)];else if (null == e) Zn(this.states_), null != this.keptStates && (Zn(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => ca(r)) : this.states_[0] = ca(r);else {\n        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new xu(\"Layer \".concat(this.name, \" expects \").concat(this.states_.length, \" state(s), but it received \").concat(e.length, \" state value(s). Input received: \").concat(e));\n        t ? this.keptStates.push(this.states_.slice()) : Zn(this.states_);\n\n        for (var _t212 = 0; _t212 < this.states_.length; ++_t212) {\n          var _n123 = e[_t212],\n              _s110 = r;\n          if (!p(_n123.shape, _s110)) throw new xu(\"State \".concat(_t212, \" is incompatible with layer \").concat(this.name, \": expected shape=\").concat(_s110, \", received shape=\").concat(_n123.shape));\n          this.states_[_t212] = _n123;\n        }\n      }\n      this.states_ = this.states_.map(e => Qn(e.clone()));\n    });\n  }\n\n  computeSingleOutputShape(e) {\n    var {\n      dataFormat: t,\n      filters: n,\n      kernelSize: s,\n      padding: r,\n      strides: a,\n      dilationRate: i\n    } = this.cell,\n        o = \"channelsFirst\" === t,\n        l = e[o ? 4 : 3],\n        u = lp(e[o ? 3 : 2], s[0], r, a[0], i[0]),\n        c = lp(l, s[1], r, a[1], i[1]);\n    return [...e.slice(0, 2), ...(o ? [n, u, c] : [u, c, n])];\n  }\n\n}\n\nPp.className = \"ConvRNN2D\";\n\nclass Wp extends Dp {\n  constructor(e) {\n    var {\n      filters: t,\n      kernelSize: n,\n      strides: s,\n      padding: r,\n      dataFormat: a,\n      dilationRate: i\n    } = e;\n    super(Object.assign({}, e, {\n      units: t\n    })), this.filters = t, Lu(this.filters, \"filters\"), this.kernelSize = op(n, 2, \"kernelSize\"), this.kernelSize.forEach(e => Lu(e, \"kernelSize\")), this.strides = op(s || 1, 2, \"strides\"), this.strides.forEach(e => Lu(e, \"strides\")), this.padding = r || \"valid\", sc(this.padding), this.dataFormat = a || \"channelsLast\", nc(this.dataFormat), this.dilationRate = op(i || 1, 2, \"dilationRate\"), this.dilationRate.forEach(e => Lu(e, \"dilationRate\"));\n  }\n\n  build(e) {\n    var t;\n    e = ih(e);\n    var n = \"channelsFirst\" === this.dataFormat ? 1 : e.length - 1;\n    if (null == e[n]) throw new xu(\"The channel dimension of the input should be defined. Found \".concat(e[n]));\n    var s = this.kernelSize.concat([e[n], 4 * this.filters]);\n    this.kernel = this.addWeight(\"kernel\", s, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint);\n    var r = this.kernelSize.concat([this.filters, 4 * this.filters]);\n\n    if (this.recurrentKernel = this.addWeight(\"recurrent_kernel\", r, null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {\n      var _e220;\n\n      if (this.unitForgetBias) {\n        var _n124 = this.biasInitializer,\n            _s111 = this.filters;\n        _e220 = new ((t = class extends Dc {\n          apply(e, t) {\n            return kc([_n124.apply([_s111]), ha([_s111]), _n124.apply([2 * _s111])]);\n          }\n\n        }).className = \"CustomInit\", t)();\n      } else _e220 = this.biasInitializer;\n\n      this.bias = this.addWeight(\"bias\", [4 * this.filters], null, _e220, this.biasRegularizer, !0, this.biasConstraint);\n    }\n\n    this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (3 !== e.length) throw new xu(\"ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got \".concat(e.length, \".\"));\n      var n = t.training || !1,\n          s = e[0],\n          r = e[1],\n          a = e[2];\n      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Mp({\n        ones: () => ya(s),\n        rate: this.dropout,\n        training: n,\n        count: 4\n      }));\n\n      var i = this.dropoutMask,\n          o = (e, t, n) => t && t[n] ? rs(t[n], e) : e;\n\n      var l = o(s, i, 0),\n          u = o(s, i, 1),\n          c = o(s, i, 2),\n          h = o(s, i, 3);\n      0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Mp({\n        ones: () => ya(r),\n        rate: this.recurrentDropout,\n        training: n,\n        count: 4\n      }));\n      var d = this.recurrentDropoutMask;\n      var p = o(r, d, 0),\n          f = o(r, d, 1),\n          g = o(r, d, 2),\n          m = o(r, d, 3);\n      var [b, x, y, k] = li(this.kernel.read(), 4, 3),\n          [w, v, I, $] = this.useBias ? li(this.bias.read(), 4) : [null, null, null, null];\n      l = this.inputConv(l, b, w, this.padding), u = this.inputConv(u, x, v, this.padding), c = this.inputConv(c, y, I, this.padding), h = this.inputConv(h, k, $, this.padding);\n      var [S, N, C, T] = li(this.recurrentKernel.read(), 4, 3);\n      p = this.recurrentConv(p, S), f = this.recurrentConv(f, N), g = this.recurrentConv(g, C), m = this.recurrentConv(m, T);\n      var E = this.recurrentActivation.apply(ts(l, p)),\n          R = this.recurrentActivation.apply(ts(u, f)),\n          A = ts(rs(R, a), rs(E, this.activation.apply(ts(c, g)))),\n          F = rs(this.recurrentActivation.apply(ts(h, m)), this.activation.apply(A));\n      return [F, F, A];\n    });\n  }\n\n  getConfig() {\n    var e = function (e, t) {\n      var n = {};\n\n      for (var s in e) {\n        Object.prototype.hasOwnProperty.call(e, s) && t.indexOf(s) < 0 && (n[s] = e[s]);\n      }\n\n      if (null != e && \"function\" == typeof Object.getOwnPropertySymbols) {\n        var r = 0;\n\n        for (s = Object.getOwnPropertySymbols(e); r < s.length; r++) {\n          t.indexOf(s[r]) < 0 && Object.prototype.propertyIsEnumerable.call(e, s[r]) && (n[s[r]] = e[s[r]]);\n        }\n      }\n\n      return n;\n    }(super.getConfig(), [\"units\"]);\n\n    return Object.assign({}, e, {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides\n    });\n  }\n\n  inputConv(e, t, n, s) {\n    var r = Ys(e, t, this.strides, s || \"valid\", \"channelsFirst\" === this.dataFormat ? \"NCHW\" : \"NHWC\", this.dilationRate);\n    return n ? Tc(r, n, this.dataFormat) : r;\n  }\n\n  recurrentConv(e, t) {\n    return Ys(e, t, 1, \"same\", \"channelsFirst\" === this.dataFormat ? \"NCHW\" : \"NHWC\");\n  }\n\n}\n\nWp.className = \"ConvLSTM2DCell\", Kn(Wp);\n\nclass Up extends Pp {\n  constructor(e) {\n    var t = new Wp(e);\n    super(Object.assign({}, e, {\n      cell: t\n    }));\n  }\n\n  static fromConfig(e, t) {\n    return new e(t);\n  }\n\n}\n\nUp.className = \"ConvLSTM2D\", Kn(Up);\n\nclass Vp extends mh {\n  constructor(e) {\n    super(e), this.rate = Math.max(Math.min(e.rate, 1), 0), this.noiseShape = e.noiseShape, this.seed = e.seed, this.supportsMasking = !0;\n  }\n\n  getNoiseShape(e) {\n    if (null == this.noiseShape) return this.noiseShape;\n    var t = e.shape,\n        n = [];\n\n    for (var _e221 = 0; _e221 < this.noiseShape.length; ++_e221) {\n      n.push(null == this.noiseShape[_e221] ? t[_e221] : this.noiseShape[_e221]);\n    }\n\n    return n;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n\n      if (0 < this.rate && this.rate < 1) {\n        var _e222 = null != t.training && t.training,\n            _s112 = this.getNoiseShape(n);\n\n        return Rc(() => Ec(n, this.rate, _s112, this.seed), () => n, _e222);\n      }\n\n      return e;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  dispose() {\n    return super.dispose();\n  }\n\n}\n\nVp.className = \"Dropout\", Kn(Vp);\n\nclass Gp extends Vp {\n  constructor(e) {\n    super(e), this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getNoiseShape(e) {\n    var t = e.shape;\n    return [t[0], 1, t[2]];\n  }\n\n}\n\nGp.className = \"SpatialDropout1D\", Kn(Gp);\n\nclass Hp extends mh {\n  constructor(e) {\n    if (super(e), this.activation = null, this.useBias = !0, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = \"glorotNormal\", this.DEFAULT_BIAS_INITIALIZER = \"zeros\", null == e.batchInputShape && null == e.inputShape && null != e.inputDim) {\n      var _t213 = null;\n      null != e.batchSize && (_t213 = e.batchSize), this.batchInputShape = [_t213, e.inputDim];\n    }\n\n    this.units = e.units, Lu(this.units, \"units\"), this.activation = Kd(e.activation), null != e.useBias && (this.useBias = e.useBias), this.kernelInitializer = Zc(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = Zc(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = Xu(e.kernelConstraint), this.biasConstraint = Xu(e.biasConstraint), this.kernelRegularizer = ep(e.kernelRegularizer), this.biasRegularizer = ep(e.biasRegularizer), this.activityRegularizer = ep(e.activityRegularizer), this.supportsMasking = !0, this.inputSpec = [{\n      minNDim: 2\n    }];\n  }\n\n  build(e) {\n    var t = (e = ih(e))[e.length - 1];\n    null == this.kernel && (this.kernel = this.addWeight(\"kernel\", [t, this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight(\"bias\", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint))), this.inputSpec = [{\n      minNDim: 2,\n      axes: {\n        [-1]: t\n      }\n    }], this.built = !0;\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ih(e)).slice();\n    return t[t.length - 1] = this.units, t;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e),\n          s = Bu(this.activation.getClassName());\n      var r;\n      return null != s ? r = $c(n, this.kernel.read(), s, this.bias ? this.bias.read() : null) : (r = $c(n, this.kernel.read()), null != this.bias && (r = Tc(r, this.bias.read())), null != this.activation && (r = this.activation.apply(r))), r;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      units: this.units,\n      activation: qd(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: Jc(this.kernelInitializer),\n      biasInitializer: Jc(this.biasInitializer),\n      kernelRegularizer: Zd(this.kernelRegularizer),\n      biasRegularizer: Zd(this.biasRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      kernelConstraint: ju(this.kernelConstraint),\n      biasConstraint: ju(this.biasConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nHp.className = \"Dense\", Kn(Hp);\n\nclass qp extends mh {\n  constructor(e) {\n    super(e = e || {}), this.inputSpec = [{\n      minNDim: 3\n    }], this.dataFormat = e.dataFormat;\n  }\n\n  computeOutputShape(e) {\n    e = ih(e);\n\n    for (var _t214 of e.slice(1)) {\n      if (null == _t214) throw new xu(\"The shape of the input to \\\"Flatten\\\" is not fully defined (got \".concat(e.slice(1), \"). Make sure to pass a complete \\\"input_shape\\\" or \\\"batch_input_shape\\\" argument to the first layer in your model.\"));\n    }\n\n    return [e[0], hc(e, 1)];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n\n      if (\"channelsFirst\" === this.dataFormat && n.rank > 1) {\n        var _e223 = [0];\n\n        for (var _t215 = 2; _t215 < n.rank; ++_t215) {\n          _e223.push(_t215);\n        }\n\n        _e223.push(1), n = Sn(n, _e223);\n      }\n\n      return function (e) {\n        if (e.rank <= 1) throw new xu(\"batchFlatten requires a minimum rank of 2. Got rank: \".concat(e.rank, \".\"));\n        var t = [e.shape[0], hc(e.shape, 1)];\n        return Rs(e, t);\n      }(n);\n    });\n  }\n\n  getConfig() {\n    var e = {};\n    null != this.dataFormat && (e.dataFormat = this.dataFormat);\n    var t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nqp.className = \"Flatten\", Kn(qp);\n\nclass jp extends mh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.activation = Kd(e.activation);\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n      return this.activation.apply(n);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      activation: qd(this.activation)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\njp.className = \"Activation\", Kn(jp);\n\nclass Kp extends mh {\n  constructor(e) {\n    super(e), this.n = e.n, this.inputSpec = [{\n      ndim: 2\n    }];\n  }\n\n  computeOutputShape(e) {\n    return [e[0], this.n, e[1]];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      return e = ah(e), t = e, n = this.n, Jn(() => {\n        if (2 !== t.shape.length) throw new xu(\"repeat() expects a rank-2 tensor, but received a rank-\".concat(t.shape.length, \" tensor.\"));\n        return vc(mc(t, 1), [1, n, 1]);\n      });\n      var t, n;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      n: this.n\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nKp.className = \"RepeatVector\", Kn(Kp);\n\nclass Xp extends mh {\n  constructor(e) {\n    super(e), this.targetShape = e.targetShape;\n\n    for (var _e224 = 0; _e224 < this.targetShape.length; ++_e224) {\n      this.isUnknown(this.targetShape[_e224]) && (this.targetShape[_e224] = null);\n    }\n  }\n\n  isUnknown(e) {\n    return e < 0 || null == e;\n  }\n\n  fixUnknownDimension(e, t) {\n    var n = \"Total size of new array must be unchanged.\",\n        s = t.slice();\n    var r = 1,\n        a = null;\n\n    for (var _e225 = 0; _e225 < s.length; ++_e225) {\n      var _t216 = s[_e225];\n\n      if (this.isUnknown(_t216)) {\n        if (null !== a) throw new xu(\"Can only specifiy one unknown dimension.\");\n        a = _e225;\n      } else r *= _t216;\n    }\n\n    var i = hc(e);\n\n    if (null !== a) {\n      if (0 === r || i % r != 0) throw new xu(n);\n      s[a] = i / r;\n    } else if (i !== r) throw new xu(n);\n\n    return s;\n  }\n\n  computeOutputShape(e) {\n    var t = !1;\n\n    for (var _n125 = 0; _n125 < e.length; ++_n125) {\n      if (this.isUnknown(e[_n125])) {\n        t = !0;\n        break;\n      }\n    }\n\n    return t ? e.slice(0, 1).concat(this.targetShape) : e.slice(0, 1).concat(this.fixUnknownDimension(e.slice(1), this.targetShape));\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e),\n          s = n.shape,\n          r = s.slice(0, 1).concat(this.fixUnknownDimension(s.slice(1), this.targetShape));\n      return Rs(n, r);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      targetShape: this.targetShape\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nXp.className = \"Reshape\", Kn(Xp);\n\nclass Yp extends mh {\n  constructor(e) {\n    if (super(e), null == e.dims) throw new Error(\"Required configuration field `dims` is missing during Permute constructor call.\");\n    if (!Array.isArray(e.dims)) throw new Error(\"Permute constructor requires `dims` to be an Array, but received \".concat(e.dims, \" instead.\"));\n    var t = fc(1, e.dims.length + 1);\n    if (!p(e.dims.slice().sort(), t)) throw new Error(\"Invalid permutation `dims`: \" + JSON.stringify(e.dims) + \" `dims` must contain consecutive integers starting from 1.\");\n    this.dims = e.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new hh({\n      ndim: this.dims.length + 1\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t = (e = ih(e)).slice();\n    return this.dims.forEach((n, s) => {\n      t[s + 1] = e[n];\n    }), t;\n  }\n\n  call(e, t) {\n    return Sn(ah(e), this.dimsIncludingBatch);\n  }\n\n  getConfig() {\n    var e = {\n      dims: this.dims\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nYp.className = \"Permute\", Kn(Yp);\n\nclass Jp extends mh {\n  constructor(e) {\n    super(null == e ? {} : e), this.supportsMasking = !0, this.maskValue = null != e ? null == e.maskValue ? 0 : e.maskValue : 0;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      maskValue: this.maskValue\n    };\n    return Object.assign(t, e), t;\n  }\n\n  computeMask(e, t) {\n    var n = ah(e);\n    return us(xa(n, this.maskValue), -1);\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e),\n          s = us(xa(n, this.maskValue), -1, !0);\n      return rs(n, fn(s, n.dtype));\n    });\n  }\n\n}\n\nJp.className = \"Masking\", Kn(Jp);\n\nclass Zp extends mh {\n  constructor(e) {\n    if (super(e), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = \"randomUniform\", null == e.batchInputShape && null == e.inputShape) {\n      var _t217 = null;\n      null != e.batchSize && (_t217 = e.batchSize), this.batchInputShape = null == e.inputLength ? [_t217, null] : [_t217].concat(Su(e.inputLength));\n    }\n\n    this.inputDim = e.inputDim, Lu(this.inputDim, \"inputDim\"), this.outputDim = e.outputDim, Lu(this.outputDim, \"outputDim\"), this.embeddingsInitializer = Zc(e.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = ep(e.embeddingsRegularizer), this.activityRegularizer = ep(e.activityRegularizer), this.embeddingsConstraint = Xu(e.embeddingsConstraint), this.maskZero = e.maskZero, this.supportsMasking = e.maskZero, this.inputLength = e.inputLength;\n  }\n\n  build(e) {\n    this.embeddings = this.addWeight(\"embeddings\", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, !0, this.embeddingsConstraint), this.built = !0;\n  }\n\n  warnOnIncompatibleInputShape(e) {}\n\n  computeMask(e, t) {\n    return Jn(() => this.maskZero ? (e = ah(e), xa(e, fr(e))) : null);\n  }\n\n  computeOutputShape(e) {\n    if (e = ih(e), null == this.inputLength) return [...e, this.outputDim];\n    var t = Su(this.inputLength);\n    if (t.length !== e.length - 1) throw new xu(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received input shape has shape \").concat(e));\n    {\n      var _n126 = 0;\n\n      for (var _s113 = 0; _s113 < t.length; ++_s113) {\n        var _r77 = t[_s113],\n            _a61 = e[_s113 + 1];\n        if (null != _r77 && null != _a61 && _r77 !== _a61) throw new xu(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received input shape has shape \").concat(e));\n        null == _r77 && (t[_n126] = _a61), _n126++;\n      }\n    }\n    return [e[0], ...t, this.outputDim];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n      \"int32\" !== n.dtype && (n = gc(n, \"int32\"));\n      var s = Sc(this.embeddings.read(), Rs(n, [n.size]));\n      return Rs(s, ih(this.computeOutputShape(n.shape)));\n    });\n  }\n\n  getConfig() {\n    var e = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: Jc(this.embeddingsInitializer),\n      embeddingsRegularizer: Zd(this.embeddingsRegularizer),\n      activityRegularizer: Zd(this.activityRegularizer),\n      embeddingsConstraint: ju(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nZp.className = \"Embedding\", Kn(Zp);\n\nclass Qp extends mh {\n  constructor(e) {\n    super(e || {}), this.supportsMasking = !0;\n  }\n\n  mergeFunction(e) {\n    throw new yu();\n  }\n\n  computeElementwiseOpOutputShape(e, t) {\n    if (null == e || null == t) return null;\n    if (e.length < t.length) return this.computeElementwiseOpOutputShape(t, e);\n    if (0 === t.length) return e;\n    var n = e.slice(0, e.length - t.length);\n\n    for (var _s114 = 0; _s114 < t.length; ++_s114) {\n      var _r78 = e[e.length - t.length + _s114],\n          _a62 = t[_s114];\n      if (null == _r78 || null == _a62 || _r78 < 0 || _a62 < 0) n.push(null);else if (1 === _r78) n.push(_a62);else if (1 === _a62) n.push(_r78);else {\n        if (_r78 !== _a62) throw new xu(\"Operands could not be broadcast together with shapes \" + JSON.stringify(e) + \" \" + JSON.stringify(t));\n        n.push(_r78);\n      }\n    }\n\n    return n;\n  }\n\n  build(e) {\n    if (Array.isArray(e) && !Array.isArray(e[0]) && (e = [ih(e)]), (e = e).length < 2) throw new xu(\"A merge layer should be called on an Array of at least 2 inputs. Got \".concat(e.length, \" input(s).\"));\n    var t = [];\n\n    for (var _n127 of e) {\n      null != _n127 && null !== _n127[0] && t.push(_n127[0]);\n    }\n\n    if (t = Du(t), t.length > 1) throw new xu(\"Can not merge tensors with different batch sizes. Got tensors with shapes: \".concat(JSON.stringify(e), \".\"));\n    var n = null == e[0] ? null : e[0].slice(1);\n\n    for (var _t218 = 1; _t218 < e.length; ++_t218) {\n      var _s115 = null == e[_t218] ? null : e[_t218].slice(1);\n\n      n = this.computeElementwiseOpOutputShape(n, _s115);\n    }\n\n    var s = e.map(e => e.length);\n    this.reshapeRequired = -1 !== e.indexOf(null) || 1 !== Du(s).length;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (e = e, this.reshapeRequired) {\n        var _t219 = [],\n            _n128 = e.map(e => e.rank);\n\n        if (-1 === _n128.indexOf(null)) {\n          var _s116 = pc(_n128);\n\n          for (var _n129 of e) {\n            var _e226 = _n129.rank;\n\n            for (var _t220 = 0; _t220 < _s116 - _e226; ++_t220) {\n              _n129 = mc(_n129, 1);\n            }\n\n            _t219.push(_n129);\n          }\n\n          return this.mergeFunction(_t219);\n        }\n\n        {\n          var _n130 = !1;\n\n          for (var _s118 of e) {\n            var _e227 = _s118.rank;\n\n            if (null == _e227) {\n              var _e228 = _s118.shape,\n                  _r80 = _e228[0],\n                  _a63 = _e228.slice(1).concat([_r80]);\n\n              var _i35 = Rs(_s118, [_r80].concat(hc(_e228.slice(1))));\n\n              _i35 = Sn(_i35, [1, 0]), _i35 = Rs(_i35, _a63), _t219.push(_i35), _n130 = !0;\n            } else if (_e227 > 1) {\n              var _r81 = fc(1, _e227).concat([0]);\n\n              _t219.push(Sn(_s118, _r81)), _n130 = !0;\n            } else _t219.push(_s118);\n          }\n\n          var _s117 = this.mergeFunction(_t219);\n\n          var _r79 = _s117.rank;\n          if (_n130) if (null == _r79) {\n            var _e229 = _s117.shape,\n                _t221 = _e229[_e229.length - 1],\n                _n131 = [_t221].concat(_e229.slice(0, _e229.length - 1));\n\n            _s117 = Rs(Sn(Rs(_s117, [-1, _t221]), [1, 0]), _n131);\n          } else if (_r79 > 1) {\n            var _e230 = [_r79 - 1].concat(fc(0, _r79 - 1));\n\n            _s117 = Sn(_s117, _e230);\n          }\n          return _s117;\n        }\n      }\n\n      return this.mergeFunction(e);\n    });\n  }\n\n  computeOutputShape(e) {\n    var t;\n    t = null == (e = e)[0] ? null : e[0].slice(1);\n\n    for (var _n132 = 1; _n132 < e.length; ++_n132) {\n      var _s119 = null == e[_n132] ? null : e[_n132].slice(1);\n\n      t = this.computeElementwiseOpOutputShape(t, _s119);\n    }\n\n    var n = [];\n\n    for (var _t222 of e) {\n      null != _t222 && null !== _t222[0] && n.push(_t222[0]);\n    }\n\n    return n = Du(n), t = 1 === n.length ? n.concat(t) : [null].concat(t), t;\n  }\n\n  computeMask(e, t) {\n    return Jn(() => {\n      if (null == t) return null;\n      if (!Array.isArray(t)) throw new xu(\"`mask` should be an Array\");\n      if (!Array.isArray(e)) throw new xu(\"`inputs` should be an Array\");\n      if (t.length !== e.length) throw new xu(\"The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (\".concat(e.length, \" vs \").concat(t.length, \")\"));\n      if (t.every(e => null == e)) return null;\n      var n = (t = t.map(e => null == e ? e : kr(e, 0)))[0];\n\n      for (var _e231 = 1; _e231 < t.length - 1; ++_e231) {\n        n = na(n, t[_e231]);\n      }\n\n      return n;\n    });\n  }\n\n}\n\nclass ef extends Qp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Jn(() => {\n      var t = e[0].clone();\n\n      for (var _n133 = 1; _n133 < e.length; ++_n133) {\n        t = ts(t, e[_n133]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nef.className = \"Add\", Kn(ef);\n\nclass tf extends Qp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Jn(() => {\n      var t = e[0].clone();\n\n      for (var _n134 = 1; _n134 < e.length; ++_n134) {\n        t = rs(t, e[_n134]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\ntf.className = \"Multiply\", Kn(tf);\n\nclass nf extends Qp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Jn(() => {\n      var t = e[0].clone();\n\n      for (var _n135 = 1; _n135 < e.length; ++_n135) {\n        t = ts(t, e[_n135]);\n      }\n\n      return rs(1 / e.length, t);\n    });\n  }\n\n}\n\nnf.className = \"Average\", Kn(nf);\n\nclass sf extends Qp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Jn(() => {\n      var t = e[0];\n\n      for (var _n136 = 1; _n136 < e.length; ++_n136) {\n        t = la(t, e[_n136]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nsf.className = \"Maximum\", Kn(sf);\n\nclass rf extends Qp {\n  constructor(e) {\n    super(e);\n  }\n\n  mergeFunction(e) {\n    return Jn(() => {\n      var t = e[0];\n\n      for (var _n137 = 1; _n137 < e.length; ++_n137) {\n        t = pa(t, e[_n137]);\n      }\n\n      return t;\n    });\n  }\n\n}\n\nrf.className = \"Minimum\", Kn(rf);\n\nclass af extends Qp {\n  constructor(e) {\n    super(e), this.DEFAULT_AXIS = -1, null == e && (e = {}), this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis, this.supportsMasking = !0, this.reshapeRequired = !1;\n  }\n\n  build(e) {\n    if (!Array.isArray(e) || !Array.isArray(e[0]) || 1 === e.length) throw new xu(\"A `Concatenate` layer should be called on a list of at least 2 inputs\");\n    e = e;\n    var t = !0;\n\n    for (var _n138 of e) {\n      if (null != _n138) {\n        t = !1;\n        break;\n      }\n    }\n\n    if (t) return;\n    var n = [];\n\n    for (var _t223 = 0; _t223 < e.length; ++_t223) {\n      var _s120 = e[_t223].slice();\n\n      _s120.splice(this.axis, 1);\n\n      var _r82 = !1;\n\n      for (var _e232 of n) {\n        if (p(_e232, _s120)) {\n          _r82 = !0;\n          break;\n        }\n      }\n\n      _r82 || n.push(_s120);\n    }\n\n    if (n.length > 1) throw new xu(\"A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: \" + JSON.stringify(e));\n  }\n\n  mergeFunction(e) {\n    return Jn(() => kc(e, this.axis));\n  }\n\n  computeOutputShape(e) {\n    if (!Array.isArray(e) || !Array.isArray(e[0])) throw new xu(\"A `Concatenate` layer should be called on a list of inputs.\");\n    var t = e,\n        n = t[0].slice(),\n        s = this.axis < 0 ? n.length + this.axis : this.axis;\n\n    for (var _e233 of t.slice(1)) {\n      if (null == n[s] || null == _e233[s]) {\n        n[s] = null;\n        break;\n      }\n\n      n[s] += _e233[s];\n    }\n\n    return n;\n  }\n\n  computeMask(e, t) {\n    if (null == t) return null;\n    if (!Array.isArray(t)) throw new xu(\"`mask` should be an array for Concatenate\");\n    if (!Array.isArray(e)) throw new xu(\"`inputs` should be an array for Concatenate\");\n    if (t.length !== e.length) throw new xu(\"Mismatch in the length of mask (\".concat(t.length, \") and the legnth of inputs (\").concat(e.length, \")\"));\n    return Jn(() => {\n      var n = !0;\n      if (t.forEach(e => {\n        null == e || (n = !1);\n      }), n) return null;\n      var s = [];\n\n      for (var _n139 = 0; _n139 < e.length; ++_n139) {\n        s.push(null == t[_n139] ? fn(ya(e[_n139]), \"bool\") : t[_n139].rank < e[_n139].rank ? kr(t[_n139], -1) : t[_n139]);\n      }\n\n      var r = Ds(s, this.axis);\n      return ls(r, -1, !1);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction of(e, t) {\n  for (; e < 0;) {\n    e += t;\n  }\n\n  return e;\n}\n\naf.className = \"Concatenate\", Kn(af);\n\nclass lf extends Qp {\n  constructor(e) {\n    super(e), this.axes = e.axes, this.normalize = null != e.normalize && e.normalize, this.supportsMasking = !0, this.reshapeRequired = !1;\n  }\n\n  build(e) {\n    l(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => \"A `Dot` layer should be called on a list of exactly 2 inputs.\");\n    var t = e[0],\n        n = e[1];\n    if (t.length > 3 || n.length > 3) throw new yu(\"Dot layer does not support tensors of 4D or higher rank yet.\");\n    var s = this.interpretAxes(t, n);\n    if (t[s[0]] !== n[s[1]]) throw new xu(\"Dimension incompatibility: \".concat(t[s[0]], \" !== \").concat(n[s[1]]));\n  }\n\n  mergeFunction(e) {\n    if (2 !== e.length) throw new xu(\"A `Dot` layer must be called on exactly 2 inputs, but received \".concat(e.length, \" input(s).\"));\n    var t,\n        n = e[0],\n        s = e[1];\n    return t = Array.isArray(this.axes) ? this.axes.map((t, n) => of(t, e[n].shape.length)) : [of(this.axes, n.shape.length), of(this.axes, s.shape.length)], this.normalize && (n = Ah(n, t[0]), s = Ah(s, t[1])), function (e, t, n) {\n      if (e.shape.length > 3 || t.shape.length > 3) throw new yu(\"batchDot is not implemented for tensors of 4D or higher rank yet\");\n      if (l(e.shape.length >= 2, () => \"batchDot requires the rank of x to be >= 2, but got \".concat(e.shape.length)), l(e.shape.length >= 2, () => \"batchDot requires the rank of y to be >= 2, but got \".concat(t.shape.length)), \"number\" == typeof n && (n = [n, n]), \"complex64\" === e.dtype || \"complex64\" === t.dtype) throw new yu(\"batchDot is not implemented for complex64-type Tensors yet.\");\n      var s = e.shape.length,\n          r = t.shape.length;\n      null == n && (n = [s - 1, r - 2]);\n      var a = n;\n      return Jn(() => {\n        var n, i;\n\n        if (s > r) {\n          n = s - r;\n          var _e234 = [];\n\n          for (var _t224 = 0; _t224 < n; ++_t224) {\n            _e234.push(1);\n          }\n\n          t = Rs(t, t.shape.concat(_e234));\n        } else if (r > s) {\n          n = r - s;\n          var _t225 = [];\n\n          for (var _e235 = 0; _e235 < n; ++_e235) {\n            _t225.push(1);\n          }\n\n          e = Rs(e, e.shape.concat(_t225));\n        } else n = 0;\n\n        if (i = 2 === e.shape.length && 2 === t.shape.length ? a[0] === a[1] ? Hr(rs(e, t), a[0]) : Hr(rs(Sn(e, [1, 0]), t), a[1]) : In(e, t, a[0] !== e.shape.length - 1, a[1] === t.shape.length - 1), n > 0) {\n          var _e236;\n\n          _e236 = s > r ? s + r - 3 : s - 1;\n          var _t226 = [];\n\n          for (var _s121 = _e236; _s121 < _e236 + n; ++_s121) {\n            _t226.push(_s121);\n          }\n\n          i = di(i, _t226);\n        }\n\n        return 1 === i.shape.length && (i = kr(i, 1)), i;\n      });\n    }(n, s, t);\n  }\n\n  interpretAxes(e, t) {\n    var n;\n    return n = Array.isArray(this.axes) ? this.axes : [of(this.axes, e.length), of(this.axes, t.length)], n;\n  }\n\n  computeOutputShape(e) {\n    l(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => \"A `Dot` layer should be called on a list of exactly 2 inputs.\");\n    var t = e[0].slice(),\n        n = e[1].slice();\n    if (t.length > 3 || n.length > 3) throw new yu(\"Dot layer does not support tensors of 4D or higher rank yet.\");\n    var s = this.interpretAxes(t, n);\n    t.splice(s[0], 1), n.splice(s[1], 1), n.splice(0, 1);\n    var r = t.concat(n);\n    return 1 === r.length && r.push(1), r;\n  }\n\n  computeMask(e, t) {\n    return null;\n  }\n\n  getConfig() {\n    var e = {\n      axes: this.axes,\n      normalize: this.normalize\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nlf.className = \"Dot\", Kn(lf);\n\nclass uf extends mh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.stddev = e.stddev;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      stddev: this.stddev\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n      return Rc(() => ts(Ic(n.shape, 0, this.stddev), n), () => n, t.training || !1);\n    });\n  }\n\n}\n\nuf.className = \"GaussianNoise\", Kn(uf);\n\nclass cf extends mh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.rate = e.rate;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      rate: this.rate\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t);\n      var n = ah(e);\n      return this.rate > 0 && this.rate < 1 ? Rc(() => {\n        var e = Math.sqrt(this.rate / (1 - this.rate));\n        return rs(n, Ic(n.shape, 1, e));\n      }, () => n, t.training || !1) : n;\n    });\n  }\n\n}\n\ncf.className = \"GaussianDropout\", Kn(cf);\n\nclass hf extends mh {\n  constructor(e) {\n    super(e), this.supportsMasking = !0, this.rate = e.rate, this.noiseShape = e.noiseShape;\n  }\n\n  _getNoiseShape(e) {\n    return this.noiseShape || ah(e).shape;\n  }\n\n  computeOutputShape(e) {\n    return e;\n  }\n\n  getConfig() {\n    var e = super.getConfig(),\n        t = {\n      rate: this.rate\n    };\n    return Object.assign(t, e), t;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      if (this.rate < 1 && this.rate > 0) {\n        var _n140 = this._getNoiseShape(e);\n\n        return Rc(() => {\n          var t = ah(e),\n              s = -1.7580993408473766;\n          var r = Tr(Ba(_n140), this.rate);\n          r = gc(r, \"float32\");\n          var a = ((1 - this.rate) * (1 + this.rate * s ** 2)) ** -.5,\n              i = -a * s * this.rate,\n              o = ts(rs(t, r), rs(ts(r, -1), s));\n          return ts(rs(o, a), i);\n        }, () => ah(e), t.training || !1);\n      }\n\n      return e;\n    });\n  }\n\n}\n\nfunction df(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : .001;\n  var i;\n  if (2 === e.rank) i = Bs(e, t, n, s, r, a);else if (3 === e.rank) i = Ps(e, t, n, s, r, a);else {\n    if (4 !== e.rank) throw new yu(\"batchNormalization is not implemented for array of rank \".concat(e.rank, \" yet\"));\n    i = Ws(e, t, n, s, r, a);\n  }\n  return i;\n}\n\nhf.className = \"AlphaDropout\", Kn(hf);\n\nclass pf extends mh {\n  constructor(e) {\n    null == e && (e = {}), super(e), this.supportsMasking = !0, this.axis = null == e.axis ? -1 : e.axis, this.momentum = null == e.momentum ? .99 : e.momentum, this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = Zc(e.betaInitializer || \"zeros\"), this.gammaInitializer = Zc(e.gammaInitializer || \"ones\"), this.movingMeanInitializer = Zc(e.movingMeanInitializer || \"zeros\"), this.movingVarianceInitializer = Zc(e.movingVarianceInitializer || \"ones\"), this.betaConstraint = Xu(e.betaConstraint), this.gammaConstraint = Xu(e.gammaConstraint), this.betaRegularizer = ep(e.betaRegularizer), this.gammaRegularizer = ep(e.gammaRegularizer);\n  }\n\n  build(e) {\n    e = ih(e);\n    var t = this.axis >= 0 ? this.axis : this.axis + e.length,\n        n = e[t];\n    if (null == n) throw new xu(\"Axis \".concat(t, \" of input tensor should have a defined dimension but the layer received an input with shape \").concat(JSON.stringify(e), \".\"));\n    this.inputSpec = [new hh({\n      ndim: e.length,\n      axes: {\n        [t]: n\n      }\n    })];\n    var s = [n];\n    this.scale && (this.gamma = this.addWeight(\"gamma\", s, null, this.gammaInitializer, this.gammaRegularizer, !0, this.gammaConstraint)), this.center && (this.beta = this.addWeight(\"beta\", s, null, this.betaInitializer, this.betaRegularizer, !0, this.betaConstraint)), this.movingMean = this.addWeight(\"moving_mean\", s, null, this.movingMeanInitializer, null, !1), this.movingVariance = this.addWeight(\"moving_variance\", s, null, this.movingVarianceInitializer, null, !1), this.built = !0;\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var n = null != t.training && t.training,\n          s = ah(e),\n          r = s.shape,\n          a = r.length,\n          i = fc(0, a),\n          o = this.axis >= 0 ? this.axis : this.axis + a;\n      i.splice(o, 1);\n      var l = wu(1, a);\n      l[o] = r[o];\n      var u = i.slice();\n      u.sort();\n      var c = !p(u, fc(0, a).slice(0, a - 1));\n      if (!n) return (() => {\n        if (c) {\n          var _e237 = Rs(this.movingMean.read(), l),\n              _t227 = Rs(this.movingVariance.read(), l),\n              _n141 = this.center ? Rs(this.beta.read(), l) : null,\n              _r83 = this.scale ? Rs(this.gamma.read(), l) : null;\n\n          return df(s, _e237, _t227, _n141, _r83, this.epsilon);\n        }\n\n        return df(s, this.movingMean.read(), this.movingVariance.read(), null == this.beta ? null : this.beta.read(), null == this.gamma ? null : this.gamma.read(), this.epsilon);\n      })();\n\n      var [h, d, f] = function (e, t, n, s) {\n        var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n        return p(s.slice().sort(), fc(0, e.rank - 1)) ? function (e, t, n, s) {\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n          return Jn(() => {\n            var a = ba(e, s),\n                i = a.mean,\n                o = a.variance;\n            return [df(e, i, o, n, t, r), i, o];\n          });\n        }(e, t, n, s, r) : function (e, t, n, s) {\n          var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;\n          return Jn(() => {\n            var a = ba(e, s),\n                i = a.mean,\n                o = a.variance,\n                l = [];\n\n            for (var _t228 of fc(0, e.rank)) {\n              -1 !== s.indexOf(_t228) ? l.push(1) : l.push(e.shape[_t228]);\n            }\n\n            var u = Rs(i, l),\n                c = Rs(o, l),\n                h = null == t ? null : Rs(t, l),\n                d = null == n ? null : Rs(n, l);\n            return [df(e, u, c, d, h, r), i, o];\n          });\n        }(e, t, n, s, r);\n      }(s, this.gamma.read(), this.beta.read(), i, this.epsilon),\n          g = (e, t, n) => {\n        Jn(() => {\n          var s = 1 - n,\n              r = e.read(),\n              a = rs(Gr(r, t), s);\n          e.write(Gr(r, a));\n        });\n      };\n\n      return (() => {\n        g(this.movingMean, d, this.momentum), g(this.movingVariance, f, this.momentum);\n      })(), h;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis,\n      momentum: this.momentum,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: Jc(this.betaInitializer),\n      gammaInitializer: Jc(this.gammaInitializer),\n      movingMeanInitializer: Jc(this.movingMeanInitializer),\n      movingVarianceInitializer: Jc(this.movingVarianceInitializer),\n      betaRegularizer: Zd(this.betaRegularizer),\n      gammaRegularizer: Zd(this.gammaRegularizer),\n      betaConstraint: ju(this.betaConstraint),\n      gammaConstraint: ju(this.gammaConstraint)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\npf.className = \"BatchNormalization\", Kn(pf);\n\nclass ff extends mh {\n  constructor(e) {\n    if (null == e && (e = {}), super(e), this.axis = null == e.axis ? -1 : e.axis, \"number\" == typeof this.axis) {\n      if (!Number.isInteger(this.axis)) throw new Error(\"Expected axis to be an integer, but received \".concat(this.axis));\n    } else {\n      if (!Array.isArray(this.axis)) throw new Error(\"Expected axis to be an integer or an array of integers, but received \".concat(JSON.stringify(this.axis)));\n\n      for (var _e238 of this.axis) {\n        if (!Number.isInteger(_e238)) throw new Error(\"Expected axis to be an array of integers, but received \".concat(JSON.stringify(this.axis)));\n      }\n    }\n\n    this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = Zc(e.betaInitializer || \"zeros\"), this.gammaInitializer = Zc(e.gammaInitializer || \"ones\"), this.betaRegularizer = ep(e.betaRegularizer), this.gammaRegularizer = ep(e.gammaRegularizer), this.supportsMasking = !0;\n  }\n\n  build(e) {\n    var t = (e = ih(e)).length;\n    \"number\" == typeof this.axis && (this.axis = [this.axis]);\n\n    for (var _e239 = 0; _e239 < this.axis.length; ++_e239) {\n      this.axis[_e239] < 0 && (this.axis[_e239] += t);\n    }\n\n    for (var _e240 of this.axis) {\n      if (_e240 < 0 || _e240 >= t) throw new Error(\"Invalid axis: \".concat(_e240));\n    }\n\n    if (this.axis.length !== Du(this.axis).length) throw new Error(\"Found duplicate axes in: \".concat(this.axis));\n    var n = this.axis.map(t => e[t]);\n    this.gamma = this.scale ? this.addWeight(\"gamma\", n, \"float32\", this.gammaInitializer, this.gammaRegularizer, !0) : null, this.beta = this.center ? this.addWeight(\"beta\", n, \"float32\", this.betaInitializer, this.betaRegularizer, !0) : null, this.built = !0;\n  }\n\n  call(e, t) {\n    var n = ah(e),\n        s = n.shape,\n        r = s.length;\n    return Jn(() => {\n      var {\n        mean: e,\n        variance: t\n      } = ba(n, this.axis, !0);\n      var a = wu(1, r);\n\n      for (var _e241 of this.axis) {\n        a[_e241] = s[_e241];\n      }\n\n      var i = e => null != e && e.shape.length !== r && this.axis !== [r - 1] ? Rs(e, a) : e;\n\n      var o = i(this.gamma.read()),\n          l = i(this.beta.read());\n      var u = [],\n          c = [];\n\n      for (var _e242 = 0; _e242 < r; ++_e242) {\n        -1 !== this.axis.indexOf(_e242) ? (u.push(s[_e242]), c.push(1)) : (u.push(1), c.push(s[_e242]));\n      }\n\n      return e = vr(e, u), t = vr(t, u), o = vr(o, c), l = vr(l, c), df(n, e, t, l, o, this.epsilon);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      axis: this.axis,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: Jc(this.betaInitializer),\n      gammaInitializer: Jc(this.gammaInitializer),\n      betaRegularizer: Zd(this.betaRegularizer),\n      gammaRegularizer: Zd(this.gammaRegularizer)\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nff.className = \"LayerNormalization\", Kn(ff);\n\nclass gf extends mh {\n  constructor(e) {\n    if (null == e && (e = {}), super(e), this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, null == e.padding) this.padding = [[1, 1], [1, 1]];else if (\"number\" == typeof e.padding) this.padding = [[e.padding, e.padding], [e.padding, e.padding]];else {\n      if (e.padding = e.padding, 2 !== e.padding.length) throw new xu(\"ZeroPadding2D expects padding to be a length-2 array, but received a length-\".concat(e.padding.length, \" array.\"));\n\n      var _t229, _n142;\n\n      if (\"number\" == typeof e.padding[0]) _t229 = [e.padding[0], e.padding[0]], _n142 = [e.padding[1], e.padding[1]];else {\n        if (e.padding = e.padding, 2 !== e.padding[0].length) throw new xu(\"ZeroPadding2D expects height padding to be a length-2 array, but received a length-\".concat(e.padding[0].length, \" array.\"));\n        if (_t229 = e.padding[0], 2 !== e.padding[1].length) throw new xu(\"ZeroPadding2D expects width padding to be a length-2 array, but received a length-\".concat(e.padding[1].length, \" array.\"));\n        _n142 = e.padding[1];\n      }\n      this.padding = [_t229, _n142];\n    }\n    this.inputSpec = [new hh({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t, n;\n    return e = ih(e), \"channelsFirst\" === this.dataFormat ? (t = null != e[2] && e[2] >= 0 ? e[2] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[3] && e[3] >= 0 ? e[3] + this.padding[1][0] + this.padding[1][1] : null, [e[0], e[1], t, n]) : (t = null != e[1] && e[1] >= 0 ? e[1] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[2] && e[2] >= 0 ? e[2] + this.padding[1][0] + this.padding[1][1] : null, [e[0], t, n, e[3]]);\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      return t = ah(e), n = this.padding, s = this.dataFormat, Jn(() => {\n        if (4 !== t.rank) throw new xu(\"temporalPadding expects input tensor to be 4-D, but received a \".concat(t.rank, \"-D tensor.\"));\n        if (null == n && (n = [[1, 1], [1, 1]]), 2 !== n.length || 2 !== n[0].length || 2 !== n[1].length) throw new xu(\"spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.\");\n        if (null == s && (s = \"channelsLast\"), \"channelsLast\" !== s && \"channelsFirst\" !== s) throw new xu(\"Unknown data format: \".concat(s, \". Supported data formats are 'channelsLast' and 'channelsFirst.\"));\n        var e;\n        return e = \"channelsFirst\" === s ? [[0, 0], [0, 0], n[0], n[1]] : [[0, 0], n[0], n[1], [0, 0]], ka(t, e);\n      });\n      var t, n, s;\n    });\n  }\n\n  getConfig() {\n    var e = {\n      padding: this.padding,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nfunction mf(e, t, n, s, r, a) {\n  return Jn(() => {\n    var i;\n    nc(r), rc(a), sc(s), null == n && (n = [1, 1]), null == s && (s = \"valid\"), null == r && (r = \"channelsLast\"), null == a && (a = \"max\"), e = cp(e, r);\n    var o = \"same\" === s ? \"same\" : \"valid\";\n    return i = \"max\" === a ? ia(e, t, n, o) : As(e, t, n, o), \"channelsFirst\" === r && (i = Sn(i, [0, 3, 1, 2])), i;\n  });\n}\n\nfunction bf(e, t, n, s, r, a) {\n  return Jn(() => {\n    var i;\n    nc(r), rc(a), sc(s), null == n && (n = [1, 1, 1]), null == s && (s = \"valid\"), null == r && (r = \"channelsLast\"), null == a && (a = \"max\"), e = hp(e, r);\n    var o = \"same\" === s ? \"same\" : \"valid\";\n    return i = \"max\" === a ? oa(e, t, n, o) : Fs(e, t, n, o), \"channelsFirst\" === r && (i = Sn(i, [0, 4, 1, 2, 3])), i;\n  });\n}\n\ngf.className = \"ZeroPadding2D\", Kn(gf);\n\nclass xf extends mh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = 2), super(e), \"number\" == typeof e.poolSize) this.poolSize = [e.poolSize];else {\n      if (!Array.isArray(e.poolSize) || 1 !== e.poolSize.length || \"number\" != typeof e.poolSize[0]) throw new xu(\"poolSize for 1D convolutional layer must be a number or an Array of a single number, but received \".concat(JSON.stringify(e.poolSize)));\n      this.poolSize = e.poolSize;\n    }\n    if (Lu(this.poolSize, \"poolSize\"), null == e.strides) this.strides = this.poolSize;else if (\"number\" == typeof e.strides) this.strides = [e.strides];else {\n      if (!Array.isArray(e.strides) || 1 !== e.strides.length || \"number\" != typeof e.strides[0]) throw new xu(\"strides for 1D convolutional layer must be a number or an Array of a single number, but received \".concat(JSON.stringify(e.strides)));\n      this.strides = e.strides;\n    }\n    Lu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, sc(this.padding), this.inputSpec = [new hh({\n      ndim: 3\n    })];\n  }\n\n  computeOutputShape(e) {\n    var t = lp((e = ih(e))[1], this.poolSize[0], this.padding, this.strides[0]);\n    return [e[0], t, e[2]];\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      this.invokeCallHook(e, t), e = mc(ah(e), 2);\n      var n = this.poolingFunction(ah(e), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, \"channelsLast\");\n      return di(n, [2]);\n    });\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass yf extends xf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), mf(e, t, n, s, r, \"max\");\n  }\n\n}\n\nyf.className = \"MaxPooling1D\", Kn(yf);\n\nclass kf extends xf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), mf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nkf.className = \"AveragePooling1D\", Kn(kf);\n\nclass wf extends mh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = [2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {\n      if (2 !== e.strides.length) throw new xu(\"If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length \".concat(e.strides.length, \".\"));\n      this.strides = e.strides;\n    } else this.strides = [e.strides, e.strides];\n    Lu(this.poolSize, \"poolSize\"), Lu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, nc(this.dataFormat), sc(this.padding), this.inputSpec = [new hh({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    e = ih(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[2] : e[1],\n        n = \"channelsFirst\" === this.dataFormat ? e[3] : e[2];\n    return t = lp(t, this.poolSize[0], this.padding, this.strides[0]), n = lp(n, this.poolSize[1], this.padding, this.strides[1]), \"channelsFirst\" === this.dataFormat ? [e[0], e[1], t, n] : [e[0], t, n, e[3]];\n  }\n\n  call(e, t) {\n    return Jn(() => (this.invokeCallHook(e, t), this.poolingFunction(ah(e), this.poolSize, this.strides, this.padding, this.dataFormat)));\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass vf extends wf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), mf(e, t, n, s, r, \"max\");\n  }\n\n}\n\nvf.className = \"MaxPooling2D\", Kn(vf);\n\nclass If extends wf {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), mf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nIf.className = \"AveragePooling2D\", Kn(If);\n\nclass $f extends mh {\n  constructor(e) {\n    if (null == e.poolSize && (e.poolSize = [2, 2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {\n      if (3 !== e.strides.length) throw new xu(\"If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length \".concat(e.strides.length, \".\"));\n      this.strides = e.strides;\n    } else this.strides = [e.strides, e.strides, e.strides];\n    Lu(this.poolSize, \"poolSize\"), Lu(this.strides, \"strides\"), this.padding = null == e.padding ? \"valid\" : e.padding, this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, nc(this.dataFormat), sc(this.padding), this.inputSpec = [new hh({\n      ndim: 5\n    })];\n  }\n\n  computeOutputShape(e) {\n    e = ih(e);\n    var t = \"channelsFirst\" === this.dataFormat ? e[2] : e[1],\n        n = \"channelsFirst\" === this.dataFormat ? e[3] : e[2],\n        s = \"channelsFirst\" === this.dataFormat ? e[4] : e[3];\n    return t = lp(t, this.poolSize[0], this.padding, this.strides[0]), n = lp(n, this.poolSize[1], this.padding, this.strides[1]), s = lp(s, this.poolSize[2], this.padding, this.strides[2]), \"channelsFirst\" === this.dataFormat ? [e[0], e[1], t, n, s] : [e[0], t, n, s, e[4]];\n  }\n\n  call(e, t) {\n    return Jn(() => (this.invokeCallHook(e, t), this.poolingFunction(ah(e), this.poolSize, this.strides, this.padding, this.dataFormat)));\n  }\n\n  getConfig() {\n    var e = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass Sf extends $f {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), bf(e, t, n, s, r, \"max\");\n  }\n\n}\n\nSf.className = \"MaxPooling3D\", Kn(Sf);\n\nclass Nf extends $f {\n  constructor(e) {\n    super(e);\n  }\n\n  poolingFunction(e, t, n, s, r) {\n    return nc(r), sc(s), bf(e, t, n, s, r, \"avg\");\n  }\n\n}\n\nNf.className = \"AveragePooling3D\", Kn(Nf);\n\nclass Cf extends mh {\n  constructor(e) {\n    super(e), this.inputSpec = [new hh({\n      ndim: 3\n    })];\n  }\n\n  computeOutputShape(e) {\n    return [e[0], e[2]];\n  }\n\n  call(e, t) {\n    throw new yu();\n  }\n\n}\n\nclass Tf extends Cf {\n  constructor(e) {\n    super(e || {});\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      return ua(t, 1);\n    });\n  }\n\n}\n\nTf.className = \"GlobalAveragePooling1D\", Kn(Tf);\n\nclass Ef extends Cf {\n  constructor(e) {\n    super(e || {});\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      return Vr(t, 1);\n    });\n  }\n\n}\n\nEf.className = \"GlobalMaxPooling1D\", Kn(Ef);\n\nclass Rf extends mh {\n  constructor(e) {\n    super(e), this.dataFormat = null == e.dataFormat ? \"channelsLast\" : e.dataFormat, nc(this.dataFormat), this.inputSpec = [new hh({\n      ndim: 4\n    })];\n  }\n\n  computeOutputShape(e) {\n    return e = e, \"channelsLast\" === this.dataFormat ? [e[0], e[3]] : [e[0], e[1]];\n  }\n\n  call(e, t) {\n    throw new yu();\n  }\n\n  getConfig() {\n    var e = {\n      dataFormat: this.dataFormat\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n}\n\nclass Af extends Rf {\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      return ua(t, \"channelsLast\" === this.dataFormat ? [1, 2] : [2, 3]);\n    });\n  }\n\n}\n\nAf.className = \"GlobalAveragePooling2D\", Kn(Af);\n\nclass Ff extends Rf {\n  call(e, t) {\n    return Jn(() => {\n      var t = ah(e);\n      return Vr(t, \"channelsLast\" === this.dataFormat ? [1, 2] : [2, 3]);\n    });\n  }\n\n}\n\nFf.className = \"GlobalMaxPooling2D\", Kn(Ff);\n\nclass Df extends mh {\n  constructor(e) {\n    super(e), this.layer = e.layer;\n  }\n\n  build(e) {\n    this.built = !0;\n  }\n\n  get trainable() {\n    return null != this.layer && this.layer.trainable;\n  }\n\n  set trainable(e) {\n    null != this.layer && (this.layer.trainable = e);\n  }\n\n  get trainableWeights() {\n    return this.layer.trainableWeights;\n  }\n\n  get nonTrainableWeights() {\n    return this.layer.nonTrainableWeights;\n  }\n\n  get updates() {\n    return this.layer._updates;\n  }\n\n  get losses() {\n    return this.layer.losses;\n  }\n\n  getWeights() {\n    return this.layer.getWeights();\n  }\n\n  setWeights(e) {\n    this.layer.setWeights(e);\n  }\n\n  getConfig() {\n    var e = {\n      layer: {\n        className: this.layer.getClassName(),\n        config: this.layer.getConfig()\n      }\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.layer && this.layer.setFastWeightInitDuringBuild(e);\n  }\n\n  static fromConfig(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var s = Rh(t.layer, n);\n    delete t.layer;\n    var r = {\n      layer: s\n    };\n    return Object.assign(r, t), new e(r);\n  }\n\n}\n\nclass _f extends Df {\n  constructor(e) {\n    super(e), this.supportsMasking = !0;\n  }\n\n  build(e) {\n    if ((e = ih(e)).length < 3) throw new xu(\"TimeDistributed layer expects an input shape >= 3D, but received input shape \".concat(JSON.stringify(e)));\n    this.inputSpec = [{\n      shape: e\n    }];\n    var t = [e[0]].concat(e.slice(2));\n    this.layer.built || (this.layer.build(t), this.layer.built = !0), super.build(e);\n  }\n\n  computeOutputShape(e) {\n    var t = [(e = ih(e))[0]].concat(e.slice(2)),\n        n = this.layer.computeOutputShape(t);\n    return [n[0], e[1]].concat(n.slice(1));\n  }\n\n  call(e, t) {\n    return Jn(() => Np((e, n) => [ah(this.layer.call(e, t)), []], e = ah(e), [], !1, null, null, !1, !0)[1]);\n  }\n\n}\n\n_f.className = \"TimeDistributed\", Kn(_f);\n\nclass Of extends Df {\n  constructor(e) {\n    super(e);\n    var t = e.layer.getConfig(),\n        n = {};\n    n.className = e.layer.getClassName(), n.config = t, this.forwardLayer = Rh(n), t.goBackwards = !0 !== t.goBackwards;\n    var s = {};\n    if (s.className = e.layer.getClassName(), s.config = t, this.backwardLayer = Rh(s), this.forwardLayer.name = \"forward_\" + this.forwardLayer.name, this.backwardLayer.name = \"backward_\" + this.backwardLayer.name, this.mergeMode = void 0 === e.mergeMode ? \"concat\" : e.mergeMode, Ou(ec, \"BidirectionalMergeMode\", this.mergeMode), e.weights) throw new yu(\"weights support is not implemented for Bidirectional layer yet.\");\n    this._stateful = e.layer.stateful, this.returnSequences = e.layer.returnSequences, this.returnState = e.layer.returnState, this.supportsMasking = !0, this._trainable = !0, this.inputSpec = e.layer.inputSpec, this.numConstants = null;\n  }\n\n  get trainable() {\n    return this._trainable;\n  }\n\n  set trainable(e) {\n    this._trainable = e, null != this.forwardLayer && (this.forwardLayer.trainable = e), null != this.backwardLayer && (this.backwardLayer.trainable = e);\n  }\n\n  getWeights() {\n    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());\n  }\n\n  setWeights(e) {\n    var t = Math.floor(e.length / 2);\n    this.forwardLayer.setWeights(e.slice(0, t)), this.backwardLayer.setWeights(e.slice(t));\n  }\n\n  computeOutputShape(e) {\n    var t,\n        n,\n        s,\n        r = this.forwardLayer.computeOutputShape(e);\n    return Array.isArray(r) && Array.isArray(r[0]) || (r = [r]), r = r, this.returnState ? (s = r.slice(1), t = r[0]) : t = r[0], t = t, \"concat\" === this.mergeMode ? (t[t.length - 1] *= 2, n = [t]) : n = null == this.mergeMode ? [t, t.slice()] : [t], this.returnState ? null == this.mergeMode ? n.concat(s).concat(s.slice()) : [t].concat(s).concat(s.slice()) : $u(n);\n  }\n\n  apply(e, t) {\n    var n = null == t ? null : t.initialState,\n        s = null == t ? null : t.constants;\n    null == t && (t = {});\n    var r = Sp(e, n, s, this.numConstants);\n    if (e = r.inputs, n = r.initialState, s = r.constants, Array.isArray(e) && (n = e.slice(1), e = e[0]), (null == n || 0 === n.length) && null == s) return super.apply(e, t);\n    var a = [],\n        i = [];\n\n    if (null != n) {\n      var _e243 = n.length;\n      if (_e243 % 2 > 0) throw new xu(\"When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.\");\n      t.initialState = n, a.push(...n);\n\n      var _s122 = n.map(e => new hh({\n        shape: e.shape\n      }));\n\n      this.forwardLayer.stateSpec = _s122.slice(0, _e243 / 2), this.backwardLayer.stateSpec = _s122.slice(_e243 / 2), i.push(..._s122);\n    }\n\n    if (null != s) throw new yu(\"Support for constants in Bidirectional layers is not implemented yet.\");\n    var o = a[0] instanceof dh;\n\n    for (var _e244 of a) {\n      if (_e244 instanceof dh !== o) throw new xu(\"The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors\");\n    }\n\n    if (o) {\n      var _n143 = [e].concat(a),\n          _s123 = this.inputSpec.concat(i),\n          _r84 = this.inputSpec;\n\n      this.inputSpec = _s123;\n\n      var _o29 = super.apply(_n143, t);\n\n      return this.inputSpec = _r84, _o29;\n    }\n\n    return super.apply(e, t);\n  }\n\n  call(e, t) {\n    return Jn(() => {\n      var n = t.initialState;\n      var s, r, a, i;\n      if (null == n) s = this.forwardLayer.call(e, t), r = this.backwardLayer.call(e, t);else {\n        var _a64 = n.slice(0, n.length / 2),\n            _i36 = n.slice(n.length / 2);\n\n        s = this.forwardLayer.call(e, Object.assign(t, {\n          initialState: _a64\n        })), r = this.backwardLayer.call(e, Object.assign(t, {\n          initialState: _i36\n        }));\n      }\n      return this.returnState && (Array.isArray(s) && (a = s.slice(1).concat(r.slice(1))), s = s[0], r = r[0]), this.returnSequences && (r = Ha(r, 1)), \"concat\" === this.mergeMode ? i = kc([s, r]) : \"sum\" === this.mergeMode ? i = ts(s, r) : \"ave\" === this.mergeMode ? i = rs(.5, ts(s, r)) : \"mul\" === this.mergeMode ? i = rs(s, r) : null == this.mergeMode && (i = [s, r]), this.returnState ? null == this.mergeMode ? i.concat(a) : [i].concat(a) : i;\n    });\n  }\n\n  resetStates(e) {\n    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();\n  }\n\n  build(e) {\n    ic(this.forwardLayer.name, () => {\n      this.forwardLayer.build(e);\n    }), ic(this.backwardLayer.name, () => {\n      this.backwardLayer.build(e);\n    }), this.built = !0;\n  }\n\n  computeMask(e, t) {\n    var n;\n\n    if (Array.isArray(t) && (t = t[0]), n = this.returnSequences ? null == this.mergeMode ? [t, t] : t : null == this.mergeMode ? [null, null] : null, this.returnState) {\n      var _e245 = this.forwardLayer.states.map(e => null);\n\n      return Array.isArray(n) ? n.concat(_e245).concat(_e245) : [n].concat(_e245).concat(_e245);\n    }\n\n    return n;\n  }\n\n  get trainableWeights() {\n    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);\n  }\n\n  get nonTrainableWeights() {\n    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);\n  }\n\n  setFastWeightInitDuringBuild(e) {\n    super.setFastWeightInitDuringBuild(e), null != this.forwardLayer && this.forwardLayer.setFastWeightInitDuringBuild(e), null != this.backwardLayer && this.backwardLayer.setFastWeightInitDuringBuild(e);\n  }\n\n  getConfig() {\n    var e = {\n      mergeMode: this.mergeMode\n    },\n        t = super.getConfig();\n    return Object.assign(e, t), e;\n  }\n\n  static fromConfig(e, t) {\n    var n = Rh(t.layer);\n    if (delete t.layer, null != t.numConstants) throw new yu(\"Deserialization of a Bidirectional layer with numConstants present is not supported yet.\");\n    var s = t;\n    return s.layer = n, new e(s);\n  }\n\n}\n\nfunction Mf(e) {\n  return new wp(e);\n}\n\nfunction Lf(e) {\n  return new Vp(e);\n}\n\nfunction zf(e) {\n  return new yf(e);\n}\n\nfunction Bf(e, t) {\n  Array.isArray(e) || (e = [e]), e.forEach(e => {\n    null != e && l(\"complex64\" !== e.dtype, () => \"\".concat(t, \" does not support complex64 tensors in the CPU backend.\"));\n  });\n}\n\nOf.className = \"Bidirectional\", Kn(Of), function (e) {\n  e[e.DT_INVALID = 0] = \"DT_INVALID\", e[e.DT_FLOAT = 1] = \"DT_FLOAT\", e[e.DT_DOUBLE = 2] = \"DT_DOUBLE\", e[e.DT_INT32 = 3] = \"DT_INT32\", e[e.DT_UINT8 = 4] = \"DT_UINT8\", e[e.DT_INT16 = 5] = \"DT_INT16\", e[e.DT_INT8 = 6] = \"DT_INT8\", e[e.DT_STRING = 7] = \"DT_STRING\", e[e.DT_COMPLEX64 = 8] = \"DT_COMPLEX64\", e[e.DT_INT64 = 9] = \"DT_INT64\", e[e.DT_BOOL = 10] = \"DT_BOOL\", e[e.DT_QINT8 = 11] = \"DT_QINT8\", e[e.DT_QUINT8 = 12] = \"DT_QUINT8\", e[e.DT_QINT32 = 13] = \"DT_QINT32\", e[e.DT_BFLOAT16 = 14] = \"DT_BFLOAT16\", e[e.DT_FLOAT_REF = 101] = \"DT_FLOAT_REF\", e[e.DT_DOUBLE_REF = 102] = \"DT_DOUBLE_REF\", e[e.DT_INT32_REF = 103] = \"DT_INT32_REF\", e[e.DT_UINT8_REF = 104] = \"DT_UINT8_REF\", e[e.DT_INT16_REF = 105] = \"DT_INT16_REF\", e[e.DT_INT8_REF = 106] = \"DT_INT8_REF\", e[e.DT_STRING_REF = 107] = \"DT_STRING_REF\", e[e.DT_COMPLEX64_REF = 108] = \"DT_COMPLEX64_REF\", e[e.DT_INT64_REF = 109] = \"DT_INT64_REF\", e[e.DT_BOOL_REF = 110] = \"DT_BOOL_REF\", e[e.DT_QINT8_REF = 111] = \"DT_QINT8_REF\", e[e.DT_QUINT8_REF = 112] = \"DT_QUINT8_REF\", e[e.DT_QINT32_REF = 113] = \"DT_QINT32_REF\", e[e.DT_BFLOAT16_REF = 114] = \"DT_BFLOAT16_REF\";\n}(Lp || (Lp = {})), function (e) {\n  var t;\n  (t = e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}))[t.LEGACY = 0] = \"LEGACY\", t[t.V1 = 1] = \"V1\", t[t.V2 = 2] = \"V2\";\n}(zp || (zp = {})), function (e) {\n  e[e.FAIL = 0] = \"FAIL\", e[e.SHORTEST = 1] = \"SHORTEST\", e[e.LONGEST = 2] = \"LONGEST\";\n}(Bp || (Bp = {}));\nvar Pf = $i;\n\nclass Wf extends n {\n  constructor() {\n    super(), this.blockSize = 48, this.firstUse = !0, this.data = new t(this, Xn());\n  }\n\n  nextDataId() {\n    return Wf.nextDataId++;\n  }\n\n  write(e, t, n) {\n    this.firstUse && (this.firstUse = !1, G().get(\"IS_NODE\") && W(\"\\n============================\\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\\n============================\"));\n    var s = {\n      id: this.nextDataId()\n    };\n    return this.data.set(s, {\n      values: e,\n      dtype: n,\n      refCount: 1\n    }), s;\n  }\n\n  makeTensorInfo(e, t, n) {\n    var s;\n\n    if (\"string\" === t && null != n && n.length > 0 && N(n[0])) {\n      var _r85 = n.map(e => He(e));\n\n      s = this.write(_r85, e, t);\n    } else s = this.write(n, e, t);\n\n    return {\n      dataId: s,\n      shape: e,\n      dtype: t\n    };\n  }\n\n  refCount(e) {\n    return this.data.has(e) ? this.data.get(e).refCount : 0;\n  }\n\n  incRef(e) {\n    this.data.get(e).refCount++;\n  }\n\n  decRef(e) {\n    this.data.has(e) && this.data.get(e).refCount--;\n  }\n\n  move(e, t, n, s, r) {\n    this.data.set(e, {\n      values: t,\n      dtype: s,\n      refCount: r\n    });\n  }\n\n  numDataIds() {\n    return this.data.numDataIds();\n  }\n\n  read(e) {\n    var _this69 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this69.readSync(e);\n    })();\n  }\n\n  readSync(e) {\n    var {\n      dtype: t,\n      complexTensorInfos: n\n    } = this.data.get(e);\n    return \"complex64\" === t ? Lo(this.readSync(n.real.dataId), this.readSync(n.imag.dataId)) : this.data.get(e).values;\n  }\n\n  bufferSync(e) {\n    var t = this.readSync(e.dataId);\n    var n = t;\n    if (\"string\" === e.dtype) try {\n      n = t.map(e => qe(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode encoded string bytes into utf-8\");\n    }\n    return pn(e.shape, e.dtype, n);\n  }\n\n  makeOutput(e, t, n) {\n    var s = this.write(e, t, n);\n    return Xn().makeTensorFromDataId(s, t, n, this);\n  }\n\n  disposeData(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n\n    if (this.data.has(e)) {\n      if (this.data.get(e).refCount--, !t && this.data.get(e).refCount > 0) return !1;\n      var {\n        complexTensorInfos: _n144\n      } = this.data.get(e);\n      null != _n144 && (this.disposeData(_n144.real.dataId, !0), this.disposeData(_n144.imag.dataId, !0)), this.data.delete(e);\n    }\n\n    return !0;\n  }\n\n  disposeIntermediateTensorInfo(e) {\n    this.disposeData(e.dataId);\n  }\n\n  time(e) {\n    return _asyncToGenerator(function* () {\n      var t = Ge();\n      return e(), {\n        kernelMs: Ge() - t\n      };\n    })();\n  }\n\n  memory() {\n    return {\n      unreliable: !0,\n      reasons: [\"The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less.\"]\n    };\n  }\n\n  where(e) {\n    Bf([e], \"where\");\n    var t = this.readSync(e.dataId);\n    return Pf(e.shape, t);\n  }\n\n  dispose() {}\n\n  floatPrecision() {\n    return 32;\n  }\n\n  epsilon() {\n    return super.epsilon();\n  }\n\n}\n\nfunction Uf(e) {\n  var t = new Float32Array(e.length);\n\n  for (var _n145 = 0; _n145 < e.length; ++_n145) {\n    t[_n145] = Math.abs(e[_n145]);\n  }\n\n  return t;\n}\n\nWf.nextDataId = 0;\nvar Vf = {\n  kernelName: \"Abs\",\n  backendName: \"cpu\",\n  kernelFunc: e => {\n    var {\n      x: t\n    } = e.inputs,\n        n = e.backend;\n    Bf(t, \"abs\");\n    var s = new Float32Array(d(t.shape));\n    return s = Uf(n.data.get(t.dataId).values), n.makeOutput(s, t.shape, \"float32\");\n  }\n};\n\nfunction Gf(e) {\n  return (t, n, s, r, a) => {\n    var i = hr(t, n),\n        o = i.length,\n        l = A(i),\n        u = w(a, d(i)),\n        c = t.length,\n        h = n.length,\n        p = A(t),\n        f = A(n),\n        g = ur(t, i),\n        m = ur(n, i);\n    if (g.length + m.length === 0) for (var _t230 = 0; _t230 < u.length; ++_t230) {\n      u[_t230] = e(s[_t230 % s.length], r[_t230 % r.length]);\n    } else {\n      var _loop25 = function _loop25(_t231) {\n        var n = B(_t231, o, l),\n            a = n.slice(-c);\n        g.forEach(e => a[e] = 0);\n        var i = z(a, c, p),\n            d = n.slice(-h);\n        m.forEach(e => d[e] = 0);\n        var b = z(d, h, f);\n        u[_t231] = e(s[i], r[b]);\n      };\n\n      for (var _t231 = 0; _t231 < u.length; ++_t231) {\n        _loop25(_t231);\n      }\n    }\n    return [u, i];\n  };\n}\n\nfunction Hf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    real: s,\n    imag: r\n  } = t,\n      a = n.data.get(s.dataId).values,\n      i = n.data.get(r.dataId).values,\n      o = n.makeTensorInfo(s.shape, \"complex64\");\n  return n.data.get(o.dataId).complexTensorInfos = {\n    real: n.makeTensorInfo(s.shape, \"float32\", a),\n    imag: n.makeTensorInfo(r.shape, \"float32\", i)\n  }, o;\n}\n\nvar qf = {\n  kernelName: \"Complex\",\n  backendName: \"cpu\",\n  kernelFunc: Hf\n};\n\nfunction jf(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"float32\";\n  if (\"complex64\" === n) return Hf({\n    inputs: {\n      real: jf(e, t, \"float32\"),\n      imag: jf(e, t, \"float32\")\n    },\n    backend: e\n  });\n  var s = O(d(t), n);\n  return e.makeTensorInfo(t, n, s);\n}\n\nfunction Kf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  return n.incRef(s.dataId), {\n    dataId: s.dataId,\n    shape: s.shape,\n    dtype: s.dtype\n  };\n}\n\nvar Xf = {\n  kernelName: \"Identity\",\n  backendName: \"cpu\",\n  kernelFunc: Kf\n};\n\nfunction Yf(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t,\n      r = n.data.get(s.dataId).complexTensorInfos.real,\n      a = n.data.get(r.dataId).values;\n  return n.makeTensorInfo(r.shape, r.dtype, a);\n}\n\nvar Jf = {\n  kernelName: \"Real\",\n  backendName: \"cpu\",\n  kernelFunc: Yf\n};\n\nfunction Zf(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    dtype: a\n  } = s;\n\n  if (\"complex64\" === a) {\n    if (\"complex64\" === r.dtype) return Kf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n\n    var _e246 = jf(n, r.shape, r.dtype),\n        _t232 = Zf({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        dtype: \"float32\"\n      }\n    }),\n        _s124 = Hf({\n      inputs: {\n        real: _t232,\n        imag: _e246\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e246), n.disposeIntermediateTensorInfo(_t232), _s124;\n  }\n\n  if (\"complex64\" === r.dtype) {\n    var _e247 = Yf({\n      inputs: {\n        input: r\n      },\n      backend: n\n    }),\n        _t233 = Zf({\n      inputs: {\n        x: _e247\n      },\n      backend: n,\n      attrs: {\n        dtype: a\n      }\n    });\n\n    return n.disposeIntermediateTensorInfo(_e247), _t233;\n  }\n\n  if (!I(r.dtype, a)) {\n    var _e248 = Kf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n\n    return {\n      dataId: _e248.dataId,\n      shape: _e248.shape,\n      dtype: a\n    };\n  }\n\n  if (\"int32\" === a) {\n    var _e249 = n.data.get(r.dataId).values,\n        _t234 = Int32Array.from(_e249);\n\n    return n.makeTensorInfo(r.shape, \"int32\", _t234);\n  }\n\n  if (\"bool\" === a) {\n    var _e250 = n.data.get(r.dataId).values,\n        _t235 = Ve([0], r.dtype),\n        [_s125, _a65] = Gf((e, t) => e !== t ? 1 : 0)(r.shape, [], _e250, _t235, \"bool\");\n\n    return n.makeTensorInfo(_a65, \"bool\", _s125);\n  }\n\n  throw new Error(\"Error in Cast: failed to cast \".concat(r.dtype, \" to \").concat(a));\n}\n\nvar Qf = {\n  kernelName: \"Cast\",\n  backendName: \"cpu\",\n  kernelFunc: Zf\n};\n\nfunction eg(e, t, n, s) {\n  return null == n ? _ref9 => {\n    var {\n      inputs: n,\n      backend: r\n    } = _ref9;\n    var {\n      a,\n      b: i\n    } = n,\n        o = r;\n    Bf([a, i], e);\n    var l = o.data.get(a.dataId).values,\n        u = o.data.get(i.dataId).values,\n        c = \"string\" === a.dtype ? nl(l) : l,\n        h = \"string\" === a.dtype ? nl(u) : u,\n        d = s || a.dtype,\n        [p, f] = t(a.shape, i.shape, c, h, d);\n    return o.makeTensorInfo(f, d, p);\n  } : _ref10 => {\n    var {\n      inputs: e,\n      backend: r\n    } = _ref10;\n    var {\n      a,\n      b: i\n    } = e,\n        o = r;\n\n    if (\"complex64\" === a.dtype || \"complex64\" === i.dtype) {\n      var _e251 = Zf({\n        inputs: {\n          x: a\n        },\n        backend: o,\n        attrs: {\n          dtype: \"complex64\"\n        }\n      }),\n          _t236 = o.data.get(_e251.dataId),\n          _s126 = _t236.complexTensorInfos.imag,\n          _r86 = o.data.get(_t236.complexTensorInfos.real.dataId).values,\n          _l18 = o.data.get(_s126.dataId).values,\n          _u11 = Zf({\n        inputs: {\n          x: i\n        },\n        backend: o,\n        attrs: {\n          dtype: \"complex64\"\n        }\n      }),\n          _c11 = o.data.get(_u11.dataId),\n          _h8 = _c11.complexTensorInfos.imag,\n          _d8 = o.data.get(_c11.complexTensorInfos.real.dataId).values,\n          _p7 = o.data.get(_h8.dataId).values,\n          [_f6, _g8, _m7] = n(a.shape, i.shape, _r86, _l18, _d8, _p7),\n          _b6 = o.makeTensorInfo(_m7, \"float32\", _f6),\n          _x50 = o.makeTensorInfo(_m7, \"float32\", _g8),\n          _y6 = Hf({\n        inputs: {\n          real: _b6,\n          imag: _x50\n        },\n        backend: o\n      });\n\n      return o.disposeIntermediateTensorInfo(_e251), o.disposeIntermediateTensorInfo(_u11), o.disposeIntermediateTensorInfo(_b6), o.disposeIntermediateTensorInfo(_x50), _y6;\n    }\n\n    {\n      var _e252 = o.data.get(a.dataId).values,\n          _n146 = o.data.get(i.dataId).values,\n          _r87 = s || a.dtype,\n          [_l19, _u12] = t(a.shape, i.shape, _e252, _n146, _r87);\n\n      return o.makeTensorInfo(_u12, _r87, _l19);\n    }\n  };\n}\n\nfunction tg(e) {\n  return (t, n, s, r, a, i) => {\n    var o = hr(t, n),\n        l = d(o),\n        u = o.length,\n        c = A(o),\n        h = w(\"float32\", l),\n        p = w(\"float32\", l),\n        f = ur(t, o),\n        g = ur(n, o),\n        m = Lo(s, r),\n        b = Lo(a, i),\n        x = t.length,\n        y = A(t),\n        k = n.length,\n        v = A(n);\n    if (f.length + g.length === 0) for (var _t237 = 0; _t237 < h.length; _t237++) {\n      var _n147 = _t237 % m.length,\n          _s127 = _t237 % b.length,\n          _r88 = e(m[2 * _n147], m[2 * _n147 + 1], b[2 * _s127], b[2 * _s127 + 1]);\n\n      h[_t237] = _r88.real, p[_t237] = _r88.imag;\n    } else {\n      var _loop26 = function _loop26(_t238) {\n        var n = B(_t238, u, c),\n            s = n.slice(-x);\n        f.forEach(e => s[e] = 0);\n        var r = z(s, x, y),\n            a = n.slice(-k);\n        g.forEach(e => a[e] = 0);\n        var i = z(a, k, v),\n            o = e(m[2 * r], m[2 * r + 1], b[2 * i], b[2 * i + 1]);\n        h[_t238] = o.real, p[_t238] = o.imag;\n      };\n\n      for (var _t238 = 0; _t238 < h.length; _t238++) {\n        _loop26(_t238);\n      }\n    }\n    return [h, p, o];\n  };\n}\n\nvar ng = Gf((e, t) => e + t),\n    sg = eg(\"Add\", ng, tg((e, t, n, s) => ({\n  real: e + n,\n  imag: t + s\n}))),\n    rg = {\n  kernelName: \"Add\",\n  backendName: \"cpu\",\n  kernelFunc: sg\n};\n\nfunction ag(e, t, n, s, r) {\n  var a = d(s),\n      i = O(r, n);\n\n  for (var _n148 = 0; _n148 < e.length; _n148++) {\n    var _s128 = e[_n148];\n    if (_s128 < 0) throw new Error(\"Input x must be non-negative!\");\n    _s128 >= r || (i[_s128] += a > 0 ? t[_n148] : 1);\n  }\n\n  return i;\n}\n\nfunction ig(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n  var r = e.shape[0],\n      a = e.shape[1],\n      i = pn([r, n], t.dtype);\n\n  for (var _o30 = 0; _o30 < r; _o30++) {\n    for (var _r89 = 0; _r89 < a; _r89++) {\n      var _a66 = e.get(_o30, _r89);\n\n      if (_a66 < 0) throw new Error(\"Input x must be non-negative!\");\n      _a66 >= n || i.set(s ? 1 : t.size > 0 ? i.get(_o30, _a66) + t.get(_o30, _r89) : i.get(_o30, _a66) + 1, _o30, _a66);\n    }\n  }\n\n  return i;\n}\n\nfunction og(e) {\n  return (t, n, s) => {\n    var r = w(n, t.length);\n\n    for (var _n149 = 0; _n149 < t.length; ++_n149) {\n      r[_n149] = e(t[_n149], s);\n    }\n\n    return r;\n  };\n}\n\nfunction lg(e, t, n) {\n  return _ref11 => {\n    var {\n      inputs: s,\n      attrs: r,\n      backend: a\n    } = _ref11;\n    var {\n      x: i\n    } = s;\n    if (Bf(i, e), \"string\" === i.dtype || \"string\" === n) throw new Error(\"unaryKernelFunc does not support string input/output\");\n    var o = a,\n        l = o.data.get(i.dataId).values,\n        u = d(i.shape),\n        c = n || i.dtype,\n        h = v(c, u);\n\n    for (var _e253 = 0; _e253 < u; ++_e253) {\n      h[_e253] = t(l[_e253], r);\n    }\n\n    return o.makeTensorInfo(i.shape, c, h);\n  };\n}\n\nfunction ug(e, t, n) {\n  return _ref12 => {\n    var {\n      inputs: s,\n      attrs: r,\n      backend: a\n    } = _ref12;\n    var {\n      x: i\n    } = s;\n    if (Bf(i, e), \"string\" === i.dtype || \"string\" === n) throw new Error(\"unaryKernelFunc does not support string input/output\");\n    var o = a,\n        l = o.data.get(i.dataId).values,\n        u = n || i.dtype,\n        c = t(l, u, r);\n    return o.makeTensorInfo(i.shape, u, c);\n  };\n}\n\nvar cg = og(e => Math.ceil(e)),\n    hg = {\n  kernelName: \"Ceil\",\n  backendName: \"cpu\",\n  kernelFunc: ug(\"Ceil\", cg)\n};\n\nfunction dg(e, t, n, s) {\n  var r = v(n, d(t));\n\n  if (s && \"string\" !== n) {\n    var _t239 = 0;\n    e.forEach(e => {\n      var n = d(e.shape);\n      r.set(e.vals, _t239), _t239 += n;\n    });\n  } else {\n    var _s129 = 0;\n    e.forEach(e => {\n      var a = \"string\" === n ? nl(e.vals) : e.vals;\n      var i = 0;\n\n      for (var _n150 = 0; _n150 < e.shape[0]; ++_n150) {\n        var _o31 = _n150 * t[1] + _s129;\n\n        for (var _t240 = 0; _t240 < e.shape[1]; ++_t240) {\n          r[_o31 + _t240] = a[i++];\n        }\n      }\n\n      _s129 += e.shape[1];\n    });\n  }\n\n  return r;\n}\n\nvar pg = Gf((e, t) => e === t ? 1 : 0),\n    fg = eg(\"Equal\", pg, null, \"bool\"),\n    gg = {\n  kernelName: \"Equal\",\n  backendName: \"cpu\",\n  kernelFunc: fg\n},\n    mg = og(e => Math.exp(e)),\n    bg = ug(\"Exp\", mg),\n    xg = {\n  kernelName: \"Exp\",\n  backendName: \"cpu\",\n  kernelFunc: bg\n},\n    yg = og(e => Math.expm1(e)),\n    kg = {\n  kernelName: \"Expm1\",\n  backendName: \"cpu\",\n  kernelFunc: ug(\"Expm1\", yg)\n},\n    wg = og(e => Math.floor(e)),\n    vg = {\n  kernelName: \"Floor\",\n  backendName: \"cpu\",\n  kernelFunc: ug(\"Floor\", wg)\n};\n\nfunction Ig(e, t, n, s, r, a, i, o, l) {\n  var u = pn([s, a], n);\n\n  for (var _n151 = 0; _n151 < s; _n151++) {\n    var _s130 = [];\n    var _c12 = 0;\n\n    for (var _t241 = 0; _t241 < r; _t241++) {\n      var _a67 = e[_n151 * r + _t241];\n      _c12 += _a67 * i[_t241], _s130.push(_a67);\n    }\n\n    if (_c12 < 0 || _c12 >= l / a) throw new Error(\"Invalid indices: \".concat(_s130, \" does not index into \").concat(o));\n\n    for (var _e254 = 0; _e254 < a; _e254++) {\n      u.values[_n151 * a + _e254] = t.get(...t.indexToLoc(_c12 * a + _e254));\n    }\n  }\n\n  return u;\n}\n\nfunction $g(e, t, n) {\n  var s = pn(n, e.dtype);\n\n  for (var _n152 = 0; _n152 < s.size; ++_n152) {\n    var _r90 = s.indexToLoc(_n152).slice(),\n        _a68 = t.locToIndex([_r90[0], _r90[2]]);\n\n    _r90[2] = t.values[_a68];\n\n    var _i37 = e.locToIndex(_r90);\n\n    s.values[_n152] = e.values[_i37];\n  }\n\n  return s;\n}\n\nvar Sg = Gf((e, t) => e > t ? 1 : 0),\n    Ng = {\n  kernelName: \"Greater\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Greater\", Sg, null, \"bool\")\n},\n    Cg = Gf((e, t) => e >= t ? 1 : 0),\n    Tg = {\n  kernelName: \"GreaterEqual\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"GreaterEqual\", Cg, null, \"bool\")\n},\n    Eg = Gf((e, t) => e < t ? 1 : 0),\n    Rg = {\n  kernelName: \"Less\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Less\", Eg, null, \"bool\")\n},\n    Ag = Gf((e, t) => e <= t ? 1 : 0),\n    Fg = {\n  kernelName: \"LessEqual\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"LessEqual\", Ag, null, \"bool\")\n};\n\nfunction Dg(e, t, n) {\n  var s = (t - e) / (n - 1),\n      r = O(n, \"float32\");\n  r[0] = e;\n\n  for (var _e255 = 1; _e255 < r.length; _e255++) {\n    r[_e255] = r[_e255 - 1] + s;\n  }\n\n  return r;\n}\n\nvar _g = og(e => Math.log(e)),\n    Og = {\n  kernelName: \"Log\",\n  backendName: \"cpu\",\n  kernelFunc: ug(\"Log\", _g)\n};\n\nfunction Mg(e, t, n, s) {\n  var r = w(s, d(n));\n\n  for (var _n153 = 0; _n153 < r.length; ++_n153) {\n    var _s131 = _n153 * t;\n\n    var _a69 = e[_s131];\n\n    for (var _n154 = 0; _n154 < t; ++_n154) {\n      var _t242 = e[_s131 + _n154];\n      (Number.isNaN(_t242) || _t242 > _a69) && (_a69 = _t242);\n    }\n\n    r[_n153] = _a69;\n  }\n\n  return r;\n}\n\nvar Lg = Gf((e, t) => Math.max(e, t)),\n    zg = {\n  kernelName: \"Maximum\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Maximum\", Lg)\n},\n    Bg = Gf((e, t) => Math.min(e, t)),\n    Pg = {\n  kernelName: \"Minimum\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Minimum\", Bg)\n},\n    Wg = Gf((e, t) => e * t),\n    Ug = tg((e, t, n, s) => ({\n  real: e * n - t * s,\n  imag: e * s + t * n\n})),\n    Vg = eg(\"Multiply\", Wg, Ug),\n    Gg = {\n  kernelName: \"Multiply\",\n  backendName: \"cpu\",\n  kernelFunc: Vg\n};\n\nfunction Hg(e, t, n) {\n  var s = Ue(-1, n);\n  return Wg([], t, s, e, n);\n}\n\nvar qg = {\n  kernelName: \"Neg\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n    Bf(s, \"neg\");\n    var r = n.data.get(s.dataId).values,\n        [a, i] = Hg(r, s.shape, s.dtype);\n    return n.makeTensorInfo(i, s.dtype, a);\n  }\n},\n    jg = Gf((e, t) => e !== t ? 1 : 0),\n    Kg = {\n  kernelName: \"NotEqual\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"NotEqual\", jg, null, \"bool\")\n};\n\nfunction Xg(e, t, n, s, r) {\n  var a = t.length,\n      i = d(t),\n      o = A(t),\n      l = A(r),\n      u = w(n, d(r));\n\n  for (var _t243 = 0; _t243 < i; ++_t243) {\n    var _n155 = B(_t243, a, o),\n        _r91 = new Array(_n155.length);\n\n    for (var _e256 = 0; _e256 < _r91.length; _e256++) {\n      _r91[_e256] = _n155[s[_e256]];\n    }\n\n    u[z(_r91, a, l)] = e[_t243];\n  }\n\n  return u;\n}\n\nfunction Yg(e) {\n  var {\n    inputs: t,\n    attrs: n,\n    backend: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    perm: a\n  } = n;\n  Bf(r, \"transpose\");\n  var i = new Array(r.shape.length);\n\n  for (var _e257 = 0; _e257 < i.length; _e257++) {\n    i[_e257] = r.shape[a[_e257]];\n  }\n\n  var o = Xg(s.data.get(r.dataId).values, r.shape, r.dtype, a, i);\n  return {\n    dataId: s.write(o, i, r.dtype),\n    shape: i,\n    dtype: r.dtype\n  };\n}\n\nvar Jg = {\n  kernelName: \"Transpose\",\n  backendName: \"cpu\",\n  kernelFunc: Yg\n};\n\nfunction Zg(e, t, n, s) {\n  var [r, a] = Xr(e, s),\n      i = pt(t, \"int32\"),\n      o = O(d(r), i),\n      l = d(a);\n\n  for (var _e258 = 0; _e258 < o.length; ++_e258) {\n    var _t244 = _e258 * l;\n\n    var _s132 = 1;\n\n    for (var _e259 = 0; _e259 < l; ++_e259) {\n      _s132 *= n[_t244 + _e259];\n    }\n\n    o[_e258] = _s132;\n  }\n\n  return {\n    outVals: o,\n    outShape: r,\n    outDtype: i\n  };\n}\n\nvar Qg = {\n  kernelName: \"Prod\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    Bf(r, \"prod\");\n    var o = r.shape.length,\n        l = y(a, r.shape),\n        u = Zr(l, o);\n    var c = l,\n        h = r;\n    var d = [];\n    null != u && (h = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), d.push(h), c = ea(c.length, o));\n    var p = n.data.get(h.dataId).values,\n        {\n      outVals: f,\n      outShape: g,\n      outDtype: m\n    } = Zg(h.shape, h.dtype, p, c);\n    var b = g;\n    return i && (b = Yr(g, l)), d.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(b, m, f);\n  }\n};\n\nfunction em(e, t, n, s) {\n  if (e === t || e < t && n < 0 || t < e && n > 1) return O(0, s);\n  var r = O(Math.abs(Math.ceil((t - e) / n)), s);\n  t < e && 1 === n && (n = -1), r[0] = e;\n\n  for (var _e260 = 1; _e260 < r.length; _e260++) {\n    r[_e260] = r[_e260 - 1] + n;\n  }\n\n  return r;\n}\n\nvar tm = og(e => 1 / Math.sqrt(e)),\n    nm = {\n  kernelName: \"Rsqrt\",\n  backendName: \"cpu\",\n  kernelFunc: ug(\"Rsqrt\", tm)\n},\n    sm = og(e => 1 / (1 + Math.exp(-e))),\n    rm = lg(\"Sigmoid\", e => 1 / (1 + Math.exp(-e))),\n    am = {\n  kernelName: \"Sigmoid\",\n  backendName: \"cpu\",\n  kernelFunc: rm\n};\n\nfunction im(e, t, n, s, r) {\n  var a = Wn(s, t, n),\n      i = d(n),\n      o = A(s);\n\n  if (a) {\n    var _n156 = Un(t, o);\n\n    return \"string\" === r ? e.slice(_n156, _n156 + i) : e.subarray(_n156, _n156 + i);\n  }\n\n  var l = pn(s, r, \"string\" === r ? nl(e) : e),\n      u = pn(n, r);\n\n  for (var _e261 = 0; _e261 < u.size; ++_e261) {\n    var _n157 = u.indexToLoc(_e261),\n        _s133 = _n157.map((e, n) => e + t[n]);\n\n    u.set(l.get(..._s133), ..._n157);\n  }\n\n  return \"string\" === r ? sl(u.values) : u.values;\n}\n\nfunction om(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    begin: a,\n    size: i\n  } = s;\n  Bf(r, \"slice\");\n  var [o, l] = Vn(r, a, i);\n  En(r, o, l);\n  var u = im(n.data.get(r.dataId).values, o, l, r.shape, r.dtype);\n  return n.makeTensorInfo(l, r.dtype, u);\n}\n\nvar lm = {\n  kernelName: \"Slice\",\n  backendName: \"cpu\",\n  kernelFunc: om\n};\n\nfunction um(e, t, n, s, r, a, i) {\n  var o = t[0],\n      l = a[0],\n      u = new Array(l),\n      c = new Array(o),\n      h = t[1];\n\n  if (0 === l) {\n    if (0 !== o) throw new Error(\"Received SparseTensor with denseShape[0] = 0 but\\n         indices.shape[0] = \".concat(o));\n    return [v(n, 0), [0, h], v(r, 0), u, c];\n  }\n\n  var d = !0,\n      p = 0;\n  var f = new Array(l).fill(0);\n\n  for (var _t245 = 0; _t245 < o; ++_t245) {\n    var _n158 = e[_t245 * h];\n    if (_n158 < 0) throw new Error(\"indices(\".concat(_t245, \", 0) is invalid: \").concat(_n158, \" < 0\"));\n    if (_n158 >= l) throw new Error(\"indices(\".concat(_t245, \", 0) is invalid: \").concat(_n158, \" >= \").concat(l));\n    ++f[_n158], d = d && _n158 >= p, p = _n158;\n  }\n\n  var g = !0;\n\n  for (var _e262 = 0; _e262 < l; ++_e262) {\n    var _t246 = 0 === f[_e262];\n\n    u[_e262] = _t246, g = g && !_t246, f[_e262] = Math.max(f[_e262], 1), _e262 > 0 && (f[_e262] += f[_e262 - 1]);\n  }\n\n  if (g && d) {\n    var _t247 = e,\n        _n159 = s;\n\n    for (var _e263 = 0; _e263 < o; ++_e263) {\n      c[_e263] = _e263;\n    }\n\n    return [_t247, [o, h], _n159, u, c];\n  }\n\n  {\n    var _t248 = f[l - 1],\n        _a70 = v(n, _t248 * h),\n        _d9 = v(r, _t248),\n        _p8 = new Array(l).fill(0);\n\n    for (var _t249 = 0; _t249 < o; ++_t249) {\n      var _n160 = e[_t249 * h],\n          _r92 = (0 === _n160 ? 0 : f[_n160 - 1]) + _p8[_n160];\n\n      _p8[_n160]++;\n\n      for (var _n161 = 0; _n161 < h; ++_n161) {\n        _a70[_r92 * h + _n161] = e[_t249 * h + _n161];\n      }\n\n      _d9[_r92] = s[_t249], c[_t249] = _r92;\n    }\n\n    for (var _e264 = 0; _e264 < l; ++_e264) {\n      if (0 === _p8[_e264]) {\n        var _t250 = 0 === _e264 ? 0 : f[_e264 - 1];\n\n        _a70[_t250 * h + 0] = _e264;\n\n        for (var _e265 = 1; _e265 < h; ++_e265) {\n          _a70[_t250 * h + _e265] = 0;\n        }\n\n        _d9[_t250] = i;\n      }\n    }\n\n    return [_a70, [_t248, h], _d9, u, c];\n  }\n}\n\nfunction cm(e, t, n, s, r) {\n  var a = d(s),\n      i = t[0],\n      o = r.length,\n      l = [];\n  var u = 1,\n      c = -1;\n\n  for (var _e266 = 0; _e266 < o; ++_e266) {\n    var _t251 = r[_e266];\n\n    if (-1 === _t251) {\n      if (-1 !== c) throw new Error(\"only one output dimension may be -1, not both \".concat(c, \" and \").concat(_e266));\n      c = _e266, l.push(1);\n    } else {\n      if (_t251 < 0) throw new Error(\"size \".concat(_e266, \" must be non-negative, not \").concat(_t251));\n      u *= _t251, l.push(_t251);\n    }\n  }\n\n  if (-1 !== c) {\n    if (u <= 0) throw new Error(\"reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\");\n\n    var _e267 = Math.trunc(a / u);\n\n    if (u * _e267 !== a) throw new Error(\"Input to reshape is a SparseTensor with \".concat(a, \"\\n          dense values, but the requested shape requires a multiple of \").concat(u, \". inputShape=\").concat(s, \" outputShape= \").concat(l));\n    l[c] = _e267;\n  }\n\n  var h = d(l);\n  if (h !== a) throw new Error(\"Input to reshape is a tensor with \".concat(a, \" dense values, but the requested shape has \").concat(h, \". inputShape=\").concat(s, \" outputShape=\").concat(l));\n  var p = s.length,\n      f = [];\n\n  if (p > 0) {\n    f[p - 1] = 1;\n\n    for (var _e268 = p - 2; _e268 >= 0; --_e268) {\n      f[_e268] = f[_e268 + 1] * s[_e268 + 1];\n    }\n  }\n\n  var g = [];\n\n  if (o > 0) {\n    g[o - 1] = 1;\n\n    for (var _e269 = o - 2; _e269 >= 0; --_e269) {\n      g[_e269] = g[_e269 + 1] * l[_e269 + 1];\n    }\n  }\n\n  var m = v(n, i * o);\n\n  for (var _t252 = 0; _t252 < i; ++_t252) {\n    var _n162 = 0;\n\n    for (var _s134 = 0; _s134 < p; ++_s134) {\n      _n162 += e[_t252 * p + _s134] * f[_s134];\n    }\n\n    for (var _e270 = 0; _e270 < o; ++_e270) {\n      m[_t252 * o + _e270] = Math.trunc(_n162 / g[_e270]), _n162 %= g[_e270];\n    }\n  }\n\n  return [m, [i, o], l];\n}\n\nfunction hm(e, t, n, s, r) {\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;\n  var o = s.length;\n  if (o !== r.length) throw new Error(\"segmentIds and indices should have same size.\");\n  var l = [t[0], e.length / t[0]],\n      u = l[1],\n      c = o > 0 ? r[o - 1] + 1 : 0;\n  if (c < 0) throw new Error(\"segment ids must be >= 0\");\n  var h = t.slice();\n  h[0] = c;\n  var d = v(n, h.reduce((e, t) => e * t, 1));\n  if (0 === o) return c > 0 && d.fill(i), [d, h];\n  if (c <= 0) throw new Error(\"segment ids must be >= 0\");\n  var p = 0,\n      f = 1,\n      g = 0,\n      m = r[p];\n\n  for (;;) {\n    var _t253 = 0;\n\n    if (f < o) {\n      if (_t253 = r[f], m === _t253) {\n        ++f;\n        continue;\n      }\n\n      if (m >= _t253) throw new Error(\"segment ids are not increasing\");\n    }\n\n    if (m < 0 || m >= c) throw new Error(\"Segment id \".concat(m, \" out of range [0, \").concat(c, \"), possibly because segmentIds input is not sorted.\"));\n    m > g && d.fill(i, g * u, m * u);\n\n    for (var _t254 = p; _t254 < f; ++_t254) {\n      var _n163 = s[_t254];\n      if (_n163 < 0 || _n163 >= l[0]) throw new Error(\"Bad: indices[\".concat(_t254, \"] == \").concat(s[_t254], \" out of range [0, \").concat(l[0], \")\"));\n\n      for (var _t255 = 0; _t255 < u; _t255++) {\n        d[m * u + _t255] += e[_n163 * u + _t255];\n      }\n    }\n\n    if (a) for (var _e271 = 0; _e271 < u; _e271++) {\n      d[m * u + _e271] /= f - p;\n    }\n    if (p = f, ++f, g = m + 1, m = _t253, f > o) break;\n  }\n\n  return g < c && d.fill(i, g * u, c * u), [d, h];\n}\n\nvar dm = og(e => Math.sqrt(e)),\n    pm = {\n  kernelName: \"Sqrt\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Sqrt\", e => Math.sqrt(e))\n},\n    fm = Gf((e, t) => {\n  var n = e - t;\n  return n * n;\n}),\n    gm = {\n  kernelName: \"SquaredDifference\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"SquaredDifference\", fm)\n};\n\nfunction mm(e, t, n, s) {\n  var r = pn(e, t.dtype);\n\n  for (var _e272 = 0; _e272 < r.size; _e272++) {\n    var _a71 = r.indexToLoc(_e272),\n        _i38 = new Array(_a71.length);\n\n    for (var _e273 = 0; _e273 < _i38.length; _e273++) {\n      _i38[_e273] = _a71[_e273] * n[_e273] + s[_e273];\n    }\n\n    r.set(t.get(..._i38), ..._a71);\n  }\n\n  return r;\n}\n\nclass bm {\n  constructor(e, t, n, s, r, a) {\n    this.separator = He(e), this.nGramWidths = t, this.leftPad = He(n), this.rightPad = He(s), this.padWidth = r, this.preserveShort = a;\n  }\n\n  getPadWidth(e) {\n    return Math.min(this.padWidth < 0 ? e - 1 : this.padWidth, e - 1);\n  }\n\n  getNumNGrams(e, t) {\n    var n = this.getPadWidth(t);\n    return Math.max(0, e + 2 * n - t + 1);\n  }\n\n  createNGrams(e, t, n, s, r, a) {\n    var _this70 = this;\n\n    var _loop27 = function _loop27(_i39) {\n      var o = _this70.getPadWidth(a),\n          l = Math.max(0, o - _i39),\n          u = Math.max(0, o - (r - (_i39 + 1))),\n          c = a - (l + u),\n          h = t + (l > 0 ? 0 : _i39 - o);\n\n      var d = 0;\n      d += l * _this70.leftPad.length;\n\n      for (var _t256 = 0; _t256 < c; ++_t256) {\n        d += e[h + _t256].length;\n      }\n\n      d += u * _this70.rightPad.length, d += (l + u + c - 1) * _this70.separator.length, n[s + _i39] = new Uint8Array(d);\n      var p = n[s + _i39];\n      var f = 0;\n\n      var g = e => e.forEach(e => p[f++] = e);\n\n      for (var _e274 = 0; _e274 < l; ++_e274) {\n        g(_this70.leftPad), g(_this70.separator);\n      }\n\n      for (var _t257 = 0; _t257 < c - 1; ++_t257) {\n        g(e[h + _t257]), g(_this70.separator);\n      }\n\n      if (c > 0) {\n        g(e[h + c - 1]);\n\n        for (var _e275 = 0; _e275 < u; ++_e275) {\n          g(_this70.separator), g(_this70.rightPad);\n        }\n      } else {\n        for (var _e276 = 0; _e276 < u - 1; ++_e276) {\n          g(_this70.rightPad), g(_this70.separator);\n        }\n\n        g(_this70.rightPad);\n      }\n    };\n\n    for (var _i39 = 0; _i39 < r; ++_i39) {\n      _loop27(_i39);\n    }\n  }\n\n  compute(e, t) {\n    var _this71 = this;\n\n    var n = e.length,\n        s = t.length;\n\n    if (s > 0) {\n      var _e277 = t[0];\n      if (0 !== _e277) throw new Error(\"First split value must be 0, got \".concat(_e277));\n\n      for (var _r93 = 1; _r93 < s; ++_r93) {\n        var _s135 = t[_r93] >= _e277;\n\n        if (_s135 = _s135 && t[_r93] <= n, !_s135) throw new Error(\"Invalid split value \".concat(t[_r93], \", must be in [\").concat(_e277, \", \").concat(n, \"]\"));\n        _e277 = t[_r93];\n      }\n\n      if (_e277 !== n) throw new Error(\"Last split value must be data size. Expected \".concat(n, \", got \").concat(_e277));\n    }\n\n    var r = s - 1,\n        a = v(\"int32\", s);\n\n    if (0 === n || 0 === s) {\n      var _e278 = new Array(n);\n\n      for (var _e279 = 0; _e279 <= r; ++_e279) {\n        a[_e279] = 0;\n      }\n\n      return [_e278, a];\n    }\n\n    a[0] = 0;\n\n    var _loop28 = function _loop28(_e280) {\n      var n = t[_e280] - t[_e280 - 1];\n      var s = 0;\n      _this71.nGramWidths.forEach(e => {\n        s += _this71.getNumNGrams(n, e);\n      }), _this71.preserveShort && n > 0 && 0 === s && (s = 1), a[_e280] = a[_e280 - 1] + s;\n    };\n\n    for (var _e280 = 1; _e280 <= r; ++_e280) {\n      _loop28(_e280);\n    }\n\n    var i = new Array(a[r]);\n\n    var _loop29 = function _loop29(_n164) {\n      var s = t[_n164];\n      var r = a[_n164];\n\n      if (_this71.nGramWidths.forEach(a => {\n        var o = _this71.getNumNGrams(t[_n164 + 1] - t[_n164], a);\n\n        _this71.createNGrams(e, s, i, r, o, a), r += o;\n      }), _this71.preserveShort && r === a[_n164]) {\n        var _a72 = t[_n164 + 1] - t[_n164];\n\n        if (0 === _a72) return \"continue\";\n\n        _this71.createNGrams(e, s, i, r, 1, _a72 + 2 * _this71.padWidth);\n      }\n    };\n\n    for (var _n164 = 0; _n164 < r; ++_n164) {\n      var _ret4 = _loop29(_n164);\n\n      if (_ret4 === \"continue\") continue;\n    }\n\n    return [i, a];\n  }\n\n}\n\nfunction xm(e, t, n, s, r, a, i, o) {\n  return new bm(n, s, r, a, i, o).compute(e, t);\n}\n\nfunction ym(e, t, n, s) {\n  if (!e.length) return;\n\n  if (0 === t.length) {\n    for (var _t258 = 0; _t258 < e.length; ++_t258) {\n      s.push(e.subarray(_t258, _t258 + 1));\n    }\n\n    return;\n  }\n\n  if (1 === t.length) {\n    var _r94 = t[0];\n\n    var _a73 = e.indexOf(_r94);\n\n    for (; -1 !== _a73;) {\n      var _t259 = e.subarray(0, _a73);\n\n      n && 0 === _t259.length || s.push(_t259), _a73 = (e = e.subarray(_a73 + 1)).indexOf(_r94);\n    }\n\n    return void (n && 0 === e.length || s.push(e));\n  }\n\n  var r = 0;\n\n  for (var _a74 = 0; _a74 < e.length + 1; _a74++) {\n    if (_a74 === e.length || -1 !== t.indexOf(e[_a74])) {\n      var _t260 = e.subarray(r, _a74);\n\n      n && 0 === _t260.length || s.push(_t260), r = _a74 + 1;\n    }\n  }\n}\n\nfunction km(e, t, n) {\n  var s = e.length,\n      r = [];\n  var a = 0,\n      i = 0;\n  var o = new Array(s);\n\n  for (var _l20 = 0; _l20 < s; ++_l20) {\n    var _s136 = r.length;\n    ym(e[_l20], t, n, r);\n\n    var _u13 = r.length - _s136;\n\n    o[_l20] = _u13, a += _u13, i = Math.max(i, _u13);\n  }\n\n  var l = v(\"int32\", 2 * a),\n      u = new Array(a),\n      c = [s, i];\n  var h = 0;\n\n  for (var _e281 = 0; _e281 < s; ++_e281) {\n    for (var _t261 = 0; _t261 < o[_e281]; ++_t261) {\n      l[2 * h] = _e281, l[2 * h + 1] = _t261, u[h] = r[h], ++h;\n    }\n  }\n\n  return [l, u, c];\n}\n\nfunction wm(e, t) {\n  var n = v(\"int32\", e.length);\n\n  for (var _s137 = 0; _s137 < e.length; ++_s137) {\n    n[_s137] = We(e[_s137]).modulo(t).getLowBitsUnsigned();\n  }\n\n  return n;\n}\n\nvar vm = Gf((e, t) => e - t),\n    Im = eg(\"Sub\", vm, tg((e, t, n, s) => ({\n  real: e - n,\n  imag: t - s\n}))),\n    $m = {\n  kernelName: \"Sub\",\n  backendName: \"cpu\",\n  kernelFunc: Im\n};\n\nfunction Sm(e, t) {\n  var n = new Array(e.rank);\n\n  for (var _s138 = 0; _s138 < n.length; _s138++) {\n    n[_s138] = e.shape[_s138] * t[_s138];\n  }\n\n  var s = pn(n, e.dtype);\n\n  for (var _t262 = 0; _t262 < s.values.length; ++_t262) {\n    var _n165 = s.indexToLoc(_t262),\n        _r95 = new Array(e.rank);\n\n    for (var _t263 = 0; _t263 < _r95.length; _t263++) {\n      _r95[_t263] = _n165[_t263] % e.shape[_t263];\n    }\n\n    var _a75 = e.locToIndex(_r95);\n\n    s.values[_t262] = e.values[_a75];\n  }\n\n  return s;\n}\n\nvar Nm = (e, t) => {\n  var n = t.value - e.value;\n  return 0 === n ? e.index - t.index : n;\n};\n\nfunction Cm(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : e.length - 1;\n\n  for (; s > n;) {\n    if (s - n > 600) {\n      var _r97 = s - n + 1,\n          _a77 = t - n + 1,\n          _i41 = Math.log(_r97),\n          _o32 = .5 * Math.exp(2 * _i41 / 3),\n          _l21 = .5 * Math.sqrt(_i41 * _o32 * (_r97 - _o32) / _r97) * Math.sign(_a77 - _r97 / 2);\n\n      Cm(e, t, Math.max(n, Math.floor(t - _a77 * _o32 / _r97 + _l21)), Math.min(s, Math.floor(t + (_r97 - _a77) * _o32 / _r97 + _l21)));\n    }\n\n    var _r96 = e[t];\n    var _a76 = n,\n        _i40 = s;\n\n    for (o(e, n, t), Nm(e[s], _r96) > 0 && o(e, n, s); _a76 < _i40;) {\n      for (o(e, _a76, _i40), _a76++, _i40--; Nm(e[_a76], _r96) < 0;) {\n        _a76 += 1;\n      }\n\n      for (; Nm(e[_i40], _r96) > 0;) {\n        _i40 -= 1;\n      }\n    }\n\n    0 === Nm(e[n], _r96) ? o(e, n, _i40) : (_i40 += 1, o(e, _i40, s)), _i40 <= t && (n = _i40 + 1), t <= _i40 && (s = _i40 - 1);\n  }\n}\n\nfunction Tm(e, t, n, s, r) {\n  var a = t[t.length - 1],\n      [i, o] = [e.length / a, a],\n      l = w(n, i * s),\n      u = w(\"int32\", i * s);\n\n  var _loop30 = function _loop30(_t264) {\n    var n = _t264 * o,\n        a = e.subarray(n, n + o);\n    var i = new Array(a.length);\n    a.forEach((e, t) => i[t] = {\n      value: e,\n      index: t\n    }), s < i.length && (Cm(i, s), i = i.slice(0, s)), r && i.sort(Nm);\n    var c = _t264 * s,\n        h = l.subarray(c, c + s),\n        d = u.subarray(c, c + s);\n\n    for (var _e282 = 0; _e282 < s; _e282++) {\n      h[_e282] = i[_e282].value, d[_e282] = i[_e282].index;\n    }\n  };\n\n  for (var _t264 = 0; _t264 < i; _t264++) {\n    _loop30(_t264);\n  }\n\n  var c = t.slice();\n  return c[c.length - 1] = s, [pn(c, n, l), pn(c, \"int32\", u)];\n}\n\nfunction Em(e, t, n, s) {\n  var r = y(t, n)[0],\n      a = [1, n[0], 1];\n\n  for (var _e283 = 0; _e283 < r; _e283++) {\n    a[0] *= n[_e283];\n  }\n\n  a[1] = n[r];\n\n  for (var _e284 = r + 1; _e284 < n.length; _e284++) {\n    a[2] *= n[_e284];\n  }\n\n  var i = {},\n      o = new Int32Array(n[r]),\n      l = new tt(a, s, e),\n      u = [],\n      c = 1 === a[0] && 1 === a[2];\n\n  for (var _t265 = 0; _t265 < n[r]; _t265++) {\n    var _n166 = void 0;\n\n    if (c) _n166 = e[_t265].toString();else {\n      var _e285 = [];\n\n      for (var _n167 = 0; _n167 < a[0]; _n167++) {\n        for (var _s139 = 0; _s139 < a[2]; _s139++) {\n          _e285.push(l.get(_n167, _t265, _s139));\n        }\n      }\n\n      _n166 = _e285.join(\",\");\n    }\n    if (void 0 !== i[_n166]) o[_t265] = i[_n166];else {\n      var _e286 = Object.keys(i).length;\n      i[_n166] = _e286, o[_t265] = _e286, u.push(_t265);\n    }\n  }\n\n  var h = a.slice();\n  h[1] = Object.keys(i).length;\n  var d = new tt(h, s);\n  u.forEach((e, t) => {\n    for (var _n168 = 0; _n168 < a[0]; _n168++) {\n      for (var _s140 = 0; _s140 < a[2]; _s140++) {\n        d.set(l.get(_n168, e, _s140), _n168, t, _s140);\n      }\n    }\n  });\n  var p = n.slice();\n  return p[r] = h[1], {\n    outputValues: d.values,\n    outputShape: p,\n    indices: o\n  };\n}\n\nvar Rm = {\n  __proto__: null,\n  simpleAbsImpl: Uf,\n  addImpl: ng,\n  bincountImpl: ag,\n  bincountReduceImpl: ig,\n  ceilImpl: cg,\n  concatImpl: dg,\n  equalImpl: pg,\n  expImpl: mg,\n  expm1Impl: yg,\n  floorImpl: wg,\n  gatherNdImpl: Ig,\n  gatherV2Impl: $g,\n  greaterImpl: Sg,\n  greaterEqualImpl: Cg,\n  lessImpl: Eg,\n  lessEqualImpl: Ag,\n  linSpaceImpl: Dg,\n  logImpl: _g,\n  maxImpl: Mg,\n  maximumImpl: Lg,\n  minimumImpl: Bg,\n  multiplyImpl: Wg,\n  negImpl: Hg,\n  notEqualImpl: jg,\n  prodImpl: Zg,\n  rangeImpl: em,\n  rsqrtImpl: tm,\n  sigmoidImpl: sm,\n  sliceImpl: im,\n  sparseFillEmptyRowsImpl: um,\n  sparseReshapeImpl: cm,\n  sparseSegmentReductionImpl: hm,\n  sqrtImpl: dm,\n  squaredDifferenceImpl: fm,\n  stridedSliceImpl: mm,\n  stringNGramsImpl: xm,\n  stringSplitImpl: km,\n  stringToHashBucketFastImpl: wm,\n  subImpl: vm,\n  tileImpl: Sm,\n  topKImpl: Tm,\n  transposeImpl: Xg,\n  uniqueImpl: Em\n};\nes(\"cpu\", () => new Wf(), 1);\nvar Am = lg(\"Elu\", e => e >= 0 ? e : Math.exp(e) - 1),\n    Fm = {\n  kernelName: \"Elu\",\n  backendName: \"cpu\",\n  kernelFunc: Am\n};\n\nfunction Dm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    alpha: a\n  } = s;\n  Bf([r], \"leakyRelu\");\n  var i = d(r.shape),\n      o = n.data.get(r.dataId).values,\n      l = w(\"float32\", i);\n\n  for (var _e287 = 0; _e287 < o.length; _e287++) {\n    l[_e287] = o[_e287] < 0 ? a * o[_e287] : o[_e287];\n  }\n\n  return n.makeTensorInfo(r.shape, \"float32\", l);\n}\n\nvar _m = {\n  kernelName: \"LeakyRelu\",\n  backendName: \"cpu\",\n  kernelFunc: Dm\n},\n    Om = Gf((e, t) => e < 0 ? t * e : e);\n\nfunction Mm(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s,\n    alpha: r\n  } = t;\n  Bf([s, r], \"prelu\");\n  var a = n.data.get(s.dataId).values,\n      i = n.data.get(r.dataId).values,\n      [o, l] = Om(s.shape, r.shape, a, i, s.dtype);\n  return n.makeTensorInfo(l, s.dtype, o);\n}\n\nvar Lm = {\n  kernelName: \"Prelu\",\n  backendName: \"cpu\",\n  kernelFunc: Mm\n},\n    zm = lg(\"Relu\", e => Math.max(0, e)),\n    Bm = {\n  kernelName: \"Relu\",\n  backendName: \"cpu\",\n  kernelFunc: zm\n},\n    Pm = lg(\"Relu6\", e => Math.min(Math.max(0, e), 6)),\n    Wm = {\n  kernelName: \"Relu6\",\n  backendName: \"cpu\",\n  kernelFunc: Pm\n};\n\nfunction Um(e, t, n, s, r) {\n  if (\"linear\" === n) return Kf({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"relu\" === n) return zm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"elu\" === n) return Am({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"relu6\" === n) return Pm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  if (\"prelu\" === n) return Mm({\n    inputs: {\n      x: t,\n      alpha: s\n    },\n    backend: e\n  });\n  if (\"leakyrelu\" === n) return Dm({\n    inputs: {\n      x: t\n    },\n    backend: e,\n    attrs: {\n      alpha: r\n    }\n  });\n  if (\"sigmoid\" === n) return rm({\n    inputs: {\n      x: t\n    },\n    backend: e\n  });\n  throw new Error(\"Activation \".concat(n, \" has not been implemented for the CPU backend.\"));\n}\n\nfunction Vm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    shape: a\n  } = s,\n      i = d(r.shape),\n      o = x(a, i),\n      u = d(o);\n  l(i === u, () => \"The new shape (\".concat(o, \") has \").concat(u, \" elements and the old shape (\").concat(r.shape, \") has \").concat(i, \" elements. The new shape and old shape must have the same number of elements.\")), n.incRef(r.dataId);\n  var c = n.data.get(r.dataId);\n\n  if (null != c.complexTensorInfos) {\n    var _e288 = c.complexTensorInfos.imag;\n    c.complexTensorInfos.real.shape = o, _e288.shape = o;\n  }\n\n  return {\n    dataId: r.dataId,\n    shape: o,\n    dtype: r.dtype\n  };\n}\n\nvar Gm = {\n  kernelName: \"Reshape\",\n  backendName: \"cpu\",\n  kernelFunc: Vm\n};\n\nfunction Hm(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    a: r,\n    b: a\n  } = t,\n      {\n    transposeA: i,\n    transposeB: o\n  } = s;\n  Bf([r, a], \"matMul\");\n  var u = r.shape.length,\n      c = a.shape.length,\n      h = i ? r.shape[u - 2] : r.shape[u - 1],\n      p = o ? a.shape[c - 1] : a.shape[c - 2],\n      f = i ? r.shape[u - 1] : r.shape[u - 2],\n      g = o ? a.shape[c - 2] : a.shape[c - 1],\n      m = r.shape.slice(0, -2),\n      b = a.shape.slice(0, -2),\n      x = d(m),\n      y = d(b);\n  l(u >= 2 && c >= 2 && (x === y || 1 === x || 1 === y), () => \"Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (\".concat(m, \") and (\").concat(b, \").\"));\n  var k = (x > y ? r.shape.slice(0, -2) : a.shape.slice(0, -2)).concat([f, g]);\n  l(h === p, () => \"Error in matMul: inner shapes (\".concat(h, \") and (\").concat(p, \") of Tensors with shapes \").concat(r.shape, \" and \").concat(a.shape, \" and transposeA=\").concat(i, \" and transposeB=\").concat(o, \" must match.\"));\n  var w = o ? [y, g, p] : [y, p, g],\n      v = Vm({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: i ? [x, h, f] : [x, f, h]\n    }\n  }),\n      I = Vm({\n    inputs: {\n      x: a\n    },\n    backend: n,\n    attrs: {\n      shape: w\n    }\n  }),\n      $ = i ? v.shape[1] : v.shape[2],\n      S = i ? v.shape[2] : v.shape[1],\n      N = o ? I.shape[1] : I.shape[2],\n      C = Math.max(x, y),\n      T = n.data.get(v.dataId).values,\n      E = n.data.get(I.dataId).values,\n      R = A(v.shape),\n      F = A(I.shape),\n      [D, _, O] = i ? [R[0], 1, R[1]] : [R[0], R[1], 1],\n      [M, L, z] = o ? [1, F[1], F[0]] : [F[1], 1, F[0]],\n      B = S * N,\n      P = pn([C, S, N], v.dtype),\n      W = P.values,\n      U = n.blockSize;\n\n  for (var _e289 = 0; _e289 < C; _e289++) {\n    for (var _t266 = 0; _t266 < S; _t266 += U) {\n      for (var _n169 = 0; _n169 < N; _n169 += U) {\n        for (var _s141 = 0; _s141 < $; _s141 += U) {\n          var _r98 = Math.min(_t266 + U, S),\n              _a78 = Math.min(_n169 + U, N),\n              _i42 = Math.min(_s141 + U, $);\n\n          for (var _o33 = _t266; _o33 < _r98; _o33++) {\n            for (var _t267 = _n169; _t267 < _a78; _t267++) {\n              var _n170 = 0;\n\n              for (var _r99 = _s141; _r99 < _i42; _r99++) {\n                var _s142 = Math.min(_e289, x - 1) * D,\n                    _a79 = Math.min(_e289, y - 1) * z;\n\n                _n170 += T[_s142 + _o33 * _ + _r99 * O] * E[_r99 * M + _t267 * L + _a79];\n              }\n\n              W[_e289 * B + (_o33 * N + _t267)] += _n170;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.disposeIntermediateTensorInfo(v), n.disposeIntermediateTensorInfo(I), n.makeTensorInfo(k, P.dtype, P.values);\n}\n\nvar qm = {\n  kernelName: \"BatchMatMul\",\n  backendName: \"cpu\",\n  kernelFunc: Hm\n},\n    jm = {\n  kernelName: \"_FusedMatMul\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      transposeA: l,\n      transposeB: u,\n      activation: c,\n      leakyreluAlpha: h\n    } = s;\n    var d, p, f;\n    var g = [];\n    d = Hm({\n      inputs: {\n        a: r,\n        b: a\n      },\n      attrs: {\n        transposeA: l,\n        transposeB: u\n      },\n      backend: n\n    }), i && (p = sg({\n      inputs: {\n        a: d,\n        b: i\n      },\n      backend: n\n    }), g.push(d), d = p), c && (f = Um(n, d, c, o, h), g.push(d), d = f);\n\n    for (var _e290 of g) {\n      n.disposeIntermediateTensorInfo(_e290);\n    }\n\n    return d;\n  }\n},\n    Km = {\n  kernelName: \"Acos\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Acos\", e => Math.acos(e))\n},\n    Xm = {\n  kernelName: \"Acosh\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Acosh\", e => Math.acosh(e))\n},\n    Ym = {\n  kernelName: \"AddN\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        s = t;\n    Bf(t, \"addN\");\n    var r = s.map(e => n.data.get(e.dataId).values),\n        a = pn(s[0].shape, s[0].dtype),\n        i = a.values;\n\n    for (var _e291 = 0; _e291 < s.length; _e291++) {\n      var _t268 = r[_e291];\n\n      for (var _e292 = 0; _e292 < i.length; _e292++) {\n        i[_e292] += _t268[_e292];\n      }\n    }\n\n    return n.makeTensorInfo(a.shape, a.dtype, a.values);\n  }\n},\n    Jm = {\n  kernelName: \"All\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    Bf(r, \"all\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Zr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = ea(l.length, r.shape.length)), Jr(\"all\", l, c.shape.length);\n    var [h, p] = Xr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e293 = 0; _e293 < g.length; ++_e293) {\n      var _t269 = _e293 * f;\n\n      var _n171 = m[_t269];\n\n      for (var _e294 = 0; _e294 < f; ++_e294) {\n        var _s143 = m[_t269 + _e294];\n        _n171 = _n171 && _s143;\n      }\n\n      g[_e293] = _n171;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e295 = Vm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Yr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e295;\n    }\n\n    return b;\n  }\n},\n    Zm = {\n  kernelName: \"Any\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    Bf(r, \"any\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Zr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = ea(l.length, r.shape.length)), Jr(\"any\", l, c.shape.length);\n    var [h, p] = Xr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e296 = 0; _e296 < g.length; ++_e296) {\n      var _t270 = _e296 * f;\n\n      var _n172 = m[_t270];\n\n      for (var _e297 = 0; _e297 < f; ++_e297) {\n        var _s144 = m[_t270 + _e297];\n        _n172 = _n172 || _s144;\n      }\n\n      g[_e296] = _n172;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e298 = Vm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Yr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e298;\n    }\n\n    return b;\n  }\n},\n    Qm = {\n  kernelName: \"ArgMax\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    Bf(r, \"argMax\");\n    var i = y(a, r.shape);\n    var o = Zr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = ea(i.length, l.shape.length)), i = [i[0]], Jr(\"argMax\", i, l.shape.length);\n    var [c, h] = Xr(l.shape, i),\n        p = O(d(c), \"int32\"),\n        f = d(h),\n        g = n.data.get(l.dataId).values;\n\n    for (var _e299 = 0; _e299 < p.length; ++_e299) {\n      var _t271 = _e299 * f;\n\n      var _n173 = g[_t271],\n          _s145 = 0;\n\n      for (var _e300 = 0; _e300 < f; ++_e300) {\n        var _r100 = g[_t271 + _e300];\n        _r100 > _n173 && (_n173 = _r100, _s145 = _e300);\n      }\n\n      p[_e299] = _s145;\n    }\n\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, \"int32\", p);\n  }\n},\n    eb = {\n  kernelName: \"ArgMin\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    Bf(r, \"argMin\");\n    var i = y(a, r.shape);\n    var o = Zr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = ea(i.length, l.shape.length)), i = [i[0]], Jr(\"argMin\", i, l.shape.length);\n    var [c, h] = Xr(l.shape, i),\n        p = O(d(c), \"int32\"),\n        f = d(h),\n        g = n.data.get(l.dataId).values;\n\n    for (var _e301 = 0; _e301 < p.length; ++_e301) {\n      var _t272 = _e301 * f;\n\n      var _n174 = g[_t272],\n          _s146 = 0;\n\n      for (var _e302 = 0; _e302 < f; ++_e302) {\n        var _r101 = g[_t272 + _e302];\n        _r101 < _n174 && (_n174 = _r101, _s146 = _e302);\n      }\n\n      p[_e301] = _s146;\n    }\n\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, \"int32\", p);\n  }\n},\n    tb = {\n  kernelName: \"Asin\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Asin\", e => Math.asin(e))\n},\n    nb = {\n  kernelName: \"Asinh\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Asinh\", e => Math.asinh(e))\n},\n    sb = {\n  kernelName: \"Atan\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Atan\", e => Math.atan(e))\n},\n    rb = {\n  kernelName: \"Atan2\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Atan2\", Gf((e, t) => Math.atan2(e, t)))\n},\n    ab = {\n  kernelName: \"Atanh\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Atanh\", e => Math.atanh(e))\n};\n\nfunction ib(e, t, n, s, r, a) {\n  var i = r.strideHeight,\n      o = r.strideWidth,\n      l = r.dilationHeight,\n      u = r.dilationWidth,\n      c = r.effectiveFilterHeight,\n      h = r.effectiveFilterWidth,\n      d = r.padInfo.top,\n      p = r.padInfo.left,\n      f = \"max\" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n      g = pn(r.outShape, n),\n      m = g.values,\n      b = r.outShape[1] * r.outShape[2] * r.outShape[3],\n      x = r.outShape[2] * r.outShape[3],\n      y = r.outShape[3];\n\n  for (var _t273 = 0; _t273 < r.batchSize; ++_t273) {\n    var _n175 = _t273 * b,\n        _g9 = _t273 * s[0];\n\n    for (var _t274 = 0; _t274 < r.inChannels; ++_t274) {\n      for (var _b7 = 0; _b7 < r.outHeight; ++_b7) {\n        var _k4 = _b7 * i - d,\n            _w3 = Math.max(0, _k4),\n            _v3 = Math.min(r.inHeight, c + _k4),\n            _I2 = _n175 + _b7 * x;\n\n        for (var _n176 = 0; _n176 < r.outWidth; ++_n176) {\n          var _i43 = _n176 * o - p,\n              _c13 = Math.max(0, _i43),\n              _d10 = Math.min(r.inWidth, h + _i43);\n\n          var _b8 = f,\n              _x51 = 0,\n              _k5 = 0;\n\n          for (var _n177 = _w3; _n177 < _v3; _n177 += l) {\n            var _r102 = _g9 + _n177 * s[1];\n\n            for (var _n178 = _c13; _n178 < _d10; _n178 += u) {\n              var _i44 = e[_r102 + _n178 * s[2] + _t274];\n              \"max\" === a && _i44 > _b8 ? _b8 = _i44 : \"avg\" === a && (_x51 += _i44, _k5++);\n            }\n\n            if (isNaN(_b8)) break;\n          }\n\n          m[_I2 + _n176 * y + _t274] = \"avg\" === a ? _x51 / _k5 : _b8;\n        }\n      }\n    }\n  }\n\n  return g;\n}\n\nfunction ob(e, t, n, s) {\n  var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n  var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n  var i = pn(s.outShape, \"int32\"),\n      o = s.strideHeight,\n      l = s.strideWidth,\n      u = s.dilationHeight,\n      c = s.dilationWidth,\n      h = s.effectiveFilterHeight,\n      d = s.effectiveFilterWidth,\n      p = s.padInfo.top,\n      f = s.padInfo.left,\n      g = pn(t, n, e);\n\n  for (var _e303 = 0; _e303 < s.batchSize; ++_e303) {\n    for (var _t275 = 0; _t275 < s.inChannels; ++_t275) {\n      for (var _n179 = 0; _n179 < s.outHeight; ++_n179) {\n        var _m8 = _n179 * o - p;\n\n        var _b9 = _m8;\n\n        for (; _b9 < 0;) {\n          _b9 += u;\n        }\n\n        var _x52 = Math.min(s.inHeight, h + _m8);\n\n        for (var _o34 = 0; _o34 < s.outWidth; ++_o34) {\n          var _h9 = _o34 * l - f;\n\n          var _p9 = _h9;\n\n          for (; _p9 < 0;) {\n            _p9 += c;\n          }\n\n          var _y7 = Math.min(s.inWidth, d + _h9);\n\n          var _k6 = Number.NEGATIVE_INFINITY,\n              _w4 = -1;\n\n          for (var _n180 = _b9; _n180 < _x52; _n180 += u) {\n            var _i45 = _n180 - _m8;\n\n            for (var _o35 = _p9; _o35 < _y7; _o35 += c) {\n              var _l22 = _o35 - _h9,\n                  _u14 = g.get(_e303, _n180, _o35, _t275);\n\n              _u14 > _k6 && (_k6 = _u14, _w4 = r ? a ? ((_e303 * s.inHeight + _n180) * s.inWidth + _o35) * s.inChannels + _t275 : (_n180 * s.inWidth + _o35) * s.inChannels + _t275 : _i45 * d + _l22);\n            }\n          }\n\n          i.set(_w4, _e303, _n179, _o34, _t275);\n        }\n      }\n    }\n  }\n\n  return i;\n}\n\nfunction lb(e, t, n, s, r, a) {\n  var i = r.strideDepth,\n      o = r.strideHeight,\n      l = r.strideWidth,\n      u = r.dilationDepth,\n      c = r.dilationHeight,\n      h = r.dilationWidth,\n      d = r.effectiveFilterDepth,\n      p = r.effectiveFilterHeight,\n      f = r.effectiveFilterWidth,\n      g = r.padInfo.front,\n      m = r.padInfo.top,\n      b = r.padInfo.left,\n      x = \"max\" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,\n      y = pn(r.outShape, n),\n      k = y.values,\n      w = r.outShape[1] * r.outShape[2] * r.outShape[3] * r.outShape[4],\n      v = r.outShape[2] * r.outShape[3] * r.outShape[4],\n      I = r.outShape[3] * r.outShape[4],\n      $ = r.outShape[4];\n\n  for (var _t276 = 0; _t276 < r.batchSize; ++_t276) {\n    var _n181 = _t276 * w,\n        _y8 = _t276 * s[0];\n\n    for (var _t277 = 0; _t277 < r.inChannels; ++_t277) {\n      for (var _w5 = 0; _w5 < r.outDepth; ++_w5) {\n        var _S2 = _w5 * i - g;\n\n        var _N2 = _S2;\n\n        for (; _N2 < 0;) {\n          _N2 += u;\n        }\n\n        var _C = Math.min(r.inDepth, d + _S2),\n            _T = _n181 + _w5 * v;\n\n        for (var _n182 = 0; _n182 < r.outHeight; ++_n182) {\n          var _i46 = _n182 * o - m;\n\n          var _d11 = _i46;\n\n          for (; _d11 < 0;) {\n            _d11 += c;\n          }\n\n          var _g10 = Math.min(r.inHeight, p + _i46),\n              _w6 = _T + _n182 * I;\n\n          for (var _n183 = 0; _n183 < r.outWidth; ++_n183) {\n            var _i47 = _n183 * l - b;\n\n            var _o36 = _i47;\n\n            for (; _o36 < 0;) {\n              _o36 += h;\n            }\n\n            var _p10 = Math.min(r.inWidth, f + _i47),\n                _m9 = _w6 + _n183 * $;\n\n            var _v4 = x,\n                _I3 = 0,\n                _S3 = 0;\n\n            for (var _n184 = _N2; _n184 < _C; _n184 += u) {\n              var _r103 = _y8 + _n184 * s[1];\n\n              for (var _n185 = _d11; _n185 < _g10; _n185 += c) {\n                var _i48 = _r103 + _n185 * s[2];\n\n                for (var _n186 = _o36; _n186 < _p10; _n186 += h) {\n                  var _r104 = e[_i48 + _n186 * s[3] + _t277];\n                  if (\"max\" === a && _r104 > _v4 ? _v4 = _r104 : \"avg\" === a && (_I3 += _r104, _S3++), isNaN(_v4)) break;\n                }\n\n                if (isNaN(_v4)) break;\n              }\n\n              if (isNaN(_v4)) break;\n            }\n\n            k[_m9 + _t277] = \"avg\" === a ? _I3 / _S3 : _v4;\n          }\n        }\n      }\n    }\n  }\n\n  return y;\n}\n\nvar ub = {\n  kernelName: \"AvgPool\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    Bf(r, \"avgPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ts(i, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = xs(r.shape, a, i, 1, o, u);\n    var h;\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) h = Kf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });else {\n      var _e304 = n.data.get(r.dataId).values,\n          _t278 = A(r.shape),\n          _s147 = ib(_e304, 0, r.dtype, _t278, c, \"avg\");\n\n      h = n.makeTensorInfo(c.outShape, r.dtype, _s147.values);\n    }\n    return h;\n  }\n},\n    cb = {\n  kernelName: \"AvgPool3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s;\n    Bf(r, \"avgPool3d\");\n    var c = ys(r.shape, a, i, 1, o, l, u),\n        h = lb(n.data.get(r.dataId).values, 0, r.dtype, A(r.shape), c, \"avg\");\n    return n.makeTensorInfo(h.shape, \"float32\", h.values);\n  }\n},\n    hb = {\n  kernelName: \"AvgPool3DGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        {\n      filterSize: i,\n      strides: o,\n      pad: l,\n      dimRoundingMode: u\n    } = s;\n    Bf([r, a], \"avgPool3DGrad\");\n    var c = ys(a.shape, i, o, 1, l, u),\n        h = c.strideDepth,\n        d = c.strideHeight,\n        p = c.strideWidth,\n        f = c.filterDepth,\n        g = c.filterHeight,\n        m = c.filterWidth,\n        b = c.dilationDepth,\n        x = c.dilationHeight,\n        y = c.dilationWidth,\n        k = c.effectiveFilterDepth,\n        w = c.effectiveFilterHeight,\n        v = c.effectiveFilterWidth,\n        I = k - 1 - c.padInfo.front,\n        $ = v - 1 - c.padInfo.left,\n        S = w - 1 - c.padInfo.top,\n        N = pn(a.shape, \"float32\"),\n        C = 1 / (f * g * m),\n        T = n.bufferSync(r);\n\n    for (var _e305 = 0; _e305 < c.batchSize; ++_e305) {\n      for (var _t279 = 0; _t279 < c.inChannels; ++_t279) {\n        for (var _n187 = 0; _n187 < c.inDepth; ++_n187) {\n          for (var _s148 = 0; _s148 < c.inHeight; ++_s148) {\n            for (var _r105 = 0; _r105 < c.inWidth; ++_r105) {\n              var _a80 = _n187 - I,\n                  _i49 = _s148 - S,\n                  _o37 = _r105 - $;\n\n              var _l23 = 0;\n\n              for (var _n188 = 0; _n188 < k; _n188 += b) {\n                var _s149 = (_a80 + _n188) / h;\n\n                if (!(_s149 < 0 || _s149 >= c.outDepth || Math.floor(_s149) !== _s149)) for (var _n189 = 0; _n189 < w; _n189 += x) {\n                  var _r106 = (_i49 + _n189) / d;\n\n                  if (!(_r106 < 0 || _r106 >= c.outHeight || Math.floor(_r106) !== _r106)) for (var _n190 = 0; _n190 < v; _n190 += y) {\n                    var _a81 = (_o37 + _n190) / p;\n\n                    _a81 < 0 || _a81 >= c.outWidth || Math.floor(_a81) !== _a81 || (_l23 += T.get(_e305, _s149, _r106, _a81, _t279));\n                  }\n                }\n              }\n\n              N.set(_l23 * C, _e305, _n187, _s148, _r105, _t279);\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(N.shape, N.dtype, N.values);\n  }\n},\n    db = {\n  kernelName: \"AvgPoolGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a;\n    Bf([r, a], \"avgPoolGrad\");\n    var {\n      filterSize: o,\n      strides: l,\n      pad: u\n    } = s,\n        c = xs(i.shape, o, l, 1, u),\n        h = c.strideHeight,\n        d = c.strideWidth,\n        p = c.filterHeight,\n        f = c.filterWidth,\n        g = c.dilationHeight,\n        m = c.dilationWidth,\n        b = c.effectiveFilterHeight,\n        x = c.effectiveFilterWidth,\n        y = x - 1 - c.padInfo.left,\n        k = b - 1 - c.padInfo.top,\n        w = pn(i.shape, \"float32\"),\n        v = 1 / (p * f),\n        I = n.data.get(r.dataId).values,\n        $ = pn(r.shape, \"float32\", I);\n\n    for (var _e306 = 0; _e306 < c.batchSize; ++_e306) {\n      for (var _t280 = 0; _t280 < c.inChannels; ++_t280) {\n        for (var _n191 = 0; _n191 < c.inHeight; ++_n191) {\n          for (var _s150 = 0; _s150 < c.inWidth; ++_s150) {\n            var _r107 = _n191 - k,\n                _a82 = _s150 - y;\n\n            var _i50 = 0;\n\n            for (var _n192 = 0; _n192 < b; _n192 += g) {\n              var _s151 = (_r107 + _n192) / h;\n\n              if (!(_s151 < 0 || _s151 >= c.outHeight || Math.floor(_s151) !== _s151)) for (var _n193 = 0; _n193 < x; _n193 += m) {\n                var _r108 = (_a82 + _n193) / d;\n\n                _r108 < 0 || _r108 >= c.outWidth || Math.floor(_r108) !== _r108 || (_i50 += $.get(_e306, _s151, _r108, _t280));\n              }\n            }\n\n            w.set(_i50 * v, _e306, _n191, _s150, _t280);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(w.shape, w.dtype, w.values);\n  }\n},\n    pb = {\n  kernelName: \"FusedBatchNorm\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      scale: a,\n      offset: i,\n      mean: o,\n      variance: u\n    } = t;\n    l(o.shape.length === u.shape.length, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == i || o.shape.length === i.shape.length, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == a || o.shape.length === a.shape.length, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\"), Bf([r, o, u, a, i], \"batchNorm\");\n    var {\n      varianceEpsilon: c\n    } = s;\n    null == c && (c = .001);\n    var h = n.data.get(r.dataId).values,\n        d = n.data.get(o.dataId).values,\n        p = n.data.get(u.dataId).values,\n        f = a ? n.data.get(a.dataId).values : new Float32Array([1]),\n        g = i ? n.data.get(i.dataId).values : new Float32Array([0]),\n        m = new Float32Array(h.length),\n        b = g.length,\n        x = f.length,\n        y = p.length,\n        k = d.length;\n    var w = 0,\n        v = 0,\n        I = 0,\n        $ = 0;\n\n    for (var _e307 = 0; _e307 < h.length; ++_e307) {\n      m[_e307] = g[w++] + (h[_e307] - d[v++]) * f[I++] / Math.sqrt(p[$++] + c), w >= b && (w = 0), v >= k && (v = 0), I >= x && (I = 0), $ >= y && ($ = 0);\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, m);\n  }\n},\n    fb = {\n  kernelName: \"BatchToSpaceND\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      crops: i\n    } = s;\n    Bf([r], \"batchToSpaceND\");\n\n    var o = a.reduce((e, t) => e * t),\n        l = Fo(r.shape, a, o),\n        u = Do(l.length, a.length),\n        c = _o(r.shape, a, o),\n        h = Oo(i, a.length),\n        d = Mo(c, i, a.length),\n        p = Vm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: l\n      }\n    }),\n        f = Yg({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }),\n        g = Vm({\n      inputs: {\n        x: f\n      },\n      backend: n,\n      attrs: {\n        shape: c\n      }\n    }),\n        m = om({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        begin: h,\n        size: d\n      }\n    });\n\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n  }\n},\n    gb = {\n  kernelName: \"Bincount\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i\n    } = s,\n        o = ag(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);\n    return n.makeTensorInfo([i], a.dtype, o);\n  }\n},\n    mb = {\n  kernelName: \"BroadcastArgs\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      s0: s,\n      s1: r\n    } = t,\n        a = n.data.get(s.dataId).values,\n        i = n.data.get(r.dataId).values,\n        o = hr(Array.from(a), Array.from(i));\n    return n.makeTensorInfo([o.length], \"int32\", Int32Array.from(o));\n  }\n},\n    bb = {\n  kernelName: \"ClipByValue\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"ClipByValue\", (e, t) => e > t.clipValueMax ? t.clipValueMax : e < t.clipValueMin ? t.clipValueMin : e)\n},\n    xb = {\n  kernelName: \"ComplexAbs\",\n  backendName: \"cpu\",\n  kernelFunc: e => {\n    var {\n      x: t\n    } = e.inputs,\n        n = e.backend,\n        s = new Float32Array(d(t.shape)),\n        r = n.data.get(t.dataId),\n        a = r.complexTensorInfos.imag,\n        i = n.data.get(r.complexTensorInfos.real.dataId).values,\n        o = n.data.get(a.dataId).values;\n\n    for (var _e308 = 0; _e308 < i.length; _e308++) {\n      s[_e308] = Math.hypot(i[_e308], o[_e308]);\n    }\n\n    return n.makeOutput(s, t.shape, \"float32\");\n  }\n};\n\nfunction yb(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t,\n      r = n.data.get(s.dataId).complexTensorInfos.imag,\n      a = n.data.get(r.dataId).values;\n  return n.makeTensorInfo(r.shape, r.dtype, a);\n}\n\nvar kb = {\n  kernelName: \"Imag\",\n  backendName: \"cpu\",\n  kernelFunc: yb\n};\n\nfunction wb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s,\n      a = y(r, t[0].shape)[0];\n  var i = Eo(t.map(e => e.shape), a);\n  if (0 === d(i)) return n.makeTensorInfo(i, t[0].dtype, []);\n  var o = t.filter(e => d(e.shape) > 0);\n  if (1 === o.length) return Kf({\n    inputs: {\n      x: o[0]\n    },\n    backend: n\n  });\n\n  if (To(o.map(e => e.shape), a), \"complex64\" === o[0].dtype) {\n    var _e309 = o.map(e => Yf({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _t281 = o.map(e => yb({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _s152 = wb({\n      inputs: _e309,\n      backend: n,\n      attrs: {\n        axis: a\n      }\n    }),\n        _r109 = wb({\n      inputs: _t281,\n      backend: n,\n      attrs: {\n        axis: a\n      }\n    }),\n        _i51 = Hf({\n      inputs: {\n        real: _s152,\n        imag: _r109\n      },\n      backend: n\n    });\n\n    return _e309.forEach(e => n.disposeIntermediateTensorInfo(e)), _t281.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_s152), n.disposeIntermediateTensorInfo(_r109), _i51;\n  }\n\n  var l = o.map(e => {\n    var t = d(e.shape.slice(a));\n    return Vm({\n      inputs: {\n        x: e\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, t]\n      }\n    });\n  }),\n      u = l.map(e => ({\n    vals: n.data.get(e.dataId).values,\n    shape: e.shape\n  }));\n  i = Eo(l.map(e => e.shape), 1);\n  var c = dg(u, i, t[0].dtype, 1 === l[0].shape[0]),\n      h = Eo(o.map(e => e.shape), a),\n      p = n.makeTensorInfo(h, t[0].dtype, c);\n  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;\n}\n\nvar vb = {\n  kernelName: \"Concat\",\n  backendName: \"cpu\",\n  kernelFunc: wb\n};\n\nfunction Ib(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    filter: a\n  } = t,\n      {\n    strides: i,\n    pad: o,\n    dataFormat: l,\n    dilations: u,\n    dimRoundingMode: c\n  } = s;\n  Bf([r, a], \"conv2d\");\n  var h = Es(l),\n      d = ks(r.shape, a.shape, i, u, o, c, !1, h),\n      p = d.filterHeight,\n      f = d.filterWidth,\n      g = d.dilationHeight,\n      m = d.dilationWidth,\n      b = d.padInfo.left,\n      x = d.padInfo.top,\n      y = \"channelsLast\" === d.dataFormat,\n      k = new tt(d.outShape, r.dtype),\n      w = A(r.shape),\n      v = A(a.shape),\n      I = w[0],\n      $ = y ? w[1] : w[2],\n      S = y ? w[2] : 1,\n      N = y ? 1 : w[1],\n      C = k.strides[0],\n      T = y ? k.strides[1] : k.strides[2],\n      E = y ? k.strides[2] : 1,\n      R = y ? 1 : k.strides[1],\n      F = n.data.get(r.dataId).values,\n      D = n.data.get(a.dataId).values,\n      _ = k.values;\n\n  for (var _e310 = 0; _e310 < d.batchSize; ++_e310) {\n    var _t282 = _e310 * I,\n        _n194 = _e310 * C;\n\n    for (var _e311 = 0; _e311 < d.outHeight; ++_e311) {\n      var _s153 = _n194 + _e311 * T,\n          _r110 = _e311 * d.strideHeight - x;\n\n      for (var _e312 = 0; _e312 < p; ++_e312) {\n        var _n195 = _r110 + _e312 * g;\n\n        if (_n195 < 0 || _n195 >= d.inHeight) continue;\n\n        var _a83 = _e312 * v[0],\n            _i52 = _t282 + _n195 * $;\n\n        for (var _e313 = 0; _e313 < d.outWidth; ++_e313) {\n          var _t283 = _s153 + _e313 * E,\n              _n196 = _e313 * d.strideWidth - b;\n\n          for (var _e314 = 0; _e314 < f; ++_e314) {\n            var _s154 = _n196 + _e314 * m;\n\n            if (_s154 < 0 || _s154 >= d.inWidth) continue;\n\n            var _r111 = _i52 + _s154 * S;\n\n            var _o38 = _a83 + _e314 * v[1];\n\n            for (var _e315 = 0; _e315 < d.inChannels; ++_e315) {\n              var _n197 = F[_r111 + _e315 * N];\n\n              for (var _e316 = 0; _e316 < d.outChannels; ++_e316) {\n                _[_t283 + _e316 * R] += _n197 * D[_o38 + _e316];\n              }\n\n              _o38 += d.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.makeTensorInfo(k.shape, k.dtype, _);\n}\n\nvar $b = {\n  kernelName: \"Conv2D\",\n  backendName: \"cpu\",\n  kernelFunc: Ib\n},\n    Sb = {\n  kernelName: \"Conv2DBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s;\n    Bf([r, a], \"conv2dBackpropFilter\");\n    var h = Es(l),\n        d = ks(r.shape, c, i, 1, o, u, !1, h),\n        {\n      strideHeight: p,\n      strideWidth: f,\n      filterHeight: g,\n      filterWidth: m\n    } = d,\n        b = \"channelsLast\" === d.dataFormat,\n        x = new tt(d.filterShape, \"float32\"),\n        y = d.padInfo.left,\n        k = d.padInfo.top,\n        w = n.data.get(r.dataId).values,\n        v = n.data.get(a.dataId).values,\n        I = new tt(r.shape, r.dtype, w),\n        $ = new tt(a.shape, a.dtype, v);\n\n    for (var _e317 = 0; _e317 < g; ++_e317) {\n      var _t284 = Math.max(0, Math.ceil((k - _e317) / p)),\n          _n198 = Math.min(d.outHeight, (d.inHeight + k - _e317) / p);\n\n      for (var _s155 = 0; _s155 < m; ++_s155) {\n        var _r112 = Math.max(0, Math.ceil((y - _s155) / f)),\n            _a84 = Math.min(d.outWidth, (d.inWidth + y - _s155) / f);\n\n        for (var _i53 = 0; _i53 < d.inChannels; ++_i53) {\n          for (var _o39 = 0; _o39 < d.outChannels; ++_o39) {\n            var _l24 = 0;\n\n            for (var _u15 = 0; _u15 < d.batchSize; ++_u15) {\n              for (var _c14 = _t284; _c14 < _n198; ++_c14) {\n                var _t285 = _e317 + _c14 * p - k;\n\n                for (var _e318 = _r112; _e318 < _a84; ++_e318) {\n                  var _n199 = _s155 + _e318 * f - y;\n\n                  _l24 += b ? I.get(_u15, _t285, _n199, _i53) * $.get(_u15, _c14, _e318, _o39) : I.get(_u15, _i53, _t285, _n199) * $.get(_u15, _o39, _c14, _e318);\n                }\n              }\n            }\n\n            x.set(_l24, _e317, _s155, _i53, _o39);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(x.shape, x.dtype, x.values);\n  }\n},\n    Nb = {\n  kernelName: \"Conv2DBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      inputShape: i,\n      strides: o,\n      pad: l,\n      dataFormat: u,\n      dimRoundingMode: c\n    } = s;\n    Bf([r, a], \"conv2dBackpropInput\");\n    var h = A(a.shape),\n        d = A(r.shape);\n    var p = Es(u);\n    var f = ks(i, a.shape, o, 1, l, c, !1, p),\n        g = new tt(f.inShape, \"float32\"),\n        m = g.values,\n        b = n.data.get(r.dataId).values,\n        x = n.data.get(a.dataId).values,\n        [y, k, w] = h,\n        {\n      batchSize: v,\n      filterHeight: I,\n      filterWidth: $,\n      inChannels: S,\n      inHeight: N,\n      inWidth: C,\n      outChannels: T,\n      outHeight: E,\n      outWidth: R,\n      strideHeight: F,\n      strideWidth: D\n    } = f;\n    p = f.dataFormat;\n\n    var _ = I - 1 - f.padInfo.top,\n        O = $ - 1 - f.padInfo.left,\n        M = \"channelsLast\" === p,\n        L = g.strides[0],\n        z = M ? g.strides[1] : g.strides[2],\n        B = M ? g.strides[2] : 1,\n        P = M ? 1 : g.strides[1],\n        W = d[0],\n        U = M ? d[1] : d[2],\n        V = M ? d[2] : 1,\n        G = M ? 1 : d[1];\n\n    for (var _e319 = 0; _e319 < v; ++_e319) {\n      for (var _t286 = 0; _t286 < S; ++_t286) {\n        for (var _n200 = 0; _n200 < N; ++_n200) {\n          var _s156 = _n200 - _,\n              _r113 = Math.max(0, Math.ceil(_s156 / F)),\n              _a85 = Math.min(E, (I + _s156) / F);\n\n          for (var _i54 = 0; _i54 < C; ++_i54) {\n            var _o40 = _i54 - O,\n                _l25 = Math.max(0, Math.ceil(_o40 / D)),\n                _u16 = Math.min(R, ($ + _o40) / D);\n\n            var _c15 = 0;\n\n            for (var _n201 = _r113; _n201 < _a85; ++_n201) {\n              var _r114 = _n201 * F - _s156;\n\n              for (var _s157 = _l25; _s157 < _u16; ++_s157) {\n                var _a86 = W * _e319 + U * _n201 + V * _s157,\n                    _i55 = y * (I - 1 - _r114) + k * ($ - 1 - (_s157 * D - _o40)) + w * _t286;\n\n                for (var _e320 = 0; _e320 < T; ++_e320) {\n                  _c15 += b[_a86 + G * _e320] * x[_i55 + _e320];\n                }\n              }\n            }\n\n            m[L * _e319 + z * _n200 + B * _i54 + P * _t286] = _c15;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(g.shape, g.dtype, g.values);\n  }\n},\n    Cb = {\n  kernelName: \"Conv3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s;\n    Bf([r, a], \"conv3d\");\n    var u = ws(r.shape, a.shape, i, l, o),\n        {\n      filterDepth: c,\n      filterHeight: h,\n      filterWidth: d,\n      dilationDepth: p,\n      dilationHeight: f,\n      dilationWidth: g,\n      padInfo: m\n    } = u,\n        b = m.front,\n        x = m.left,\n        y = m.top,\n        k = new tt(u.outShape, r.dtype),\n        w = n.data.get(r.dataId).values,\n        v = n.data.get(a.dataId).values,\n        I = k.values,\n        $ = A(r.shape),\n        S = A(a.shape);\n\n    for (var _e321 = 0; _e321 < u.batchSize; ++_e321) {\n      var _t287 = _e321 * $[0],\n          _n202 = _e321 * k.strides[0];\n\n      for (var _e322 = 0; _e322 < u.outDepth; ++_e322) {\n        var _s158 = _n202 + _e322 * k.strides[1],\n            _r115 = _e322 * u.strideDepth - b;\n\n        for (var _e323 = 0; _e323 < c; ++_e323) {\n          var _n203 = _r115 + _e323 * p;\n\n          if (_n203 < 0 || _n203 >= u.inDepth) continue;\n\n          var _a87 = _e323 * S[0],\n              _i56 = _t287 + _n203 * $[1];\n\n          for (var _e324 = 0; _e324 < u.outHeight; ++_e324) {\n            var _t288 = _s158 + _e324 * k.strides[2],\n                _n204 = _e324 * u.strideHeight - y;\n\n            for (var _e325 = 0; _e325 < h; ++_e325) {\n              var _s159 = _n204 + _e325 * f;\n\n              if (_s159 < 0 || _s159 >= u.inHeight) continue;\n\n              var _r116 = _a87 + _e325 * S[1],\n                  _o41 = _i56 + _s159 * $[2];\n\n              for (var _e326 = 0; _e326 < u.outWidth; ++_e326) {\n                var _n205 = _t288 + _e326 * u.outChannels,\n                    _s160 = _e326 * u.strideWidth - x;\n\n                for (var _e327 = 0; _e327 < d; ++_e327) {\n                  var _t289 = _s160 + _e327 * g;\n\n                  if (_t289 < 0 || _t289 >= u.inWidth) continue;\n\n                  var _a88 = _o41 + _t289 * u.inChannels;\n\n                  var _i57 = _r116 + _e327 * S[2];\n\n                  for (var _e328 = 0; _e328 < u.inChannels; ++_e328) {\n                    var _t290 = w[_a88 + _e328];\n\n                    for (var _e329 = 0; _e329 < u.outChannels; ++_e329) {\n                      I[_n205 + _e329] += _t290 * v[_i57 + _e329];\n                    }\n\n                    _i57 += u.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(k.shape, k.dtype, k.values);\n  }\n},\n    Tb = {\n  kernelName: \"Conv3DBackpropFilterV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      filterShape: l\n    } = s;\n    Bf([r, a], \"conv3dBackpropFilterV2\");\n    var u = A(r.shape),\n        c = A(a.shape),\n        h = ws(r.shape, l, i, 1, o),\n        d = h.strideDepth,\n        p = h.strideHeight,\n        f = h.strideWidth,\n        g = h.filterDepth,\n        m = h.filterHeight,\n        b = h.filterWidth,\n        x = new tt(h.filterShape, \"float32\"),\n        y = x.values,\n        [k, w, v, I] = x.strides,\n        $ = n.data.get(a.dataId).values,\n        [S, N, C, T] = c,\n        E = n.data.get(r.dataId).values,\n        [R, F, D, _] = u,\n        O = h.padInfo.front,\n        M = h.padInfo.left,\n        L = h.padInfo.top;\n\n    for (var _e330 = 0; _e330 < g; ++_e330) {\n      var _t291 = Math.max(0, Math.ceil((O - _e330) / d)),\n          _n206 = Math.min(h.outDepth, (h.inDepth + O - _e330) / d),\n          _s161 = _e330 * k;\n\n      for (var _r117 = 0; _r117 < m; ++_r117) {\n        var _a89 = Math.max(0, Math.ceil((L - _r117) / p)),\n            _i58 = Math.min(h.outHeight, (h.inHeight + L - _r117) / p),\n            _o42 = _r117 * w + _s161;\n\n        for (var _s162 = 0; _s162 < b; ++_s162) {\n          var _l26 = Math.max(0, Math.ceil((M - _s162) / f)),\n              _u17 = Math.min(h.outWidth, (h.inWidth + M - _s162) / f),\n              _c16 = _s162 * v + _o42;\n\n          for (var _o43 = 0; _o43 < h.inChannels; ++_o43) {\n            var _g11 = _o43 * I + _c16;\n\n            for (var _c17 = 0; _c17 < h.outChannels; ++_c17) {\n              var _m10 = 0;\n\n              for (var _g12 = 0; _g12 < h.batchSize; ++_g12) {\n                var _h10 = _g12 * R,\n                    _b10 = _g12 * S;\n\n                for (var _g13 = _t291; _g13 < _n206; ++_g13) {\n                  var _t292 = (_e330 + _g13 * d - O) * F + _h10,\n                      _n207 = _g13 * N + _b10;\n\n                  for (var _e331 = _a89; _e331 < _i58; ++_e331) {\n                    var _a90 = (_r117 + _e331 * p - L) * D + _t292,\n                        _i59 = _e331 * C + _n207;\n\n                    for (var _e332 = _l26; _e332 < _u17; ++_e332) {\n                      _m10 += E[(_s162 + _e332 * f - M) * _ + _a90 + _o43] * $[_e332 * T + _i59 + _c17];\n                    }\n                  }\n                }\n              }\n\n              y[_g11 + _c17] = _m10;\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(x.shape, x.dtype, x.values);\n  }\n},\n    Eb = {\n  kernelName: \"Conv3DBackpropInputV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      pad: i,\n      strides: o,\n      inputShape: l\n    } = s;\n    Bf([r], \"conv3dBackpropInputV2\");\n    var u = A(r.shape),\n        c = A(a.shape),\n        h = ws(l, a.shape, o, 1, i),\n        d = new tt(h.inShape, \"float32\"),\n        p = d.values,\n        [f, g, m, b] = d.strides,\n        x = n.data.get(r.dataId).values,\n        [y, k, w, v] = u,\n        I = n.data.get(a.dataId).values,\n        [$, S, N, C] = c,\n        {\n      batchSize: T,\n      filterDepth: E,\n      filterHeight: R,\n      filterWidth: F,\n      inChannels: D,\n      inDepth: _,\n      inHeight: O,\n      inWidth: M,\n      outChannels: L,\n      outDepth: z,\n      outHeight: B,\n      outWidth: P,\n      strideDepth: W,\n      strideHeight: U,\n      strideWidth: V\n    } = h,\n        G = E - 1 - h.padInfo.front,\n        H = R - 1 - h.padInfo.top,\n        q = F - 1 - h.padInfo.left;\n\n    for (var _e333 = 0; _e333 < T; ++_e333) {\n      for (var _t293 = 0; _t293 < D; ++_t293) {\n        for (var _n208 = 0; _n208 < _; ++_n208) {\n          var _s163 = _n208 - G,\n              _r118 = Math.max(0, Math.ceil(_s163 / W)),\n              _a91 = Math.min(z, (E + _s163) / W);\n\n          for (var _i60 = 0; _i60 < O; ++_i60) {\n            var _o44 = _i60 - H,\n                _l27 = Math.max(0, Math.ceil(_o44 / U)),\n                _u18 = Math.min(B, (R + _o44) / U);\n\n            for (var _c18 = 0; _c18 < M; ++_c18) {\n              var _h11 = _c18 - q,\n                  _d12 = Math.max(0, Math.ceil(_h11 / V)),\n                  _T2 = Math.min(P, (F + _h11) / V);\n\n              var _A = 0;\n\n              for (var _n209 = _r118; _n209 < _a91; ++_n209) {\n                var _r119 = _n209 * W - _s163;\n\n                for (var _s164 = _l27; _s164 < _u18; ++_s164) {\n                  var _a92 = _s164 * U - _o44;\n\n                  for (var _i61 = _d12; _i61 < _T2; ++_i61) {\n                    var _o45 = y * _e333 + k * _n209 + w * _s164 + v * _i61,\n                        _l28 = $ * (E - 1 - _r119) + S * (R - 1 - _a92) + N * (F - 1 - (_i61 * V - _h11)) + C * _t293;\n\n                    for (var _e334 = 0; _e334 < L; ++_e334) {\n                      _A += x[_o45 + _e334] * I[_l28 + _e334];\n                    }\n                  }\n                }\n              }\n\n              p[f * _e333 + g * _n208 + m * _i60 + b * _c18 + _t293] = _A;\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(d.shape, d.dtype, d.values);\n  }\n},\n    Rb = {\n  kernelName: \"Cos\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Cos\", e => Math.cos(e))\n},\n    Ab = {\n  kernelName: \"Cosh\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Cosh\", e => Math.cosh(e))\n},\n    Fb = {\n  kernelName: \"CropAndResize\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      boxes: a,\n      boxInd: i\n    } = t,\n        {\n      cropSize: o,\n      method: l,\n      extrapolationValue: u\n    } = s,\n        [c, h, d, p] = r.shape,\n        f = a.shape[0],\n        [g, m] = o,\n        b = pn([f, g, m, p], \"float32\"),\n        x = n.data.get(a.dataId).values,\n        y = n.data.get(i.dataId).values,\n        k = n.data.get(r.dataId).values,\n        w = A(r.shape),\n        v = A(b.shape);\n\n    for (var _e335 = 0; _e335 < f; _e335++) {\n      var _t294 = 4 * _e335,\n          _n210 = x[_t294],\n          _s165 = x[_t294 + 1],\n          _r120 = x[_t294 + 2],\n          _a93 = x[_t294 + 3],\n          _i62 = y[_e335];\n\n      if (_i62 >= c) continue;\n\n      var _o46 = g > 1 ? (_r120 - _n210) * (h - 1) / (g - 1) : 0,\n          _f7 = m > 1 ? (_a93 - _s165) * (d - 1) / (m - 1) : 0;\n\n      for (var _t295 = 0; _t295 < g; _t295++) {\n        var _c19 = g > 1 ? _n210 * (h - 1) + _t295 * _o46 : .5 * (_n210 + _r120) * (h - 1);\n\n        if (_c19 < 0 || _c19 > h - 1) for (var _n211 = 0; _n211 < m; _n211++) {\n          for (var _s166 = 0; _s166 < p; _s166++) {\n            b.values[_s166 + _n211 * v[2] + _t295 * v[1] + _e335 * v[0]] = u;\n          }\n        } else if (\"bilinear\" === l) {\n          var _n212 = Math.floor(_c19),\n              _r121 = Math.ceil(_c19),\n              _o47 = _c19 - _n212;\n\n          for (var _l29 = 0; _l29 < m; _l29++) {\n            var _c20 = m > 1 ? _s165 * (d - 1) + _l29 * _f7 : .5 * (_s165 + _a93) * (d - 1);\n\n            if (_c20 < 0 || _c20 > d - 1) {\n              for (var _n213 = 0; _n213 < p; _n213++) {\n                b.values[_n213 + _l29 * v[2] + _t295 * v[1] + _e335 * v[0]] = u;\n              }\n\n              continue;\n            }\n\n            var _h12 = Math.floor(_c20),\n                _g14 = Math.ceil(_c20),\n                _x53 = _c20 - _h12;\n\n            for (var _s167 = 0; _s167 < p; _s167++) {\n              var _a94 = _s167 + _h12 * w[2] + _n212 * w[1] + _i62 * w[0];\n\n              var _u19 = k[_a94];\n              _a94 = _s167 + _g14 * w[2] + _n212 * w[1] + _i62 * w[0];\n              var _c21 = k[_a94];\n              _a94 = _s167 + _h12 * w[2] + _r121 * w[1] + _i62 * w[0];\n              var _d13 = k[_a94];\n              _a94 = _s167 + _g14 * w[2] + _r121 * w[1] + _i62 * w[0];\n\n              var _p11 = k[_a94],\n                  _f8 = _u19 + (_c21 - _u19) * _x53;\n\n              _a94 = _s167 + _l29 * v[2] + _t295 * v[1] + _e335 * v[0], b.values[_a94] = _f8 + (_d13 + (_p11 - _d13) * _x53 - _f8) * _o47;\n            }\n          }\n        } else for (var _n214 = 0; _n214 < m; ++_n214) {\n          var _r122 = m > 1 ? _s165 * (d - 1) + _n214 * _f7 : .5 * (_s165 + _a93) * (d - 1);\n\n          if (_r122 < 0 || _r122 > d - 1) {\n            for (var _s168 = 0; _s168 < p; _s168++) {\n              b.values[_s168 + _n214 * v[2] + _t295 * v[1] + _e335 * v[0]] = u;\n            }\n\n            continue;\n          }\n\n          var _o48 = Math.round(_r122),\n              _l30 = Math.round(_c19);\n\n          for (var _s169 = 0; _s169 < p; _s169++) {\n            b.values[_s169 + _n214 * v[2] + _t295 * v[1] + _e335 * v[0]] = k[_s169 + _o48 * w[2] + _l30 * w[1] + _i62 * w[0]];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(b.shape, b.dtype, b.values);\n  }\n},\n    Db = {\n  kernelName: \"Cumsum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      exclusive: i,\n      reverse: o\n    } = s;\n    Bf(r, \"cumsum\");\n    var l = Zr([a], r.shape.length);\n    var u = r;\n    null != l && (u = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: l\n      }\n    }));\n    var c = ea(1, r.shape.length)[0];\n    if (c !== u.shape.length - 1) throw new Error(\"backend.cumsum in CPU expects an inner-most axis=\".concat(u.shape.length - 1, \" but got axis=\").concat(c));\n    var h = pt(u.dtype, \"int32\"),\n        p = O(d(u.shape), h),\n        f = n.data.get(u.dataId).values,\n        g = u.shape[u.shape.length - 1],\n        m = o ? (e, t) => e + g - t - 1 : (e, t) => e + t;\n\n    for (var _e336 = 0; _e336 < f.length; _e336 += g) {\n      for (var _t296 = 0; _t296 < g; _t296++) {\n        var _n215 = m(_e336, _t296);\n\n        if (0 === _t296) p[_n215] = i ? 0 : f[_n215];else {\n          var _s170 = m(_e336, _t296 - 1);\n\n          p[_n215] = i ? f[_s170] + p[_s170] : f[_n215] + p[_s170];\n        }\n      }\n    }\n\n    var b = n.makeTensorInfo(u.shape, h, p);\n\n    if (null != l) {\n      var _e337 = Yg({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          perm: Qr(l)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(u), _e337;\n    }\n\n    return b;\n  }\n},\n    _b = {\n  kernelName: \"DenseBincount\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i,\n      binaryOutput: o\n    } = s;\n\n    if (1 === r.shape.length) {\n      var _e338 = ag(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);\n\n      return n.makeTensorInfo([i], a.dtype, _e338);\n    }\n\n    if (2 === r.shape.length) {\n      var _e339 = ig(n.bufferSync(r), n.bufferSync(a), i, o);\n\n      return n.makeTensorInfo(_e339.shape, a.dtype, _e339.values);\n    }\n\n    throw new Error(\"Error in denseBincount: input must be at most rank 2, but got rank\".concat(r.shape.length, \".\"));\n  }\n},\n    Ob = {\n  kernelName: \"DepthToSpace\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockSize: a,\n      dataFormat: i\n    } = s;\n    l(\"NHWC\" === i, () => \"Only NHWC dataFormat supported on CPU for depthToSpace. Got \".concat(i)), l(a > 1, () => \"blockSize should be > 1 for depthToSpace, but was: \".concat(a));\n    var o = r.shape[0],\n        u = r.shape[1],\n        c = r.shape[2],\n        h = r.shape[3],\n        d = u * a,\n        p = c * a,\n        f = h / (a * a),\n        g = n.data.get(r.dataId).values,\n        m = new Float32Array(o * d * p * f);\n    var b = 0;\n\n    for (var _e340 = 0; _e340 < o; ++_e340) {\n      for (var _t297 = 0; _t297 < d; ++_t297) {\n        var _n216 = Math.floor(_t297 / a),\n            _s171 = _t297 % a;\n\n        for (var _t298 = 0; _t298 < p; ++_t298) {\n          var _r123 = Math.floor(_t298 / a),\n              _i63 = (_s171 * a + _t298 % a) * f;\n\n          for (var _t299 = 0; _t299 < f; ++_t299) {\n            m[b++] = g[_t299 + _i63 + h * (_r123 + c * (_n216 + u * _e340))];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([o, d, p, f], r.dtype, m);\n  }\n};\n\nfunction Mb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    filter: a\n  } = t,\n      {\n    strides: i,\n    pad: o,\n    dilations: u,\n    dimRoundingMode: c\n  } = s;\n  Bf([r, a], \"depthwiseConv2DNative\");\n  var h = A(r.shape),\n      d = A(a.shape);\n  var p = u;\n  null == p && (p = [1, 1]), l(Ts(i, p), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '\").concat(p, \"'\"));\n  var f = ks(r.shape, a.shape, i, p, o, c, !0),\n      {\n    filterHeight: g,\n    filterWidth: m,\n    dilationHeight: b,\n    dilationWidth: x,\n    padInfo: y\n  } = f,\n      k = y.left,\n      w = y.top,\n      v = f.outChannels / f.inChannels,\n      I = new tt(f.outShape, r.dtype),\n      $ = n.data.get(r.dataId).values,\n      S = n.data.get(a.dataId).values,\n      N = I.values;\n\n  for (var _e341 = 0; _e341 < f.batchSize; ++_e341) {\n    var _t300 = _e341 * h[0],\n        _n217 = _e341 * I.strides[0];\n\n    for (var _e342 = 0; _e342 < f.outHeight; ++_e342) {\n      var _s172 = _n217 + _e342 * I.strides[1],\n          _r124 = _e342 * f.strideHeight - w;\n\n      for (var _e343 = 0; _e343 < g; ++_e343) {\n        var _n218 = _r124 + _e343 * b;\n\n        if (_n218 < 0 || _n218 >= f.inHeight) continue;\n\n        var _a95 = _e343 * d[0],\n            _i64 = _t300 + _n218 * h[1];\n\n        for (var _e344 = 0; _e344 < f.outWidth; ++_e344) {\n          var _t301 = _s172 + _e344 * I.strides[2],\n              _n219 = _e344 * f.strideWidth - k;\n\n          for (var _e345 = 0; _e345 < m; ++_e345) {\n            var _s173 = _n219 + _e345 * x;\n\n            if (_s173 < 0 || _s173 >= f.inWidth) continue;\n\n            var _r125 = _i64 + _s173 * f.inChannels;\n\n            var _o49 = _t301,\n                _l31 = _a95 + _e345 * d[1];\n\n            for (var _e346 = 0; _e346 < f.inChannels; ++_e346) {\n              var _t302 = $[_r125 + _e346];\n\n              for (var _e347 = 0; _e347 < v; ++_e347) {\n                N[_o49 + _e347] += _t302 * S[_l31 + _e347];\n              }\n\n              _o49 += v, _l31 += v;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return n.makeTensorInfo(I.shape, I.dtype, I.values);\n}\n\nvar Lb = {\n  kernelName: \"DepthwiseConv2dNative\",\n  backendName: \"cpu\",\n  kernelFunc: Mb\n},\n    zb = {\n  kernelName: \"DepthwiseConv2dNativeBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s;\n    Bf([r, a], \"depthwiseConv2dNativeBackpropFilter\");\n    var h = ks(r.shape, c, i, o, l, u, !0),\n        {\n      strideHeight: d,\n      strideWidth: p,\n      filterHeight: f,\n      filterWidth: g\n    } = h,\n        m = new tt(h.filterShape, \"float32\"),\n        b = h.padInfo.left,\n        x = h.padInfo.top,\n        y = h.outChannels / h.inChannels,\n        k = n.data.get(r.dataId).values,\n        w = new tt(r.shape, r.dtype, k),\n        v = n.data.get(a.dataId).values,\n        I = new tt(a.shape, a.dtype, v);\n\n    for (var _e348 = 0; _e348 < f; ++_e348) {\n      var _t303 = Math.max(0, Math.ceil((x - _e348) / d)),\n          _n220 = Math.min(h.outHeight, (h.inHeight + x - _e348) / d);\n\n      for (var _s174 = 0; _s174 < g; ++_s174) {\n        var _r126 = Math.max(0, Math.ceil((b - _s174) / p)),\n            _a96 = Math.min(h.outWidth, (h.inWidth + b - _s174) / p);\n\n        for (var _i65 = 0; _i65 < h.outChannels; ++_i65) {\n          var _o50 = Math.trunc(_i65 / y),\n              _l32 = _i65 % y;\n\n          var _u20 = 0;\n\n          for (var _l33 = 0; _l33 < h.batchSize; ++_l33) {\n            for (var _c22 = _t303; _c22 < _n220; ++_c22) {\n              var _t304 = _e348 + _c22 * d - x;\n\n              for (var _e349 = _r126; _e349 < _a96; ++_e349) {\n                _u20 += w.get(_l33, _t304, _s174 + _e349 * p - b, _o50) * I.get(_l33, _c22, _e349, _i65);\n              }\n            }\n          }\n\n          m.set(_u20, _e348, _s174, _o50, _l32);\n        }\n      }\n    }\n\n    return n.makeTensorInfo(m.shape, m.dtype, m.values);\n  }\n},\n    Bb = {\n  kernelName: \"DepthwiseConv2dNativeBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      inputShape: c\n    } = s;\n    Bf([r, a], \"depthwiseConv2DNativeBackpropInput\");\n    var h = A(r.shape),\n        d = A(a.shape),\n        p = ks(c, a.shape, i, o, l, u, !0),\n        f = new tt(p.inShape, \"float32\"),\n        g = f.values,\n        [m, b, x] = f.strides,\n        y = n.data.get(r.dataId).values,\n        [k, w, v] = h,\n        I = n.data.get(a.dataId).values,\n        [$, S, N] = d,\n        {\n      batchSize: C,\n      filterHeight: T,\n      filterWidth: E,\n      inChannels: R,\n      inHeight: F,\n      inWidth: D,\n      outChannels: _,\n      outHeight: O,\n      outWidth: M,\n      strideHeight: L,\n      strideWidth: z\n    } = p,\n        B = T - 1 - p.padInfo.top,\n        P = E - 1 - p.padInfo.left,\n        W = _ / R;\n\n    for (var _e350 = 0; _e350 < C; ++_e350) {\n      for (var _t305 = 0; _t305 < R; ++_t305) {\n        for (var _n221 = 0; _n221 < F; ++_n221) {\n          var _s175 = _n221 - B,\n              _r127 = Math.max(0, Math.ceil(_s175 / L)),\n              _a97 = Math.min(O, (T + _s175) / L);\n\n          for (var _i66 = 0; _i66 < D; ++_i66) {\n            var _o51 = _i66 - P,\n                _l34 = Math.max(0, Math.ceil(_o51 / z)),\n                _u21 = Math.min(M, (E + _o51) / z);\n\n            var _c23 = 0;\n\n            for (var _n222 = _r127; _n222 < _a97; ++_n222) {\n              var _r128 = _n222 * L - _s175;\n\n              for (var _s176 = _l34; _s176 < _u21; ++_s176) {\n                var _a98 = k * _e350 + w * _n222 + v * _s176,\n                    _i67 = $ * (T - 1 - _r128) + S * (E - 1 - (_s176 * z - _o51)) + N * _t305;\n\n                for (var _e351 = 0; _e351 < W; ++_e351) {\n                  _c23 += y[_a98 + (_t305 * W + _e351)] * I[_i67 + _e351];\n                }\n              }\n            }\n\n            g[m * _e350 + b * _n221 + x * _i66 + _t305] = _c23;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(f.shape, f.dtype, f.values);\n  }\n},\n    Pb = {\n  kernelName: \"Diag\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = d(s.shape),\n        a = n.data.get(s.dataId).values,\n        i = pn([r, r], s.dtype),\n        o = i.values;\n\n    for (var _e352 = 0; _e352 < a.length; _e352++) {\n      o[_e352 * r + _e352] = a[_e352];\n    }\n\n    var l = [...s.shape, ...s.shape];\n    return n.makeTensorInfo(l, i.dtype, i.values);\n  }\n},\n    Wb = {\n  kernelName: \"Dilation2D\",\n  backendName: \"cpu\",\n  kernelFunc: _ref13 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref13;\n    var {\n      x: s,\n      filter: r\n    } = e,\n        {\n      strides: a,\n      pad: i,\n      dilations: o\n    } = n,\n        l = t,\n        u = l.data.get(s.dataId).values,\n        c = s.shape.length,\n        h = l.data.get(r.dataId).values,\n        p = r.shape.length,\n        {\n      batchSize: f,\n      inHeight: g,\n      inWidth: m,\n      inChannels: b,\n      outHeight: x,\n      outWidth: y,\n      padInfo: k,\n      strideHeight: w,\n      strideWidth: I,\n      filterHeight: $,\n      filterWidth: S,\n      dilationHeight: N,\n      dilationWidth: C,\n      outShape: T\n    } = bs(s.shape, r.shape, a, i, \"NHWC\", o),\n        E = d(T),\n        R = T.length,\n        F = v(s.dtype, E);\n\n    for (var _e353 = 0; _e353 < f; ++_e353) {\n      for (var _t306 = 0; _t306 < x; ++_t306) {\n        var _n223 = _t306 * w - k.top;\n\n        for (var _a99 = 0; _a99 < y; ++_a99) {\n          var _i68 = _a99 * I - k.left;\n\n          for (var _o52 = 0; _o52 < b; ++_o52) {\n            var _l35 = Number.MIN_SAFE_INTEGER;\n\n            for (var _t307 = 0; _t307 < $; ++_t307) {\n              var _a100 = _n223 + _t307 * N;\n\n              if (_a100 >= 0 && _a100 < g) for (var _n224 = 0; _n224 < S; ++_n224) {\n                var _d14 = _i68 + _n224 * C;\n\n                if (_d14 >= 0 && _d14 < m) {\n                  var _i69 = z([_e353, _a100, _d14, _o52], c, A(s.shape)),\n                      _f9 = z([_t307, _n224, _o52], p, A(r.shape)),\n                      _g15 = u[_i69] + h[_f9];\n\n                  _g15 > _l35 && (_l35 = _g15);\n                }\n              }\n            }\n\n            F[z([_e353, _t306, _a99, _o52], R, A(T))] = _l35;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: l.write(Ve(F, s.dtype), T, s.dtype),\n      shape: T,\n      dtype: s.dtype\n    };\n  }\n},\n    Ub = {\n  kernelName: \"Dilation2DBackpropFilter\",\n  backendName: \"cpu\",\n  kernelFunc: _ref14 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref14;\n    var {\n      x: s,\n      filter: r,\n      dy: a\n    } = e,\n        {\n      strides: i,\n      pad: o,\n      dilations: u\n    } = n,\n        c = t,\n        h = D(s.shape, c.data.get(s.dataId).values),\n        d = D(r.shape, c.data.get(r.dataId).values),\n        {\n      batchSize: p,\n      inHeight: f,\n      inWidth: g,\n      inChannels: m,\n      outHeight: b,\n      outWidth: x,\n      padInfo: y,\n      strideHeight: k,\n      strideWidth: w,\n      filterHeight: v,\n      filterWidth: I,\n      dilationHeight: $,\n      dilationWidth: S,\n      outShape: N\n    } = bs(s.shape, r.shape, i, o, \"NHWC\", u);\n    l(a.rank === N.length, () => \"Error in Dilation2DBackpropFilter, dy must have the same rank as output \".concat(N.length, \", but got \").concat(a.rank));\n    var C = D(N, c.data.get(a.dataId).values),\n        T = M(r.shape, r.dtype);\n\n    for (var _e354 = 0; _e354 < p; ++_e354) {\n      for (var _t308 = 0; _t308 < b; ++_t308) {\n        var _n225 = _t308 * k - y.top;\n\n        for (var _s177 = 0; _s177 < x; ++_s177) {\n          var _r129 = _s177 * w - y.left;\n\n          for (var _a101 = 0; _a101 < m; ++_a101) {\n            var _i70 = Number.MIN_SAFE_INTEGER,\n                _o53 = 0,\n                _l36 = 0;\n\n            for (var _t309 = 0; _t309 < v; ++_t309) {\n              var _s178 = _n225 + _t309 * $;\n\n              if (_s178 >= 0 && _s178 < f) for (var _n226 = 0; _n226 < I; ++_n226) {\n                var _u22 = _r129 + _n226 * S;\n\n                if (_u22 >= 0 && _u22 < g) {\n                  var _r130 = h[_e354][_s178][_u22][_a101] + d[_t309][_n226][_a101];\n\n                  _r130 > _i70 && (_i70 = _r130, _o53 = _t309, _l36 = _n226);\n                }\n              }\n            }\n\n            T[_o53][_l36][_a101] += C[_e354][_t308][_s177][_a101];\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: c.write(Ve(T, s.dtype), r.shape, r.dtype),\n      shape: r.shape,\n      dtype: r.dtype\n    };\n  }\n},\n    Vb = {\n  kernelName: \"Dilation2DBackpropInput\",\n  backendName: \"cpu\",\n  kernelFunc: _ref15 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref15;\n    var {\n      x: s,\n      filter: r,\n      dy: a\n    } = e,\n        {\n      strides: i,\n      pad: o,\n      dilations: u\n    } = n,\n        c = t,\n        h = D(s.shape, c.data.get(s.dataId).values),\n        d = D(r.shape, c.data.get(r.dataId).values),\n        {\n      batchSize: p,\n      inHeight: f,\n      inWidth: g,\n      inChannels: m,\n      outHeight: b,\n      outWidth: x,\n      padInfo: y,\n      strideHeight: k,\n      strideWidth: w,\n      filterHeight: v,\n      filterWidth: I,\n      dilationHeight: $,\n      dilationWidth: S,\n      outShape: N\n    } = bs(s.shape, r.shape, i, o, \"NHWC\", u);\n    l(a.rank === N.length, () => \"Error in Dilation2DBackpropInput, dy must have the same rank as output \".concat(N.length, \", but got \").concat(a.rank));\n    var C = D(N, c.data.get(a.dataId).values),\n        T = M(s.shape, s.dtype);\n\n    for (var _e355 = 0; _e355 < p; ++_e355) {\n      for (var _t310 = 0; _t310 < b; ++_t310) {\n        var _n227 = _t310 * k - y.top;\n\n        for (var _s179 = 0; _s179 < x; ++_s179) {\n          var _r131 = _s179 * w - y.left;\n\n          for (var _a102 = 0; _a102 < m; ++_a102) {\n            var _i71 = Number.MIN_SAFE_INTEGER,\n                _o54 = _n227 < 0 ? 0 : _n227,\n                _l37 = _r131 < 0 ? 0 : _r131;\n\n            for (var _t311 = 0; _t311 < v; ++_t311) {\n              var _s180 = _n227 + _t311 * $;\n\n              if (_s180 >= 0 && _s180 < f) for (var _n228 = 0; _n228 < I; ++_n228) {\n                var _u23 = _r131 + _n228 * S;\n\n                if (_u23 >= 0 && _u23 < g) {\n                  var _r132 = h[_e355][_s180][_u23][_a102] + d[_t311][_n228][_a102];\n\n                  _r132 > _i71 && (_i71 = _r132, _o54 = _s180, _l37 = _u23);\n                }\n              }\n            }\n\n            T[_e355][_o54][_l37][_a102] += C[_e355][_t310][_s179][_a102];\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: c.write(Ve(T, s.dtype), s.shape, s.dtype),\n      shape: s.shape,\n      dtype: s.dtype\n    };\n  }\n};\n\nfunction Gb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    axis: a,\n    keepDims: i\n  } = s;\n  var o;\n  Bf(r, \"sum\"), o = \"bool\" === r.dtype ? Zf({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      dtype: \"int32\"\n    }\n  }) : Kf({\n    inputs: {\n      x: r\n    },\n    backend: n\n  });\n  var l = o.shape.length,\n      u = y(a, o.shape),\n      c = Zr(u, l);\n  var h = u,\n      p = o;\n  null != c && (p = Yg({\n    inputs: {\n      x: o\n    },\n    backend: n,\n    attrs: {\n      perm: c\n    }\n  }), h = ea(h.length, l)), Jr(\"sum\", h, p.shape.length);\n  var [f, g] = Xr(p.shape, h);\n  var m = jf(n, f, pt(p.dtype, \"int32\"));\n  var b = d(g),\n      x = n.data.get(m.dataId).values,\n      k = n.data.get(p.dataId).values;\n\n  for (var _e356 = 0; _e356 < x.length; ++_e356) {\n    var _t312 = _e356 * b;\n\n    var _n229 = 0;\n\n    for (var _e357 = 0; _e357 < b; ++_e357) {\n      _n229 += k[_t312 + _e357];\n    }\n\n    x[_e356] = _n229;\n  }\n\n  if (i) {\n    var _e358 = m;\n    m = Vm({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Yr(m.shape, u)\n      }\n    }), n.disposeIntermediateTensorInfo(_e358);\n  }\n\n  return n.disposeIntermediateTensorInfo(o), null != c && n.disposeIntermediateTensorInfo(p), m;\n}\n\nvar Hb = {\n  kernelName: \"Sum\",\n  backendName: \"cpu\",\n  kernelFunc: Gb\n},\n    qb = {\n  kernelName: \"Einsum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      equation: r\n    } = s,\n        a = t,\n        {\n      allDims: i,\n      summedDims: o,\n      idDims: l\n    } = qo(r, a.length);\n    Ko(i.length, l, a);\n    var {\n      path: u,\n      steps: c\n    } = Xo(o, l),\n        h = c.length;\n    var d = null,\n        f = i.length;\n    var g = [];\n\n    for (var _e359 = 0; _e359 < h; ++_e359) {\n      for (var _t313 of c[_e359]) {\n        var {\n          permutationIndices: _e360,\n          expandDims: _s181\n        } = jo(f, l[_t313]);\n\n        var _r133 = void 0;\n\n        Yo(_e360) ? _r133 = a[_t313] : (_r133 = Yg({\n          inputs: {\n            x: a[_t313]\n          },\n          backend: n,\n          attrs: {\n            perm: _e360\n          }\n        }), g.push(_r133));\n\n        var _i72 = _r133.shape.slice();\n\n        for (var _e361 = 0; _e361 < _s181.length; ++_e361) {\n          _i72.splice(_s181[_e361], 0, 1);\n        }\n\n        p(_r133.shape, _i72) || (_r133 = Vm({\n          inputs: {\n            x: _r133\n          },\n          backend: n,\n          attrs: {\n            shape: _i72\n          }\n        }), g.push(_r133)), null === d ? d = _r133 : (d = Vg({\n          inputs: {\n            a: _r133,\n            b: d\n          },\n          backend: n\n        }), g.push(d));\n      }\n\n      _e359 < h - 1 && (u[_e359] >= 0 && (d = Gb({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          axis: u[_e359] - (i.length - f),\n          keepDims: !1\n        }\n      }), g.push(d)), f--);\n    }\n\n    for (var _e362 of g) {\n      _e362 !== d && n.disposeIntermediateTensorInfo(_e362);\n    }\n\n    return d;\n  }\n},\n    jb = {\n  kernelName: \"EluGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      dy: s,\n      y: r\n    } = t;\n    Bf([s, r], \"eluGrad\");\n    var a = new Float32Array(d(r.shape)),\n        i = n.data.get(r.dataId).values,\n        o = n.data.get(s.dataId).values;\n\n    for (var _e363 = 0; _e363 < i.length; ++_e363) {\n      var _t314 = i[_e363];\n      a[_e363] = _t314 >= 1 ? o[_e363] : o[_e363] * (_t314 + 1);\n    }\n\n    return n.makeTensorInfo(r.shape, \"float32\", a);\n  }\n},\n    Kb = {\n  kernelName: \"Erf\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Erf\", e => {\n    var t = Math.sign(e),\n        n = Math.abs(e),\n        s = 1 / (1 + .3275911 * n);\n    return t * (1 - ((((1.061405429 * s - 1.453152027) * s + 1.421413741) * s - .284496736) * s + .254829592) * s * Math.exp(-n * n));\n  })\n};\n\nfunction Xb(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    input: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = r.shape.length,\n      o = r.shape.slice();\n  var u = a;\n  return a < 0 && (l(-(i + 1) <= a, () => \"Axis must be in the interval [\".concat(-(i + 1), \", \").concat(i, \"]\")), u = i + a + 1), o.splice(u, 0, 1), Vm({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: o\n    }\n  });\n}\n\nvar Yb = {\n  kernelName: \"ExpandDims\",\n  backendName: \"cpu\",\n  kernelFunc: Xb\n},\n    Jb = eg(\"RealDiv\", Gf((e, t) => e / t)),\n    Zb = {\n  kernelName: \"RealDiv\",\n  backendName: \"cpu\",\n  kernelFunc: Jb\n};\n\nfunction Qb(e, t, n) {\n  var s = e.shape,\n      r = s[0],\n      a = s[1],\n      i = n.data.get(e.dataId),\n      o = i.complexTensorInfos.real,\n      l = i.complexTensorInfos.imag,\n      u = [r, a],\n      c = d(u),\n      h = w(\"float32\", c),\n      p = w(\"float32\", c);\n\n  for (var _e364 = 0; _e364 < r; _e364++) {\n    var _s182 = om({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        begin: [_e364, 0],\n        size: [1, a]\n      }\n    }),\n        _r134 = om({\n      inputs: {\n        x: l\n      },\n      backend: n,\n      attrs: {\n        begin: [_e364, 0],\n        size: [1, a]\n      }\n    }),\n        _i73 = Hf({\n      inputs: {\n        real: _s182,\n        imag: _r134\n      },\n      backend: n\n    }),\n        {\n      real: _u24,\n      imag: _c24\n    } = ex(_i73, t, n),\n        _d15 = Lo(_u24, _c24);\n\n    for (var _t315 = 0; _t315 < a; _t315++) {\n      var _n230 = Wo(_d15, _t315);\n\n      h[_e364 * a + _t315] = _n230.real, p[_e364 * a + _t315] = _n230.imag;\n    }\n\n    n.disposeIntermediateTensorInfo(_s182), n.disposeIntermediateTensorInfo(_r134), n.disposeIntermediateTensorInfo(_i73);\n  }\n\n  var f = n.makeTensorInfo(u, \"float32\", h),\n      g = n.makeTensorInfo(u, \"float32\", p),\n      m = Hf({\n    inputs: {\n      real: f,\n      imag: g\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n}\n\nfunction ex(e, t, n) {\n  var s = d(e.shape),\n      r = n.data.get(e.dataId),\n      a = n.data.get(r.complexTensorInfos.real.dataId).values,\n      i = n.data.get(r.complexTensorInfos.imag.dataId).values;\n\n  if (0 == ((o = s) & o - 1)) {\n    var _r135 = tx(a, i, s, t, n),\n        _o55 = [e.shape[0], e.shape[1]];\n\n    if (t) {\n      var _e365 = n.makeTensorInfo(_o55, \"float32\", _r135.real),\n          _t316 = n.makeTensorInfo(_o55, \"float32\", _r135.imag),\n          _a103 = n.makeTensorInfo([], \"float32\", Ue(s, \"float32\")),\n          _i74 = Kf({\n        inputs: {\n          x: _a103\n        },\n        backend: n\n      }),\n          _l38 = Zb.kernelFunc({\n        inputs: {\n          a: _e365,\n          b: _a103\n        },\n        backend: n\n      }),\n          _u25 = Zb.kernelFunc({\n        inputs: {\n          a: _t316,\n          b: _i74\n        },\n        backend: n\n      }),\n          _c25 = n.data.get(_l38.dataId).values,\n          _h13 = n.data.get(_u25.dataId).values;\n\n      return n.disposeIntermediateTensorInfo(_e365), n.disposeIntermediateTensorInfo(_t316), n.disposeIntermediateTensorInfo(_a103), n.disposeIntermediateTensorInfo(_i74), n.disposeIntermediateTensorInfo(_l38), n.disposeIntermediateTensorInfo(_u25), {\n        real: _c25,\n        imag: _h13\n      };\n    }\n\n    return _r135;\n  }\n\n  return zo(function (e, t, n) {\n    var s = new Float32Array(2 * t);\n\n    for (var _r136 = 0; _r136 < t; _r136++) {\n      var _a104 = 0,\n          _i75 = 0;\n\n      for (var _s183 = 0; _s183 < t; _s183++) {\n        var _o56 = Go(_r136 * _s183, t, n),\n            _l39 = Wo(e, _s183);\n\n        _a104 += _l39.real * _o56.real - _l39.imag * _o56.imag, _i75 += _l39.real * _o56.imag + _l39.imag * _o56.real;\n      }\n\n      n && (_a104 /= t, _i75 /= t), Uo(s, _a104, _i75, _r136);\n    }\n\n    return s;\n  }(Lo(a, i), s, t));\n  var o;\n}\n\nfunction tx(e, t, n, s, r) {\n  if (1 === n) return {\n    real: e,\n    imag: t\n  };\n\n  var a = Lo(e, t),\n      i = n / 2,\n      o = Bo(a),\n      l = o.real,\n      u = o.imag,\n      c = [l.length],\n      h = r.makeTensorInfo(c, \"float32\", l),\n      d = r.makeTensorInfo(c, \"float32\", u),\n      p = Hf({\n    inputs: {\n      real: h,\n      imag: d\n    },\n    backend: r\n  }),\n      f = Po(a),\n      g = f.real,\n      m = f.imag,\n      b = [g.length],\n      x = r.makeTensorInfo(b, \"float32\", g),\n      y = r.makeTensorInfo(b, \"float32\", m),\n      k = Hf({\n    inputs: {\n      real: x,\n      imag: y\n    },\n    backend: r\n  }),\n      w = tx(l, u, i, s, r),\n      v = w.real,\n      I = w.imag,\n      $ = [v.length],\n      S = r.makeTensorInfo($, \"float32\", v),\n      N = r.makeTensorInfo($, \"float32\", I),\n      C = Hf({\n    inputs: {\n      real: S,\n      imag: N\n    },\n    backend: r\n  }),\n      T = tx(g, m, i, s, r),\n      E = T.real,\n      R = T.imag,\n      A = [E.length],\n      F = r.makeTensorInfo(A, \"float32\", E),\n      D = r.makeTensorInfo(A, \"float32\", R),\n      _ = Hf({\n    inputs: {\n      real: F,\n      imag: D\n    },\n    backend: r\n  }),\n      O = Vo(n, s),\n      M = [O.real.length],\n      L = r.makeTensorInfo(M, \"float32\", O.real),\n      z = r.makeTensorInfo(M, \"float32\", O.imag),\n      B = Hf({\n    inputs: {\n      real: L,\n      imag: z\n    },\n    backend: r\n  }),\n      P = Vg({\n    inputs: {\n      a: B,\n      b: _\n    },\n    backend: r\n  }),\n      W = sg({\n    inputs: {\n      a: C,\n      b: P\n    },\n    backend: r\n  }),\n      U = Im({\n    inputs: {\n      a: C,\n      b: P\n    },\n    backend: r\n  }),\n      V = Yf({\n    inputs: {\n      input: W\n    },\n    backend: r\n  }),\n      G = Yf({\n    inputs: {\n      input: U\n    },\n    backend: r\n  }),\n      H = yb({\n    inputs: {\n      input: W\n    },\n    backend: r\n  }),\n      q = yb({\n    inputs: {\n      input: U\n    },\n    backend: r\n  }),\n      j = wb({\n    inputs: [V, G],\n    backend: r,\n    attrs: {\n      axis: 0\n    }\n  }),\n      K = wb({\n    inputs: [H, q],\n    backend: r,\n    attrs: {\n      axis: 0\n    }\n  }),\n      X = r.data.get(j.dataId).values,\n      Y = r.data.get(K.dataId).values;\n\n  return r.disposeIntermediateTensorInfo(h), r.disposeIntermediateTensorInfo(d), r.disposeIntermediateTensorInfo(p), r.disposeIntermediateTensorInfo(x), r.disposeIntermediateTensorInfo(y), r.disposeIntermediateTensorInfo(k), r.disposeIntermediateTensorInfo(S), r.disposeIntermediateTensorInfo(N), r.disposeIntermediateTensorInfo(C), r.disposeIntermediateTensorInfo(F), r.disposeIntermediateTensorInfo(D), r.disposeIntermediateTensorInfo(_), r.disposeIntermediateTensorInfo(L), r.disposeIntermediateTensorInfo(z), r.disposeIntermediateTensorInfo(B), r.disposeIntermediateTensorInfo(P), r.disposeIntermediateTensorInfo(W), r.disposeIntermediateTensorInfo(U), r.disposeIntermediateTensorInfo(V), r.disposeIntermediateTensorInfo(H), r.disposeIntermediateTensorInfo(G), r.disposeIntermediateTensorInfo(q), r.disposeIntermediateTensorInfo(j), r.disposeIntermediateTensorInfo(K), {\n    real: X,\n    imag: Y\n  };\n}\n\nvar nx = {\n  kernelName: \"FFT\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t,\n        r = d(s.shape),\n        a = s.shape[s.shape.length - 1],\n        i = Vm({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [r / a, a]\n      }\n    }),\n        o = Qb(i, !1, n),\n        l = Vm({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        shape: s.shape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(o), l;\n  }\n};\n\nfunction sx(e) {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    shape: s,\n    value: r,\n    dtype: a\n  } = n,\n      i = a || T(r),\n      o = v(i, d(s));\n  return function (e, t, n) {\n    e.fill(t);\n  }(o, r), t.makeTensorInfo(s, i, o);\n}\n\nvar rx = {\n  kernelName: \"Fill\",\n  backendName: \"cpu\",\n  kernelFunc: sx\n},\n    ax = {\n  kernelName: \"FlipLeftRight\",\n  backendName: \"cpu\",\n  kernelFunc: _ref16 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref16;\n    var {\n      image: n\n    } = e,\n        s = t,\n        r = w(n.dtype, d(n.shape)),\n        [a, i, o, l] = n.shape,\n        u = s.data.get(n.dataId).values;\n\n    for (var _e366 = 0; _e366 < a; _e366++) {\n      var _t317 = _e366 * o * i * l;\n\n      for (var _e367 = 0; _e367 < i; _e367++) {\n        var _n231 = _e367 * (o * l);\n\n        for (var _e368 = 0; _e368 < o; _e368++) {\n          var _s184 = _e368 * l;\n\n          for (var _a105 = 0; _a105 < l; _a105++) {\n            var _i76 = Math.round(o - _e368 - 1),\n                _c26 = _t317 + _n231 + _s184 + _a105;\n\n            var _h14 = u[_c26];\n            _i76 >= 0 && _i76 < o && (_h14 = u[_t317 + _n231 + _i76 * l + _a105]), r[_c26] = _h14;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: s.write(r, n.shape, n.dtype),\n      shape: n.shape,\n      dtype: n.dtype\n    };\n  }\n},\n    ix = {\n  kernelName: \"FloorDiv\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"FloorDiv\", Gf((e, t) => Math.floor(e / t)), null, \"int32\")\n},\n    ox = {\n  kernelName: \"FusedConv2D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s;\n    var g = Ib({\n      inputs: {\n        x: r,\n        filter: a\n      },\n      backend: n,\n      attrs: {\n        strides: l,\n        pad: u,\n        dataFormat: c,\n        dilations: h,\n        dimRoundingMode: d\n      }\n    });\n\n    if (i) {\n      var _e369 = g;\n      g = sg({\n        inputs: {\n          a: g,\n          b: i\n        },\n        backend: n\n      }), n.disposeIntermediateTensorInfo(_e369);\n    }\n\n    if (p) {\n      var _e370 = g;\n      g = Um(n, g, p, o, f), n.disposeIntermediateTensorInfo(_e370);\n    }\n\n    return g;\n  }\n},\n    lx = {\n  kernelName: \"FusedDepthwiseConv2D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s;\n    var g = Mb({\n      inputs: {\n        x: r,\n        filter: a\n      },\n      backend: n,\n      attrs: {\n        strides: l,\n        pad: u,\n        dataFormat: c,\n        dilations: h,\n        dimRoundingMode: d\n      }\n    });\n\n    if (i) {\n      var _e371 = g;\n      g = sg({\n        inputs: {\n          a: g,\n          b: i\n        },\n        backend: n\n      }), n.disposeIntermediateTensorInfo(_e371);\n    }\n\n    if (p) {\n      var _e372 = g;\n      g = Um(n, g, p, o, f), n.disposeIntermediateTensorInfo(_e372);\n    }\n\n    return g;\n  }\n},\n    ux = {\n  kernelName: \"GatherNd\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      params: s,\n      indices: r\n    } = t,\n        a = d(s.shape),\n        i = r.shape,\n        o = i[i.length - 1],\n        [l, u, c, h] = Nn(s, r);\n    if (0 === u) return n.makeTensorInfo(l, s.dtype, []);\n    var p = Ig(n.data.get(r.dataId).values, n.bufferSync(s), s.dtype, u, o, c, h, s.shape, a);\n    return n.makeTensorInfo(l, s.dtype, p.values);\n  }\n},\n    cx = {\n  kernelName: \"GatherV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      indices: a\n    } = t,\n        {\n      axis: i,\n      batchDims: o\n    } = s;\n    Bf([r, a], \"gatherV2\");\n    var l = o;\n    null == o && (l = 0);\n    var u = d(a.shape),\n        c = tl(r, a, y(i, r.shape)[0], l),\n        h = Vm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [c.batchSize, c.outerSize, c.dimSize, c.sliceSize]\n      }\n    }),\n        p = Vm({\n      inputs: {\n        x: a\n      },\n      backend: n,\n      attrs: {\n        shape: [c.batchSize, u / c.batchSize]\n      }\n    }),\n        f = [c.batchSize, c.outerSize, u / c.batchSize, c.sliceSize],\n        g = n.bufferSync(p),\n        m = $g(n.bufferSync(h), g, f);\n    return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(p), n.makeTensorInfo(c.outputShape, m.dtype, m.values);\n  }\n},\n    hx = {\n  kernelName: \"IFFT\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t,\n        r = d(s.shape),\n        a = s.shape[s.shape.length - 1],\n        i = Vm({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [r / a, a]\n      }\n    }),\n        o = Qb(i, !0, n),\n        l = Vm({\n      inputs: {\n        x: o\n      },\n      backend: n,\n      attrs: {\n        shape: s.shape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(o), l;\n  }\n},\n    dx = {\n  kernelName: \"IsFinite\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"IsFinite\", e => Number.isFinite(e) ? 1 : 0, \"bool\")\n},\n    px = {\n  kernelName: \"IsInf\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"IsInf\", e => Infinity === Math.abs(e) ? 1 : 0, \"bool\")\n},\n    fx = {\n  kernelName: \"IsNan\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"IsNan\", e => Number.isNaN(e) ? 1 : 0, \"bool\")\n},\n    gx = {\n  kernelName: \"LinSpace\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      num: a\n    } = n,\n        i = Dg(s, r, a);\n    return t.makeTensorInfo([i.length], \"float32\", i);\n  }\n},\n    mx = {\n  kernelName: \"Log1p\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Log1p\", e => Math.log1p(e))\n},\n    bx = {\n  kernelName: \"LogicalAnd\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"LogicalAnd\", Gf((e, t) => e && t), null, \"bool\")\n},\n    xx = {\n  kernelName: \"LogicalNot\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"LogicalNot\", e => e ? 0 : 1, \"bool\")\n},\n    yx = {\n  kernelName: \"LogicalOr\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"LogicalOr\", Gf((e, t) => e || t), null, \"bool\")\n},\n    kx = {\n  kernelName: \"LRN\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = s;\n    Bf(r, \"LRN\");\n    var u = r.shape[3],\n        c = u - 1,\n        h = n.data.get(r.dataId).values,\n        p = d(r.shape),\n        f = new Float32Array(p);\n\n    function g(e) {\n      var t = e % u;\n      var n = e - t + Math.max(0, t - a);\n      var s = e - t + Math.min(t + a, c);\n      var r = 0;\n\n      for (; n <= s; n++) {\n        var _e373 = h[n];\n        r += _e373 * _e373;\n      }\n\n      return r;\n    }\n\n    for (var _e374 = 0; _e374 < p; _e374++) {\n      var _t318 = g(_e374),\n          _n232 = h[_e374] * Math.pow(i + o * _t318, -l);\n\n      f[_e374] = _n232;\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, f);\n  }\n},\n    wx = {\n  kernelName: \"LRNGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      y: a,\n      dy: i\n    } = t,\n        {\n      depthRadius: o,\n      bias: l,\n      alpha: u,\n      beta: c\n    } = s;\n    Bf(i, \"LRNGrad\");\n    var h = d(i.shape),\n        p = i.shape[3],\n        f = n.data.get(i.dataId).values,\n        g = n.data.get(r.dataId).values,\n        m = n.data.get(a.dataId).values,\n        b = new Float32Array(h),\n        x = h;\n\n    for (var _e375 = 0; _e375 < x; _e375++) {\n      var _t319 = _e375 % p,\n          _n233 = _e375 - _t319 + Math.max(0, _t319 - o),\n          _s185 = _e375 - _t319 + Math.min(p, _t319 + o + 1);\n\n      var _r137 = 0;\n\n      for (var _e376 = _n233; _e376 < _s185; _e376++) {\n        _r137 += Math.pow(g[_e376], 2);\n      }\n\n      _r137 = u * _r137 + l;\n\n      for (var _t320 = _n233; _t320 < _s185; _t320++) {\n        var _n234 = -2 * u * c * g[_t320] * m[_e375] / _r137;\n\n        _e375 === _t320 && (_n234 += Math.pow(_r137, -c)), _n234 *= f[_e375], b[_t320] += _n234;\n      }\n    }\n\n    return n.makeTensorInfo(i.shape, r.dtype, b);\n  }\n};\n\nfunction vx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reductionIndices: a,\n    keepDims: i\n  } = s,\n      o = n;\n  var l = r.shape;\n  var u = l.length,\n      c = y(a, l);\n  var h = c;\n  var p = Zr(h, u);\n  var f = o.data.get(r.dataId).values;\n\n  if (null != p) {\n    var _e377 = new Array(u);\n\n    for (var _t321 = 0; _t321 < _e377.length; _t321++) {\n      _e377[_t321] = l[p[_t321]];\n    }\n\n    f = Xg(f, l, r.dtype, p, _e377), h = ea(h.length, u), l = _e377;\n  }\n\n  Bf(r, \"max\"), Jr(\"max\", h, u);\n  var [g, m] = Xr(l, h),\n      b = Mg(f, d(m), g, r.dtype),\n      x = o.write(b, g, r.dtype);\n  var k = g;\n  return i && (k = Yr(g, c)), {\n    dataId: x,\n    shape: k,\n    dtype: r.dtype\n  };\n}\n\nvar Ix = {\n  kernelName: \"Max\",\n  backendName: \"cpu\",\n  kernelFunc: vx\n},\n    $x = {\n  kernelName: \"MaxPool\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    Bf(r, \"maxPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ts(i, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = xs(r.shape, a, i, 1, o, u);\n    var h;\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) h = Kf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });else {\n      var _e378 = n.data.get(r.dataId).values,\n          _t322 = A(r.shape),\n          _s186 = ib(_e378, 0, r.dtype, _t322, c, \"max\");\n\n      h = n.makeTensorInfo(c.outShape, r.dtype, _s186.values);\n    }\n    return h;\n  }\n},\n    Sx = {\n  kernelName: \"MaxPool3D\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s;\n    Bf(r, \"maxPool3d\");\n    var c = ys(r.shape, a, i, 1, o, l, u),\n        h = lb(n.data.get(r.dataId).values, 0, r.dtype, A(r.shape), c, \"max\");\n    return n.makeTensorInfo(h.shape, \"float32\", h.values);\n  }\n},\n    Nx = {\n  kernelName: \"MaxPool3DGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        {\n      filterSize: i,\n      strides: o,\n      pad: l,\n      dimRoundingMode: u\n    } = s;\n    Bf([r, a], \"maxPool3DGrad\");\n\n    var c = ys(a.shape, i, o, 1, l, u),\n        h = function (e, t) {\n      var n = pn(t.outShape, \"int32\"),\n          s = t.strideDepth,\n          r = t.strideHeight,\n          a = t.strideWidth,\n          i = t.dilationDepth,\n          o = t.dilationHeight,\n          l = t.dilationWidth,\n          u = t.effectiveFilterDepth,\n          c = t.effectiveFilterHeight,\n          h = t.effectiveFilterWidth,\n          d = t.padInfo.front,\n          p = t.padInfo.top,\n          f = t.padInfo.left;\n\n      for (var _g16 = 0; _g16 < t.batchSize; ++_g16) {\n        for (var _m11 = 0; _m11 < t.inChannels; ++_m11) {\n          for (var _b11 = 0; _b11 < t.outDepth; ++_b11) {\n            var _x54 = _b11 * s - d;\n\n            var _y9 = _x54;\n\n            for (; _y9 < 0;) {\n              _y9 += i;\n            }\n\n            var _k7 = Math.min(t.inDepth, u + _x54);\n\n            for (var _s187 = 0; _s187 < t.outHeight; ++_s187) {\n              var _u26 = _s187 * r - p;\n\n              var _d16 = _u26;\n\n              for (; _d16 < 0;) {\n                _d16 += o;\n              }\n\n              var _w7 = Math.min(t.inHeight, c + _u26);\n\n              for (var _r138 = 0; _r138 < t.outWidth; ++_r138) {\n                var _p12 = _r138 * a - f;\n\n                var _v5 = _p12;\n\n                for (; _v5 < 0;) {\n                  _v5 += l;\n                }\n\n                var _I4 = Math.min(t.inWidth, h + _p12);\n\n                var _$2 = Number.NEGATIVE_INFINITY,\n                    _S4 = -1;\n\n                for (var _t323 = _y9; _t323 < _k7; _t323 += i) {\n                  var _n235 = _t323 - _x54;\n\n                  for (var _s188 = _d16; _s188 < _w7; _s188 += o) {\n                    var _r139 = _s188 - _u26;\n\n                    for (var _a106 = _v5; _a106 < _I4; _a106 += l) {\n                      var _i77 = _a106 - _p12,\n                          _o57 = e.get(_g16, _t323, _s188, _a106, _m11);\n\n                      _o57 >= _$2 && (_$2 = _o57, _S4 = _n235 * c * h + _r139 * c + _i77);\n                    }\n                  }\n                }\n\n                n.set(_S4, _g16, _b11, _s187, _r138, _m11);\n              }\n            }\n          }\n        }\n      }\n\n      return n;\n    }(n.bufferSync(a), c),\n        d = c.strideDepth,\n        p = c.strideHeight,\n        f = c.strideWidth,\n        g = c.dilationDepth,\n        m = c.dilationHeight,\n        b = c.dilationWidth,\n        x = c.effectiveFilterDepth,\n        y = c.effectiveFilterHeight,\n        k = c.effectiveFilterWidth,\n        w = x - 1 - c.padInfo.front,\n        v = k - 1 - c.padInfo.left,\n        I = y - 1 - c.padInfo.top,\n        $ = pn(a.shape, \"float32\"),\n        S = n.bufferSync(r);\n\n    for (var _e379 = 0; _e379 < c.batchSize; ++_e379) {\n      for (var _t324 = 0; _t324 < c.inChannels; ++_t324) {\n        for (var _n236 = 0; _n236 < c.inDepth; ++_n236) {\n          for (var _s189 = 0; _s189 < c.inHeight; ++_s189) {\n            for (var _r140 = 0; _r140 < c.inWidth; ++_r140) {\n              var _a107 = _n236 - w,\n                  _i78 = _s189 - I,\n                  _o58 = _r140 - v;\n\n              var _l40 = 0;\n\n              for (var _n237 = 0; _n237 < x; _n237 += g) {\n                var _s190 = (_a107 + _n237) / d;\n\n                if (!(_s190 < 0 || _s190 >= c.outDepth || Math.floor(_s190) !== _s190)) for (var _r141 = 0; _r141 < y; _r141 += m) {\n                  var _a108 = (_i78 + _r141) / p;\n\n                  if (!(_a108 < 0 || _a108 >= c.outHeight || Math.floor(_a108) !== _a108)) for (var _i79 = 0; _i79 < k; _i79 += b) {\n                    var _u27 = (_o58 + _i79) / f;\n\n                    if (_u27 < 0 || _u27 >= c.outWidth || Math.floor(_u27) !== _u27) continue;\n\n                    var _d17 = x * y * k - 1 - h.get(_e379, _s190, _a108, _u27, _t324) === _n237 * y * k + _r141 * k + _i79 ? 1 : 0;\n\n                    0 !== _d17 && (_l40 += S.get(_e379, _s190, _a108, _u27, _t324) * _d17);\n                  }\n                }\n              }\n\n              $.set(_l40, _e379, _n236, _s189, _r140, _t324);\n            }\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo($.shape, $.dtype, $.values);\n  }\n},\n    Cx = {\n  kernelName: \"MaxPoolGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a,\n      output: i\n    } = t,\n        o = a;\n    Bf([a, i], \"maxPoolGrad\");\n    var {\n      filterSize: l,\n      strides: u,\n      pad: c,\n      dimRoundingMode: h\n    } = s,\n        d = xs(o.shape, l, u, 1, c, h),\n        p = n.data.get(o.dataId).values,\n        f = pn(d.outShape, o.dtype, ob(p, o.shape, o.dtype, d).values),\n        g = d.strideHeight,\n        m = d.strideWidth,\n        b = d.dilationHeight,\n        x = d.dilationWidth,\n        y = d.effectiveFilterHeight,\n        k = d.effectiveFilterWidth,\n        w = k - 1 - d.padInfo.left,\n        v = y - 1 - d.padInfo.top,\n        I = pn(o.shape, \"float32\"),\n        $ = n.data.get(r.dataId).values,\n        S = pn(r.shape, \"float32\", $);\n\n    for (var _e380 = 0; _e380 < d.batchSize; ++_e380) {\n      for (var _t325 = 0; _t325 < d.inChannels; ++_t325) {\n        for (var _n238 = 0; _n238 < d.inHeight; ++_n238) {\n          for (var _s191 = 0; _s191 < d.inWidth; ++_s191) {\n            var _r142 = _n238 - v,\n                _a109 = _s191 - w;\n\n            var _i80 = 0;\n\n            for (var _n239 = 0; _n239 < y; _n239 += b) {\n              var _s192 = (_r142 + _n239) / g;\n\n              if (!(_s192 < 0 || _s192 >= d.outHeight || Math.floor(_s192) !== _s192)) for (var _r143 = 0; _r143 < k; _r143 += x) {\n                var _o59 = (_a109 + _r143) / m;\n\n                if (_o59 < 0 || _o59 >= d.outWidth || Math.floor(_o59) !== _o59) continue;\n\n                var _l41 = y * k - 1 - f.get(_e380, _s192, _o59, _t325) === _n239 * k + _r143 ? 1 : 0;\n\n                0 !== _l41 && (_i80 += S.get(_e380, _s192, _o59, _t325) * _l41);\n              }\n            }\n\n            I.set(_i80, _e380, _n238, _s191, _t325);\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(I.shape, I.dtype, I.values);\n  }\n},\n    Tx = {\n  kernelName: \"MaxPoolWithArgmax\",\n  backendName: \"cpu\",\n  kernelFunc: _ref17 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref17;\n    var {\n      x: s\n    } = e,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      includeBatchInIndex: o\n    } = t,\n        l = n;\n    Bf(s, \"MaxPoolWithArgmax\");\n\n    var u = l.data.get(s.dataId).values,\n        c = xs(s.shape, r, a, [1, 1], i),\n        [h, d] = function (e, t, n, s, r) {\n      var a = ib(e, 0, n, A(t), r, \"max\"),\n          i = ob(e, t, n, r, !0, s);\n      return [a.values, i.values];\n    }(u, s.shape, s.dtype, o, c),\n        p = l.write(h, c.outShape, s.dtype),\n        f = l.write(d, c.outShape, s.dtype);\n\n    return [{\n      dataId: p,\n      shape: c.outShape,\n      dtype: s.dtype\n    }, {\n      dataId: f,\n      shape: c.outShape,\n      dtype: \"int32\"\n    }];\n  }\n},\n    Ex = {\n  kernelName: \"Mean\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = y(a, r.shape),\n        l = d(Xr(r.shape, o)[1]),\n        u = [],\n        c = n.makeTensorInfo([], \"float32\", new Float32Array([l]));\n    u.push(c);\n    var h = Zf({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        dtype: \"float32\"\n      }\n    });\n    u.push(h);\n    var p = Jb({\n      inputs: {\n        a: h,\n        b: c\n      },\n      backend: n\n    });\n    u.push(p);\n    var f = Gb({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        axis: a,\n        keepDims: i\n      }\n    });\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), f;\n  }\n},\n    Rx = {\n  kernelName: \"Min\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s;\n    Bf(r, \"min\");\n    var o = y(a, r.shape);\n    var l = o;\n    var u = Zr(l, r.shape.length);\n    var c = r;\n    null != u && (c = Yg({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }), l = ea(l.length, r.shape.length)), Jr(\"min\", l, c.shape.length);\n    var [h, p] = Xr(c.shape, l),\n        f = d(p),\n        g = O(d(h), c.dtype),\n        m = n.data.get(c.dataId).values;\n\n    for (var _e381 = 0; _e381 < g.length; ++_e381) {\n      var _t326 = _e381 * f;\n\n      var _n240 = m[_t326];\n\n      for (var _e382 = 0; _e382 < f; ++_e382) {\n        var _s193 = m[_t326 + _e382];\n        (Number.isNaN(_s193) || _s193 < _n240) && (_n240 = _s193);\n      }\n\n      g[_e381] = _n240;\n    }\n\n    null != u && n.disposeIntermediateTensorInfo(c);\n    var b = n.makeTensorInfo(h, c.dtype, g);\n\n    if (i) {\n      var _e383 = Vm({\n        inputs: {\n          x: b\n        },\n        backend: n,\n        attrs: {\n          shape: Yr(h, o)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(b), _e383;\n    }\n\n    return b;\n  }\n},\n    Ax = {\n  kernelName: \"MirrorPad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      paddings: a,\n      mode: i\n    } = s;\n    Bf(r, \"mirrorPad\");\n    var o = a.map((e, t) => e[0] + r.shape[t] + e[1]),\n        l = a.map(e => e[0]),\n        u = a.map((e, t) => e[0] + r.shape[t]),\n        c = \"reflect\" === i ? 0 : 1,\n        h = n.data.get(r.dataId).values,\n        p = r.shape.length,\n        f = A(r.shape),\n        g = d(o),\n        m = o.length,\n        b = A(o),\n        x = w(r.dtype, g);\n\n    for (var _e384 = 0; _e384 < g; _e384++) {\n      var _t327 = B(_e384, m, b);\n\n      for (var _e385 = 0; _e385 < m; _e385++) {\n        _t327[_e385] < l[_e385] ? _t327[_e385] = 2 * l[_e385] - _t327[_e385] - c : _t327[_e385] >= u[_e385] && (_t327[_e385] = 2 * (u[_e385] - 1) - _t327[_e385] + c);\n      }\n\n      _t327 = _t327.map((e, t) => e - l[t]);\n\n      var _n241 = z(_t327, p, f);\n\n      x[_e384] = h[_n241];\n    }\n\n    return {\n      dataId: n.write(x, o, r.dtype),\n      shape: o,\n      dtype: r.dtype\n    };\n  }\n},\n    Fx = {\n  kernelName: \"Mod\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Mod\", Gf((e, t) => {\n    var n = e % t;\n    return e < 0 && t < 0 || e >= 0 && t >= 0 ? n : (n + t) % t;\n  }))\n};\n\nfunction Dx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    logits: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = r.shape.length;\n  var o = a;\n  if (-1 === o && (o = i - 1), o !== i - 1) throw Error(\"Softmax along a non-last dimension is not yet supported. Logits was rank \".concat(i, \" and dim was \").concat(o));\n  var l = y([o], r.shape),\n      u = vx({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      reductionIndices: l,\n      keepDims: !1\n    }\n  }),\n      c = Yr(u.shape, l),\n      h = Vm({\n    inputs: {\n      x: u\n    },\n    backend: n,\n    attrs: {\n      shape: c\n    }\n  }),\n      d = Im({\n    inputs: {\n      a: r,\n      b: h\n    },\n    backend: n\n  }),\n      p = bg({\n    inputs: {\n      x: d\n    },\n    backend: n\n  }),\n      f = Gb({\n    inputs: {\n      x: p\n    },\n    backend: n,\n    attrs: {\n      axis: l,\n      keepDims: !1\n    }\n  }),\n      g = Vm({\n    inputs: {\n      x: f\n    },\n    backend: n,\n    attrs: {\n      shape: c\n    }\n  }),\n      m = Jb({\n    inputs: {\n      a: p,\n      b: g\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n}\n\nvar _x = {\n  kernelName: \"Softmax\",\n  backendName: \"cpu\",\n  kernelFunc: Dx\n},\n    Ox = {\n  kernelName: \"Multinomial\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      logits: r\n    } = t,\n        {\n      numSamples: a,\n      seed: i,\n      normalized: o\n    } = s;\n    Bf(r, \"multinomial\");\n    var l = o ? r : Dx({\n      inputs: {\n        logits: r\n      },\n      backend: n,\n      attrs: {\n        dim: -1\n      }\n    }),\n        u = l.shape[0],\n        c = l.shape[1],\n        h = n.data.get(l.dataId).values,\n        p = [u, a],\n        f = O(d(p), \"int32\");\n\n    for (var _e386 = 0; _e386 < u; ++_e386) {\n      var _t328 = _e386 * c,\n          _n242 = new Float32Array(c - 1);\n\n      _n242[0] = h[_t328];\n\n      for (var _e387 = 1; _e387 < _n242.length; ++_e387) {\n        _n242[_e387] = _n242[_e387 - 1] + h[_t328 + _e387];\n      }\n\n      var _s194 = Oa.alea(i.toString()),\n          _r144 = _e386 * a;\n\n      for (var _e388 = 0; _e388 < a; ++_e388) {\n        var _t329 = _s194();\n\n        f[_r144 + _e388] = _n242.length;\n\n        for (var _s195 = 0; _s195 < _n242.length; _s195++) {\n          if (_t329 < _n242[_s195]) {\n            f[_r144 + _e388] = _s195;\n            break;\n          }\n        }\n      }\n    }\n\n    return o || n.disposeIntermediateTensorInfo(l), n.makeTensorInfo(p, \"int32\", f);\n  }\n},\n    Mx = Ki,\n    Lx = {\n  kernelName: \"NonMaxSuppressionV3\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l\n    } = s;\n    Bf(r, \"NonMaxSuppression\");\n    var u = n.data.get(r.dataId).values,\n        c = n.data.get(a.dataId).values,\n        {\n      selectedIndices: h\n    } = Mx(u, c, i, o, l);\n    return n.makeTensorInfo([h.length], \"int32\", new Int32Array(h));\n  }\n},\n    zx = Xi,\n    Bx = {\n  kernelName: \"NonMaxSuppressionV4\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      padToMaxOutputSize: u\n    } = s;\n    Bf(r, \"NonMaxSuppressionPadded\");\n    var c = n.data.get(r.dataId).values,\n        h = n.data.get(a.dataId).values,\n        {\n      selectedIndices: d,\n      validOutputs: p\n    } = zx(c, h, i, o, l, u);\n    return [n.makeTensorInfo([d.length], \"int32\", new Int32Array(d)), n.makeTensorInfo([], \"int32\", new Int32Array([p]))];\n  }\n},\n    Px = Yi,\n    Wx = {\n  kernelName: \"NonMaxSuppressionV5\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      softNmsSigma: u\n    } = s;\n    Bf(r, \"NonMaxSuppressionWithScore\");\n    var c = n.data.get(r.dataId).values,\n        h = n.data.get(a.dataId).values,\n        d = i,\n        p = o,\n        f = l,\n        g = u,\n        {\n      selectedIndices: m,\n      selectedScores: b\n    } = Px(c, h, d, p, f, g);\n    return [n.makeTensorInfo([m.length], \"int32\", new Int32Array(m)), n.makeTensorInfo([b.length], \"float32\", new Float32Array(b))];\n  }\n},\n    Ux = {\n  kernelName: \"OneHot\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r\n    } = t,\n        {\n      depth: a,\n      onValue: i,\n      offValue: o\n    } = s;\n    Bf(r, \"oneHot\");\n    var l = d(r.shape),\n        u = new Float32Array(l * a);\n    u.fill(o);\n    var c = n.data.get(r.dataId).values;\n\n    for (var _e389 = 0; _e389 < l; ++_e389) {\n      c[_e389] >= 0 && c[_e389] < a && (u[_e389 * a + c[_e389]] = i);\n    }\n\n    return n.makeTensorInfo([...r.shape, a], \"int32\", u);\n  }\n};\n\nfunction Vx(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  if (\"string\" === s.dtype) throw new Error(\"zerosLike is not supported for string tensors\");\n\n  if (\"complex64\" === s.dtype) {\n    var _e390 = Yf({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _t330 = Vx({\n      inputs: {\n        x: _e390\n      },\n      backend: n\n    }),\n        _r145 = yb({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _a110 = Vx({\n      inputs: {\n        x: _r145\n      },\n      backend: n\n    }),\n        _i81 = Hf({\n      inputs: {\n        real: _t330,\n        imag: _a110\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e390), n.disposeIntermediateTensorInfo(_t330), n.disposeIntermediateTensorInfo(_r145), n.disposeIntermediateTensorInfo(_a110), _i81;\n  }\n\n  return sx({\n    backend: n,\n    attrs: {\n      shape: s.shape,\n      value: 0,\n      dtype: s.dtype\n    }\n  });\n}\n\nvar Gx = {\n  kernelName: \"ZerosLike\",\n  backendName: \"cpu\",\n  kernelFunc: Vx\n},\n    Hx = {\n  kernelName: \"OnesLike\",\n  backendName: \"cpu\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        {\n      x: r\n    } = n;\n    if (\"string\" === r.dtype) throw new Error(\"onesLike is not supported for string tensors\");\n\n    if (\"complex64\" === r.dtype) {\n      var _t331 = Yf({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _n243 = e({\n        inputs: {\n          x: _t331\n        },\n        backend: s\n      }),\n          _a111 = yb({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _i82 = Vx({\n        inputs: {\n          x: _a111\n        },\n        backend: s\n      }),\n          _o60 = Hf({\n        inputs: {\n          real: _n243,\n          imag: _i82\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_t331), s.disposeIntermediateTensorInfo(_n243), s.disposeIntermediateTensorInfo(_a111), s.disposeIntermediateTensorInfo(_i82), _o60;\n    }\n\n    return sx({\n      backend: s,\n      attrs: {\n        shape: r.shape,\n        value: 1,\n        dtype: r.dtype\n      }\n    });\n  }\n};\n\nfunction qx(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s;\n  if (1 === t.length) return Xb({\n    inputs: {\n      input: t[0]\n    },\n    backend: n,\n    attrs: {\n      dim: r\n    }\n  });\n  var a = t[0].shape,\n      i = t[0].dtype;\n  t.forEach(e => {\n    u(a, e.shape, \"All tensors passed to stack must have matching shapes\"), l(i === e.dtype, () => \"All tensors passed to stack must have matching dtypes\");\n  });\n  var o = [],\n      c = wb({\n    inputs: t.map(e => {\n      var t = Xb({\n        inputs: {\n          input: e\n        },\n        backend: n,\n        attrs: {\n          dim: r\n        }\n      });\n      return o.push(t), t;\n    }),\n    backend: n,\n    attrs: {\n      axis: r\n    }\n  });\n  return o.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n}\n\nvar jx = {\n  kernelName: \"Pack\",\n  backendName: \"cpu\",\n  kernelFunc: qx\n},\n    Kx = {\n  kernelName: \"PadV2\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      paddings: a,\n      constantValue: i\n    } = s;\n    Bf(r, \"pad\");\n    var o = a.map((e, t) => e[0] + r.shape[t] + e[1]),\n        l = a.map(e => e[0]),\n        u = n.data.get(r.dataId).values,\n        c = d(r.shape),\n        h = r.shape.length,\n        p = A(r.shape),\n        f = d(o),\n        g = o.length,\n        m = A(o),\n        b = w(r.dtype, f);\n    0 !== i && b.fill(i);\n\n    for (var _e391 = 0; _e391 < c; _e391++) {\n      b[z(B(_e391, h, p).map((e, t) => e + l[t]), g, m)] = u[_e391];\n    }\n\n    return {\n      dataId: n.write(b, o, r.dtype),\n      shape: o,\n      dtype: r.dtype\n    };\n  }\n},\n    Xx = {\n  kernelName: \"Pow\",\n  backendName: \"cpu\",\n  kernelFunc: eg(\"Pow\", Gf((e, t) => Math.pow(e, t)))\n},\n    Yx = {\n  kernelName: \"Range\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      dtype: a,\n      step: i\n    } = n,\n        o = em(s, r, i, a);\n    return t.makeTensorInfo([o.length], a, o);\n  }\n},\n    Jx = {\n  kernelName: \"Reciprocal\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Reciprocal\", e => 1 / e)\n},\n    Zx = {\n  kernelName: \"ResizeBilinear\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s;\n    Bf(r, \"resizeBilinear\");\n    var l = A(r.shape),\n        [u, c] = o,\n        [h, p, f, g] = r.shape,\n        m = n.data.get(r.dataId).values,\n        b = new Float32Array(d([h, u, c, g])),\n        x = [a && u > 1 ? p - 1 : p, a && c > 1 ? f - 1 : f],\n        y = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c];\n    var k = 0;\n    var w = x[0] / y[0],\n        v = x[1] / y[1];\n\n    for (var _e392 = 0; _e392 < h; _e392++) {\n      for (var _t332 = 0; _t332 < u; _t332++) {\n        var _n244 = void 0;\n\n        _n244 = i ? w * (_t332 + .5) - .5 : w * _t332;\n\n        var _s196 = Math.max(0, Math.floor(_n244)),\n            _r146 = _n244 - _s196,\n            _a112 = Math.min(p - 1, Math.ceil(_n244)),\n            _o61 = _e392 * l[0] + _s196 * l[1],\n            _u28 = _e392 * l[0] + _a112 * l[1];\n\n        for (var _e393 = 0; _e393 < c; _e393++) {\n          var _t333 = void 0;\n\n          _t333 = i ? v * (_e393 + .5) - .5 : v * _e393;\n\n          var _n245 = Math.max(0, Math.floor(_t333)),\n              _s197 = _t333 - _n245,\n              _a113 = Math.min(f - 1, Math.ceil(_t333)),\n              _c27 = _o61 + _n245 * l[2],\n              _h15 = _u28 + _n245 * l[2],\n              _d18 = _o61 + _a113 * l[2],\n              _p13 = _u28 + _a113 * l[2];\n\n          for (var _e394 = 0; _e394 < g; _e394++) {\n            var _t334 = m[_c27 + _e394],\n                _n246 = m[_h15 + _e394],\n                _a114 = _t334 + (m[_d18 + _e394] - _t334) * _s197;\n\n            b[k++] = _a114 + (_n246 + (m[_p13 + _e394] - _n246) * _s197 - _a114) * _r146;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([h, u, c, g], \"float32\", b);\n  }\n},\n    Qx = {\n  kernelName: \"ResizeBilinearGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s;\n    Bf([a, r], \"resizeBilinearGrad\");\n    var o = A(r.shape),\n        [l, u, c, h] = r.shape,\n        [, d, p] = a.shape,\n        f = new Float32Array(l * u * c * h),\n        g = [i && d > 1 ? u - 1 : u, i && p > 1 ? c - 1 : c],\n        m = [i && d > 1 ? d - 1 : d, i && p > 1 ? p - 1 : p],\n        b = g[0] / m[0],\n        x = g[1] / m[1],\n        y = n.data.get(a.dataId).values;\n    var k = 0;\n\n    for (var _e395 = 0; _e395 < l; _e395++) {\n      var _t335 = _e395 * o[0];\n\n      for (var _e396 = 0; _e396 < d; _e396++) {\n        var _n247 = _e396 * b,\n            _s198 = Math.floor(_n247),\n            _r147 = Math.min(Math.ceil(_n247), u - 1),\n            _a115 = _t335 + _s198 * o[1],\n            _i83 = _t335 + _r147 * o[1],\n            _l42 = _n247 - _s198,\n            _d19 = 1 - _l42;\n\n        for (var _e397 = 0; _e397 < p; _e397++) {\n          var _t336 = _e397 * x,\n              _n248 = Math.floor(_t336),\n              _s199 = Math.min(Math.ceil(_t336), c - 1),\n              _r148 = _t336 - _n248,\n              _u29 = 1 - _r148,\n              _p14 = _a115 + _n248 * o[2],\n              _g17 = _a115 + _s199 * o[2],\n              _m12 = _i83 + _n248 * o[2],\n              _b12 = _i83 + _s199 * o[2],\n              _w8 = _d19 * _u29,\n              _v6 = _d19 * _r148,\n              _I5 = _l42 * _u29,\n              _$3 = _l42 * _r148;\n\n          for (var _e398 = 0; _e398 < h; _e398++) {\n            var _t337 = y[k++];\n            f[_p14 + _e398] += _t337 * _w8, f[_g17 + _e398] += _t337 * _v6, f[_m12 + _e398] += _t337 * _I5, f[_b12 + _e398] += _t337 * _$3;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([l, c, u, h], \"float32\", f);\n  }\n},\n    ey = {\n  kernelName: \"ResizeNearestNeighbor\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s;\n    Bf(r, \"resizeNearestNeighbor\");\n    var l = A(r.shape),\n        [u, c] = o,\n        [h, d, p, f] = r.shape,\n        g = n.data.get(r.dataId).values,\n        m = new Float32Array(h * u * c * f),\n        b = [a && u > 1 ? d - 1 : d, a && c > 1 ? p - 1 : p],\n        x = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c],\n        y = b[0] / x[0],\n        k = b[1] / x[1];\n    var w = 0;\n\n    for (var _e399 = 0; _e399 < h; _e399++) {\n      var _t338 = _e399 * l[0];\n\n      for (var _e400 = 0; _e400 < u; _e400++) {\n        var _n249 = i ? y * (_e400 + .5) : y * _e400;\n\n        var _s200 = Math.min(d - 1, a ? Math.round(_n249) : Math.floor(_n249));\n\n        i && (_s200 = Math.max(0, _s200));\n\n        var _r149 = _t338 + _s200 * l[1];\n\n        for (var _e401 = 0; _e401 < c; _e401++) {\n          var _t339 = i ? k * (_e401 + .5) : k * _e401;\n\n          var _n250 = Math.min(p - 1, a ? Math.round(_t339) : Math.floor(_t339));\n\n          i && (_n250 = Math.max(0, _n250));\n\n          var _s201 = _r149 + _n250 * l[2];\n\n          for (var _e402 = 0; _e402 < f; _e402++) {\n            m[w++] = g[_s201 + _e402];\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo([h, u, c, f], r.dtype, m);\n  }\n},\n    ty = {\n  kernelName: \"ResizeNearestNeighborGrad\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s;\n    Bf([a, r], \"resizeNearestNeighborGrad\");\n    var o = A(r.shape),\n        l = A(a.shape),\n        [u, c, h, d] = r.shape,\n        [, p, f] = a.shape,\n        g = new Float32Array(u * c * h * d),\n        m = n.data.get(a.dataId).values,\n        b = [i && p > 1 ? c - 1 : c, i && f > 1 ? h - 1 : h],\n        x = [i && p > 1 ? p - 1 : p, i && f > 1 ? f - 1 : f],\n        y = b[0] / x[0],\n        k = b[1] / x[1],\n        w = 1 / y,\n        v = 1 / k,\n        I = 2 * Math.ceil(w) + 2,\n        $ = 2 * Math.ceil(v) + 2;\n\n    for (var _e403 = 0; _e403 < u; _e403++) {\n      var _t340 = _e403 * o[0];\n\n      for (var _e404 = 0; _e404 < c; _e404++) {\n        var _n251 = _t340 + _e404 * o[1],\n            _s202 = Math.floor(_e404 * w),\n            _r150 = Math.floor(_s202 - I / 2);\n\n        for (var _s203 = 0; _s203 < h; _s203++) {\n          var _a116 = _n251 + _s203 * o[2],\n              _u30 = Math.floor(_s203 * v),\n              _b13 = Math.floor(_u30 - $ / 2);\n\n          for (var _n252 = 0; _n252 < d; _n252++) {\n            var _o62 = 0;\n\n            for (var _a117 = 0; _a117 < I; _a117++) {\n              var _u31 = _a117 + _r150;\n\n              if (_u31 < 0 || _u31 >= p) continue;\n\n              var _d20 = _t340 + _u31 * l[1],\n                  _g18 = _u31 * y;\n\n              if (_e404 === Math.min(c - 1, i ? Math.round(_g18) : Math.floor(_g18))) for (var _e405 = 0; _e405 < $; _e405++) {\n                var _t341 = _e405 + _b13;\n\n                if (_t341 < 0 || _t341 >= f) continue;\n\n                var _r151 = _d20 + _t341 * l[2],\n                    _a118 = _t341 * k;\n\n                _s203 === Math.min(h - 1, i ? Math.round(_a118) : Math.floor(_a118)) && (_o62 += m[_r151 + _n252]);\n              }\n            }\n\n            g[_a116 + _n252] = _o62;\n          }\n        }\n      }\n    }\n\n    return n.makeTensorInfo(r.shape, r.dtype, g);\n  }\n},\n    ny = {\n  kernelName: \"Reverse\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      dims: a\n    } = s;\n    Bf(r, \"reverse\");\n    var i = r.shape.length,\n        o = y(a, r.shape);\n    if (0 === i) return Kf({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var l = new tt(r.shape, r.dtype),\n        u = n.bufferSync(r);\n\n    var _loop31 = function _loop31(_e406) {\n      var t = l.indexToLoc(_e406),\n          n = t.slice();\n      o.forEach(e => n[e] = r.shape[e] - 1 - n[e]), l.set(u.get(...n), ...t);\n    };\n\n    for (var _e406 = 0; _e406 < l.size; _e406++) {\n      _loop31(_e406);\n    }\n\n    return n.makeTensorInfo(l.shape, l.dtype, l.values);\n  }\n},\n    sy = {\n  kernelName: \"RotateWithOffset\",\n  backendName: \"cpu\",\n  kernelFunc: _ref18 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref18;\n    var {\n      image: s\n    } = e,\n        {\n      radians: r,\n      fillValue: a,\n      center: i\n    } = t,\n        o = n,\n        l = w(s.dtype, d(s.shape)),\n        [u, c, h, p] = s.shape,\n        [f, g] = Ao(i, c, h),\n        m = Math.sin(r),\n        b = Math.cos(r),\n        x = o.data.get(s.dataId).values;\n\n    for (var _e407 = 0; _e407 < u; _e407++) {\n      var _t342 = _e407 * h * c * p;\n\n      for (var _e408 = 0; _e408 < c; _e408++) {\n        var _n253 = _e408 * (h * p);\n\n        for (var _s204 = 0; _s204 < h; _s204++) {\n          var _r152 = _s204 * p;\n\n          for (var _i84 = 0; _i84 < p; _i84++) {\n            var _o63 = [u, _e408, _s204, _i84],\n                _d21 = _o63[2],\n                _y10 = _o63[1];\n\n            var _k8 = (_d21 - f) * b - (_y10 - g) * m,\n                _w9 = (_d21 - f) * m + (_y10 - g) * b;\n\n            _k8 = Math.round(_k8 + f), _w9 = Math.round(_w9 + g);\n            var _v7 = a;\n            \"number\" != typeof a && (_v7 = 3 === _i84 ? 255 : a[_i84]), _k8 >= 0 && _k8 < h && _w9 >= 0 && _w9 < c && (_v7 = x[_t342 + _w9 * (h * p) + _k8 * p + _i84]), l[_t342 + _n253 + _r152 + _i84] = _v7;\n          }\n        }\n      }\n    }\n\n    return {\n      dataId: o.write(l, s.shape, s.dtype),\n      shape: s.shape,\n      dtype: s.dtype\n    };\n  }\n},\n    ry = {\n  kernelName: \"Round\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Round\", e => {\n    var t = Math.floor(e);\n    return e - t < .5 ? Math.floor(e) : e - t > .5 ? Math.ceil(e) : t % 2 == 0 ? t : t + 1;\n  })\n};\n\nfunction ay(e, t, n, s, r, a, i, o, l, u) {\n  var c = [s / r, r],\n      h = e.values,\n      d = t.values;\n  if (0 === s) return pn(n, t.dtype);\n  var p = pn(c, t.dtype);\n  p.values.fill(l);\n\n  for (var _e409 = 0; _e409 < a; _e409++) {\n    var _a119 = [];\n    var _l43 = 0;\n\n    for (var _t343 = 0; _t343 < i; _t343++) {\n      var _n254 = h[_e409 * i + _t343];\n      _a119.push(_n254), _l43 += _n254 * o[_t343];\n    }\n\n    if (_l43 < 0 || _l43 >= s / r) throw new Error(\"Invalid indices: \".concat(_a119, \" does not index into \").concat(n));\n\n    for (var _n255 = 0; _n255 < r; _n255++) {\n      u ? p.values[_l43 * r + _n255] += d[_e409 * r + _n255] : p.values[_l43 * r + _n255] = 0 === t.rank ? d[0] : d[_e409 * r + _n255];\n    }\n  }\n\n  return p;\n}\n\nvar iy = {\n  kernelName: \"ScatterNd\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r,\n      updates: a\n    } = t,\n        {\n      shape: i\n    } = s,\n        {\n      sliceRank: o,\n      numUpdates: l,\n      sliceSize: u,\n      strides: c,\n      outputSize: h\n    } = Tn(0, r, i),\n        d = ay(n.bufferSync(r), n.bufferSync(a), i, h, u, l, o, c, 0, !0);\n    return n.makeTensorInfo(i, d.dtype, d.values);\n  }\n},\n    oy = {\n  kernelName: \"Select\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      condition: s,\n      t: r,\n      e: a\n    } = t;\n    Bf([s, r, a], \"select\");\n    var i = s.shape.length,\n        o = n.data.get(s.dataId).values,\n        l = n.data.get(r.dataId).values,\n        u = n.data.get(a.dataId).values,\n        c = pt(r.dtype, a.dtype),\n        h = O(d(r.shape), c);\n    var p = 0;\n    var f = 0 === i || i > 1 || 1 === r.shape.length ? 1 : d(r.shape.slice(1));\n\n    for (var _e410 = 0; _e410 < o.length; _e410++) {\n      for (var _t344 = 0; _t344 < f; _t344++) {\n        h[p++] = 1 === o[_e410] ? l[_e410] : u[_e410];\n      }\n    }\n\n    return n.makeTensorInfo(r.shape, c, h);\n  }\n},\n    ly = {\n  kernelName: \"Selu\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Selu\", e => e >= 0 ? 1.0507009873554805 * e : 1.7580993408473768 * (Math.exp(e) - 1))\n},\n    uy = {\n  kernelName: \"Sign\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Sign\", e => e < 0 ? -1 : e > 0 ? 1 : 0)\n},\n    cy = {\n  kernelName: \"Sin\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Sin\", e => Math.sin(e))\n},\n    hy = {\n  kernelName: \"Sinh\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Sinh\", e => Math.sinh(e))\n},\n    dy = Math.log(1.1920928955078125e-7) + 2,\n    py = {\n  kernelName: \"Softplus\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Softplus\", e => {\n    var t = e > -dy,\n        n = e < dy,\n        s = Math.exp(e);\n    var r;\n    return r = n ? s : t ? e : Math.log(1 + s), r;\n  })\n},\n    fy = {\n  kernelName: \"SpaceToBatchND\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      paddings: i\n    } = s;\n    Bf([r], \"spaceToBatchND\");\n    var o = d(a),\n        l = [[0, 0]];\n    l.push(...i);\n\n    for (var _e411 = 1 + a.length; _e411 < r.shape.length; ++_e411) {\n      l.push([0, 0]);\n    }\n\n    var u = Kx.kernelFunc({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        paddings: l,\n        constantValue: 0\n      }\n    }),\n        c = Fo(u.shape, a, o, !1),\n        h = Do(c.length, a.length, !1),\n        p = _o(u.shape, a, o, !1),\n        f = Vm({\n      inputs: {\n        x: u\n      },\n      backend: n,\n      attrs: {\n        shape: c\n      }\n    }),\n        g = Yg({\n      inputs: {\n        x: f\n      },\n      backend: n,\n      attrs: {\n        perm: h\n      }\n    }),\n        m = Vm({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    });\n\n    return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(g), m;\n  }\n},\n    gy = {\n  kernelName: \"SparseFillEmptyRows\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      indices: s,\n      values: r,\n      denseShape: a,\n      defaultValue: i\n    } = t;\n    if (1 !== a.shape.length) throw new Error(\"Dense shape must be a vector, saw:\\n        \".concat(a.shape));\n    if (2 !== s.shape.length) throw new Error(\"Indices must be a matrix, saw:\\n        \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Values must be a vector, saw:\\n        \".concat(r.shape));\n    if (0 !== i.shape.length) throw new Error(\"Default value must be a scalar, saw:\\n        \".concat(i.shape));\n    var o = n.data.get(s.dataId).values,\n        l = n.data.get(r.dataId).values,\n        u = n.data.get(a.dataId).values,\n        c = n.data.get(i.dataId).values[0],\n        [h, d, p, f, g] = um(o, s.shape, s.dtype, l, r.dtype, u, c);\n    return [n.makeTensorInfo(d, s.dtype, h), n.makeTensorInfo([d[0]], r.dtype, p), n.makeTensorInfo([f.length], \"bool\", new Uint8Array(f.map(e => Number(e)))), n.makeTensorInfo([g.length], s.dtype, new Int32Array(g))];\n  }\n},\n    my = {\n  kernelName: \"SparseReshape\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    } = t;\n    if (2 !== s.shape.length) throw new Error(\"Input indices should be a matrix but received shape\\n        \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Input shape should be a vector but received shape\\n        \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Target shape should be a vector but received shape \".concat(a.shape));\n    var i = Array.from(n.data.get(r.dataId).values),\n        o = n.data.get(s.dataId).values,\n        l = Array.from(n.data.get(a.dataId).values),\n        [u, c, h] = cm(o, s.shape, s.dtype, i, l);\n    return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))];\n  }\n},\n    by = {\n  kernelName: \"SparseSegmentMean\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n          \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n          \".concat(a.shape));\n    var i = n.data.get(s.dataId).values,\n        o = n.data.get(r.dataId).values,\n        l = n.data.get(a.dataId).values,\n        [u, c] = hm(i, s.shape, s.dtype, o, l, !0);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    xy = {\n  kernelName: \"SparseSegmentSum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n         \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n         \".concat(a.shape));\n    var i = n.data.get(s.dataId).values,\n        o = n.data.get(r.dataId).values,\n        l = n.data.get(a.dataId).values,\n        [u, c] = hm(i, s.shape, s.dtype, o, l);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    yy = {\n  kernelName: \"SparseToDense\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      sparseIndices: r,\n      sparseValues: a,\n      defaultValue: i\n    } = t,\n        {\n      outputShape: o\n    } = s,\n        {\n      sliceRank: l,\n      numUpdates: u,\n      sliceSize: c,\n      strides: h,\n      outputSize: d\n    } = Tn(0, r, o),\n        p = ay(n.bufferSync(r), n.bufferSync(a), o, d, c, u, l, h, n.data.get(i.dataId).values[0], !1);\n    return n.makeTensorInfo(o, p.dtype, p.values);\n  }\n},\n    ky = {\n  kernelName: \"SplitV\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      numOrSizeSplits: a,\n      axis: i\n    } = s,\n        o = y(i, r.shape)[0],\n        l = Zo(r, a, o),\n        u = new Array(r.shape.length).fill(0),\n        c = r.shape.slice();\n    return l.map(e => {\n      var t = [...c];\n      t[o] = e;\n      var s = om({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: u,\n          size: t\n        }\n      });\n      return u[o] += e, s;\n    });\n  }\n},\n    wy = {\n  kernelName: \"Square\",\n  backendName: \"cpu\",\n  kernelFunc: _ref19 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref19;\n    var {\n      x: n\n    } = e,\n        s = t;\n    Bf(n, \"square\");\n    var r = s.data.get(n.dataId).values,\n        a = new Float32Array(r.length);\n\n    for (var _e412 = 0; _e412 < r.length; ++_e412) {\n      var _t345 = r[_e412];\n      a[_e412] = _t345 * _t345;\n    }\n\n    return {\n      dataId: s.write(a, n.shape, n.dtype),\n      shape: n.shape,\n      dtype: n.dtype\n    };\n  }\n},\n    vy = {\n  kernelName: \"Step\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Step\", (e, t) => {\n    var n = t;\n    return isNaN(e) ? NaN : e > 0 ? 1 : n.alpha;\n  })\n},\n    Iy = {\n  kernelName: \"StridedSlice\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      begin: a,\n      end: i,\n      strides: o,\n      beginMask: l,\n      endMask: u,\n      ellipsisMask: c,\n      newAxisMask: h,\n      shrinkAxisMask: d\n    } = s;\n    Bf(r, \"stridedSlice\");\n    var {\n      nonStrided: p,\n      $begin: f,\n      $strides: g,\n      size: m,\n      newShape: b,\n      outShape: x\n    } = Gn(r.shape, a, i, o, l, u, c, h, d),\n        y = Vm({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: b\n      }\n    });\n    var k;\n\n    if (p) {\n      var _e413 = om({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          begin: f,\n          size: m\n        }\n      });\n\n      k = Vm({\n        inputs: {\n          x: _e413\n        },\n        backend: n,\n        attrs: {\n          shape: x\n        }\n      }), n.disposeIntermediateTensorInfo(_e413);\n    } else if (x.some(e => 0 === e)) k = n.makeTensorInfo(x, r.dtype, []);else {\n      var _e414 = mm(x, n.bufferSync(y), g, f);\n\n      k = n.makeTensorInfo(_e414.shape, _e414.dtype, _e414.values);\n    }\n\n    var w = Vm({\n      inputs: {\n        x: k\n      },\n      backend: n,\n      attrs: {\n        shape: x\n      }\n    });\n    return n.disposeIntermediateTensorInfo(y), n.disposeIntermediateTensorInfo(k), w;\n  }\n},\n    $y = {\n  kernelName: \"StringNGrams\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      separator: r,\n      nGramWidths: a,\n      leftPad: i,\n      rightPad: o,\n      padWidth: l,\n      preserveShortSequences: u\n    } = s,\n        {\n      data: c,\n      dataSplits: h\n    } = t,\n        d = n.data.get(c.dataId).values,\n        p = n.data.get(h.dataId).values,\n        [f, g] = xm(d, p, r, a, i, o, l, u);\n    return [n.makeTensorInfo([f.length], \"string\", f), n.makeTensorInfo(h.shape, \"int32\", g)];\n  }\n},\n    Sy = {\n  kernelName: \"StringSplit\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      skipEmpty: r\n    } = s,\n        {\n      input: a,\n      delimiter: i\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (1 !== a.shape.length) throw new Error(\"Input must be a vector, got shape: \".concat(a.shape));\n    if (0 !== i.shape.length) throw new Error(\"Delimiter must be a scalar, got shape: \".concat(i.shape));\n    var o = n.data.get(a.dataId).values,\n        l = n.data.get(i.dataId).values[0],\n        [u, c, h] = km(o, l, r),\n        d = c.length;\n    return [n.makeTensorInfo([d, 2], \"int32\", u), n.makeTensorInfo([d], \"string\", c), n.makeTensorInfo([2], \"int32\", new Int32Array(h))];\n  }\n},\n    Ny = {\n  kernelName: \"StringToHashBucketFast\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      numBuckets: r\n    } = s,\n        {\n      input: a\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (r <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    var i = wm(n.data.get(a.dataId).values, r);\n    return n.makeTensorInfo(a.shape, \"int32\", i);\n  }\n},\n    Cy = {\n  kernelName: \"Tan\",\n  backendName: \"cpu\",\n  kernelFunc: lg(\"Tan\", e => Math.tan(e))\n},\n    Ty = lg(\"Tanh\", e => Math.tanh(e));\n\nfunction Ey(e, t, n) {\n  switch (n) {\n    case \"reflect\":\n      return function (e, t) {\n        var n = e;\n        if (n < 0) {\n          if (t <= 1) n = 0;else {\n            var _e415 = 2 * t;\n\n            n < _e415 && (n = _e415 * Math.trunc(-n / _e415) + n), n = n < -t ? n + _e415 : -n - 1;\n          }\n        } else if (n > t - 1) if (t <= 1) n = 0;else {\n          var _e416 = 2 * t;\n\n          n -= _e416 * Math.trunc(n / _e416), n >= t && (n = _e416 - n - 1);\n        }\n        return a(0, n, t - 1);\n      }(e, t);\n\n    case \"wrap\":\n      return function (e, t) {\n        var n = e;\n        return n < 0 ? t <= 1 ? n = 0 : n += t * (Math.trunc(-n / (t - 1)) + 1) : n > t - 1 && (t <= 1 ? n = 0 : n -= t * Math.trunc(n / (t - 1))), a(0, n, t - 1);\n      }(e, t);\n\n    case \"nearest\":\n      return function (e, t) {\n        return a(0, e, t - 1);\n      }(e, t);\n\n    case \"constant\":\n    default:\n      return function (e, t) {\n        return e;\n      }(e);\n  }\n}\n\nfunction Ry(e, t, n, s, r, a, i, o, l, u, c) {\n  return 0 <= o && o < t && 0 <= l && l < n ? e[i * s + o * r + l * a + u] : c;\n}\n\nfunction Ay(e, t, n, s, r, a, i, o, l, u, c) {\n  return Ry(e, t, n, s, r, a, i, Math.round(o), Math.round(l), u, c);\n}\n\nfunction Fy(e, t, n, s, r, a, i, o, l, u, c) {\n  var h = Math.floor(o),\n      d = Math.floor(l),\n      p = h + 1,\n      f = d + 1;\n  return (p - o) * ((f - l) * Ry(e, t, n, s, r, a, i, h, d, u, c) + (l - d) * Ry(e, t, n, s, r, a, i, h, f, u, c)) + (o - h) * ((f - l) * Ry(e, t, n, s, r, a, i, p, d, u, c) + (l - d) * Ry(e, t, n, s, r, a, i, p, f, u, c));\n}\n\nvar Dy = [jm, Vf, Km, Xm, rg, Ym, Jm, Zm, Qm, eb, tb, nb, sb, rb, ab, ub, cb, hb, db, qm, pb, fb, gb, mb, Qf, hg, bb, qf, xb, vb, Sb, Nb, $b, Tb, Eb, Cb, Rb, Ab, Fb, Db, _b, Ob, Lb, zb, Bb, Pb, Wb, Vb, Ub, Zb, qb, Fm, jb, gg, Kb, xg, Yb, kg, nx, rx, ax, vg, ix, ox, lx, ux, cx, Ng, Tg, Xf, hx, kb, dx, px, fx, _m, Rg, Fg, gx, Og, mx, bx, xx, yx, kx, wx, zg, $x, Sx, Nx, Cx, Tx, Ix, Ex, Rx, Pg, Ax, Fx, Ox, Gg, qg, Lx, Bx, Wx, Kg, Ux, Hx, jx, Kx, Xx, Lm, Qg, Yx, Jf, Jx, Bm, Wm, Gm, Zx, Qx, ey, ty, ny, sy, ry, nm, iy, oy, ly, am, uy, cy, hy, lm, _x, py, fy, gy, my, by, xy, yy, ky, pm, wy, gm, vy, Iy, $y, Sy, Ny, $m, Hb, Cy, {\n  kernelName: \"Tanh\",\n  backendName: \"cpu\",\n  kernelFunc: Ty\n}, {\n  kernelName: \"Tile\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      reps: a\n    } = s;\n    Bf(r, \"tile\");\n    var i = Sm(n.bufferSync(r), a);\n    return n.makeTensorInfo(i.shape, i.dtype, i.values);\n  }\n}, {\n  kernelName: \"TopK\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      k: a,\n      sorted: i\n    } = s;\n    Bf(r, \"topk\");\n    var o = n.data.get(r.dataId).values,\n        [l, u] = Tm(o, r.shape, r.dtype, a, i);\n    return [n.makeTensorInfo(l.shape, l.dtype, l.values), n.makeTensorInfo(u.shape, u.dtype, u.values)];\n  }\n}, Jg, {\n  kernelName: \"Transform\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      image: r,\n      transforms: a\n    } = t,\n        {\n      interpolation: i,\n      fillMode: o,\n      fillValue: l,\n      outputShape: u\n    } = n,\n        [c, h, p, f] = r.shape,\n        [g, m] = null != u ? u : [h, p],\n        b = [c, g, m, f],\n        x = A(r.shape),\n        y = x[0],\n        k = x[1],\n        v = x[2],\n        I = w(r.dtype, d(b));\n    I.fill(l);\n    var $ = s.data.get(r.dataId).values,\n        S = s.data.get(a.dataId).values;\n\n    for (var _e417 = 0; _e417 < c; ++_e417) {\n      var _t346 = 1 === a.shape[0] ? S : S.subarray(8 * _e417, 8 * _e417 + 8);\n\n      for (var _n256 = 0; _n256 < g; ++_n256) {\n        for (var _s205 = 0; _s205 < m; ++_s205) {\n          for (var _r153 = 0; _r153 < f; ++_r153) {\n            var _a120 = void 0;\n\n            var _u32 = _t346[6] * _s205 + _t346[7] * _n256 + 1;\n\n            if (0 === _u32) continue;\n\n            var _c28 = (_t346[3] * _s205 + _t346[4] * _n256 + _t346[5]) / _u32,\n                _d22 = Ey((_t346[0] * _s205 + _t346[1] * _n256 + _t346[2]) / _u32, p, o),\n                _f10 = Ey(_c28, h, o);\n\n            switch (i) {\n              case \"nearest\":\n                _a120 = Ay($, h, p, y, k, v, _e417, _f10, _d22, _r153, l);\n                break;\n\n              case \"bilinear\":\n                _a120 = Fy($, h, p, y, k, v, _e417, _f10, _d22, _r153, l);\n                break;\n\n              default:\n                throw new Error(\"Error in Transform: Expect 'nearest' or 'bilinear', but got \".concat(i));\n            }\n\n            I[_e417 * y + _n256 * k + _s205 * v + _r153] = _a120;\n          }\n        }\n      }\n\n      return s.makeTensorInfo(b, r.dtype, I);\n    }\n\n    return {\n      dataId: s.write(I, b, r.dtype),\n      shape: r.shape,\n      dtype: r.dtype\n    };\n  }\n}, {\n  kernelName: \"Unique\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      axis: r\n    } = n,\n        {\n      x: a\n    } = t;\n    Bf(a, \"unique\");\n    var i = s.data.get(a.dataId).values,\n        {\n      outputValues: o,\n      outputShape: l,\n      indices: u\n    } = Em(i, r, a.shape, a.dtype);\n    return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], \"int32\", u)];\n  }\n}, {\n  kernelName: \"Unpack\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      value: r\n    } = t;\n    var {\n      axis: a\n    } = s;\n    a < 0 && (a += r.shape.length);\n    var i = r.shape.length,\n        o = r.shape[a],\n        l = new Array(i - 1);\n    var u = 0;\n\n    for (var _e418 = 0; _e418 < i; _e418++) {\n      _e418 !== a && (l[u++] = r.shape[_e418]);\n    }\n\n    var c = new Array(i).fill(0),\n        h = r.shape.slice();\n    h[a] = 1;\n    var d = new Array(o);\n\n    for (var _e419 = 0; _e419 < d.length; _e419++) {\n      c[a] = _e419;\n\n      var _t347 = om({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: c,\n          size: h\n        }\n      });\n\n      d[_e419] = Vm({\n        inputs: {\n          x: _t347\n        },\n        backend: n,\n        attrs: {\n          shape: l\n        }\n      }), n.disposeIntermediateTensorInfo(_t347);\n    }\n\n    return d;\n  }\n}, {\n  kernelName: \"UnsortedSegmentSum\",\n  backendName: \"cpu\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      segmentIds: a\n    } = t,\n        {\n      numSegments: i\n    } = s;\n    Bf(r, \"unsortedSegmentSum\");\n    var o = [],\n        l = [],\n        u = r.shape.length - a.shape.length;\n    var c = a;\n\n    for (var _e420 = 0; _e420 < u; ++_e420) {\n      var _t348 = Xb({\n        inputs: {\n          input: c\n        },\n        backend: n,\n        attrs: {\n          dim: _e420 + 1\n        }\n      });\n\n      c = _t348, l.push(_t348);\n    }\n\n    for (var _e421 = 0; _e421 < i; ++_e421) {\n      var _t349 = Ue(_e421, \"int32\"),\n          _s206 = n.makeTensorInfo([], \"int32\", _t349),\n          _a121 = fg({\n        inputs: {\n          a: _s206,\n          b: c\n        },\n        backend: n\n      }),\n          _i85 = Zf({\n        inputs: {\n          x: _a121\n        },\n        backend: n,\n        attrs: {\n          dtype: \"float32\"\n        }\n      }),\n          _u33 = Vg({\n        inputs: {\n          a: _i85,\n          b: r\n        },\n        backend: n\n      }),\n          _h16 = Gb({\n        inputs: {\n          x: _u33\n        },\n        backend: n,\n        attrs: {\n          axis: 0,\n          keepDims: !1\n        }\n      });\n\n      o.push(_h16), l.push(_s206), l.push(_a121), l.push(_i85), l.push(_u33), l.push(_h16);\n    }\n\n    var h = qx({\n      inputs: o,\n      backend: n,\n      attrs: {\n        axis: 0\n      }\n    });\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), h;\n  }\n}, Gx];\n\nfor (var _e422 of Dy) {\n  ee(_e422);\n}\n\nvar _y = {},\n    Oy = {\n  alpha: !1,\n  antialias: !1,\n  premultipliedAlpha: !1,\n  preserveDrawingBuffer: !1,\n  depth: !1,\n  stencil: !1,\n  failIfMajorPerformanceCaveat: !0\n};\n\nfunction My(e) {\n  if (!(e in _y)) {\n    var _t350 = function (e) {\n      if (1 !== e && 2 !== e) throw new Error(\"Cannot get WebGL rendering context, WebGL is disabled.\");\n\n      var t = function (e) {\n        if (\"undefined\" != typeof OffscreenCanvas && 2 === e) return new OffscreenCanvas(300, 150);\n        if (\"undefined\" != typeof document) return document.createElement(\"canvas\");\n        throw new Error(\"Cannot create a canvas in this context\");\n      }(e);\n\n      return t.addEventListener(\"webglcontextlost\", t => {\n        t.preventDefault(), delete _y[e];\n      }, !1), 1 === e ? t.getContext(\"webgl\", Oy) || t.getContext(\"experimental-webgl\", Oy) : t.getContext(\"webgl2\", Oy);\n    }(e);\n\n    if (null === _t350) return console.log(\"Could not get context for WebGL version\", e), null;\n    _y[e] = _t350;\n  }\n\n  var t = _y[e];\n  return t.isContextLost() ? (delete _y[e], My(e)) : (t.disable(t.DEPTH_TEST), t.disable(t.STENCIL_TEST), t.disable(t.BLEND), t.disable(t.DITHER), t.disable(t.POLYGON_OFFSET_FILL), t.disable(t.SAMPLE_COVERAGE), t.enable(t.SCISSOR_TEST), t.enable(t.CULL_FACE), t.cullFace(t.BACK), _y[e]);\n}\n\nvar Ly, zy, By;\n\nfunction Py(e, t) {\n  return [t, e];\n}\n\nfunction Wy(e) {\n  var t = d(e);\n  return g(Math.ceil(t / 4));\n}\n\nfunction Uy(e, t) {\n  return [Math.max(1, Math.ceil(t / 2)), Math.max(1, Math.ceil(e / 2))];\n}\n\nfunction Vy(e, t) {\n  var n = e;\n  var s, r, a, i, o, l, u, c, h, d;\n  return 2 === G().getNumber(\"WEBGL_VERSION\") ? (s = n.R32F, r = n.R16F, a = n.RGBA16F, i = n.RGBA32F, o = n.RED, u = 4, c = 1, h = n.HALF_FLOAT, d = n.FLOAT) : (s = e.RGBA, r = e.RGBA, a = e.RGBA, i = n.RGBA, o = e.RGBA, u = 4, c = 4, h = null != t ? t.HALF_FLOAT_OES : null, d = e.FLOAT), l = e.RGBA, {\n    internalFormatFloat: s,\n    internalFormatHalfFloat: r,\n    internalFormatPackedHalfFloat: a,\n    internalFormatPackedFloat: i,\n    textureFormatFloat: o,\n    downloadTextureFormat: l,\n    downloadUnpackNumChannels: u,\n    defaultNumChannels: c,\n    textureTypeHalfFloat: h,\n    textureTypeFloat: d\n  };\n}\n\nfunction Gy(e, t) {\n  var n = t();\n  return G().getBool(\"DEBUG\") && function (e) {\n    var t = e.getError();\n    if (t !== e.NO_ERROR) throw new Error(\"WebGL Error: \" + function (e, t) {\n      switch (t) {\n        case e.NO_ERROR:\n          return \"NO_ERROR\";\n\n        case e.INVALID_ENUM:\n          return \"INVALID_ENUM\";\n\n        case e.INVALID_VALUE:\n          return \"INVALID_VALUE\";\n\n        case e.INVALID_OPERATION:\n          return \"INVALID_OPERATION\";\n\n        case e.INVALID_FRAMEBUFFER_OPERATION:\n          return \"INVALID_FRAMEBUFFER_OPERATION\";\n\n        case e.OUT_OF_MEMORY:\n          return \"OUT_OF_MEMORY\";\n\n        case e.CONTEXT_LOST_WEBGL:\n          return \"CONTEXT_LOST_WEBGL\";\n\n        default:\n          return \"Unknown error code \".concat(t);\n      }\n    }(e, t));\n  }(e), n;\n}\n\nfunction Hy(e) {\n  return !!(G().getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") || 0 === e || 5.96e-8 < Math.abs(e) && Math.abs(e) < 65504);\n}\n\nfunction qy(e, t) {\n  return Qy(e, () => e.getExtension(t), 'Extension \"' + t + '\" not supported on this browser.');\n}\n\n!function (e) {\n  e[e.DENSE = 0] = \"DENSE\", e[e.SHARED_BATCH = 1] = \"SHARED_BATCH\";\n}(Ly || (Ly = {})), function (e) {\n  e[e.RENDER = 0] = \"RENDER\", e[e.UPLOAD = 1] = \"UPLOAD\", e[e.PIXELS = 2] = \"PIXELS\", e[e.DOWNLOAD = 3] = \"DOWNLOAD\";\n}(zy || (zy = {})), function (e) {\n  e[e.UNPACKED_FLOAT16 = 0] = \"UNPACKED_FLOAT16\", e[e.UNPACKED_FLOAT32 = 1] = \"UNPACKED_FLOAT32\", e[e.PACKED_4X1_UNSIGNED_BYTE = 2] = \"PACKED_4X1_UNSIGNED_BYTE\", e[e.PACKED_2X2_FLOAT32 = 3] = \"PACKED_2X2_FLOAT32\", e[e.PACKED_2X2_FLOAT16 = 4] = \"PACKED_2X2_FLOAT16\";\n}(By || (By = {}));\nvar jy = /ERROR: [0-9]+:([0-9]+):/g;\n\nfunction Ky(e, t) {\n  if (Gy(e, () => e.validateProgram(t)), !1 === e.getProgramParameter(t, e.VALIDATE_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error(\"Shader program validation failed.\");\n}\n\nfunction Xy(e, t, n, s, r, a, i) {\n  var o = e.getAttribLocation(t, n);\n  return -1 !== o && (Gy(e, () => e.bindBuffer(e.ARRAY_BUFFER, s)), Gy(e, () => e.vertexAttribPointer(o, r, e.FLOAT, !1, a, i)), Gy(e, () => e.enableVertexAttribArray(o)), !0);\n}\n\nfunction Yy(e, t, n) {\n  Gy(e, () => e.bindFramebuffer(e.FRAMEBUFFER, n)), Gy(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, t, 0));\n}\n\nfunction Jy(e, t) {\n  Gy(e, () => e.bindFramebuffer(e.FRAMEBUFFER, t)), Gy(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, null, 0));\n}\n\nfunction Zy(e) {\n  var t = e.checkFramebufferStatus(e.FRAMEBUFFER);\n  if (t !== e.FRAMEBUFFER_COMPLETE) throw new Error(\"Error binding framebuffer: \" + function (e, t) {\n    switch (t) {\n      case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:\n        return \"FRAMEBUFFER_INCOMPLETE_ATTACHMENT\";\n\n      case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:\n        return \"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT\";\n\n      case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:\n        return \"FRAMEBUFFER_INCOMPLETE_DIMENSIONS\";\n\n      case e.FRAMEBUFFER_UNSUPPORTED:\n        return \"FRAMEBUFFER_UNSUPPORTED\";\n\n      default:\n        return \"unknown error \".concat(t);\n    }\n  }(e, t));\n}\n\nfunction Qy(e, t, n) {\n  var s = Gy(e, () => t());\n  if (null == s) throw new Error(n);\n  return s;\n}\n\nfunction ek(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 2;\n  return d(e.slice(0, e.length - t));\n}\n\nfunction tk(e) {\n  if (0 === e.length) throw Error(\"Cannot get rows and columns of an empty shape array.\");\n  return [e.length > 1 ? e[e.length - 2] : 1, e[e.length - 1]];\n}\n\nfunction nk(e) {\n  var t = [1, 1, 1];\n  return 0 === e.length || 1 === e.length && 1 === e[0] || (t = [ek(e), ...tk(e)]), t;\n}\n\nfunction sk(e) {\n  return e % 2 == 0;\n}\n\nfunction rk(e, t) {\n  if (p(e = e.slice(-2), t = t.slice(-2))) return !0;\n  if (!e.length || !t.length) return !0;\n  if (0 === e[0] || 0 === e[1] || 0 === t[0] || 0 === t[1]) return !0;\n\n  if (e.length !== t.length) {\n    var _n257 = e.slice(-1)[0],\n        _s207 = t.slice(-1)[0];\n    if (_n257 === _s207) return !0;\n    if (sk(_n257) && sk(_s207) && (1 === e[0] || 1 === t[0])) return !0;\n  }\n\n  return e[1] === t[1] && sk(e[0]) && sk(t[0]);\n}\n\nvar ak, ik;\n\nfunction ok(e, t) {\n  return null != e.getExtension(t);\n}\n\nfunction lk(e) {\n  try {\n    if (null != My(e)) return !0;\n  } catch (e) {\n    return console.log(\"Error when getting WebGL context: \", e), !1;\n  }\n\n  return !1;\n}\n\nfunction uk(e) {\n  var t = Vy(e),\n      n = e.createTexture();\n  e.bindTexture(e.TEXTURE_2D, n), e.texImage2D(e.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);\n  var s = e.createFramebuffer();\n  e.bindFramebuffer(e.FRAMEBUFFER, s), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, n, 0);\n  var r = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;\n  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(n), e.deleteFramebuffer(s), r;\n}\n\nfunction ck(e, t) {\n  Array.isArray(e) || (e = [e]), e.forEach(e => {\n    null != e && l(\"complex64\" !== e.dtype, () => \"\".concat(t, \" does not support complex64 tensors in the WebGL backend.\"));\n  });\n}\n\nvar hk = G();\n\nfunction dk() {\n  var e, t, n, s, r, a, i, o, l, u;\n  return 2 === G().getNumber(\"WEBGL_VERSION\") ? (e = \"#version 300 es\", t = \"in\", n = \"out\", s = \"in\", r = \"texture\", a = \"outputColor\", i = \"out vec4 outputColor;\", o = \"\\n      bool isnan_custom(float val) {\\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\\n      }\\n\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan_custom(val.x),\\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\\n      }\\n\\n      #define isnan(value) isnan_custom(value)\\n    \", l = \"\", u = \"\\n      #define round(value) newRound(value)\\n      int newRound(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 newRound(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \") : (e = \"\", t = \"attribute\", n = \"varying\", s = \"varying\", r = \"texture2D\", a = \"gl_FragColor\", i = \"\", o = \"\\n      #define isnan(value) isnan_custom(value)\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\\n      }\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\\n      }\\n    \", l = \"\\n      uniform float INFINITY;\\n\\n      bool isinf(float val) {\\n        return abs(val) == INFINITY;\\n      }\\n      bvec4 isinf(vec4 val) {\\n        return equal(abs(val), vec4(INFINITY));\\n      }\\n    \", u = \"\\n      int round(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 round(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \"), {\n    version: e,\n    attribute: t,\n    varyingVs: n,\n    varyingFs: s,\n    texture2D: r,\n    output: a,\n    defineOutput: i,\n    defineSpecialNaN: o,\n    defineSpecialInf: l,\n    defineRound: u\n  };\n}\n\nfunction pk(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"index\";\n  var s = A(t);\n  return s.map((t, r) => \"int \".concat(e[r], \" = \").concat(n, \" / \").concat(t, \"; \").concat(r === s.length - 1 ? \"int \".concat(e[r + 1], \" = \").concat(n, \" - \").concat(e[r], \" * \").concat(t) : \"index -= \".concat(e[r], \" * \").concat(t), \";\")).join(\"\");\n}\n\nfunction fk(e, t) {\n  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"index\";\n  var s = A(t);\n  return s.map((t, r) => \"int \".concat(e[r], \" = \").concat(n, \" / outShapeStrides[\").concat(r, \"]; \").concat(r === s.length - 1 ? \"int \".concat(e[r + 1], \" = \").concat(n, \" - \").concat(e[r], \" * outShapeStrides[\").concat(r, \"]\") : \"index -= \".concat(e[r], \" * outShapeStrides[\").concat(r, \"]\"), \";\")).join(\"\");\n}\n\nfunction gk(e) {\n  var t = A(e).map(e => e.toString());\n  return \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * \".concat(t[0], \" + coords.y * \").concat(t[1], \" + coords.z;\\n  }\\n\");\n}\n\nhk.registerFlag(\"HAS_WEBGL\", () => hk.getNumber(\"WEBGL_VERSION\") > 0), hk.registerFlag(\"WEBGL_VERSION\", () => lk(2) ? 2 : lk(1) ? 1 : 0), hk.registerFlag(\"WEBGL_CHECK_NUMERICAL_PROBLEMS\", () => !1), hk.registerFlag(\"WEBGL_BUFFER_SUPPORTED\", () => 2 === hk.get(\"WEBGL_VERSION\")), hk.registerFlag(\"WEBGL_CPU_FORWARD\", () => !0), hk.registerFlag(\"WEBGL_FORCE_F16_TEXTURES\", () => !1), hk.registerFlag(\"WEBGL_PACK\", () => hk.getBool(\"HAS_WEBGL\")), hk.registerFlag(\"WEBGL_PACK_NORMALIZATION\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_CLIP\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_DEPTHWISECONV\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_BINARY_OPERATIONS\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_UNARY_OPERATIONS\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_ARRAY_OPERATIONS\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_IMAGE_OPERATIONS\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_PACK_REDUCE\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_LAZILY_UNPACK\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_CONV_IM2COL\", () => hk.getBool(\"WEBGL_PACK\")), hk.registerFlag(\"WEBGL_MAX_TEXTURE_SIZE\", () => function (e) {\n  if (null == ak) {\n    var _t351 = My(e);\n\n    ak = _t351.getParameter(_t351.MAX_TEXTURE_SIZE);\n  }\n\n  return ak;\n}(hk.getNumber(\"WEBGL_VERSION\"))), hk.registerFlag(\"WEBGL_MAX_TEXTURES_IN_SHADER\", () => function (e) {\n  if (null == ik) {\n    var _t352 = My(e);\n\n    ik = _t352.getParameter(_t352.MAX_TEXTURE_IMAGE_UNITS);\n  }\n\n  return Math.min(16, ik);\n}(hk.getNumber(\"WEBGL_VERSION\"))), hk.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\", () => {\n  var e = hk.getNumber(\"WEBGL_VERSION\");\n  return 0 === e ? 0 : function (e) {\n    if (0 === e) return 0;\n    var t;\n    var n = My(e);\n    return t = ok(n, \"EXT_disjoint_timer_query_webgl2\") && 2 === e ? 2 : ok(n, \"EXT_disjoint_timer_query\") ? 1 : 0, t;\n  }(e);\n}), hk.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\", () => hk.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") > 0 && !$t()), hk.registerFlag(\"WEBGL_RENDER_FLOAT32_CAPABLE\", () => function (e) {\n  if (0 === e) return !1;\n  var t = My(e);\n\n  if (1 === e) {\n    if (!ok(t, \"OES_texture_float\")) return !1;\n  } else if (!ok(t, \"EXT_color_buffer_float\")) return !1;\n\n  return uk(t);\n}(hk.getNumber(\"WEBGL_VERSION\"))), hk.registerFlag(\"WEBGL_RENDER_FLOAT32_ENABLED\", () => !hk.getBool(\"WEBGL_FORCE_F16_TEXTURES\") && hk.getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\")), hk.registerFlag(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\", () => function (e) {\n  if (0 === e) return !1;\n  var t = My(e);\n\n  if (1 !== e) {\n    if (ok(t, \"EXT_color_buffer_float\")) return uk(t);\n    var _e423 = \"EXT_color_buffer_half_float\";\n\n    if (ok(t, _e423)) {\n      var _n258 = t.getExtension(_e423);\n\n      return function (e, t) {\n        var n = Vy(e, t),\n            s = e.createTexture();\n        e.bindTexture(e.TEXTURE_2D, s), e.texImage2D(e.TEXTURE_2D, 0, n.internalFormatHalfFloat, 1, 1, 0, n.textureFormatFloat, n.textureTypeHalfFloat, null);\n        var r = e.createFramebuffer();\n        e.bindFramebuffer(e.FRAMEBUFFER, r), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, s, 0);\n        var a = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;\n        return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(s), e.deleteFramebuffer(r), a;\n      }(t, _n258);\n    }\n\n    return !1;\n  }\n\n  return !!ok(t, \"OES_texture_float\") && !!ok(t, \"WEBGL_color_buffer_float\") && uk(t);\n}(hk.getNumber(\"WEBGL_VERSION\"))), hk.registerFlag(\"WEBGL_FENCE_API_ENABLED\", () => {\n  return 2 === (e = hk.getNumber(\"WEBGL_VERSION\")) && null != My(e).fenceSync;\n  var e;\n}), hk.registerFlag(\"WEBGL_SIZE_UPLOAD_UNIFORM\", () => hk.getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") ? 4 : 0), hk.registerFlag(\"WEBGL_DELETE_TEXTURE_THRESHOLD\", () => -1, e => {\n  if (e < 0 && -1 !== e) throw new Error(\"WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got \".concat(e, \".\"));\n}), hk.registerFlag(\"WEBGL_FLUSH_THRESHOLD\", () => $t() && hk.getBool(\"IS_CHROME\") ? 1 : -1, e => {\n  if (e < 0 && -1 !== e) throw new Error(\"WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got \".concat(e, \".\"));\n}), hk.registerFlag(\"CPU_HANDOFF_SIZE_THRESHOLD\", () => 128), hk.registerFlag(\"WEBGL_USE_SHAPES_UNIFORMS\", () => !1), hk.registerFlag(\"TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD\", () => 1e5), hk.registerFlag(\"TOPK_K_CPU_HANDOFF_THRESHOLD\", () => 128);\nvar mk = \"\\n  const float FLOAT_MAX = 1.70141184e38;\\n  const float FLOAT_MIN = 1.17549435e-38;\\n\\n  lowp vec4 encode_float(highp float v) {\\n    if (isnan(v)) {\\n      return vec4(255, 255, 255, 255);\\n    }\\n\\n    highp float av = abs(v);\\n\\n    if(av < FLOAT_MIN) {\\n      return vec4(0.0, 0.0, 0.0, 0.0);\\n    } else if(v > FLOAT_MAX) {\\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n    } else if(v < -FLOAT_MAX) {\\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n    }\\n\\n    highp vec4 c = vec4(0,0,0,0);\\n\\n    highp float e = floor(log2(av));\\n    highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n    c[2] = floor(128.0 * m);\\n    m -= c[2] / 128.0;\\n    c[1] = floor(32768.0 * m);\\n    m -= c[1] / 32768.0;\\n    c[0] = floor(8388608.0 * m);\\n\\n    highp float ebias = e + 127.0;\\n    c[3] = floor(ebias / 2.0);\\n    ebias -= c[3] * 2.0;\\n    c[2] += floor(ebias) * 128.0;\\n\\n    c[3] += 128.0 * step(0.0, -v);\\n\\n    return c / 255.0;\\n  }\\n\",\n    {\n  getBroadcastDims: bk\n} = rl;\n\nfunction xk(e, t, n) {\n  var s = [];\n\n  if (e.forEach(e => {\n    var t = d(e.shapeInfo.logicalShape);\n\n    if (e.shapeInfo.isUniform ? s.push(\"uniform float \".concat(e.name).concat(t > 1 ? \"[\".concat(t, \"]\") : \"\", \";\")) : (s.push(\"uniform sampler2D \".concat(e.name, \";\")), s.push(\"uniform int offset\".concat(e.name, \";\"))), n.enableShapeUniforms) {\n      var {\n        uniformShape: _t353\n      } = Tk(n.packedInputs, e.shapeInfo.logicalShape, e.shapeInfo.texShape);\n\n      switch (_t353.length) {\n        case 1:\n          s.push(\"uniform int \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 2:\n          s.push(\"uniform ivec2 \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 3:\n          s.push(\"uniform ivec3 \".concat(e.name, \"Shape;\"));\n          break;\n\n        case 4:\n          s.push(\"uniform ivec4 \".concat(e.name, \"Shape;\"));\n      }\n\n      s.push(\"uniform ivec2 \".concat(e.name, \"TexShape;\"));\n    }\n  }), n.enableShapeUniforms) {\n    switch (t.logicalShape.length) {\n      case 1:\n        s.push(\"uniform int outShape;\");\n        break;\n\n      case 2:\n        s.push(\"uniform ivec2 outShape;\"), s.push(\"uniform int outShapeStrides;\");\n        break;\n\n      case 3:\n        s.push(\"uniform ivec3 outShape;\"), s.push(\"uniform ivec2 outShapeStrides;\");\n        break;\n\n      case 4:\n        s.push(\"uniform ivec4 outShape;\"), s.push(\"uniform ivec3 outShapeStrides;\");\n    }\n\n    s.push(\"uniform ivec2 outTexShape;\");\n  }\n\n  n.customUniforms && n.customUniforms.forEach(e => {\n    s.push(\"uniform \".concat(e.type, \" \").concat(e.name).concat(e.arrayIndex ? \"[\".concat(e.arrayIndex, \"]\") : \"\", \";\"));\n  });\n\n  var r = s.join(\"\\n\"),\n      a = e.map(e => function (e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;\n    var s = arguments.length > 3 ? arguments[3] : undefined;\n    var r = \"\";\n    return r += n ? kk(e, s) : yk(e, s), e.shapeInfo.logicalShape.length <= t.logicalShape.length && (r += n ? function (e, t) {\n      var n = e.name,\n          s = n.charAt(0).toUpperCase() + n.slice(1),\n          r = \"get\" + s + \"AtOutCoords\",\n          a = e.shapeInfo.logicalShape.length,\n          i = t.logicalShape.length,\n          o = bk(e.shapeInfo.logicalShape, t.logicalShape),\n          l = Ck(i),\n          u = i - a;\n      var c;\n      var h = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n      c = 0 === a ? \"\" : i < 2 && o.length >= 1 ? \"coords = 0;\" : o.map(e => \"coords.\".concat(h[e + u], \" = 0;\")).join(\"\\n\");\n      var p = \"\";\n      p = i < 2 && a > 0 ? \"coords\" : e.shapeInfo.logicalShape.map((e, t) => \"coords.\".concat(h[t + u])).join(\", \");\n      var f = \"return outputValue;\";\n      var g = 1 === d(e.shapeInfo.logicalShape),\n          m = 1 === d(t.logicalShape);\n\n      if (1 !== a || g || m) {\n        if (g && !m) f = 1 === i ? \"\\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\\n      \" : \"\\n        return vec4(outputValue.x);\\n      \";else if (o.length) {\n          var _e424 = a - 2,\n              _t354 = a - 1;\n\n          o.indexOf(_e424) > -1 && o.indexOf(_t354) > -1 ? f = \"return vec4(outputValue.x);\" : o.indexOf(_e424) > -1 ? f = \"return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);\" : o.indexOf(_t354) > -1 && (f = \"return vec4(outputValue.xx, outputValue.zz);\");\n        }\n      } else f = \"\\n      return vec4(outputValue.xy, outputValue.xy);\\n    \";\n\n      return \"\\n    vec4 \".concat(r, \"() {\\n      \").concat(l, \" coords = getOutputCoords();\\n      \").concat(c, \"\\n      vec4 outputValue = get\").concat(s, \"(\").concat(p, \");\\n      \").concat(f, \"\\n    }\\n  \");\n    }(e, t) : function (e, t) {\n      var n = e.name,\n          s = n.charAt(0).toUpperCase() + n.slice(1),\n          r = \"get\" + s + \"AtOutCoords\",\n          a = e.shapeInfo.logicalShape.length,\n          i = t.logicalShape.length;\n      if (!e.shapeInfo.isUniform && a === i && null == e.shapeInfo.flatOffset && p(e.shapeInfo.texShape, t.texShape)) return \"\\n      float \".concat(r, \"() {\\n        return sampleTexture(\").concat(n, \", resultUV);\\n      }\\n    \");\n      var o = Ck(i),\n          l = bk(e.shapeInfo.logicalShape, t.logicalShape),\n          u = i - a;\n      var c;\n      var h = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n      c = 0 === a ? \"\" : i < 2 && l.length >= 1 ? \"coords = 0;\" : l.map(e => \"coords.\".concat(h[e + u], \" = 0;\")).join(\"\\n\");\n      var d = \"\";\n      return d = i < 2 && a > 0 ? \"coords\" : e.shapeInfo.logicalShape.map((e, t) => \"coords.\".concat(h[t + u])).join(\", \"), \"\\n    float \".concat(r, \"() {\\n      \").concat(o, \" coords = getOutputCoords();\\n      \").concat(c, \"\\n      return get\").concat(s, \"(\").concat(d, \");\\n    }\\n  \");\n    }(e, t)), r;\n  }(e, t, n.packedInputs, n.enableShapeUniforms)).join(\"\\n\"),\n      i = t.texShape,\n      o = dk(),\n      l = function (e) {\n    return \"\\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n      return \".concat(e.texture2D, \"(textureSampler, uv).r;\\n    }\\n  \");\n  }(o);\n\n  var u,\n      c,\n      h = function (e) {\n    return \"\".concat(e.version, \"\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    \").concat(e.varyingFs, \" vec2 resultUV;\\n    \").concat(e.defineOutput, \"\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    uniform float NAN;\\n    \").concat(e.defineSpecialNaN, \"\\n    \").concat(e.defineSpecialInf, \"\\n    \").concat(e.defineRound, \"\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    int idiv(int a, int b, float sign) {\\n      int res = a / b;\\n      int mod = imod(a, b);\\n      if (sign < 0. && mod != 0) {\\n        res -= 1;\\n      }\\n      return res;\\n    }\\n\\n    //Based on the work of Dave Hoskins\\n    //https://www.shadertoy.com/view/4djSRW\\n    #define HASHSCALE1 443.8975\\n    float random(float seed){\\n      vec2 p = resultUV * seed;\\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\\n      p3 += dot(p3, p3.yzx + 19.19);\\n      return fract((p3.x + p3.y) * p3.z);\\n    }\\n\\n    \").concat(wk, \"\\n    \").concat(vk, \"\\n    \").concat(Ik, \"\\n  \");\n  }(o);\n\n  return t.isPacked ? (u = function (e, t, n) {\n    switch (e.length) {\n      case 0:\n        return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n\n      case 1:\n        return function (e, t, n) {\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];\n          return 1 === s[0] ? n ? \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * \".concat(s[1], \".0);\\n      }\\n    \") : 1 === s[1] ? n ? \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * \".concat(s[0], \".0);\\n      }\\n    \") : n ? \"\\n    int getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\\n    }\\n  \" : \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      return 2 * (resTexRC.x * \").concat(s[1], \" + resTexRC.y);\\n    }\\n  \");\n        }(0, t, n);\n\n      case 2:\n        return function (e, t, n) {\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];\n          if (p(e, t)) return n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        return 2 * ivec2(resultUV.yx * vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      }\\n    \");\n          var r = Math.ceil(e[1] / 2);\n          return n ? \"\\n    ivec2 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \" : \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 3:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n\\n      int b = index / texelsInBatch;\\n      index -= b * texelsInBatch;\\n\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \";\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],\n              r = Math.ceil(e[2] / 2),\n              a = r * Math.ceil(e[1] / 2);\n          return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(s[0], \", \").concat(s[1], \"));\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n\\n      int b = index / \").concat(a, \";\\n      index -= b * \").concat(a, \";\\n\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      default:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(packedTexShape[0], packedTexShape[1]));\\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\\n\\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\\n      int texelsInBatchN = texelsInBatch * outShape[1];\\n\\n      int b2 = index / texelsInBatchN;\\n      index -= b2 * texelsInBatchN;\\n\\n      int b = index / texelsInBatch;\\n      index -= b * texelsInBatch;\\n\\n      int r = 2 * (index / texelsInLogicalRow);\\n      int c = imod(index, texelsInLogicalRow) * 2;\\n\\n      return ivec4(b2, b, r, c);\\n    }\\n  \";\n          var s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],\n              r = Math.ceil(e[e.length - 1] / 2),\n              a = r * Math.ceil(e[e.length - 2] / 2);\n          var i = a,\n              o = \"\",\n              l = \"b, r, c\";\n\n          for (var _t355 = 2; _t355 < e.length - 1; _t355++) {\n            i *= e[e.length - _t355 - 1], o = \"\\n      int b\".concat(_t355, \" = index / \").concat(i, \";\\n      index -= b\").concat(_t355, \" * \").concat(i, \";\\n    \") + o, l = \"b\".concat(_t355, \", \") + l;\n          }\n\n          return \"\\n    ivec\".concat(e.length, \" getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\").concat(s[0], \", \").concat(s[1], \"));\\n      int index = resTexRC.x * \").concat(s[1], \" + resTexRC.y;\\n\\n      \").concat(o, \"\\n\\n      int b = index / \").concat(a, \";\\n      index -= b * \").concat(a, \";\\n\\n      int r = 2 * (index / \").concat(r, \");\\n      int c = imod(index, \").concat(r, \") * 2;\\n\\n      return ivec\").concat(e.length, \"(\").concat(l, \");\\n    }\\n  \");\n        }(e, t, n);\n    }\n  }(t.logicalShape, i, n.enableShapeUniforms), c = function (e) {\n    return \"\\n    void setOutput(vec4 val) {\\n      \".concat(e.output, \" = val;\\n    }\\n  \");\n  }(o)) : (u = function (e, t, n) {\n    switch (e.length) {\n      case 0:\n        return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n\n      case 1:\n        return function (e, t, n) {\n          return 1 === t[0] ? n ? \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * float(outTexShape[1]));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * \".concat(t[1], \".0);\\n      }\\n    \") : 1 === t[1] ? n ? \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * float(outTexShape[0]));\\n      }\\n    \" : \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * \".concat(t[0], \".0);\\n      }\\n    \") : n ? \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(outTexShape[0], outTexShape[1]));\\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\\n    }\\n  \" : \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      return resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n    }\\n  \");\n        }(0, t, n);\n\n      case 2:\n        return function (e, t, n) {\n          return p(e, t) ? n ? \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      }\\n    \") : 1 === e[1] ? n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(outTexShape[0], outTexShape[1]));\\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n        int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \") : 1 === e[0] ? n ? \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(outTexShape[0], outTexShape[1]));\\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \" : \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n        int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \") : n ? \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(outTexShape[0], outTexShape[1]));\\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n      int r = index / outShape[1];\\n      int c = index - r * outShape[1];\\n      return ivec2(r, c);\\n    }\\n  \" : \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      int r = index / \").concat(e[1], \";\\n      int c = index - r * \").concat(e[1], \";\\n      return ivec2(r, c);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 3:\n        return function (e, t, n) {\n          if (n) return \"\\n  ivec3 getOutputCoords() {\\n    ivec2 resTexRC = ivec2(resultUV.yx *\\n                           vec2(outTexShape[0], outTexShape[1]));\\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n    \".concat(fk([\"r\", \"c\", \"d\"], e), \"\\n    return ivec3(r, c, d);\\n  }\\n\");\n          var s = pk([\"r\", \"c\", \"d\"], e);\n          return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      \").concat(s, \"\\n      return ivec3(r, c, d);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 4:\n        return function (e, t, n) {\n          if (n) return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(outTexShape[0], outTexShape[1]));\\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\\n      \".concat(fk([\"r\", \"c\", \"d\", \"d2\"], e), \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \");\n          var s = pk([\"r\", \"c\", \"d\", \"d2\"], e);\n          return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n      \").concat(s, \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \");\n        }(e, t, n);\n\n      case 5:\n        return function (e, t) {\n          var n = pk([\"r\", \"c\", \"d\", \"d2\", \"d3\"], e);\n          return \"\\n    ivec5 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(\".concat(t[0], \",\\n                             \").concat(t[1], \"));\\n\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n\\n      \").concat(n, \"\\n\\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\\n      return outShape;\\n    }\\n  \");\n        }(e, t);\n\n      case 6:\n        return function (e, t) {\n          var n = pk([\"r\", \"c\", \"d\", \"d2\", \"d3\", \"d4\"], e);\n          return \"\\n    ivec6 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\".concat(t[0], \", \").concat(t[1], \"));\\n      int index = resTexRC.x * \").concat(t[1], \" + resTexRC.y;\\n\\n      \").concat(n, \"\\n\\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\\n      return result;\\n    }\\n  \");\n        }(e, t);\n\n      default:\n        throw new Error(\"\".concat(e.length, \"-D output sampling is not yet supported\"));\n    }\n  }(t.logicalShape, i, n.enableShapeUniforms), c = function (e) {\n    return \"\\n    void setOutput(float val) {\\n      \".concat(e.output, \" = vec4(val, 0, 0, 0);\\n    }\\n  \");\n  }(o)), n.packedInputs && (h += $k), [h, l, c, r, u, a, n.userCode].join(\"\\n\");\n}\n\nfunction yk(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  var n = e.shapeInfo.logicalShape;\n\n  switch (n.length) {\n    case 0:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1);\n        if (e.shapeInfo.isUniform) return \"float \".concat(s, \"() {return \").concat(n, \";}\");\n        var [r, a] = e.shapeInfo.texShape;\n        if (1 === r && 1 === a) return \"\\n      float \".concat(s, \"() {\\n        return sampleTexture(\").concat(n, \", halfCR);\\n      }\\n    \");\n        var i = Sk(n);\n        if (t) return \"\\n    float \".concat(s, \"() {\\n      vec2 uv = uvFromFlat(\").concat(n, \"TexShape[0], \").concat(n, \"TexShape[1], \").concat(i, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n        var [o, l] = e.shapeInfo.texShape;\n        return \"\\n    float \".concat(s, \"() {\\n      vec2 uv = uvFromFlat(\").concat(o, \", \").concat(l, \", \").concat(i, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 1:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1);\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int index) {\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var r = e.shapeInfo.texShape,\n            a = r[0],\n            i = r[1];\n        if (1 === i && 1 === a) return \"\\n      float \".concat(s, \"(int index) {\\n        return sampleTexture(\").concat(n, \", halfCR);\\n      }\\n    \");\n        var o = Sk(n);\n        return 1 === i ? t ? \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \").concat(o, \") + 0.5) / float(\").concat(n, \"TexShape[0]));\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \").concat(o, \") + 0.5) / \").concat(a, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : 1 === a ? t ? \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2((float(index + \").concat(o, \") + 0.5) / float(\").concat(n, \"TexShape[1]), 0.5);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(s, \"(int index) {\\n        vec2 uv = vec2((float(index + \").concat(o, \") + 0.5) / \").concat(i, \".0, 0.5);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : t ? \"\\n    float \".concat(s, \"(int index) {\\n      vec2 uv = uvFromFlat(\").concat(n, \"TexShape[0], \").concat(n, \"TexShape[1], index + \").concat(o, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \") : \"\\n    float \".concat(s, \"(int index) {\\n      vec2 uv = uvFromFlat(\").concat(a, \", \").concat(i, \", index + \").concat(o, \");\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 2:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape;\n        if (null != a && p(n, a)) return t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(a[1], \".0, \").concat(a[0], \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n        var {\n          newShape: i,\n          keptDims: o\n        } = k(n);\n\n        if (i.length < n.length) {\n          var _n259 = [\"row\", \"col\"];\n          return \"\\n      \".concat(yk(Ek(e, i), t), \"\\n      float \").concat(r, \"(int row, int col) {\\n        return \").concat(r, \"(\").concat(Rk(_n259, o), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col) {\\n        int index = round(dot(vec2(row, col), vec2(\").concat(n[1], \", 1)));\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var l = a[0],\n            u = a[1],\n            c = Sk(s);\n        return 1 === u ? t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(s, \"Shape[1], 1, 1));\\n        vec2 uv = vec2(0.5, (index + 0.5) / float(\").concat(s, \"TexShape[0]));\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(n[1], \", 1, 1));\\n      vec2 uv = vec2(0.5, (index + 0.5) / \").concat(l, \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : 1 === l ? t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(s, \"Shape[1], 1, 1));\\n        vec2 uv = vec2((index + 0.5) / float(\").concat(s, \"TexShape[1]), 0.5);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col) {\\n      float index = dot(vec3(row, col, \").concat(c, \"), vec3(\").concat(n[1], \", 1, 1));\\n      vec2 uv = vec2((index + 0.5) / \").concat(u, \".0, 0.5);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : t ? \"\\n      float \".concat(r, \"(int row, int col) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \").concat(s, \"Shape[1] + col + \").concat(c, \";\\n        vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n  float \".concat(r, \"(int row, int col) {\\n    // Explicitly use integer operations as dot() only works on floats.\\n    int index = row * \").concat(n[1], \" + col + \").concat(c, \";\\n    vec2 uv = uvFromFlat(\").concat(l, \", \").concat(u, \", index);\\n    return sampleTexture(\").concat(s, \", uv);\\n  }\\n\");\n      }(e, t);\n\n    case 3:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = n[1] * n[2],\n            i = n[2],\n            {\n          newShape: o,\n          keptDims: l\n        } = k(n);\n\n        if (o.length < n.length) {\n          var _n260 = [\"row\", \"col\", \"depth\"];\n          return \"\\n        \".concat(yk(Ek(e, o), t), \"\\n        float \").concat(r, \"(int row, int col, int depth) {\\n          return \").concat(r, \"(\").concat(Rk(_n260, l), \");\\n        }\\n      \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        int index = round(dot(vec3(row, col, depth),\\n                          vec3(\").concat(a, \", \").concat(i, \", 1)));\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var u = e.shapeInfo.texShape,\n            c = u[0],\n            h = u[1],\n            d = e.shapeInfo.flatOffset;\n        if (h === a && null == d) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        int stride1 = \").concat(s, \"Shape[2];\\n        float texR = float(row);\\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n        float \".concat(r, \"(int row, int col, int depth) {\\n          float texR = float(row);\\n          float texC = dot(vec2(col, depth), vec2(\").concat(i, \", 1));\\n          vec2 uv = (vec2(texC, texR) + halfCR) /\\n                     vec2(\").concat(h, \".0, \").concat(c, \".0);\\n          return sampleTexture(\").concat(s, \", uv);\\n        }\\n      \");\n        if (h === i && null == d) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        float texR = dot(vec2(row, col), vec2(\").concat(s, \"Shape[1], 1));\\n        float texC = float(depth);\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(r, \"(int row, int col, int depth) {\\n      float texR = dot(vec2(row, col), vec2(\").concat(n[1], \", 1));\\n      float texC = float(depth);\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(h, \".0, \").concat(c, \".0);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n        var p = Sk(s);\n        return t ? \"\\n    float \".concat(r, \"(int row, int col, int depth) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int stride0 = \").concat(s, \"Shape[1] * \").concat(s, \"Shape[2];\\n      int stride1 = \").concat(s, \"Shape[2];\\n      int index = row * \").concat(a, \" + col * \").concat(i, \" + depth + \").concat(p, \";\\n      vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index);\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \").concat(a, \" + col * \").concat(i, \" + depth + \").concat(p, \";\\n        vec2 uv = uvFromFlat(\").concat(c, \", \").concat(h, \", index);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n  \");\n      }(e, t);\n\n    case 4:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = n[3],\n            i = n[2] * a,\n            o = n[1] * i,\n            {\n          newShape: l,\n          keptDims: u\n        } = k(n);\n\n        if (l.length < n.length) {\n          var _n261 = [\"row\", \"col\", \"depth\", \"depth2\"];\n          return \"\\n      \".concat(yk(Ek(e, l), t), \"\\n      float \").concat(r, \"(int row, int col, int depth, int depth2) {\\n        return \").concat(r, \"(\").concat(Rk(_n261, u), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        int index = round(dot(vec4(row, col, depth, depth2),\\n                          vec4(\").concat(o, \", \").concat(i, \", \").concat(a, \", 1)));\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var c = e.shapeInfo.flatOffset,\n            h = e.shapeInfo.texShape,\n            d = h[0],\n            p = h[1],\n            f = \"int stride2 = \".concat(s, \"Shape[3];\"),\n            g = \"int stride1 = \".concat(s, \"Shape[2] * stride2;\"),\n            m = \"int stride0 = \".concat(s, \"Shape[1] * stride1;\");\n        if (p === o && null == c) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        \").concat(f, \"\\n        \").concat(g, \"\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(stride1, stride2, 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(\").concat(i, \", \").concat(a, \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \");\n        if (p === a && null == c) return t ? \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\").concat(s, \"Shape[1] * \").concat(s, \"Shape[2], \").concat(s, \"Shape[2], 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\").concat(n[1] * n[2], \", \").concat(n[2], \", 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(s, \", uv);\\n      }\\n    \");\n        var b = Sk(s);\n        return t ? \"\\n    float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      \").concat(f, \"\\n      \").concat(g, \"\\n      \").concat(m, \"\\n      int index = row * stride0 + col * stride1 +\\n          depth * stride2 + depth2;\\n      vec2 uv = uvFromFlat(\").concat(s, \"TexShape[0], \").concat(s, \"TexShape[1], index + \").concat(b, \");\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \") : \"\\n    float \".concat(r, \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(o, \" + col * \").concat(i, \" +\\n          depth * \").concat(a, \" + depth2;\\n      vec2 uv = uvFromFlat(\").concat(d, \", \").concat(p, \", index + \").concat(b, \");\\n      return sampleTexture(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 5:\n      return function (e) {\n        var t = e.shapeInfo.logicalShape,\n            n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = t[4],\n            a = t[3] * r,\n            i = t[2] * a,\n            o = t[1] * i,\n            {\n          newShape: l,\n          keptDims: u\n        } = k(t);\n\n        if (l.length < t.length) {\n          var _t356 = [\"row\", \"col\", \"depth\", \"depth2\", \"depth3\"];\n          return \"\\n      \".concat(yk(Ek(e, l)), \"\\n      float \").concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        return \").concat(s, \"(\").concat(Rk(_t356, u), \");\\n      }\\n    \");\n        }\n\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        float index = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(o, \", \").concat(i, \", \").concat(a, \", \").concat(r, \")) +\\n          depth3;\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var c = e.shapeInfo.flatOffset,\n            h = e.shapeInfo.texShape,\n            d = h[0],\n            p = h[1];\n        return p === o && null == c ? \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n                         vec4(\").concat(i, \", \").concat(a, \", \").concat(r, \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : p === r && null == c ? \"\\n      float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n        float texR = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(t[1] * t[2] * t[3], \",\\n               \").concat(t[2] * t[3], \", \").concat(t[3], \", 1));\\n        int texC = depth3;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(p, \".0, \").concat(d, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(s, \"(int row, int col, int depth, int depth2, int depth3) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(o, \" + col * \").concat(i, \" + depth * \").concat(a, \" +\\n          depth2 * \").concat(r, \" + depth3 + \").concat(Sk(n), \";\\n      vec2 uv = uvFromFlat(\").concat(d, \", \").concat(p, \", index);\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e);\n\n    case 6:\n      return function (e) {\n        var t = e.shapeInfo.logicalShape,\n            n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            {\n          newShape: r,\n          keptDims: a\n        } = k(t);\n\n        if (r.length < t.length) {\n          var _t357 = [\"row\", \"col\", \"depth\", \"depth2\", \"depth3\", \"depth4\"];\n          return \"\\n      \".concat(yk(Ek(e, r)), \"\\n      float \").concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        return \").concat(s, \"(\").concat(Rk(_t357, a), \");\\n      }\\n    \");\n        }\n\n        var i = t[5],\n            o = t[4] * i,\n            l = t[3] * o,\n            u = t[2] * l,\n            c = t[1] * u;\n        if (e.shapeInfo.isUniform) return \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n        int index = round(dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\").concat(c, \", \").concat(u, \", \").concat(l, \", \").concat(o, \")) +\\n          dot(\\n            vec2(depth3, depth4),\\n            vec2(\").concat(i, \", 1)));\\n        \").concat(Nk(e), \"\\n      }\\n    \");\n        var h = e.shapeInfo.flatOffset,\n            d = e.shapeInfo.texShape,\n            p = d[0],\n            f = d[1];\n        return f === c && null == h ? \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n          vec4(\").concat(u, \", \").concat(l, \", \").concat(o, \", \").concat(i, \")) +\\n               float(depth4);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\").concat(f, \".0, \").concat(p, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : f === i && null == h ? \"\\n      float \".concat(s, \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        float texR = dot(vec4(row, col, depth, depth2),\\n          vec4(\").concat(t[1] * t[2] * t[3] * t[4], \",\\n               \").concat(t[2] * t[3] * t[4], \",\\n               \").concat(t[3] * t[4], \",\\n               \").concat(t[4], \")) + float(depth3);\\n        int texC = depth4;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\").concat(f, \".0, \").concat(p, \".0);\\n        return sampleTexture(\").concat(n, \", uv);\\n      }\\n    \") : \"\\n    float \".concat(s, \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \").concat(c, \" + col * \").concat(u, \" + depth * \").concat(l, \" +\\n          depth2 * \").concat(o, \" + depth3 * \").concat(i, \" + depth4 + \").concat(Sk(n), \";\\n      vec2 uv = uvFromFlat(\").concat(p, \", \").concat(f, \", index);\\n      return sampleTexture(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e);\n\n    default:\n      throw new Error(\"\".concat(n.length, \"-D input sampling is not yet supported\"));\n  }\n}\n\nfunction kk(e, t) {\n  switch (e.shapeInfo.logicalShape.length) {\n    case 0:\n      return function (e) {\n        var t = e.name;\n        return \"\\n    vec4 \".concat(\"get\" + t.charAt(0).toUpperCase() + t.slice(1), \"() {\\n      return \").concat(dk().texture2D, \"(\").concat(t, \", halfCR);\\n    }\\n  \");\n      }(e);\n\n    case 1:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = e.shapeInfo.texShape,\n            a = dk();\n        if (t) return \"\\n    vec4 \".concat(s, \"(int index) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(n, \"TexShape[0]) / 2.0), ceil(float(\").concat(n, \"TexShape[1]) / 2.0));\\n      vec2 uv = packedUVfrom1D(\\n        packedTexShape[0], packedTexShape[1], index);\\n      return \").concat(a.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n        var i = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)];\n        return \"\\n    vec4 \".concat(s, \"(int index) {\\n      vec2 uv = packedUVfrom1D(\\n        \").concat(i[0], \", \").concat(i[1], \", index);\\n      return \").concat(a.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 2:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape,\n            i = a[0],\n            o = a[1],\n            l = dk();\n        if (null != a && p(n, a)) return t ? \"\\n      vec4 \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(s, \"TexShape[1], \").concat(s, \"TexShape[0]);\\n\\n        return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n      }\\n    \") : \"\\n      vec4 \".concat(r, \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\").concat(o, \".0, \").concat(i, \".0);\\n\\n        return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n      }\\n    \");\n        if (t) return \"\\n    vec4 \".concat(r, \"(int row, int col) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(s, \"TexShape[0]) / 2.0), ceil(float(\").concat(s, \"TexShape[1]) / 2.0));\\n      int valuesPerRow = int(ceil(float(\").concat(s, \"Shape[1]) / 2.0));\\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\\n      return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n        var u = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];\n        return \"\\n    vec4 \".concat(r, \"(int row, int col) {\\n      vec2 uv = packedUVfrom2D(\").concat(Math.ceil(n[1] / 2), \", \").concat(u[0], \", \").concat(u[1], \", row, col);\\n      return \").concat(l.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    case 3:\n      return function (e, t) {\n        var n = e.shapeInfo.logicalShape,\n            s = e.name,\n            r = \"get\" + s.charAt(0).toUpperCase() + s.slice(1),\n            a = e.shapeInfo.texShape,\n            i = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];\n\n        if (1 === n[0]) {\n          var _s208 = [1, 2],\n              _a122 = [\"b\", \"row\", \"col\"];\n          return \"\\n        \".concat(kk(Ek(e, n.slice(1)), t), \"\\n        vec4 \").concat(r, \"(int b, int row, int col) {\\n          return \").concat(r, \"(\").concat(Rk(_a122, _s208), \");\\n        }\\n      \");\n        }\n\n        var o = dk();\n        if (t) return \"\\n    vec4 \".concat(r, \"(int b, int row, int col) {\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(s, \"TexShape[0]) / 2.0), ceil(float(\").concat(s, \"TexShape[1]) / 2.0));\\n      int valuesPerRow = int(ceil(float(\").concat(s, \"Shape[2]) / 2.0));\\n      int texelsInBatch = valuesPerRow * int(ceil(float(\").concat(s, \"Shape[1]) / 2.0));\\n      vec2 uv = packedUVfrom3D(\\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\\n      return \").concat(o.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n        var l = i[0],\n            u = i[1],\n            c = Math.ceil(n[2] / 2);\n        return \"\\n    vec4 \".concat(r, \"(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        \").concat(l, \", \").concat(u, \", \").concat(c * Math.ceil(n[1] / 2), \", \").concat(c, \", b, row, col);\\n      return \").concat(o.texture2D, \"(\").concat(s, \", uv);\\n    }\\n  \");\n      }(e, t);\n\n    default:\n      return function (e, t) {\n        var n = e.name,\n            s = \"get\" + n.charAt(0).toUpperCase() + n.slice(1),\n            r = dk();\n        if (t) return \"\\n    vec4 \".concat(s, \"(int b2, int b, int row, int col) {\\n      int valuesPerRow = int(ceil(float(\").concat(n, \"Shape[3]) / 2.0));\\n      int texelsInBatch = valuesPerRow * int(ceil(float(\").concat(n, \"Shape[2]) / 2.0));\\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\\n      texelsInBatch *= \").concat(n, \"Shape[1];\\n      index = b2 * texelsInBatch + index;\\n      ivec2 packedTexShape = ivec2(ceil(float(\").concat(n, \"TexShape[0]) / 2.0), ceil(float(\").concat(n, \"TexShape[1]) / 2.0));\\n      int texR = index / packedTexShape[1];\\n      int texC = index - texR * packedTexShape[1];\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return \").concat(r.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n        var a = e.shapeInfo.logicalShape,\n            i = a.length,\n            o = e.shapeInfo.texShape,\n            l = [Math.ceil(o[0] / 2), Math.ceil(o[1] / 2)],\n            u = l[0],\n            c = l[1],\n            h = Math.ceil(a[i - 1] / 2);\n        var d = h * Math.ceil(a[i - 2] / 2),\n            p = \"int b, int row, int col\",\n            f = \"b * \".concat(d, \" + (row / 2) * \").concat(h, \" + (col / 2)\");\n\n        for (var _e425 = 2; _e425 < i - 1; _e425++) {\n          p = \"int b\".concat(_e425, \", \") + p, d *= a[i - _e425 - 1], f = \"b\".concat(_e425, \" * \").concat(d, \" + \") + f;\n        }\n\n        return \"\\n    vec4 \".concat(s, \"(\").concat(p, \") {\\n      int index = \").concat(f, \";\\n      int texR = index / \").concat(c, \";\\n      int texC = index - texR * \").concat(c, \";\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\").concat(c, \", \").concat(u, \");\\n      return \").concat(r.texture2D, \"(\").concat(n, \", uv);\\n    }\\n  \");\n      }(e, t);\n  }\n}\n\nvar wk = \"\\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n  int texelIndex = index / 2;\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    vk = \"\\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\\n  int texNumC, int row, int col) {\\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    Ik = \"\\nvec2 packedUVfrom3D(int texNumR, int texNumC,\\n    int texelsInBatch, int texelsInLogicalRow, int b,\\n    int row, int col) {\\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",\n    $k = \"\\n  float getChannel(vec4 frag, vec2 innerDims) {\\n    vec2 modCoord = mod(innerDims, 2.);\\n    return modCoord.x == 0. ?\\n      (modCoord.y == 0. ? frag.r : frag.g) :\\n      (modCoord.y == 0. ? frag.b : frag.a);\\n  }\\n  float getChannel(vec4 frag, int dim) {\\n    float modCoord = mod(float(dim), 2.);\\n    return modCoord == 0. ? frag.r : frag.g;\\n  }\\n\";\n\nfunction Sk(e) {\n  return \"offset\".concat(e);\n}\n\nfunction Nk(e) {\n  var t = e.name,\n      n = d(e.shapeInfo.logicalShape);\n  return n < 2 ? \"return \".concat(t, \";\") : \"\\n    for (int i = 0; i < \".concat(n, \"; i++) {\\n      if (i == index) {\\n        return \").concat(t, \"[i];\\n      }\\n    }\\n  \");\n}\n\nfunction Ck(e) {\n  if (e <= 1) return \"int\";\n  if (2 === e) return \"ivec2\";\n  if (3 === e) return \"ivec3\";\n  if (4 === e) return \"ivec4\";\n  if (5 === e) return \"ivec5\";\n  if (6 === e) return \"ivec6\";\n  throw Error(\"GPU for rank \".concat(e, \" is not yet supported\"));\n}\n\nfunction Tk(e, t, n) {\n  var {\n    newShape: s,\n    keptDims: r\n  } = k(t),\n      a = t.length,\n      i = e && 3 === a && 1 === t[0],\n      o = i ? t.slice(1) : s,\n      l = !e && a > 1 && !p(t, n) && s.length < a || i;\n  return {\n    useSqueezeShape: l,\n    uniformShape: l ? o : t,\n    keptDims: r\n  };\n}\n\nfunction Ek(e, t) {\n  var n = JSON.parse(JSON.stringify(e));\n  return n.shapeInfo.logicalShape = t, n;\n}\n\nfunction Rk(e, t) {\n  return t.map(t => e[t]).join(\", \");\n}\n\nfunction Ak(e, t) {\n  if (e.length !== t.length) throw Error(\"Binary was compiled with \".concat(e.length, \" inputs, but was executed with \").concat(t.length, \" inputs\"));\n  e.forEach((e, n) => {\n    var s = e.logicalShape,\n        r = t[n],\n        a = r.shape;\n    if (!p(s, a)) throw Error(\"Binary was compiled with different shapes than the current args. Shapes \".concat(s, \" and \").concat(a, \" must match\"));\n    if (e.isUniform && r.isUniform) return;\n    var i = e.texShape,\n        o = r.isUniform ? null : r.texData.texShape;\n    if (!p(i, o)) throw Error(\"Binary was compiled with different texture shapes than the current args. Shape \".concat(i, \" and \").concat(o, \" must match\"));\n  });\n}\n\nfunction Fk(e) {\n  return G().getBool(\"WEBGL_USE_SHAPES_UNIFORMS\") && e <= 4;\n}\n\nclass Dk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0, this.outPackingScheme = Ly.DENSE, this.customUniforms = [{\n      name: \"texShape\",\n      type: \"ivec2\"\n    }];\n    var t = dk();\n    this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length), this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \".concat(this.enableShapeUniforms ? fk([\"r\", \"c\", \"d\"], e) : pk([\"r\", \"c\", \"d\"], e), \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getA(rc.x, rc.y, rc.z);\\n        }\\n\\n        \").concat(t.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nclass _k {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outPackingScheme = Ly.DENSE, this.customUniforms = [{\n      name: \"texShape\",\n      type: \"ivec2\"\n    }];\n    var t = dk();\n    this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length), this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \".concat(this.enableShapeUniforms ? fk([\"r\", \"c\", \"d\"], e) : pk([\"r\", \"c\", \"d\"], e), \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\\n        }\\n\\n        \").concat(t.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nclass Ok {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.outTexUsage = zy.DOWNLOAD;\n    var t = dk();\n    this.outputShape = e, this.userCode = \"\\n      \".concat(mk, \"\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        \").concat(t.output, \" = encode_float(x);\\n      }\\n    \");\n  }\n\n}\n\nclass Mk {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !1, this.outTexUsage = zy.DOWNLOAD;\n    var t = dk();\n    this.outputShape = e, this.userCode = \"\\n      \".concat(mk, \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\\n        \").concat(t.output, \" = encode_float(x);\\n      }\\n    \");\n  }\n\n}\n\nclass Lk {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    this.variableNames = [\"A\"], this.customUniforms = [{\n      name: \"texShape\",\n      type: \"ivec2\"\n    }];\n    var n = dk();\n    this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var s = \"result\";\n    t && (s = \"floor(result * 255. + 0.5)\"), this.userCode = \"\\n      \".concat(this.enableShapeUniforms ? \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\\n  }\\n\" : gk(e), \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        int flatIndex = getFlatIndex(coords);\\n        int offset = imod(flatIndex, 4);\\n\\n        flatIndex = idiv(flatIndex, 4, 1.);\\n\\n        int r = flatIndex / texShape[1];\\n        int c = imod(flatIndex, texShape[1]);\\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\\n        vec4 values = \").concat(n.texture2D, \"(A, uv);\\n\\n        float result;\\n\\n        if(offset == 0) {\\n          result = values[0];\\n        } else if(offset == 1) {\\n          result = values[1];\\n        } else if(offset == 2) {\\n          result = values[2];\\n        } else {\\n          result = values[3];\\n        }\\n\\n        \").concat(n.output, \" = vec4(\").concat(s, \", 0., 0., 0.);\\n      }\\n    \");\n  }\n\n}\n\nclass zk {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0, this.customUniforms = [{\n      name: \"texShape\",\n      type: \"ivec2\"\n    }];\n    var n = dk();\n    this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var s = \"\",\n        r = \"result\";\n    t && (r = \"floor(result * 255. + 0.5)\");\n\n    for (var _t358 = 0; _t358 <= 1; _t358++) {\n      for (var _r154 = 0; _r154 <= 1; _r154++) {\n        var _a123 = 2 * _t358 + _r154;\n\n        s += \"\\n          localCoords = coords;\\n          if(localCoords[2] + \".concat(_r154, \" < \").concat(this.enableShapeUniforms ? \"outShape[2]\" : \"\".concat(e[2]), \") {\\n          localCoords[2] += \").concat(_r154, \";\\n          if (localCoords[1] + \").concat(_t358, \" < \").concat(this.enableShapeUniforms ? \"outShape[1]\" : \"\".concat(e[1]), \") {\\n            localCoords[1] += \").concat(_t358, \";\\n\\n            flatIndex = getFlatIndex(localCoords);\\n            offset = imod(flatIndex, 4);\\n\\n            flatIndex = idiv(flatIndex, 4, 1.);\\n\\n            int r = flatIndex / texShape[1];\\n            int c = imod(flatIndex, texShape[1]);\\n            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\\n            values = \").concat(n.texture2D, \"(A, uv);\\n\\n            if (offset == 0) {\\n              result[\").concat(_a123, \"] = values[0];\\n            } else if (offset == 1) {\\n              result[\").concat(_a123, \"] = values[1];\\n            } else if (offset == 2) {\\n              result[\").concat(_a123, \"] = values[2];\\n            } else {\\n              result[\").concat(_a123, \"] = values[3];\\n            }\\n          }\\n        }\\n        \");\n      }\n    }\n\n    this.userCode = \"\\n        \".concat(this.enableShapeUniforms ? \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\\n  }\\n\" : gk(e), \"\\n\\n        void main() {\\n          ivec3 coords = getOutputCoords();\\n\\n          vec4 result = vec4(0.);\\n          int flatIndex, r, c, offset;\\n          ivec3 localCoords;\\n          vec2 uv;\\n          vec4 values;\\n\\n          \").concat(s, \"\\n\\n          \").concat(n.output, \" = \").concat(r, \";\\n        }\\n    \");\n  }\n\n}\n\nfunction Bk(e, t, n, s, r, a) {\n  !function (e, t) {\n    var n = G().getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");\n    if (e <= 0 || t <= 0) throw new Error(\"Requested texture size [\".concat(e, \"x\").concat(t, \"] is invalid.\"));\n    if (e > n || t > n) throw new Error(\"Requested texture size [\".concat(e, \"x\").concat(t, \"] greater than WebGL maximum on this browser / GPU [\").concat(n, \"x\").concat(n, \"].\"));\n  }(t, n);\n\n  var i = function (e) {\n    return Qy(e, () => e.createTexture(), \"Unable to create WebGLTexture.\");\n  }(e),\n      o = e.TEXTURE_2D;\n\n  return Gy(e, () => e.bindTexture(o, i)), Gy(e, () => e.texParameteri(o, e.TEXTURE_WRAP_S, e.CLAMP_TO_EDGE)), Gy(e, () => e.texParameteri(o, e.TEXTURE_WRAP_T, e.CLAMP_TO_EDGE)), Gy(e, () => e.texParameteri(o, e.TEXTURE_MIN_FILTER, e.NEAREST)), Gy(e, () => e.texParameteri(o, e.TEXTURE_MAG_FILTER, e.NEAREST)), Gy(e, () => e.texImage2D(o, 0, s, t, n, 0, r, a, null)), Gy(e, () => e.bindTexture(e.TEXTURE_2D, null)), i;\n}\n\nfunction Pk(e) {\n  return e.internalFormatFloat;\n}\n\nfunction Wk(e) {\n  return e.internalFormatHalfFloat;\n}\n\nfunction Uk(e) {\n  return e.downloadTextureFormat;\n}\n\nfunction Vk(e) {\n  return e.internalFormatPackedFloat;\n}\n\nfunction Gk(e) {\n  return e.internalFormatPackedHalfFloat;\n}\n\nclass Hk {\n  constructor(e) {\n    this.outputTexture = null, this.program = null, this.disposed = !1, this.vertexAttrsAreBound = !1, this.itemsToPoll = [];\n    var t = G().getNumber(\"WEBGL_VERSION\");\n    null != e ? (this.gl = e, function (e, t) {\n      _y[e] = t;\n    }(t, e)) : this.gl = My(t);\n    var n = \"WEBGL_color_buffer_float\";\n    var s = \"EXT_color_buffer_half_float\";\n\n    if (1 === G().getNumber(\"WEBGL_VERSION\")) {\n      var _e426 = \"OES_texture_half_float\";\n      if (this.textureFloatExtension = qy(this.gl, \"OES_texture_float\"), ok(this.gl, _e426)) this.textureHalfFloatExtension = qy(this.gl, _e426);else if (G().get(\"WEBGL_FORCE_F16_TEXTURES\")) throw new Error(\"GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.\");\n      if (this.colorBufferFloatExtension = this.gl.getExtension(n), ok(this.gl, s)) this.colorBufferHalfFloatExtension = qy(this.gl, s);else if (G().get(\"WEBGL_FORCE_F16_TEXTURES\")) throw new Error(\"GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.\");\n    } else if (n = \"EXT_color_buffer_float\", ok(this.gl, n)) this.colorBufferFloatExtension = this.gl.getExtension(n);else {\n      if (!ok(this.gl, s)) throw new Error(\"GL context does not support color renderable floats\");\n      this.colorBufferHalfFloatExtension = this.gl.getExtension(s);\n    }\n\n    this.vertexBuffer = function (e) {\n      return function (e, t) {\n        var n = Qy(e, () => e.createBuffer(), \"Unable to create WebGLBuffer\");\n        return Gy(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), Gy(e, () => e.bufferData(e.ARRAY_BUFFER, t, e.STATIC_DRAW)), n;\n      }(e, new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]));\n    }(this.gl), this.indexBuffer = function (e) {\n      return function (e, t) {\n        var n = Qy(e, () => e.createBuffer(), \"Unable to create WebGLBuffer\");\n        return Gy(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, n)), Gy(e, () => e.bufferData(e.ELEMENT_ARRAY_BUFFER, t, e.STATIC_DRAW)), n;\n      }(e, new Uint16Array([0, 1, 2, 2, 1, 3]));\n    }(this.gl), this.framebuffer = function (e) {\n      return Qy(e, () => e.createFramebuffer(), \"Unable to create WebGLFramebuffer.\");\n    }(this.gl), this.textureConfig = Vy(this.gl, this.textureHalfFloatExtension);\n  }\n\n  get debug() {\n    return G().getBool(\"DEBUG\");\n  }\n\n  dispose() {\n    if (this.disposed) return;\n    null != this.program && console.warn(\"Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.\"), null != this.outputTexture && console.warn(\"Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.\");\n    var e = this.gl;\n    Gy(e, () => e.finish()), Gy(e, () => e.bindFramebuffer(e.FRAMEBUFFER, null)), Gy(e, () => e.deleteFramebuffer(this.framebuffer)), Gy(e, () => e.bindBuffer(e.ARRAY_BUFFER, null)), Gy(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, null)), Gy(e, () => e.deleteBuffer(this.indexBuffer)), this.disposed = !0;\n  }\n\n  createFloat32MatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = Py(t, n);\n      return Bk(e, r, a, Pk(s), s.textureFormatFloat, e.FLOAT);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createFloat16MatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = Py(t, n);\n      return Bk(e, r, a, Wk(s), s.textureFormatFloat, s.textureTypeHalfFloat);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createUnsignedBytesMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = Py(t, n);\n      return Bk(e, r, a, Uk(s), e.RGBA, e.UNSIGNED_BYTE);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  uploadPixelDataToTexture(e, t) {\n    this.throwIfDisposed(), function (e, t, n) {\n      Gy(e, () => e.bindTexture(e.TEXTURE_2D, t)), n.data instanceof Uint8Array ? Gy(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, n.width, n.height, 0, e.RGBA, e.UNSIGNED_BYTE, n.data)) : Gy(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, e.RGBA, e.UNSIGNED_BYTE, n)), Gy(e, () => e.bindTexture(e.TEXTURE_2D, null));\n    }(this.gl, e, t);\n  }\n\n  uploadDenseMatrixToTexture(e, t, n, s) {\n    this.throwIfDisposed(), function (e, t, n, s, r, a) {\n      var i, o, l;\n      Gy(e, () => e.bindTexture(e.TEXTURE_2D, t)), r instanceof Uint8Array ? (i = new Uint8Array(n * s * 4), o = e.UNSIGNED_BYTE, l = e.RGBA) : (i = new Float32Array(n * s * 4), o = e.FLOAT, l = a.internalFormatPackedFloat), i.set(r), Gy(e, () => e.texImage2D(e.TEXTURE_2D, 0, l, n, s, 0, e.RGBA, o, i)), Gy(e, () => e.bindTexture(e.TEXTURE_2D, null));\n    }(this.gl, e, t, n, s, this.textureConfig);\n  }\n\n  createFloat16PackedMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = Uy(t, n);\n      return Bk(e, r, a, Gk(s), e.RGBA, s.textureTypeHalfFloat);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  createPackedMatrixTexture(e, t) {\n    return this.throwIfDisposed(), function (e, t, n, s) {\n      var [r, a] = Uy(t, n);\n      return Bk(e, r, a, Vk(s), e.RGBA, e.FLOAT);\n    }(this.gl, e, t, this.textureConfig);\n  }\n\n  deleteMatrixTexture(e) {\n    this.throwIfDisposed(), this.outputTexture === e && (Jy(this.gl, this.framebuffer), this.outputTexture = null), Gy(this.gl, () => this.gl.deleteTexture(e));\n  }\n\n  downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n) {\n    return this.downloadMatrixDriver(e, () => function (e, t, n, s) {\n      var [r, a] = Py(t, n),\n          i = new Uint8Array(t * n * 4);\n      return Gy(e, () => e.readPixels(0, 0, r, a, s.downloadTextureFormat, e.UNSIGNED_BYTE, i)), new Float32Array(i.buffer);\n    }(this.gl, t, n, this.textureConfig));\n  }\n\n  downloadPackedMatrixFromBuffer(e, t, n, s, r, a) {\n    return function (e, t, n, s, r, a, i, o) {\n      var l = e,\n          u = new Float32Array(function (e, t) {\n        var [n, s] = Uy(e, t);\n        return n * s * 4;\n      }(a, i));\n      return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, u), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), u;\n    }(this.gl, e, 0, 0, 0, r, a);\n  }\n\n  downloadFloat32MatrixFromBuffer(e, t) {\n    return function (e, t, n) {\n      var s = e,\n          r = new Float32Array(n);\n      return s.bindBuffer(s.PIXEL_PACK_BUFFER, t), s.getBufferSubData(s.PIXEL_PACK_BUFFER, 0, r), s.bindBuffer(s.PIXEL_PACK_BUFFER, null), r;\n    }(this.gl, e, t);\n  }\n\n  createBufferFromTexture(e, t, n) {\n    this.bindTextureToFrameBuffer(e);\n\n    var s = function (e, t, n, s) {\n      var r = e.createBuffer();\n      Gy(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, r));\n      var a = 16 * t * n;\n      return Gy(e, () => e.bufferData(e.PIXEL_PACK_BUFFER, a, e.STREAM_READ)), Gy(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, 0)), Gy(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, null)), r;\n    }(this.gl, t, n);\n\n    return this.unbindTextureToFrameBuffer(), s;\n  }\n\n  createAndWaitForFence() {\n    var e = this.createFence(this.gl);\n    return this.pollFence(e);\n  }\n\n  createFence(e) {\n    var t, n;\n\n    if (G().getBool(\"WEBGL_FENCE_API_ENABLED\")) {\n      var _s209 = e,\n          _r155 = _s209.fenceSync(_s209.SYNC_GPU_COMMANDS_COMPLETE, 0);\n\n      e.flush(), n = () => {\n        var e = _s209.clientWaitSync(_r155, 0, 0);\n\n        return e === _s209.ALREADY_SIGNALED || e === _s209.CONDITION_SATISFIED;\n      }, t = _r155;\n    } else G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") > 0 ? (t = this.beginQuery(), this.endQuery(), n = () => this.isQueryAvailable(t, G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))) : n = () => !0;\n\n    return {\n      query: t,\n      isFencePassed: n\n    };\n  }\n\n  downloadMatrixFromPackedTexture(e, t, n) {\n    return this.downloadMatrixDriver(e, () => function (e, t, n) {\n      var s = new Float32Array(t * n * 4);\n      return Gy(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, s)), s;\n    }(this.gl, t, n));\n  }\n\n  createProgram(e) {\n    this.throwIfDisposed();\n\n    var t = this.gl,\n        n = function (e, t) {\n      var n = Qy(e, () => e.createShader(e.FRAGMENT_SHADER), \"Unable to create fragment WebGLShader.\");\n      if (Gy(e, () => e.shaderSource(n, t)), Gy(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw function (e, t) {\n        var n = jy.exec(t);\n        if (null == n) return console.log(\"Couldn't parse line number in error: \".concat(t)), void console.log(e);\n        var s = +n[1],\n            r = e.split(\"\\n\"),\n            a = r.length.toString().length + 2,\n            i = r.map((e, t) => m((t + 1).toString(), a) + e);\n        var o = 0;\n\n        for (var _e427 = 0; _e427 < i.length; _e427++) {\n          o = Math.max(i[_e427].length, o);\n        }\n\n        var l = i.slice(0, s - 1),\n            u = i.slice(s - 1, s),\n            c = i.slice(s);\n        console.log(l.join(\"\\n\")), console.log(t.split(\"\\n\")[0]), console.log(\"%c \".concat(m(u[0], o)), \"border:1px solid red; background-color:#e3d2d2; color:#a61717\"), console.log(c.join(\"\\n\"));\n      }(t, e.getShaderInfoLog(n)), new Error(\"Failed to compile fragment shader.\");\n      return n;\n    }(t, e);\n\n    null == this.vertexShader && (this.vertexShader = function (e) {\n      var t = dk();\n      return function (e, t) {\n        var n = Qy(e, () => e.createShader(e.VERTEX_SHADER), \"Unable to create vertex WebGLShader.\");\n        if (Gy(e, () => e.shaderSource(n, t)), Gy(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw console.log(e.getShaderInfoLog(n)), new Error(\"Failed to compile vertex shader.\");\n        return n;\n      }(e, \"\".concat(t.version, \"\\n    precision highp float;\\n    \").concat(t.attribute, \" vec3 clipSpacePos;\\n    \").concat(t.attribute, \" vec2 uv;\\n    \").concat(t.varyingVs, \" vec2 resultUV;\\n\\n    void main() {\\n      gl_Position = vec4(clipSpacePos, 1);\\n      resultUV = uv;\\n    }\"));\n    }(t));\n\n    var s = function (e) {\n      return Qy(e, () => e.createProgram(), \"Unable to create WebGLProgram.\");\n    }(t);\n\n    return Gy(t, () => t.attachShader(s, this.vertexShader)), Gy(t, () => t.attachShader(s, n)), function (e, t) {\n      if (Gy(e, () => e.linkProgram(t)), !1 === e.getProgramParameter(t, e.LINK_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error(\"Failed to link vertex and fragment shaders.\");\n    }(t, s), this.debug && Ky(t, s), this.vertexAttrsAreBound || (this.setProgram(s), this.vertexAttrsAreBound = function (e, t, n) {\n      return Gy(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), Xy(e, t, \"clipSpacePos\", n, 3, 20, 0) && Xy(e, t, \"uv\", n, 2, 20, 12);\n    }(t, this.program, this.vertexBuffer)), s;\n  }\n\n  deleteProgram(e) {\n    this.throwIfDisposed(), e === this.program && (this.program = null), null != e && Gy(this.gl, () => this.gl.deleteProgram(e));\n  }\n\n  setProgram(e) {\n    this.throwIfDisposed(), this.program = e, null != this.program && this.debug && Ky(this.gl, this.program), Gy(this.gl, () => this.gl.useProgram(e));\n  }\n\n  getUniformLocation(e, t) {\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;\n    return this.throwIfDisposed(), n ? function (e, t, n) {\n      return Qy(e, () => e.getUniformLocation(t, n), 'uniform \"' + n + '\" not present in program.');\n    }(this.gl, e, t) : function (e, t, n) {\n      return e.getUniformLocation(t, n);\n    }(this.gl, e, t);\n  }\n\n  getAttributeLocation(e, t) {\n    return this.throwIfDisposed(), Gy(this.gl, () => this.gl.getAttribLocation(e, t));\n  }\n\n  getUniformLocationNoThrow(e, t) {\n    return this.throwIfDisposed(), this.gl.getUniformLocation(e, t);\n  }\n\n  setInputMatrixTexture(e, t, n) {\n    this.throwIfDisposed(), this.throwIfNoProgram(), function (e, t, n, s) {\n      Gy(e, () => function (e, t, n) {\n        !function (e, t) {\n          var n = e.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1,\n              s = t + e.TEXTURE0;\n          if (s < e.TEXTURE0 || s > n) throw new Error(\"textureUnit must be in [gl.TEXTURE0, gl.TEXTURE\".concat(n, \"].\"));\n        }(e, n), Gy(e, () => e.activeTexture(e.TEXTURE0 + n)), Gy(e, () => e.bindTexture(e.TEXTURE_2D, t));\n      }(e, t, s)), Gy(e, () => e.uniform1i(n, s));\n    }(this.gl, e, t, n);\n  }\n\n  setOutputMatrixTexture(e, t, n) {\n    this.setOutputMatrixTextureDriver(e, n, t);\n  }\n\n  setOutputPackedMatrixTexture(e, t, n) {\n    this.throwIfDisposed();\n    var [s, r] = Uy(t, n);\n    this.setOutputMatrixTextureDriver(e, s, r);\n  }\n\n  setOutputMatrixWriteRegion(e, t, n, s) {\n    this.setOutputMatrixWriteRegionDriver(n, e, s, t);\n  }\n\n  setOutputPackedMatrixWriteRegion(e, t, n, s) {\n    throw new Error(\"setOutputPackedMatrixWriteRegion not implemented.\");\n  }\n\n  debugValidate() {\n    null != this.program && Ky(this.gl, this.program), Zy(this.gl);\n  }\n\n  executeProgram() {\n    this.throwIfDisposed(), this.throwIfNoProgram();\n    var e = this.gl;\n    this.debug && this.debugValidate(), Gy(e, () => e.drawElements(e.TRIANGLES, 6, e.UNSIGNED_SHORT, 0));\n  }\n\n  blockUntilAllProgramsCompleted() {\n    this.throwIfDisposed(), Gy(this.gl, () => this.gl.finish());\n  }\n\n  getQueryTimerExtension() {\n    return null == this.disjointQueryTimerExtension && (this.disjointQueryTimerExtension = qy(this.gl, 2 === G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\") ? \"EXT_disjoint_timer_query_webgl2\" : \"EXT_disjoint_timer_query\")), this.disjointQueryTimerExtension;\n  }\n\n  getQueryTimerExtensionWebGL2() {\n    return this.getQueryTimerExtension();\n  }\n\n  getQueryTimerExtensionWebGL1() {\n    return this.getQueryTimerExtension();\n  }\n\n  beginQuery() {\n    if (2 === G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")) {\n      var _e428 = this.gl,\n          _t359 = this.getQueryTimerExtensionWebGL2(),\n          _n262 = _e428.createQuery();\n\n      return _e428.beginQuery(_t359.TIME_ELAPSED_EXT, _n262), _n262;\n    }\n\n    var e = this.getQueryTimerExtensionWebGL1(),\n        t = e.createQueryEXT();\n    return e.beginQueryEXT(e.TIME_ELAPSED_EXT, t), t;\n  }\n\n  endQuery() {\n    if (2 === G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")) {\n      var _e429 = this.gl,\n          _t360 = this.getQueryTimerExtensionWebGL2();\n\n      return void _e429.endQuery(_t360.TIME_ELAPSED_EXT);\n    }\n\n    var e = this.getQueryTimerExtensionWebGL1();\n    e.endQueryEXT(e.TIME_ELAPSED_EXT);\n  }\n\n  waitForQueryAndGetTime(e) {\n    var _this72 = this;\n\n    return _asyncToGenerator(function* () {\n      return yield b(() => _this72.disposed || _this72.isQueryAvailable(e, G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))), _this72.getQueryTime(e, G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"));\n    })();\n  }\n\n  getQueryTime(e, t) {\n    if (0 === t) return null;\n\n    if (2 === t) {\n      var _t361 = this.gl;\n      return _t361.getQueryParameter(e, _t361.QUERY_RESULT) / 1e6;\n    }\n\n    {\n      var _t362 = this.getQueryTimerExtensionWebGL1();\n\n      return _t362.getQueryObjectEXT(e, _t362.QUERY_RESULT_EXT) / 1e6;\n    }\n  }\n\n  isQueryAvailable(e, t) {\n    if (0 === t) return !0;\n\n    if (2 === t) {\n      var _t363 = this.gl,\n          _n263 = this.getQueryTimerExtensionWebGL2(),\n          _s210 = _t363.getQueryParameter(e, _t363.QUERY_RESULT_AVAILABLE);\n\n      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_n263.GPU_DISJOINT_EXT)), _s210 && !this.disjoint;\n    }\n\n    {\n      var _t364 = this.getQueryTimerExtensionWebGL1(),\n          _n264 = _t364.getQueryObjectEXT(e, _t364.QUERY_RESULT_AVAILABLE_EXT);\n\n      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_t364.GPU_DISJOINT_EXT)), _n264 && !this.disjoint;\n    }\n  }\n\n  pollFence(e) {\n    return new Promise(t => {\n      this.addItemToPoll(() => e.isFencePassed(), () => t());\n    });\n  }\n\n  pollItems() {\n    var e = function (e) {\n      var t = 0;\n\n      for (; t < e.length && e[t](); ++t) {\n        ;\n      }\n\n      return t - 1;\n    }(this.itemsToPoll.map(e => e.isDoneFn));\n\n    for (var _t365 = 0; _t365 <= e; ++_t365) {\n      var {\n        resolveFn: _e430\n      } = this.itemsToPoll[_t365];\n\n      _e430();\n    }\n\n    this.itemsToPoll = this.itemsToPoll.slice(e + 1);\n  }\n\n  addItemToPoll(e, t) {\n    this.itemsToPoll.push({\n      isDoneFn: e,\n      resolveFn: t\n    }), this.itemsToPoll.length > 1 || b(() => (this.pollItems(), 0 === this.itemsToPoll.length));\n  }\n\n  bindTextureToFrameBuffer(e) {\n    this.throwIfDisposed(), Yy(this.gl, e, this.framebuffer), this.debug && Zy(this.gl);\n  }\n\n  unbindTextureToFrameBuffer() {\n    null != this.outputTexture ? (Yy(this.gl, this.outputTexture, this.framebuffer), this.debug && Zy(this.gl)) : Jy(this.gl, this.framebuffer);\n  }\n\n  downloadMatrixDriver(e, t) {\n    this.bindTextureToFrameBuffer(e);\n    var n = t();\n    return this.unbindTextureToFrameBuffer(), n;\n  }\n\n  setOutputMatrixTextureDriver(e, t, n) {\n    this.throwIfDisposed();\n    var s = this.gl;\n    Yy(s, e, this.framebuffer), this.debug && Zy(s), this.outputTexture = e, Gy(s, () => s.viewport(0, 0, t, n)), Gy(s, () => s.scissor(0, 0, t, n));\n  }\n\n  setOutputMatrixWriteRegionDriver(e, t, n, s) {\n    this.throwIfDisposed(), Gy(this.gl, () => this.gl.scissor(e, t, n, s));\n  }\n\n  throwIfDisposed() {\n    if (this.disposed) throw new Error(\"Attempted to use disposed GPGPUContext.\");\n  }\n\n  throwIfNoProgram() {\n    if (null == this.program) throw new Error(\"No GPU program is currently set.\");\n  }\n\n}\n\nvar {\n  addImpl: qk,\n  bincountImpl: jk,\n  bincountReduceImpl: Kk,\n  ceilImpl: Xk,\n  concatImpl: Yk,\n  equalImpl: Jk,\n  expImpl: Zk,\n  expm1Impl: Qk,\n  floorImpl: ew,\n  gatherNdImpl: tw,\n  gatherV2Impl: nw,\n  greaterImpl: sw,\n  greaterEqualImpl: rw,\n  lessImpl: aw,\n  lessEqualImpl: iw,\n  linSpaceImpl: ow,\n  logImpl: lw,\n  maxImpl: uw,\n  maximumImpl: cw,\n  minimumImpl: hw,\n  multiplyImpl: dw,\n  negImpl: pw,\n  notEqualImpl: fw,\n  prodImpl: gw,\n  rangeImpl: mw,\n  rsqrtImpl: bw,\n  sigmoidImpl: xw,\n  simpleAbsImpl: yw,\n  sliceImpl: kw,\n  sparseFillEmptyRowsImpl: ww,\n  sparseReshapeImpl: vw,\n  sparseSegmentReductionImpl: Iw,\n  sqrtImpl: $w,\n  stridedSliceImpl: Sw,\n  stringNGramsImpl: Nw,\n  stringSplitImpl: Cw,\n  stringToHashBucketFastImpl: Tw,\n  subImpl: Ew,\n  tileImpl: Rw,\n  topKImpl: Aw,\n  transposeImpl: Fw,\n  uniqueImpl: Dw\n} = Rm;\n\nfunction _w(e, t) {\n  return [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, t).map(t => \"\".concat(e, \".\").concat(t));\n}\n\nfunction Ow(e, t) {\n  return 1 === t ? [e] : _w(e, t);\n}\n\nclass Mw {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0, this.outputShape = e;\n    var t = e.length;\n    if (0 === t) this.userCode = \"\\n        void main() {\\n          setOutput(vec4(getA(), 0., 0., 0.));\\n        }\\n      \";else {\n      var _n265 = Ow(\"rc\", t),\n          _s211 = Ck(t),\n          _r156 = function (e, t, n) {\n        if (1 === e) return \"rc > \".concat(t[0]);\n        var s = \"\";\n\n        for (var _r157 = e - 2; _r157 < e; _r157++) {\n          s += \"\".concat(n[_r157], \" >= \").concat(t[_r157]), _r157 < e - 1 && (s += \"||\");\n        }\n\n        return s;\n      }(t, e, _n265),\n          _a124 = function (e, t, n, s) {\n        if (1 === e) return \"\";\n        var r = s.slice(-2);\n        return \"\\n    int r = \".concat(r[0], \";\\n    int c = \").concat(r[1], \";\\n    int rp1 = r + 1;\\n    int cp1 = c + 1;\\n\\n    bool cEdge = cp1 >= \").concat(t, \";\\n    bool rEdge = rp1 >= \").concat(n, \";\\n  \");\n      }(t, e[e.length - 1], e[e.length - 2], _n265),\n          _i86 = function (e, t) {\n        var n = e.length,\n            s = function (e, t) {\n          var n = [];\n\n          for (var _s212 = 0; _s212 <= 1; _s212++) {\n            for (var _r158 = 0; _r158 <= 1; _r158++) {\n              var _a125 = \"\".concat(0 === _s212 ? \"r\" : \"rp1\", \", \").concat(0 === _r158 ? \"c\" : \"cp1\");\n\n              for (var _n266 = 2; _n266 < e; _n266++) {\n                _a125 = \"\".concat(t[t.length - 1 - _n266], \",\") + _a125;\n              }\n\n              n.push(_a125);\n            }\n          }\n\n          return n;\n        }(n, t);\n\n        return 1 === n ? \"getA(rc),\\n            rc + 1 >= \".concat(e[0], \" ? 0. : getA(rc + 1),\\n            0, 0\") : \"getA(\".concat(s[0], \"),\\n          cEdge ? 0. : getA(\").concat(s[1], \"),\\n          rEdge ? 0. : getA(\").concat(s[2], \"),\\n          rEdge || cEdge ? 0. : getA(\").concat(s[3], \")\");\n      }(e, _n265);\n\n      this.userCode = \"\\n        void main() {\\n          \".concat(_s211, \" rc = getOutputCoords();\\n\\n          if(\").concat(_r156, \") {\\n            setOutput(vec4(0));\\n          } else {\\n            \").concat(_a124, \"\\n\\n            setOutput(vec4(\").concat(_i86, \"));\\n          }\\n        }\\n      \");\n    }\n  }\n\n}\n\nclass Lw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"inputShape\",\n      type: \"ivec3\"\n    }], this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var n = \"\";\n\n    for (var _e431 = 0; _e431 < 4; _e431++) {\n      var _t366 = \"thisRC = rc;\";\n      _e431 % 2 == 1 && (_t366 += \"thisRC.z += 1;\"), _e431 > 1 && (_t366 += \"thisRC.y += 1;\"), n += \"\\n        \".concat(_t366, \"\\n        \").concat(_e431 > 0 ? \"if(thisRC.y < rows && thisRC.z < cols){\" : \"\", \"\\n          int flatIndex = getFlatIndex(thisRC);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[\").concat(_e431, \"] =\\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\\n        \").concat(_e431 > 0 ? \"}\" : \"\", \"\\n      \");\n    }\n\n    var s, r;\n    this.userCode = \"\\n      \".concat((s = t, r = this.enableShapeUniforms, \"\\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      \".concat(r ? function (e, t) {\n      var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"index\";\n\n      var s = function (e, t) {\n        var n = e.length,\n            s = e.map(e => \"\".concat(t, \"[\").concat(e, \"]\")),\n            r = new Array(n - 1);\n        r[n - 2] = s[n - 1];\n\n        for (var _e432 = n - 3; _e432 >= 0; --_e432) {\n          r[_e432] = \"(\".concat(r[_e432 + 1], \" * \").concat(s[_e432 + 1], \")\");\n        }\n\n        return r;\n      }(e.map((e, t) => t), t);\n\n      return s.map((t, r) => \"int \".concat(e[r], \" = \").concat(n, \" / \").concat(s[r], \"; \").concat(r === s.length - 1 ? \"int \".concat(e[r + 1], \" = \").concat(n, \" - \").concat(e[r], \" * \").concat(s[r]) : \"index -= \".concat(e[r], \" * \").concat(s[r]), \";\")).join(\"\");\n    }([\"r\", \"c\", \"d\"], \"inputShape\") : pk([\"r\", \"c\", \"d\"], s), \"\\n      return ivec3(r, c, d);\\n    }\\n  \")), \"\\n      \").concat(this.enableShapeUniforms ? \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\\n  }\\n\" : gk(e), \"\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n\\n        ivec3 thisRC;\\n        int rows = \").concat(this.enableShapeUniforms ? \"outShape[1]\" : e[1], \";\\n        int cols = \").concat(this.enableShapeUniforms ? \"outShape[2]\" : e[2], \";\\n\\n        \").concat(n, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass zw {\n  constructor(e) {\n    this.gpgpu = e, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.logEnabled = !1, this.usedTextures = {};\n  }\n\n  acquireTexture(e, t, n) {\n    var s = Pw(t, n),\n        r = Ww(e, s, n);\n    r in this.freeTextures || (this.freeTextures[r] = []), r in this.usedTextures || (this.usedTextures[r] = []);\n    var a = Bw(e, s, this.gpgpu.gl, this.gpgpu.textureConfig, n);\n\n    if (this.freeTextures[r].length > 0) {\n      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= a, this.log();\n\n      var _e433 = this.freeTextures[r].shift();\n\n      return this.usedTextures[r].push(_e433), _e433;\n    }\n\n    var i;\n    return s === By.PACKED_2X2_FLOAT32 ? i = this.gpgpu.createPackedMatrixTexture(e[0], e[1]) : s === By.PACKED_2X2_FLOAT16 ? i = this.gpgpu.createFloat16PackedMatrixTexture(e[0], e[1]) : s === By.UNPACKED_FLOAT32 ? i = this.gpgpu.createFloat32MatrixTexture(e[0], e[1]) : s === By.UNPACKED_FLOAT16 ? i = this.gpgpu.createFloat16MatrixTexture(e[0], e[1]) : s === By.PACKED_4X1_UNSIGNED_BYTE && (i = this.gpgpu.createUnsignedBytesMatrixTexture(e[0], e[1])), this.usedTextures[r].push(i), this.numUsedTextures++, this._numBytesAllocated += a, this.log(), i;\n  }\n\n  releaseTexture(e, t, n, s) {\n    if (null == this.freeTextures) return;\n    var r = Pw(n, s),\n        a = Ww(t, r, s);\n    a in this.freeTextures || (this.freeTextures[a] = []);\n    var i = Bw(t, r, this.gpgpu.gl, this.gpgpu.textureConfig, s),\n        o = G().get(\"WEBGL_DELETE_TEXTURE_THRESHOLD\");\n    -1 !== o && this._numBytesAllocated > o ? (this.gpgpu.deleteMatrixTexture(e), this._numBytesAllocated -= i) : (this.freeTextures[a].push(e), this.numFreeTextures++, this._numBytesFree += i), this.numUsedTextures--;\n    var l = this.usedTextures[a],\n        u = l.indexOf(e);\n    if (u < 0) throw new Error(\"Cannot release a texture that was never provided by this texture manager\");\n    l.splice(u, 1), this.log();\n  }\n\n  log() {\n    if (!this.logEnabled) return;\n    console.log(\"Free/Used\", \"\".concat(this.numFreeTextures, \" / \").concat(this.numUsedTextures), \"(\".concat(this.numFreeTextures + this.numUsedTextures, \")\"));\n    var e = this._numBytesFree / this._numBytesAllocated;\n    console.log(\"Bytes allocated: \".concat(this._numBytesAllocated)), console.log(\"Bytes unused: \".concat(this._numBytesFree, \" (\").concat(Math.round(100 * e), \"%)\"));\n  }\n\n  get numBytesAllocated() {\n    return this._numBytesAllocated;\n  }\n\n  get numBytesFree() {\n    return this._numBytesFree;\n  }\n\n  getNumUsedTextures() {\n    return this.numUsedTextures;\n  }\n\n  getNumFreeTextures() {\n    return this.numFreeTextures;\n  }\n\n  dispose() {\n    if (null != this.freeTextures) {\n      for (var _e434 in this.freeTextures) {\n        this.freeTextures[_e434].forEach(e => {\n          this.gpgpu.deleteMatrixTexture(e);\n        });\n      }\n\n      for (var _e435 in this.usedTextures) {\n        this.usedTextures[_e435].forEach(e => {\n          this.gpgpu.deleteMatrixTexture(e);\n        });\n      }\n\n      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;\n    }\n  }\n\n}\n\nfunction Bw(e, t, n, s, r) {\n  var a = function (e, t) {\n    switch (e) {\n      case By.PACKED_2X2_FLOAT32:\n        return Vk(t);\n\n      case By.PACKED_2X2_FLOAT16:\n        return Gk(t);\n\n      case By.UNPACKED_FLOAT32:\n        return Pk(t);\n\n      case By.UNPACKED_FLOAT16:\n        return Wk(t);\n\n      case By.PACKED_4X1_UNSIGNED_BYTE:\n        return Uk(t);\n\n      default:\n        throw new Error(\"Unknown physical texture type \".concat(e));\n    }\n  }(t, s);\n\n  var i;\n\n  if (r) {\n    var [_t367, _n267] = Uy(e[0], e[1]);\n    i = _t367 * _n267;\n  } else {\n    var [_t368, _n268] = Py(e[0], e[1]);\n    i = _t368 * _n268;\n  }\n\n  return i * function (e, t) {\n    if (t === e.R32F) return 4;\n    if (t === e.R16F) return 2;\n    if (t === e.RGBA32F) return 16;\n    if (t === e.RGBA) return 16;\n    if (t === e.RGBA16F) return 8;\n    throw new Error(\"Unknown internal format \".concat(t));\n  }(n, a);\n}\n\nfunction Pw(e, t) {\n  if (e === zy.UPLOAD) return By.PACKED_2X2_FLOAT32;\n  if (e === zy.RENDER || null == e) return function (e) {\n    return G().getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\") ? e ? By.PACKED_2X2_FLOAT32 : By.UNPACKED_FLOAT32 : e ? By.PACKED_2X2_FLOAT16 : By.UNPACKED_FLOAT16;\n  }(t);\n  if (e === zy.DOWNLOAD || e === zy.PIXELS) return By.PACKED_4X1_UNSIGNED_BYTE;\n  throw new Error(\"Unknown logical texture type \".concat(e));\n}\n\nfunction Ww(e, t, n) {\n  return \"\".concat(e[0], \"_\").concat(e[1], \"_\").concat(t, \"_\").concat(n);\n}\n\nclass Uw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length), this.userCode = \"\\n      float unaryOperation(float x) {\\n        \".concat(t, \"\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        float y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \");\n  }\n\n}\n\nvar Vw = \"return x;\";\n\nclass Gw {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length), this.userCode = \"\\n      vec4 unaryOperation(vec4 x) {\\n        \".concat(t, \"\\n      }\\n\\n      void main() {\\n        vec4 x = getAAtOutCoords();\\n        vec4 y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \");\n  }\n\n}\n\nclass Hw {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !1, this.outputShape = e;\n\n    var t = e.length,\n        n = Ow(\"rc\", t),\n        s = Ck(t),\n        r = function (e, t) {\n      if (1 === e) return \"rc\";\n      var n = \"\";\n\n      for (var _s213 = 0; _s213 < e; _s213++) {\n        n += t[_s213], _s213 < e - 1 && (n += \",\");\n      }\n\n      return n;\n    }(t, n),\n        a = n.slice(-2),\n        i = t <= 1 ? \"rc\" : \"vec2(\".concat(a.join(\",\"), \")\");\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(s, \" rc = getOutputCoords();\\n        vec4 packedInput = getA(\").concat(r, \");\\n\\n        setOutput(getChannel(packedInput, \").concat(i, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar qw = $i,\n    jw = {},\n    Kw = G().getNumber(\"CPU_HANDOFF_SIZE_THRESHOLD\");\n\nclass Xw extends n {\n  constructor(e) {\n    if (super(), this.pendingRead = new WeakMap(), this.pendingDisposal = new WeakSet(), this.dataRefCount = new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = !1, this.pendingDeletes = 0, this.disposed = !1, !G().getBool(\"HAS_WEBGL\")) throw new Error(\"WebGL is not supported on this device\");\n\n    if (null == e) {\n      var _e436 = My(G().getNumber(\"WEBGL_VERSION\"));\n\n      this.binaryCache = ((n = G().getNumber(\"WEBGL_VERSION\")) in jw || (jw[n] = {}), jw[n]), this.gpgpu = new Hk(_e436), this.canvas = _e436.canvas, this.gpgpuCreatedLocally = !0;\n    } else this.gpgpu = e, this.binaryCache = {}, this.gpgpuCreatedLocally = !1, this.canvas = e.gl.canvas;\n\n    var n;\n    this.textureManager = new zw(this.gpgpu), this.numMBBeforeWarning = null == G().global.screen ? 1024 : G().global.screen.height * G().global.screen.width * window.devicePixelRatio * 600 / 1024 / 1024, this.texData = new t(this, Xn());\n  }\n\n  nextDataId() {\n    return Xw.nextDataId++;\n  }\n\n  numDataIds() {\n    return this.texData.numDataIds() - this.pendingDeletes;\n  }\n\n  write(e, t, n) {\n    if ((G().getBool(\"WEBGL_CHECK_NUMERICAL_PROBLEMS\") || G().getBool(\"DEBUG\")) && this.checkNumericalProblems(e), \"complex64\" === n && null != e) throw new Error(\"Cannot write to a complex64 dtype. Please use tf.complex(real, imag).\");\n    var s = {\n      id: this.nextDataId()\n    };\n    return this.texData.set(s, {\n      shape: t,\n      dtype: n,\n      values: e,\n      usage: zy.UPLOAD,\n      refCount: 1\n    }), s;\n  }\n\n  refCount(e) {\n    return this.texData.has(e) ? this.texData.get(e).refCount : 0;\n  }\n\n  incRef(e) {\n    this.texData.get(e).refCount++;\n  }\n\n  decRef(e) {\n    this.texData.has(e) && this.texData.get(e).refCount--;\n  }\n\n  move(e, t, n, s, r) {\n    if (G().getBool(\"DEBUG\") && this.checkNumericalProblems(t), \"complex64\" === s) throw new Error(\"Cannot write to a complex64 dtype. Please use tf.complex(real, imag).\");\n    this.texData.set(e, {\n      shape: n,\n      dtype: s,\n      values: t,\n      usage: zy.UPLOAD,\n      refCount: r\n    });\n  }\n\n  disposeIntermediateTensorInfo(e) {\n    this.disposeData(e.dataId);\n  }\n\n  readSync(e) {\n    var t = this.texData.get(e),\n        {\n      values: n,\n      dtype: s,\n      complexTensorInfos: r,\n      slice: a,\n      shape: i,\n      isPacked: o\n    } = t;\n\n    if (null != a) {\n      var _t369;\n\n      _t369 = o ? new Gw(i, Vw) : new Uw(i, Vw);\n\n      var _n269 = this.runWebGLProgram(_t369, [{\n        dataId: e,\n        shape: i,\n        dtype: s\n      }], s),\n          _r159 = this.readSync(_n269.dataId);\n\n      return this.disposeIntermediateTensorInfo(_n269), _r159;\n    }\n\n    if (null != n) return this.convertAndCacheOnCPU(e);\n    if (\"string\" === s) return n;\n    var l = null != this.activeTimers;\n    var u, c;\n    return l && (u = Ge()), c = \"complex64\" === s ? Lo(this.readSync(r.real.dataId), this.readSync(r.imag.dataId)) : this.getValuesFromTexture(e), l && (this.downloadWaitMs += Ge() - u), this.convertAndCacheOnCPU(e, c);\n  }\n\n  read(e) {\n    var _this73 = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this73.pendingRead.has(e)) {\n        var _t370 = _this73.pendingRead.get(e);\n\n        return new Promise(e => _t370.push(e));\n      }\n\n      var t = _this73.texData.get(e),\n          {\n        values: n,\n        shape: s,\n        slice: r,\n        dtype: a,\n        complexTensorInfos: i,\n        isPacked: o\n      } = t;\n\n      if (null != r) {\n        var _t371;\n\n        _t371 = o ? new Gw(s, Vw) : new Uw(s, Vw);\n\n        var _n270 = _this73.runWebGLProgram(_t371, [{\n          dataId: e,\n          shape: s,\n          dtype: a\n        }], a),\n            _r160 = _this73.read(_n270.dataId);\n\n        return _this73.disposeIntermediateTensorInfo(_n270), _r160;\n      }\n\n      if (null != n) return _this73.convertAndCacheOnCPU(e);\n      if (!G().getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\") && 2 === G().getNumber(\"WEBGL_VERSION\")) throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.\");\n      var l,\n          u,\n          c = null;\n\n      if (\"complex64\" !== a && G().get(\"WEBGL_BUFFER_SUPPORTED\")) {\n        l = _this73.decode(e);\n\n        var _t372 = _this73.texData.get(l.dataId);\n\n        c = _this73.gpgpu.createBufferFromTexture(_t372.texture, ...Wy(s));\n      }\n\n      if (_this73.pendingRead.set(e, []), \"complex64\" !== a && (yield _this73.gpgpu.createAndWaitForFence()), \"complex64\" === a) {\n        var _e437 = yield Promise.all([_this73.read(i.real.dataId), _this73.read(i.imag.dataId)]);\n\n        u = Lo(_e437[0], _e437[1]);\n      } else if (null == c) u = _this73.getValuesFromTexture(e);else {\n        var _e438 = d(s);\n\n        u = _this73.gpgpu.downloadFloat32MatrixFromBuffer(c, _e438);\n      }\n\n      if (null != l && _this73.disposeIntermediateTensorInfo(l), null != c) {\n        var _e439 = _this73.gpgpu.gl;\n        Gy(_e439, () => _e439.deleteBuffer(c));\n      }\n\n      var h = _this73.convertAndCacheOnCPU(e, u),\n          p = _this73.pendingRead.get(e);\n\n      return _this73.pendingRead.delete(e), p.forEach(e => e(h)), _this73.pendingDisposal.has(e) && (_this73.pendingDisposal.delete(e), _this73.disposeData(e) && Xn().removeDataId(e, _this73), _this73.pendingDeletes--), h;\n    })();\n  }\n\n  bufferSync(e) {\n    var t = this.readSync(e.dataId);\n    var n = t;\n    if (\"string\" === e.dtype) try {\n      n = t.map(e => qe(e));\n    } catch (e) {\n      throw new Error(\"Failed to decode encoded string bytes into utf-8\");\n    }\n    return pn(e.shape, e.dtype, n);\n  }\n\n  checkNumericalProblems(e) {\n    if (null != e) for (var _t373 = 0; _t373 < e.length; _t373++) {\n      var _n271 = e[_t373];\n\n      if (!Hy(_n271)) {\n        if (G().getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\")) throw Error(\"The value \".concat(_n271, \" cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'\"));\n        throw Error(\"The value \".concat(_n271, \" cannot be represented on this device.\"));\n      }\n    }\n  }\n\n  getValuesFromTexture(e) {\n    var {\n      shape: t,\n      dtype: n,\n      isPacked: s\n    } = this.texData.get(e),\n        r = d(t);\n\n    if (G().getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\")) {\n      var _n272 = this.decode(e),\n          _s214 = this.texData.get(_n272.dataId),\n          _a126 = this.gpgpu.downloadMatrixFromPackedTexture(_s214.texture, ...Wy(t)).subarray(0, r);\n\n      return this.disposeIntermediateTensorInfo(_n272), _a126;\n    }\n\n    var a = G().getBool(\"WEBGL_PACK\") && !0 === s,\n        i = a ? nk(t) : t,\n        o = a ? new Mk(i) : new Ok(i),\n        l = this.runWebGLProgram(o, [{\n      shape: i,\n      dtype: n,\n      dataId: e\n    }], \"float32\"),\n        u = this.texData.get(l.dataId),\n        c = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture, u.texShape[0], u.texShape[1]).subarray(0, r);\n    return this.disposeIntermediateTensorInfo(l), c;\n  }\n\n  timerAvailable() {\n    return G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0;\n  }\n\n  time(e) {\n    var _this74 = this;\n\n    return _asyncToGenerator(function* () {\n      var t = _this74.activeTimers,\n          n = [];\n      var s = !1;\n      null == _this74.programTimersStack ? (_this74.programTimersStack = n, s = !0) : _this74.activeTimers.push(n), _this74.activeTimers = n, e();\n      var r = h(_this74.activeTimers.map(e => e.query)).filter(e => null != e),\n          a = h(_this74.activeTimers.map(e => e.name)).filter(e => null != e);\n      _this74.activeTimers = t, s && (_this74.programTimersStack = null);\n      var i = {\n        uploadWaitMs: _this74.uploadWaitMs,\n        downloadWaitMs: _this74.downloadWaitMs,\n        kernelMs: null,\n        wallMs: null\n      };\n\n      if (G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0) {\n        var _e440 = yield Promise.all(r);\n\n        i.kernelMs = function (e) {\n          var t = 0;\n\n          for (var _n273 = 0; _n273 < e.length; _n273++) {\n            t += e[_n273];\n          }\n\n          return t;\n        }(_e440), i.getExtraProfileInfo = () => _e440.map((e, t) => ({\n          name: a[t],\n          ms: e\n        })).map(e => \"\".concat(e.name, \": \").concat(e.ms)).join(\", \");\n      } else i.kernelMs = {\n        error: \"WebGL query timers are not supported in this environment.\"\n      };\n\n      return _this74.uploadWaitMs = 0, _this74.downloadWaitMs = 0, i;\n    })();\n  }\n\n  memory() {\n    return {\n      unreliable: !1,\n      numBytesInGPU: this.numBytesInGPU,\n      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,\n      numBytesInGPUFree: this.textureManager.numBytesFree\n    };\n  }\n\n  startTimer() {\n    return G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? this.gpgpu.beginQuery() : {\n      startMs: Ge(),\n      endMs: null\n    };\n  }\n\n  endTimer(e) {\n    return G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? (this.gpgpu.endQuery(), e) : (e.endMs = Ge(), e);\n  }\n\n  getQueryTime(e) {\n    var _this75 = this;\n\n    return _asyncToGenerator(function* () {\n      return G().getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\") > 0 ? _this75.gpgpu.waitForQueryAndGetTime(e) : e.endMs - e.startMs;\n    })();\n  }\n\n  disposeData(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    if (this.pendingDisposal.has(e)) return !1;\n    if (!this.texData.has(e)) return !0;\n    if (t ? this.texData.get(e).refCount = 0 : this.texData.get(e).refCount--, !t && this.texData.get(e).refCount > 0) return !1;\n    if (this.pendingRead.has(e)) return this.pendingDisposal.add(e), this.pendingDeletes++, !1;\n    this.releaseGPUData(e);\n    var {\n      complexTensorInfos: n\n    } = this.texData.get(e);\n    return null != n && (this.disposeData(n.real.dataId, t), this.disposeData(n.imag.dataId, t)), this.texData.delete(e), !0;\n  }\n\n  releaseGPUData(e) {\n    var {\n      texture: t,\n      dtype: n,\n      texShape: s,\n      usage: r,\n      isPacked: a,\n      slice: i\n    } = this.texData.get(e),\n        o = i && i.origDataId || e,\n        l = this.dataRefCount.get(o);\n    l > 1 ? this.dataRefCount.set(o, l - 1) : (this.dataRefCount.delete(o), null != t && (this.numBytesInGPU -= this.computeBytes(s, n), this.textureManager.releaseTexture(t, s, r, a)));\n    var u = this.texData.get(e);\n    u.texture = null, u.texShape = null, u.isPacked = !1, u.slice = null;\n  }\n\n  getTexture(e) {\n    return this.uploadToGPU(e), this.texData.get(e).texture;\n  }\n\n  getDataInfo(e) {\n    return this.texData.get(e);\n  }\n\n  shouldExecuteOnCPU(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : Kw;\n    return G().getBool(\"WEBGL_CPU_FORWARD\") && e.every(e => null == this.texData.get(e.dataId).texture && d(e.shape) < t);\n  }\n\n  getGPGPUContext() {\n    return this.gpgpu;\n  }\n\n  where(e) {\n    W(\"tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead\");\n    var t = e.dataSync();\n    return qw(e.shape, t);\n  }\n\n  packedUnaryOp(e, t, n) {\n    var s = new Gw(e.shape, t),\n        r = this.compileAndRun(s, [e], n);\n    return Xn().makeTensorFromDataId(r.dataId, r.shape, r.dtype);\n  }\n\n  abs(e) {\n    if (this.shouldExecuteOnCPU([e]) && \"complex64\" !== e.dtype) {\n      var _t374 = yw(this.texData.get(e.dataId).values);\n\n      return this.makeOutput(e.shape, e.dtype, _t374);\n    }\n\n    if (G().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\")) return this.packedUnaryOp(e, \"return abs(x);\", e.dtype);\n    var t = new Uw(e.shape, \"return abs(x);\"),\n        n = this.compileAndRun(t, [e]);\n    return Xn().makeTensorFromDataId(n.dataId, n.shape, n.dtype);\n  }\n\n  makeTensorInfo(e, t, n) {\n    var s;\n\n    if (\"string\" === t && null != n && n.length > 0 && N(n[0])) {\n      var _r161 = n.map(e => He(e));\n\n      s = this.write(_r161, e, t);\n    } else s = this.write(n, e, t);\n\n    return this.texData.get(s).usage = null, {\n      dataId: s,\n      shape: e,\n      dtype: t\n    };\n  }\n\n  makeOutput(e, t, n) {\n    var {\n      dataId: s\n    } = this.makeTensorInfo(e, t, n);\n    return Xn().makeTensorFromDataId(s, e, t, this);\n  }\n\n  unpackTensor(e) {\n    var t = new Hw(e.shape);\n    return this.runWebGLProgram(t, [e], e.dtype);\n  }\n\n  packTensor(e) {\n    var t = new Mw(e.shape);\n    return this.runWebGLProgram(t, [e], e.dtype, null, !0);\n  }\n\n  packedReshape(e, t) {\n    var n = [ek(e.shape), ...tk(e.shape)],\n        s = {\n      dtype: e.dtype,\n      shape: n,\n      dataId: e.dataId\n    },\n        r = [ek(t), ...tk(t)],\n        a = new Lw(r, n),\n        i = this.runWebGLProgram(a, [s], e.dtype, [n], !0);\n    return {\n      dataId: i.dataId,\n      shape: t,\n      dtype: i.dtype\n    };\n  }\n\n  decode(e) {\n    var t = this.texData.get(e),\n        {\n      isPacked: n,\n      shape: s,\n      dtype: r\n    } = t,\n        a = nk(s);\n    var i;\n    var o = Wy(a);\n    return i = n ? new _k(a) : new Dk(a), {\n      dtype: r,\n      shape: s,\n      dataId: this.runWebGLProgram(i, [{\n        shape: a,\n        dtype: r,\n        dataId: e\n      }], r, [o], !0).dataId\n    };\n  }\n\n  runWebGLProgram(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    var a = this.makeTensorInfo(e.outputShape, n),\n        i = this.texData.get(a.dataId);\n\n    if (e.packedOutput && (i.isPacked = !0), e.outPackingScheme === Ly.DENSE) {\n      var _t375 = Wy(e.outputShape);\n\n      i.texShape = _t375.map(e => 2 * e);\n    }\n\n    if (null != e.outTexUsage && (i.usage = e.outTexUsage), 0 === d(a.shape)) return i.values = w(a.dtype, 0), a;\n    var o = [],\n        l = t.map(t => {\n      if (\"complex64\" === t.dtype) throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.\");\n      var n = this.texData.get(t.dataId);\n\n      if (null == n.texture) {\n        if (!e.packedInputs && d(t.shape) <= G().getNumber(\"WEBGL_SIZE_UPLOAD_UNIFORM\")) return {\n          shape: t.shape,\n          texData: null,\n          isUniform: !0,\n          uniformValues: n.values\n        };\n        e.packedInputs && (n.isPacked = !0, n.shape = t.shape);\n      } else if (!!n.isPacked != !!e.packedInputs) t = n.isPacked ? this.unpackTensor(t) : this.packTensor(t), o.push(t), n = this.texData.get(t.dataId);else if (n.isPacked && !rk(n.shape, t.shape)) {\n        var _e441 = t,\n            _s215 = t.shape;\n        t.shape = n.shape, t = this.packedReshape(t, _s215), o.push(t), n = this.texData.get(t.dataId), _e441.shape = _s215;\n      }\n\n      return this.uploadToGPU(t.dataId), {\n        shape: t.shape,\n        texData: n,\n        isUniform: !1\n      };\n    });\n    this.uploadToGPU(a.dataId);\n\n    var u = {\n      shape: a.shape,\n      texData: i,\n      isUniform: !1\n    },\n        c = function (e, t, n) {\n      var s = \"\";\n      t.concat(n).forEach(t => {\n        var r = null != t.texData && null != t.texData.slice && t.texData.slice.flatOffset > 0;\n\n        if (e.enableShapeUniforms && !t.isUniform) {\n          var _a127 = t.texData.texShape,\n              {\n            useSqueezeShape: _i87,\n            uniformShape: _o64,\n            keptDims: _l44\n          } = Tk(e.packedInputs, t.shape, _a127);\n          var _u34 = \"\",\n              _c29 = \"\",\n              _h17 = \"\";\n\n          if (1 === _o64.length && e.packedInputs) {\n            var _e442 = [Math.ceil(_a127[0] / 2), Math.ceil(_a127[1] / 2)];\n            _u34 = \"\".concat(_e442[0] > 1, \"_\").concat(_e442[1] > 1);\n          } else if (2 !== _o64.length || e.packedInputs) {\n            if (_o64.length > 2 && !e.packedInputs) {\n              var _e443 = A(_o64);\n\n              _h17 = \"\".concat(_e443[0] === _a127[1], \"_\").concat(_e443[_e443.length - 1] === _a127[1]);\n            }\n          } else _c29 = \"\".concat(_o64[0] > 1, \"_\").concat(_o64[1] > 1);\n\n          var _f11 = t.shape.length,\n              _g19 = 2 === _o64.length && p(t.shape, _a127),\n              _m13 = 1 === d(t.shape),\n              _b14 = ur(t.shape, n.shape),\n              _x55 = !e.packedInputs && _f11 === n.shape.length && p(_a127, n.texData.texShape);\n\n          s += \"\".concat(_f11, \"_\").concat(_x55, \"_\").concat(_i87 ? _l44 : \"\", \"_\").concat(_o64.length, \"_\").concat(_m13, \"_\").concat(_b14, \"_\").concat(_g19, \"_\").concat(_u34, \"_\").concat(_c29, \"_\").concat(_h17, \"_\").concat(e.packedInputs || _o64.length > 2 ? \"\" : \"\".concat(_a127[0] > 1, \"_\").concat(_a127[1] > 1), \"_\").concat(r);\n        } else s += \"\".concat(t.shape, \"_\").concat(t.isUniform ? \"uniform\" : t.texData.texShape, \"_\").concat(r);\n      });\n      var r = e.constructor.name;\n      return r += \"_\" + s + \"_\" + e.userCode + \"\".concat(G().getNumber(\"WEBGL_VERSION\")), r;\n    }(e, l, u),\n        h = this.getAndSaveBinary(c, () => function (e, t, n, s) {\n      var r = n.map((e, n) => {\n        var s = {\n          logicalShape: e.shape,\n          texShape: e.isUniform ? null : e.texData.texShape,\n          isUniform: e.isUniform,\n          isPacked: !e.isUniform && e.texData.isPacked,\n          flatOffset: null\n        };\n        return null != e.texData && null != e.texData.slice && e.texData.slice.flatOffset > 0 && (s.flatOffset = e.texData.slice.flatOffset), {\n          name: t.variableNames[n],\n          shapeInfo: s\n        };\n      }),\n          a = r.map(e => e.shapeInfo),\n          i = {\n        logicalShape: s.shape,\n        texShape: s.texData.texShape,\n        isUniform: !1,\n        isPacked: s.texData.isPacked,\n        flatOffset: null\n      },\n          o = xk(r, i, t),\n          l = e.createProgram(o);\n      var u = null;\n      var c = e.getUniformLocation(l, \"NAN\", !1);\n      1 === G().getNumber(\"WEBGL_VERSION\") && (u = e.getUniformLocation(l, \"INFINITY\", !1));\n      var h = !1,\n          d = {},\n          p = {},\n          f = {};\n\n      for (var _n274 = 0; _n274 < t.variableNames.length; _n274++) {\n        var _s216 = t.variableNames[_n274];\n        d[_s216] = e.getUniformLocation(l, _s216, h), d[\"offset\".concat(_s216)] = e.getUniformLocation(l, \"offset\".concat(_s216), h), t.enableShapeUniforms && (p[\"\".concat(_s216, \"Shape\")] = e.getUniformLocation(l, \"\".concat(_s216, \"Shape\"), h), f[\"\".concat(_s216, \"TexShape\")] = e.getUniformLocation(l, \"\".concat(_s216, \"TexShape\"), h));\n      }\n\n      var g, m, b;\n      t.enableShapeUniforms && (g = e.getUniformLocation(l, \"outShape\", h), b = e.getUniformLocation(l, \"outShapeStrides\", h), m = e.getUniformLocation(l, \"outTexShape\", h));\n      var x = [];\n      return t.customUniforms && t.customUniforms.forEach((t, n) => {\n        x[n] = e.getUniformLocation(l, t.name, h);\n      }), {\n        program: t,\n        source: o,\n        webGLProgram: l,\n        uniformLocations: d,\n        customUniformLocations: x,\n        inShapeInfos: a,\n        outShapeInfo: i,\n        infLoc: u,\n        nanLoc: c,\n        inShapesLocations: p,\n        inTexShapesLocations: f,\n        outShapeLocation: g,\n        outShapeStridesLocation: b,\n        outTexShapeLocation: m\n      };\n    }(this.gpgpu, e, l, u)),\n        f = null != this.activeTimers;\n\n    var g;\n    f && (g = this.startTimer()), function (e, t, n, s, r) {\n      t.program.enableShapeUniforms || (Ak(t.inShapeInfos, n), Ak([t.outShapeInfo], [s]));\n      var a = s.texData.texture,\n          i = s.texData.texShape;\n      s.texData.isPacked ? e.setOutputPackedMatrixTexture(a, i[0], i[1]) : e.setOutputMatrixTexture(a, i[0], i[1]), e.setProgram(t.webGLProgram), 1 === G().getNumber(\"WEBGL_VERSION\") && null !== t.infLoc && e.gl.uniform1f(t.infLoc, Infinity), null !== t.nanLoc && e.gl.uniform1f(t.nanLoc, NaN), n.forEach((n, s) => {\n        var r = t.program.variableNames[s],\n            a = t.uniformLocations[r],\n            i = t.uniformLocations[\"offset\".concat(r)],\n            o = t.inShapesLocations[\"\".concat(r, \"Shape\")],\n            l = t.inTexShapesLocations[\"\".concat(r, \"TexShape\")];\n\n        if (o) {\n          var {\n            uniformShape: _s217\n          } = Tk(t.program.packedInputs, n.shape, n.texData.texShape);\n\n          switch (_s217.length) {\n            case 1:\n              e.gl.uniform1iv(o, new Int32Array(_s217));\n              break;\n\n            case 2:\n              e.gl.uniform2iv(o, new Int32Array(_s217));\n              break;\n\n            case 3:\n              e.gl.uniform3iv(o, new Int32Array(_s217));\n              break;\n\n            case 4:\n              e.gl.uniform4iv(o, new Int32Array(_s217));\n          }\n        }\n\n        if (l && e.gl.uniform2i(l, n.texData.texShape[0], n.texData.texShape[1]), null != a) if (n.isUniform) {\n          if (d(n.shape) < 2) e.gl.uniform1f(a, n.uniformValues[0]);else {\n            var _t376 = n.uniformValues;\n            _t376 instanceof Float32Array || (_t376 = new Float32Array(_t376)), e.gl.uniform1fv(a, _t376);\n          }\n        } else null != n.texData.slice && null != i && e.gl.uniform1i(i, n.texData.slice.flatOffset), e.setInputMatrixTexture(n.texData.texture, a, s);\n      });\n      var o = t.outShapeLocation;\n      if (o) switch (s.shape.length) {\n        case 1:\n          e.gl.uniform1iv(o, new Int32Array(s.shape));\n          break;\n\n        case 2:\n          e.gl.uniform2iv(o, new Int32Array(s.shape));\n          break;\n\n        case 3:\n          e.gl.uniform3iv(o, new Int32Array(s.shape));\n          break;\n\n        case 4:\n          e.gl.uniform4iv(o, new Int32Array(s.shape));\n      }\n\n      if (t.outShapeStridesLocation) {\n        var _n275 = A(s.shape);\n\n        switch (s.shape.length) {\n          case 2:\n            e.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(_n275));\n            break;\n\n          case 3:\n            e.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(_n275));\n            break;\n\n          case 4:\n            e.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(_n275));\n        }\n      }\n\n      t.outTexShapeLocation && e.gl.uniform2i(t.outTexShapeLocation, s.texData.texShape[0], s.texData.texShape[1]), t.program.customUniforms && r && t.program.customUniforms.forEach((n, s) => {\n        var a = t.customUniformLocations[s],\n            i = r[s];\n        if (\"float\" === n.type) e.gl.uniform1fv(a, i);else if (\"vec2\" === n.type) e.gl.uniform2fv(a, i);else if (\"vec3\" === n.type) e.gl.uniform3fv(a, i);else if (\"vec4\" === n.type) e.gl.uniform4fv(a, i);else if (\"int\" === n.type) e.gl.uniform1iv(a, i);else if (\"ivec2\" === n.type) e.gl.uniform2iv(a, i);else if (\"ivec3\" === n.type) e.gl.uniform3iv(a, i);else {\n          if (\"ivec4\" !== n.type) throw Error(\"uniform type \".concat(n.type, \" is not supported yet.\"));\n          e.gl.uniform4iv(a, i);\n        }\n      }), e.executeProgram();\n    }(this.gpgpu, h, l, u, s), o.forEach(e => this.disposeIntermediateTensorInfo(e)), f && (g = this.endTimer(g), this.activeTimers.push({\n      name: e.constructor.name,\n      query: this.getQueryTime(g)\n    }));\n    var m = G().get(\"WEBGL_FLUSH_THRESHOLD\");\n\n    if (m > 0) {\n      var _e444 = Ge();\n\n      _e444 - this.lastGlFlushTime > m && (this.gpgpu.gl.flush(), this.lastGlFlushTime = _e444);\n    }\n\n    if (!G().getBool(\"WEBGL_LAZILY_UNPACK\") && i.isPacked && !1 === r) {\n      var _e445 = this.unpackTensor(a);\n\n      return this.disposeIntermediateTensorInfo(a), _e445;\n    }\n\n    return a;\n  }\n\n  compileAndRun(e, t, n, s) {\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    return this.runWebGLProgram(e, t, n = n || t[0].dtype, s, r);\n  }\n\n  getAndSaveBinary(e, t) {\n    return e in this.binaryCache || (this.binaryCache[e] = t()), this.binaryCache[e];\n  }\n\n  getTextureManager() {\n    return this.textureManager;\n  }\n\n  dispose() {\n    this.disposed || (G().getBool(\"IS_TEST\") || Object.keys(this.binaryCache).forEach(e => {\n      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];\n    }), this.textureManager.dispose(), null != this.canvas && \"undefined\" != typeof HTMLCanvasElement && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = !0);\n  }\n\n  floatPrecision() {\n    return null == this.floatPrecisionValue && (this.floatPrecisionValue = Jn(() => {\n      if (!G().get(\"WEBGL_RENDER_FLOAT32_ENABLED\")) {\n        var _e446 = G().getBool(\"DEBUG\");\n\n        G().set(\"DEBUG\", !1);\n        var _t377 = this.abs(Ka(1e-8)).dataSync()[0];\n        if (G().set(\"DEBUG\", _e446), _t377 > 0) return 32;\n      }\n\n      return 16;\n    })), this.floatPrecisionValue;\n  }\n\n  epsilon() {\n    return 32 === this.floatPrecision() ? 1e-7 : 1e-4;\n  }\n\n  uploadToGPU(e) {\n    var t = this.texData.get(e),\n        {\n      shape: n,\n      dtype: s,\n      values: r,\n      texture: a,\n      usage: o,\n      isPacked: l\n    } = t;\n    if (null != a) return;\n    var u = null != this.activeTimers;\n    var c;\n    u && (c = Ge());\n    var h = t.texShape;\n\n    if (null == h && (h = function (e) {\n      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n      var n = G().getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");\n\n      if (t && (n *= 2, 1 === (e = e.map((t, n) => n >= e.length - 2 ? i(e[n]) : e[n])).length && (e = [2, e[0]])), 2 !== e.length) {\n        var _t378 = k(e);\n\n        e = _t378.newShape;\n      }\n\n      var s = d(e);\n      if (e.length <= 1 && s <= n) return [1, s];\n      if (2 === e.length && e[0] <= n && e[1] <= n) return e;\n      if (3 === e.length && e[0] * e[1] <= n && e[2] <= n) return [e[0] * e[1], e[2]];\n      if (3 === e.length && e[0] <= n && e[1] * e[2] <= n) return [e[0], e[1] * e[2]];\n      if (4 === e.length && e[0] * e[1] * e[2] <= n && e[3] <= n) return [e[0] * e[1] * e[2], e[3]];\n      if (4 === e.length && e[0] <= n && e[1] * e[2] * e[3] <= n) return [e[0], e[1] * e[2] * e[3]];\n\n      if (t) {\n        var _t379 = ek(e);\n\n        var _n276 = 2,\n            _r162 = 2;\n        return e.length && ([_n276, _r162] = tk(e)), s = _t379 * (_n276 / 2) * (_r162 / 2), g(s).map(e => 2 * e);\n      }\n\n      return g(s);\n    }(n, l), t.texShape = h), null != r) {\n      var _e447 = nk(n);\n\n      var _a128,\n          _i88 = h[1],\n          _o65 = h[0];\n\n      var _d23 = r instanceof Uint8Array;\n\n      l ? ([_i88, _o65] = Uy(h[0], h[1]), _a128 = new zk(_e447, _d23)) : _a128 = new Lk(_e447, _d23);\n\n      var _p15 = this.makeTensorInfo([_o65, _i88], s);\n\n      this.texData.get(_p15.dataId).usage = _d23 ? zy.PIXELS : zy.UPLOAD, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(_p15.dataId), _i88, _o65, r);\n\n      var _f12 = this.runWebGLProgram(_a128, [_p15], s, [[_o65, _i88]], !0),\n          _g20 = this.texData.get(_f12.dataId);\n\n      t.texture = _g20.texture, t.texShape = _g20.texShape, t.isPacked = _g20.isPacked, t.usage = _g20.usage, this.disposeIntermediateTensorInfo(_p15), this.texData.delete(_f12.dataId), t.values = null, u && (this.uploadWaitMs += Ge() - c);\n    } else {\n      var _e448 = this.acquireTexture(h, o, s, l);\n\n      t.texture = _e448;\n    }\n  }\n\n  convertAndCacheOnCPU(e, t) {\n    var n = this.texData.get(e),\n        {\n      dtype: s\n    } = n;\n    return this.releaseGPUData(e), null != t && (n.values = function (e, t) {\n      if (\"float32\" === t || \"complex64\" === t) return e;\n\n      if (\"int32\" === t || \"bool\" === t) {\n        var _n277 = \"int32\" === t ? new Int32Array(e.length) : new Uint8Array(e.length);\n\n        for (var _t380 = 0; _t380 < _n277.length; ++_t380) {\n          _n277[_t380] = Math.round(e[_t380]);\n        }\n\n        return _n277;\n      }\n\n      throw new Error(\"Unknown dtype \".concat(t));\n    }(t, s)), n.values;\n  }\n\n  acquireTexture(e, t, n, s) {\n    if (this.numBytesInGPU += this.computeBytes(e, n), !this.warnedAboutMemory && this.numBytesInGPU > 1024 * this.numMBBeforeWarning * 1024) {\n      var _e449 = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n\n      this.warnedAboutMemory = !0, console.warn(\"High memory usage in GPU: \".concat(_e449, \" MB, most likely due to a memory leak\"));\n    }\n\n    return this.textureManager.acquireTexture(e, t, s);\n  }\n\n  computeBytes(e, t) {\n    return e[0] * e[1] * S(t);\n  }\n\n}\n\nXw.nextDataId = 0, St() && es(\"webgl\", () => new Xw(), 2);\n\nclass Yw {\n  constructor(e, t, n) {\n    this.variableNames = [\"A\", \"B\"], this.outputShape = hr(t, n), this.enableShapeUniforms = Fk(this.outputShape.length), this.userCode = \"\\n      float binaryOperation(float a, float b) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \");\n  }\n\n}\n\nclass Jw {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    this.variableNames = [\"A\", \"B\"], this.supportsBroadcasting = !0, this.packedInputs = !0, this.packedOutput = !0, this.outputShape = hr(t, n);\n    var r = this.outputShape.length;\n    this.enableShapeUniforms = Fk(r);\n    var a = \"\";\n    if (s) if (0 === r || 1 === d(this.outputShape)) a = \"\\n          result.y = 0.;\\n          result.z = 0.;\\n          result.w = 0.;\\n        \";else if (a = \"\\n          \".concat(Ck(r), \" coords = getOutputCoords();\\n        \"), 1 === r) a += this.enableShapeUniforms ? \"\\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \" : \"\\n            result.y = (coords + 1) >= \".concat(this.outputShape[0], \" ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \");else {\n      var _e450 = Ow(\"coords\", r);\n\n      a += this.enableShapeUniforms ? \"\\n            bool nextRowOutOfBounds =\\n              (\".concat(_e450[r - 2], \" + 1) >= outShape[\").concat(r, \" - 2];\\n            bool nextColOutOfBounds =\\n              (\").concat(_e450[r - 1], \" + 1) >= outShape[\").concat(r, \" - 1];\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \") : \"\\n            bool nextRowOutOfBounds =\\n              (\".concat(_e450[r - 2], \" + 1) >= \").concat(this.outputShape[r - 2], \";\\n            bool nextColOutOfBounds =\\n              (\").concat(_e450[r - 1], \" + 1) >= \").concat(this.outputShape[r - 1], \";\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \");\n    }\n    this.userCode = \"\\n      vec4 binaryOperation(vec4 a, vec4 b) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n\\n        vec4 result = binaryOperation(a, b);\\n        \").concat(a, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction Zw(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n  return n.incRef(s.dataId), {\n    dataId: s.dataId,\n    shape: s.shape,\n    dtype: s.dtype\n  };\n}\n\nvar Qw = {\n  kernelName: \"Identity\",\n  backendName: \"webgl\",\n  kernelFunc: Zw\n};\n\nfunction ev(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    real: s,\n    imag: r\n  } = t,\n      a = n.makeTensorInfo(s.shape, \"complex64\"),\n      i = n.texData.get(a.dataId),\n      o = Zw({\n    inputs: {\n      x: s\n    },\n    backend: n\n  }),\n      l = Zw({\n    inputs: {\n      x: r\n    },\n    backend: n\n  });\n  return i.complexTensorInfos = {\n    real: o,\n    imag: l\n  }, a;\n}\n\nvar tv = {\n  kernelName: \"Complex\",\n  backendName: \"webgl\",\n  kernelFunc: ev\n},\n    nv = \"return (a < 0.) ? b * a : a;\",\n    sv = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\",\n    rv = {\n  kernelName: \"LeakyRelu\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      alpha: a\n    } = s,\n        i = n.makeTensorInfo([], \"float32\", Ue(a, \"float32\")),\n        o = G().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Jw(sv, r.shape, i.shape) : new Yw(nv, r.shape, i.shape),\n        l = n.runWebGLProgram(o, [r, i], r.dtype);\n    return n.disposeIntermediateTensorInfo(i), l;\n  }\n},\n    av = \"return (a < 0.) ? b * a : a;\",\n    iv = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\",\n    ov = {\n  kernelName: \"Prelu\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s,\n      alpha: r\n    } = t,\n        a = G().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Jw(iv, s.shape, r.shape) : new Yw(av, s.shape, r.shape);\n    return n.runWebGLProgram(a, [s, r], s.dtype);\n  }\n};\n\nfunction lv(_ref20) {\n  var {\n    opSnippet: e,\n    packedOpSnippet: t,\n    cpuKernelImpl: n,\n    dtype: s\n  } = _ref20;\n  return _ref21 => {\n    var {\n      inputs: r,\n      backend: a\n    } = _ref21;\n    var {\n      x: i\n    } = r,\n        o = a,\n        l = s || i.dtype;\n\n    if (o.shouldExecuteOnCPU([i]) && null != n) {\n      var _e451 = o.texData.get(i.dataId),\n          _t381 = n(_e451.values, l);\n\n      return o.makeTensorInfo(i.shape, l, _t381);\n    }\n\n    var u;\n    return u = G().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") && null != t ? new Gw(i.shape, t) : new Uw(i.shape, e), o.runWebGLProgram(u, [i], l);\n  };\n}\n\nfunction uv(_ref22) {\n  var {\n    opSnippet: e,\n    packedOpSnippet: t,\n    checkOutOfBounds: n = !1,\n    supportsComplex: s = !1,\n    cpuKernelImpl: r,\n    dtype: a\n  } = _ref22;\n  return _ref23 => {\n    var {\n      inputs: i,\n      backend: o\n    } = _ref23;\n    var {\n      a: l,\n      b: u\n    } = i,\n        c = o;\n\n    if (s && \"complex64\" === l.dtype) {\n      var _t382 = c.texData.get(l.dataId),\n          _n278 = c.texData.get(u.dataId),\n          [_s218, _r163] = [[_t382.complexTensorInfos.real, _n278.complexTensorInfos.real], [_t382.complexTensorInfos.imag, _n278.complexTensorInfos.imag]].map(t => {\n        var [n, s] = t,\n            r = {\n          dataId: n.dataId,\n          dtype: n.dtype,\n          shape: l.shape\n        },\n            a = {\n          dataId: s.dataId,\n          dtype: s.dtype,\n          shape: u.shape\n        },\n            i = new Yw(e, l.shape, u.shape);\n        return c.runWebGLProgram(i, [r, a], pt(n.dtype, s.dtype));\n      }),\n          _a129 = ev({\n        inputs: {\n          real: _s218,\n          imag: _r163\n        },\n        backend: c\n      });\n\n      return c.disposeIntermediateTensorInfo(_s218), c.disposeIntermediateTensorInfo(_r163), _a129;\n    }\n\n    var h = a || pt(l.dtype, u.dtype);\n\n    if ((\"string\" === l.dtype || \"string\" === u.dtype || c.shouldExecuteOnCPU([l, u])) && null != r) {\n      var _e452 = c.texData.get(l.dataId).values,\n          _t383 = c.texData.get(u.dataId).values,\n          _n279 = \"string\" === l.dtype ? nl(_e452) : _e452,\n          _s219 = \"string\" === l.dtype ? nl(_t383) : _t383,\n          [_a130, _i89] = r(l.shape, u.shape, _n279, _s219, h),\n          _o66 = c.makeTensorInfo(_i89, h);\n\n      return c.texData.get(_o66.dataId).values = _a130, _o66;\n    }\n\n    var d;\n    return d = G().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") && null != t ? new Jw(t, l.shape, u.shape, n) : new Yw(e, l.shape, u.shape), c.runWebGLProgram(d, [l, u], h);\n  };\n}\n\nfunction cv(e) {\n  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n  if (\"linear\" === e) return \"return x;\";\n  if (\"relu\" === e) return t ? \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\" : \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : x;\\n\";\n  if (\"elu\" === e) return t ? \"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\" : \"return (x >= 0.0) ? x : (exp(x) - 1.0);\";\n  if (\"relu6\" === e) return t ? \"\\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\" : \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : min(6.0, x);\\n\";\n  if (\"prelu\" === e) return t ? iv : av;\n  if (\"leakyrelu\" === e) return t ? sv : nv;\n  if (\"sigmoid\" === e) return \"return 1.0 / (1.0 + exp(-1.0 * x));\";\n  throw new Error(\"Activation \".concat(e, \" has not been implemented for the WebGL backend.\"));\n}\n\nclass hv {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    var a = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    var o = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;\n    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;\n    this.variableNames = [\"matrixA\", \"matrixB\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = n, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var u = Math.ceil((s ? e[1] : e[2]) / 2),\n        c = s ? \"i * 2, rc.y\" : \"rc.y, i * 2\",\n        h = r ? \"rc.z, i * 2\" : \"i * 2, rc.z\",\n        d = s ? [\"a.xxyy\", \"a.zzww\"] : [\"a.xxzz\", \"a.yyww\"],\n        p = r ? [\"b.xzxz\", \"b.ywyw\"] : [\"b.xyxy\", \"b.zwzw\"];\n    var f = \"\",\n        g = \"\";\n    i && (f = o ? \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(i, \"\\n        }\") : l ? \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(i, \"\\n        }\") : \"vec4 activation(vec4 x) {\\n          \".concat(i, \"\\n        }\"), g = \"result = activation(result);\");\n    var m = a ? \"result += getBiasAtOutCoords();\" : \"\";\n    a && this.variableNames.push(\"bias\"), o && this.variableNames.push(\"preluActivationWeights\"), l && this.variableNames.push(\"leakyreluAlpha\");\n    var b = \"rc.x\",\n        x = \"rc.x\";\n    e[0] < t[0] ? b = \"int(min(float(rc.x), \".concat(e[0] - 1, \".))\") : t[0] < e[0] && (x = \"int(min(float(rc.x), \".concat(t[0] - 1, \".))\")), this.userCode = \"\\n      \".concat(f, \"\\n      // Don't use uniform for sharedDimensionPacked for performance.\\n      const float sharedDimension = \").concat(u, \".0;\\n\\n      vec4 dot2x2ARowBCol(ivec3 rc) {\\n        vec4 result = vec4(0);\\n        for (int i = 0; i < \").concat(u, \"; i++) {\\n          int batchA = \").concat(b, \";\\n          int batchB = \").concat(x, \";\\n          vec4 a = getMatrixA(batchA, \").concat(c, \");\\n          vec4 b = getMatrixB(batchB, \").concat(h, \");\\n\\n          // These swizzled products need to be separately added.\\n          // See: https://github.com/tensorflow/tfjs/issues/1735\\n          result += (\").concat(d[0], \" * \").concat(p[0], \");\\n          result += (\").concat(d[1], \" * \").concat(p[1], \");\\n        }\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n        vec4 result = dot2x2ARowBCol(rc);\\n\\n        \").concat(m, \"\\n\\n        \").concat(g, \"\\n\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass dv {\n  constructor(e, t, n) {\n    this.variableNames = [\"AReal\", \"AImag\", \"BReal\", \"BImag\"], this.outputShape = hr(t, n), this.userCode = \"\\n      float binaryOpComplex(\\n          float areal, float aimag, float breal, float bimag) {\\n        \".concat(e, \"\\n      }\\n\\n      void main() {\\n        float areal = getARealAtOutCoords();\\n        float aimag = getAImagAtOutCoords();\\n        float breal = getBRealAtOutCoords();\\n        float bimag = getBImagAtOutCoords();\\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\\n      }\\n    \");\n  }\n\n}\n\nvar pv = \"return a * b;\";\n\nfunction fv(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    a: s,\n    b: r\n  } = t,\n      a = pt(s.dtype, r.dtype);\n\n  if (\"complex64\" === s.dtype) {\n    var _e453 = n.texData.get(s.dataId),\n        _t384 = n.texData.get(r.dataId),\n        _a131 = new dv(\"return areal * breal - aimag * bimag;\", s.shape, r.shape),\n        _i90 = new dv(\"return areal * bimag + aimag * breal;\", s.shape, r.shape),\n        _o67 = [{\n      dataId: _e453.complexTensorInfos.real.dataId,\n      dtype: _e453.complexTensorInfos.real.dtype,\n      shape: s.shape\n    }, {\n      dataId: _e453.complexTensorInfos.imag.dataId,\n      dtype: _e453.complexTensorInfos.imag.dtype,\n      shape: s.shape\n    }, {\n      dataId: _t384.complexTensorInfos.real.dataId,\n      dtype: _t384.complexTensorInfos.real.dtype,\n      shape: r.shape\n    }, {\n      dataId: _t384.complexTensorInfos.imag.dataId,\n      dtype: _t384.complexTensorInfos.imag.dtype,\n      shape: r.shape\n    }],\n        _l45 = n.runWebGLProgram(_a131, _o67, \"float32\"),\n        _u35 = n.runWebGLProgram(_i90, _o67, \"float32\"),\n        _c30 = ev({\n      inputs: {\n        real: _l45,\n        imag: _u35\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_l45), n.disposeIntermediateTensorInfo(_u35), _c30;\n  }\n\n  if (n.shouldExecuteOnCPU([s, r])) {\n    var _e454 = n.texData.get(s.dataId),\n        _t385 = n.texData.get(r.dataId),\n        [_i91, _o68] = dw(s.shape, r.shape, _e454.values, _t385.values, a),\n        _l46 = n.makeTensorInfo(_o68, a);\n\n    return n.texData.get(_l46.dataId).values = _i91, _l46;\n  }\n\n  var i;\n  return i = G().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Jw(pv, s.shape, r.shape) : new Yw(pv, s.shape, r.shape), n.runWebGLProgram(i, [s, r], a);\n}\n\nvar gv = {\n  kernelName: \"Multiply\",\n  backendName: \"webgl\",\n  kernelFunc: fv\n};\n\nfunction mv(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    shape: a\n  } = s,\n      i = n,\n      o = d(r.shape),\n      u = x(a, o),\n      c = d(u);\n  l(o === c, () => \"The new shape (\".concat(u, \") has \").concat(c, \" elements and the old shape (\").concat(r.shape, \") has \").concat(o, \" elements. The new shape and old shape must have the same number of elements.\"));\n  var h = i.texData.get(r.dataId);\n  return !h.isPacked || rk(r.shape, u) || null !== h.texture && rk(h.shape, u) ? (i.incRef(r.dataId), {\n    dataId: r.dataId,\n    shape: u,\n    dtype: r.dtype\n  }) : function (e, t, n) {\n    var s = [ek(e.shape), ...tk(e.shape)],\n        r = {\n      dtype: e.dtype,\n      shape: s,\n      dataId: e.dataId\n    },\n        a = [ek(t), ...tk(t)],\n        i = new Lw(a, s),\n        o = n.runWebGLProgram(i, [r], e.dtype, [s], !0);\n    return {\n      dataId: o.dataId,\n      shape: t,\n      dtype: o.dtype\n    };\n  }(r, u, i);\n}\n\nvar bv = {\n  kernelName: \"Reshape\",\n  backendName: \"webgl\",\n  kernelFunc: mv\n};\n\nclass xv {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var {\n      windowSize: n,\n      batchSize: s,\n      inSize: r,\n      outSize: a\n    } = e;\n    this.outputShape = [s, a];\n    var i = 4 * Math.floor(n / 4),\n        o = n % 4;\n    var l = \"sumValue += dot(values, ones);\";\n\n    if (null != t) {\n      var _e455 = 1 / t;\n\n      l = \"sumValue += dot(values * \".concat(f(_e455) ? _e455.toPrecision(2) : _e455, \", ones);\");\n    }\n\n    var u = \"\";\n    r % n > 0 && (u = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return 0.0;\\n        }\\n      \")), this.userCode = \"\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \".concat(u, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \").concat(n, \";\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(i, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \").concat(l, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(i, \";\\n        if (\").concat(1 === o, \") {\\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\\n\\n          \").concat(l, \"\\n        } else if (\").concat(2 === o, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1), 0.0, 0.0);\\n\\n          \").concat(l, \"\\n        } else if (\").concat(3 === o, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2), 0.0);\\n\\n          \").concat(l, \"\\n        }\\n        setOutput(sumValue);\\n      }\\n    \");\n  }\n\n}\n\nclass yv {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var {\n      windowSize: n,\n      batchSize: s,\n      inSize: r,\n      outSize: a\n    } = e;\n    this.outputShape = [s, a];\n    var i = \"0.0\",\n        o = \"\";\n    \"prod\" === t ? i = \"1.0\" : \"min\" === t ? (i = \"1.0 / 1e-20\", o = \"min\") : \"max\" === t && (i = \"-1.0 / 1e-20\", o = \"max\");\n    var l = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"sum\" === t ? l = \"sumValue\" : \"prod\" === t ? l = \"prodValue\" : \"all\" === t ? l = \"allValue\" : \"any\" === t && (l = \"anyValue\");\n    var u = 4 * Math.floor(n / 4),\n        c = n % 4;\n    var h = \"\\n      if (\".concat(\"sum\" === t, \") {\\n        sumValue += dot(values, ones);\\n      } else if (\").concat(\"prod\" === t, \") {\\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\\n        prodValue *= tmp[0] * tmp[1];\\n      } else {\\n        minMaxValue = \").concat(o, \"(values, minMaxValue);\\n        if (\").concat(\"min\" === t, \" || \").concat(\"max\" === t, \") {\\n          minMaxValue = \").concat(o, \"(values, minMaxValue);\\n          bvec4 isNaN = isnan(values);\\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\\n            minMaxValue = vec4(NAN);\\n          }\\n        }\\n      }\\n    \"),\n        d = \"vec4\";\n    \"all\" === t ? (i = \"1.0\", h = \"\\n        bool reducedAllValue = all(values);\\n        float floatedReducedAllValue = float(reducedAllValue);\\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\\n      \", d = \"bvec4\") : \"any\" === t && (i = \"0.0\", h = \"\\n        bool reducedAnyValue = any(values);\\n        float floatedReducedAnyValue = float(reducedAnyValue);\\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\\n      \", d = \"bvec4\");\n    var p = \"\";\n    r % n > 0 && (p = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return initializationValue;\\n        }\\n      \")), this.userCode = \"\\n      const float initializationValue = \".concat(i, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \").concat(p, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \").concat(n, \";\\n\\n        vec4 minMaxValue = vec4(\").concat(i, \");\\n        float prodValue = 1.0;\\n        float sumValue = 0.0;\\n        float allValue = 1.0;\\n        float anyValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(u, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \").concat(h, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(u, \";\\n        if (\").concat(1 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        } else if (\").concat(2 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        } else if (\").concat(3 === c, \") {\\n          \").concat(d, \" values = \").concat(d, \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          \").concat(h, \"\\n        }\\n        setOutput(\").concat(l, \");\\n      }\\n    \");\n  }\n\n}\n\nfunction kv(e, t, n, s) {\n  var r = function (e) {\n    var t = [];\n\n    for (; 0 === t.length || 1 !== t[t.length - 1].outSize;) {\n      var _n280 = t.length ? t[t.length - 1].outSize : e[1],\n          _s220 = Ro(_n280);\n\n      t.push({\n        inSize: _n280,\n        windowSize: _s220,\n        outSize: Math.ceil(_n280 / _s220)\n      });\n    }\n\n    return t;\n  }(e.shape);\n\n  var a = e;\n\n  for (var _i92 = 0; _i92 < r.length; _i92++) {\n    var {\n      inSize: _o69,\n      windowSize: _l47,\n      outSize: _u36\n    } = r[_i92];\n\n    var _c31 = void 0,\n        _h18 = void 0;\n\n    _c31 = \"mean\" === n ? 0 === _i92 ? new xv({\n      windowSize: _l47,\n      inSize: _o69,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }, _o69) : new xv({\n      windowSize: _l47,\n      inSize: _o69,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }) : new yv({\n      windowSize: _l47,\n      inSize: _o69,\n      batchSize: e.shape[0],\n      outSize: _u36\n    }, n), _h18 = a, a = s.runWebGLProgram(_c31, [a], t), _h18.dataId !== e.dataId && s.disposeIntermediateTensorInfo(_h18);\n  }\n\n  return a;\n}\n\nclass wv {\n  constructor(e, t) {\n    this.variableNames = [\"A\"];\n    var n = new Array(e.length);\n\n    for (var _s221 = 0; _s221 < n.length; _s221++) {\n      n[_s221] = e[t[_s221]];\n    }\n\n    this.outputShape = n, this.rank = n.length;\n\n    var s = Ck(this.rank),\n        r = function (e) {\n      var t = e.length;\n      if (t > 6) throw Error(\"Transpose for rank \".concat(t, \" is not yet supported\"));\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\", \"resRC.u\", \"resRC.v\"],\n          s = new Array(t);\n\n      for (var _t386 = 0; _t386 < e.length; _t386++) {\n        s[e[_t386]] = n[_t386];\n      }\n\n      return s.join();\n    }(t);\n\n    this.userCode = \"\\n    void main() {\\n      \".concat(s, \" resRC = getOutputCoords();\\n      setOutput(getA(\").concat(r, \"));\\n    }\\n    \");\n  }\n\n}\n\nclass vv {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0;\n    var n = new Array(e.length);\n\n    for (var _s222 = 0; _s222 < n.length; _s222++) {\n      n[_s222] = e[t[_s222]];\n    }\n\n    if (this.outputShape = n, this.rank = n.length, this.rank > 6) throw Error(\"Packed transpose for rank \".concat(this.rank, \" is not yet supported.\"));\n\n    var s = Ck(this.rank),\n        r = _w(\"rc\", this.rank),\n        a = new Array(this.rank);\n\n    for (var _e456 = 0; _e456 < t.length; _e456++) {\n      a[t[_e456]] = r[_e456];\n    }\n\n    var i = \"vec2(\".concat(a.slice(-2).join(), \")\"),\n        o = \"++\".concat(r[this.rank - 1], \" < \").concat(n[this.rank - 1]),\n        l = \"getChannel(getA(\".concat(a.join(), \"), \").concat(i, \")\");\n    this.userCode = \"\\n    void main() {\\n      \".concat(s, \" rc = getOutputCoords();\\n      vec4 result = vec4(0.);\\n      result[0] = \").concat(l, \";\\n      if(\").concat(o, \") {\\n        result[1] = \").concat(l, \";\\n      }\\n      --\").concat(r[this.rank - 1], \";\\n      if(++\").concat(r[this.rank - 2], \" < \").concat(n[this.rank - 2], \") {\\n        result[2] = \").concat(l, \";\\n        if(\").concat(o, \") {\\n          result[3] = \").concat(l, \";\\n        }\\n      }\\n      setOutput(result);\\n    }\\n    \");\n  }\n\n}\n\nfunction Iv(e, t, n) {\n  var s = G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new vv(e.shape, t) : new wv(e.shape, t);\n  return n.runWebGLProgram(s, [e], e.dtype);\n}\n\nfunction $v(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    axis: a,\n    keepDims: i\n  } = s;\n  return function (e, t, n, s) {\n    var r = e.shape.length,\n        a = y(t, e.shape);\n    var i = a;\n    var o = Zr(i, r),\n        l = null != o;\n    var u = e;\n    l && (u = Iv(e, o, s), i = ea(i.length, r)), Jr(\"sum\", i, r);\n    var [c, h] = Xr(u.shape, i);\n    var p = c;\n    n && (p = Yr(c, a));\n    var f = d(h),\n        g = mv({\n      inputs: {\n        x: u\n      },\n      attrs: {\n        shape: [d(e.shape) / f, f]\n      },\n      backend: s\n    }),\n        m = kv(g, ft(e.dtype), \"sum\", s),\n        b = mv({\n      inputs: {\n        x: m\n      },\n      attrs: {\n        shape: p\n      },\n      backend: s\n    });\n    return s.disposeIntermediateTensorInfo(g), s.disposeIntermediateTensorInfo(m), l && s.disposeIntermediateTensorInfo(u), b;\n  }(r, a, i, n);\n}\n\nvar Sv = {\n  kernelName: \"Sum\",\n  backendName: \"webgl\",\n  kernelFunc: $v\n};\n\nfunction Nv(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    perm: a\n  } = s,\n      i = n,\n      o = new Array(r.shape.length);\n\n  for (var _e457 = 0; _e457 < o.length; _e457++) {\n    o[_e457] = r.shape[a[_e457]];\n  }\n\n  var l;\n\n  if (i.shouldExecuteOnCPU([r])) {\n    var _e458 = i.texData.get(r.dataId),\n        _t387 = Fw(_e458.values, r.shape, r.dtype, a, o);\n\n    l = i.makeTensorInfo(o, r.dtype), i.texData.get(l.dataId).values = _t387;\n  } else l = Iv(r, a, i);\n\n  return l;\n}\n\nvar Cv = {\n  kernelName: \"Transpose\",\n  backendName: \"webgl\",\n  kernelFunc: Nv\n};\n\nfunction Tv(_ref24) {\n  var {\n    a: e,\n    b: t,\n    transposeA: n,\n    transposeB: s,\n    backend: r,\n    bias: a = null,\n    preluActivationWeights: i = null,\n    leakyreluAlpha: o = 0,\n    activation: u = null\n  } = _ref24;\n  var c = e.shape.length,\n      h = t.shape.length,\n      p = n ? e.shape[c - 2] : e.shape[c - 1],\n      f = s ? t.shape[h - 1] : t.shape[h - 2],\n      g = n ? e.shape[c - 1] : e.shape[c - 2],\n      m = s ? t.shape[h - 2] : t.shape[h - 1],\n      b = e.shape.slice(0, -2),\n      x = t.shape.slice(0, -2),\n      y = d(b),\n      k = d(x);\n  l(c >= 2 && h >= 2 && (y === k || 1 === y || 1 === k), () => \"Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (\".concat(b, \") and (\").concat(x, \").\"));\n  var w = (y > k ? e.shape.slice(0, -2) : t.shape.slice(0, -2)).concat([g, m]);\n  l(p === f, () => \"Error in matMul: inner shapes (\".concat(p, \") and (\").concat(f, \") of Tensors with shapes \").concat(e.shape, \" and \").concat(t.shape, \" and transposeA=\").concat(n, \" and transposeB=\").concat(s, \" must match.\"));\n  var v = n ? [y, p, g] : [y, g, p],\n      I = s ? [k, m, f] : [k, f, m],\n      $ = mv({\n    inputs: {\n      x: e\n    },\n    backend: r,\n    attrs: {\n      shape: v\n    }\n  }),\n      S = mv({\n    inputs: {\n      x: t\n    },\n    backend: r,\n    attrs: {\n      shape: I\n    }\n  }),\n      N = [$, S],\n      C = Math.max(y, k),\n      T = n ? $.shape[1] : $.shape[2],\n      E = null != a,\n      R = null != i,\n      A = \"leakyrelu\" === u,\n      F = null != u ? cv(u, !0) : null;\n  var D;\n\n  if ((1 === g || 1 === m) && T > 1e3 && !1 === (E || R || A || null != F)) {\n    var _e459 = $,\n        _t388 = S;\n    n && (_e459 = Nv({\n      inputs: {\n        x: $\n      },\n      backend: r,\n      attrs: {\n        perm: [0, 2, 1]\n      }\n    }), N.push(_e459)), s && (_t388 = Nv({\n      inputs: {\n        x: S\n      },\n      backend: r,\n      attrs: {\n        perm: [0, 2, 1]\n      }\n    }), N.push(_t388));\n\n    var _a132 = 1 === m;\n\n    var _i93 = _e459;\n    1 !== m && (_i93 = mv({\n      inputs: {\n        x: _e459\n      },\n      backend: r,\n      attrs: {\n        shape: [C, T, 1]\n      }\n    }), N.push(_i93));\n\n    var _o70 = 1 === m ? 2 : 1;\n\n    var _l48 = _t388;\n    _a132 && (_l48 = mv({\n      inputs: {\n        x: _t388\n      },\n      backend: r,\n      attrs: {\n        shape: [C, 1, T]\n      }\n    }), N.push(_l48));\n\n    var _u37 = fv({\n      inputs: {\n        a: _i93,\n        b: _l48\n      },\n      backend: r\n    });\n\n    D = $v({\n      inputs: {\n        x: _u37\n      },\n      backend: r,\n      attrs: {\n        axis: _o70,\n        keepDims: !0\n      }\n    }), N.push(_u37);\n  } else {\n    var _l49 = pt(e.dtype, t.dtype),\n        _u38 = new hv(v, I, [C, g, m], n, s, E, F, R, A),\n        _c32 = [$, S];\n\n    if (null != a && _c32.push(a), R && _c32.push(i), A) {\n      var _e460 = r.makeTensorInfo([], \"float32\", Ue(o, \"float32\"));\n\n      _c32.push(_e460), N.push(_e460);\n    }\n\n    D = r.runWebGLProgram(_u38, _c32, _l49);\n  }\n\n  var _ = mv({\n    inputs: {\n      x: D\n    },\n    backend: r,\n    attrs: {\n      shape: w\n    }\n  });\n\n  N.push(D);\n\n  for (var _e461 of N) {\n    r.disposeIntermediateTensorInfo(_e461);\n  }\n\n  return _;\n}\n\nvar Ev = {\n  kernelName: \"_FusedMatMul\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      transposeA: l,\n      transposeB: u,\n      activation: c,\n      leakyreluAlpha: h\n    } = s;\n    return Tv({\n      a: r,\n      b: a,\n      transposeA: l,\n      transposeB: u,\n      backend: n,\n      bias: i,\n      preluActivationWeights: o,\n      leakyreluAlpha: h,\n      activation: c\n    });\n  }\n},\n    Rv = \"return abs(x);\",\n    Av = {\n  kernelName: \"Abs\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n\n    if (n.shouldExecuteOnCPU([s]) && \"complex64\" !== s.dtype) {\n      var _e462 = n.texData.get(s.dataId),\n          _t389 = yw(_e462.values);\n\n      return n.makeTensorInfo(s.shape, s.dtype, _t389);\n    }\n\n    var r;\n    return r = G().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") ? new Gw(s.shape, Rv) : new Uw(s.shape, Rv), n.runWebGLProgram(r, [s], s.dtype);\n  }\n},\n    Fv = {\n  kernelName: \"Acos\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return acos(x);\\n\"\n  })\n},\n    Dv = {\n  kernelName: \"Acosh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (x < 1.0) return NAN;\\nreturn log(x + sqrt(x * x - 1.0));\"\n  })\n},\n    _v = \"return a + b;\",\n    Ov = {\n  kernelName: \"Add\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: _v,\n    packedOpSnippet: _v,\n    supportsComplex: !0,\n    cpuKernelImpl: qk\n  })\n};\n\nclass Mv {\n  constructor(e, t) {\n    this.outputShape = [], this.outputShape = e, this.variableNames = t.map((e, t) => \"T\".concat(t));\n    var n = [];\n    this.variableNames.forEach(e => {\n      n.push(\"float v\".concat(e, \" = get\").concat(e, \"AtOutCoords();\"));\n    });\n    var s = this.variableNames.map(e => \"v\".concat(e)).join(\" + \");\n    this.userCode = \"\\n      void main() {\\n        \".concat(n.join(\"\\n        \"), \"\\n\\n        float result = \").concat(s, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass Lv {\n  constructor(e, t) {\n    this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.variableNames = t.map((e, t) => \"T\".concat(t));\n    var n = [];\n    this.variableNames.forEach(e => {\n      n.push(\"vec4 v\".concat(e, \" = get\").concat(e, \"AtOutCoords();\"));\n    });\n    var s = this.variableNames.map(e => \"v\".concat(e)).join(\" + \");\n    this.userCode = \"\\n      void main() {\\n        \".concat(n.join(\"\\n        \"), \"\\n\\n        vec4 result = \").concat(s, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar zv = {\n  kernelName: \"AddN\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        r = n;\n    if (1 === r.length) return Zw({\n      inputs: {\n        x: r[0]\n      },\n      backend: s\n    });\n\n    if (r.length > G().get(\"WEBGL_MAX_TEXTURES_IN_SHADER\")) {\n      var _t390 = Math.floor(r.length / 2),\n          _n281 = e({\n        inputs: r.slice(0, _t390),\n        backend: s\n      }),\n          _a133 = e({\n        inputs: r.slice(_t390),\n        backend: s\n      });\n\n      return e({\n        inputs: [_n281, _a133],\n        backend: s\n      });\n    }\n\n    var a = r.map(e => e.dtype).reduce((e, t) => pt(e, t)),\n        i = r.map(e => e.shape),\n        o = G().getBool(\"WEBGL_PACK\") ? new Lv(r[0].shape, i) : new Mv(r[0].shape, i);\n    return s.runWebGLProgram(o, r, a);\n  }\n},\n    Bv = {\n  kernelName: \"All\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Zr(u, o);\n    var h = r;\n    null != c && (h = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = ea(u.length, o)), Jr(\"all\", u, o);\n    var [p, f] = Xr(h.shape, u),\n        g = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = kv(g, g.dtype, \"all\", n);\n    var b;\n    return b = mv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Yr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n},\n    Pv = {\n  kernelName: \"Any\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Zr(u, o);\n    var h = r;\n    null != c && (h = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = ea(u.length, o)), Jr(\"any\", u, o);\n    var [p, f] = Xr(h.shape, u),\n        g = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = kv(g, g.dtype, \"any\", n);\n    var b;\n    return b = mv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Yr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n};\n\nclass Wv {\n  constructor(e, t, n) {\n    this.variableNames = [\"A\"];\n    var {\n      windowSize: s,\n      batchSize: r,\n      outSize: a\n    } = e;\n    n || this.variableNames.push(\"bestIndicesA\"), this.outputShape = [r, a], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \".concat(s, \";\\n\\n        int bestIndex = inOffset;\\n        float bestValue = getA(batch, bestIndex);\\n\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          int inIdx = \").concat(n ? \"inOffset + i;\" : \"round(getBestIndicesA(batch, inOffset + i));\", \";\\n          float candidate = getA(batch, inIdx);\\n          if (candidate \").concat(\"max\" === t ? \">\" : \"<\", \" bestValue) {\\n            bestValue = candidate;\\n            bestIndex = inIdx;\\n          }\\n        }\\n        setOutput(float(bestIndex));\\n      }\\n    \");\n  }\n\n}\n\nclass Uv {\n  constructor(e, t, n, s) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, l(e.length > 2, () => \"Packed arg\".concat(n.charAt(0).toUpperCase() + n.slice(1), \" supports only inputs with rank above 2.\"));\n    var r = Math.ceil(e[e.length - 1] / t);\n    this.outputShape = e.slice(0, -1), r > 1 && this.outputShape.push(r), s || this.variableNames.push(\"bestIndicesA\");\n    var a = this.outputShape,\n        i = a.length,\n        o = Ck(i),\n        u = Ow(\"coords\", i);\n    var c, h;\n\n    if (1 === r) {\n      h = i + 1;\n\n      var _e463 = Ck(h);\n\n      c = \"\\n        \".concat(_e463, \" sourceLocR = \").concat(_e463, \"(\").concat(u.join(), \", 0);\\n        ++\").concat(u[i - 1], \";\\n        \").concat(_e463, \" sourceLocG = \").concat(_e463, \"(\").concat(u.join(), \", 0);\\n        ++\").concat(u[i - 2], \";\\n        \").concat(_e463, \" sourceLocA = \").concat(_e463, \"(\").concat(u.join(), \", 0);\\n        --\").concat(u[i - 1], \";\\n        \").concat(_e463, \" sourceLocB = \").concat(_e463, \"(\").concat(u.join(), \", 0);\\n        --\").concat(u[i - 2], \";\");\n    } else h = i, c = \"\\n        \".concat(o, \" sourceLocR = coords;\\n        ++\").concat(u[i - 1], \";\\n        \").concat(o, \" sourceLocG = coords;\\n        ++\").concat(u[i - 2], \";\\n        \").concat(o, \" sourceLocA = coords;\\n        --\").concat(u[i - 1], \";\\n        \").concat(o, \" sourceLocB = coords;\\n        --\").concat(u[i - 2], \";\");\n\n    var d = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, h),\n        p = \".\" + d[h - 1],\n        f = d.map(e => \"int \" + e),\n        g = Ow(\"sourceLocR\", h - 1).concat(\"inIdx.r\"),\n        m = Ow(\"sourceLocG\", h - 1).concat(\"inIdx.g\"),\n        b = Ow(\"sourceLocB\", h - 1).concat(\"inIdx.b\"),\n        x = Ow(\"sourceLocA\", h - 1).concat(\"inIdx.a\"),\n        y = \"max\" === n ? \"greaterThan\" : \"lessThan\",\n        k = s ? \"\" : \"\\n          inIdx = round(vec4(getBestIndicesAChannel(\".concat(g.join(), \"),\\n                             getBestIndicesAChannel(\").concat(m.join(), \"),\\n                             getBestIndicesAChannel(\").concat(b.join(), \"),\\n                             getBestIndicesAChannel(\").concat(x.join(), \")));\"),\n        w = \"vec4(\\n            getAChannel(\".concat(g.join(), \"),\\n            hasNextCol ? getAChannel(\").concat(m.join(), \") : 0.,\\n            hasNextRow ? getAChannel(\").concat(b.join(), \") : 0.,\\n            hasNextRow && hasNextCol ? getAChannel(\").concat(x.join(), \") : 0.)\"),\n        v = s ? \"\" : \"\\n      float getBestIndicesAChannel(\".concat(f.join(), \") {\\n        return getChannel(getBestIndicesA(\").concat(d.join(), \"),\\n                                          vec2(\").concat(d.slice(-2).join(), \"));\\n      }\");\n    this.userCode = \"\\n      float getAChannel(\".concat(f.join(), \") {\\n        return getChannel(getA(\").concat(d.join(), \"),\\n                               vec2(\").concat(d.slice(-2).join(), \"));\\n      }\\n      \").concat(v, \"\\n      void main() {\\n        \").concat(o, \" coords = getOutputCoords();\\n        bool hasNextCol = \").concat(u[i - 1], \" < \").concat(a[i - 1] - 1, \";\\n        bool hasNextRow = \").concat(u[i - 2], \" < \").concat(a[i - 2] - 1, \";\\n        \").concat(c, \"\\n        ivec4 srcIdx = ivec4(sourceLocR\").concat(p, \", sourceLocG\").concat(p, \",\\n          sourceLocB\").concat(p, \", sourceLocA\").concat(p, \") * \").concat(t, \";\\n        ivec4 inIdx = srcIdx;\\n        vec4 bestIndex = vec4(inIdx);\\n        vec4 bestValue = \").concat(w, \";\\n\\n        for (int i = 0; i < \").concat(t, \"; i++) {\\n          inIdx = srcIdx;\\n          \").concat(k, \"\\n          vec4 candidate = \").concat(w, \";\\n          bvec4 nan = isnan(candidate);\\n          bvec4 replace = bvec4(\\n            vec4(\").concat(y, \"(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\\n\\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\\n                           replace.y  ? candidate.y : bestValue.y,\\n                           replace.z  ? candidate.z : bestValue.z,\\n                           replace.w  ? candidate.w : bestValue.w);\\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\\n          srcIdx++;\\n        }\\n        setOutput(bestIndex);\\n      }\\n    \");\n  }\n\n}\n\nfunction Vv(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n  var r = t.shape[0],\n      a = t.shape[1];\n  null != s && (r = s.shape[0], a = s.shape[1]);\n  var i = Ro(a),\n      o = {\n    windowSize: i,\n    inSize: a,\n    batchSize: r,\n    outSize: Math.ceil(a / i)\n  },\n      l = new Wv(o, n, null == s),\n      u = [t];\n  null != s && u.push(s);\n  var c = e.runWebGLProgram(l, u, \"int32\");\n  if (1 === c.shape[1]) return c;\n  var h = Vv(e, t, n, c);\n  return e.disposeIntermediateTensorInfo(c), h;\n}\n\nfunction Gv(e, t, n) {\n  var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n  var r = null != s ? s.shape : t.shape,\n      a = Ro(r[r.length - 1]),\n      i = new Uv(r, a, n, null == s),\n      o = e.runWebGLProgram(i, null == s ? [t] : [t, s], \"int32\");\n\n  if (o.shape.length === t.shape.length) {\n    var _s223 = Gv(e, t, n, o);\n\n    return e.disposeIntermediateTensorInfo(o), _s223;\n  }\n\n  return o;\n}\n\nfunction Hv(e, t, n, s) {\n  var r = [n];\n\n  if (Jr(\"arg\" + s.charAt(0).toUpperCase() + s.slice(1), r, t.shape.length), !G().getBool(\"WEBGL_PACK_REDUCE\") || t.shape.length <= 2) {\n    var _n282 = [],\n        _a134 = e.texData.get(t.dataId);\n\n    var _i94 = t;\n    null !== _a134 && _a134.isPacked && (_i94 = e.unpackTensor(t), _n282.push(_i94));\n\n    var [_o71, _l50] = Xr(_i94.shape, r),\n        _u39 = d(_l50),\n        _c33 = mv({\n      inputs: {\n        x: _i94\n      },\n      backend: e,\n      attrs: {\n        shape: [-1, _u39]\n      }\n    });\n\n    _n282.push(_c33);\n\n    var _h19 = Vv(e, _c33, s);\n\n    _n282.push(_h19);\n\n    var _p16 = mv({\n      inputs: {\n        x: _h19\n      },\n      backend: e,\n      attrs: {\n        shape: _o71\n      }\n    });\n\n    return _n282.forEach(t => e.disposeIntermediateTensorInfo(t)), _p16;\n  }\n\n  return Gv(e, t, s);\n}\n\nvar qv = {\n  kernelName: \"ArgMax\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    var i = y(a, r.shape);\n    var o = Zr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = ea(i.length, l.shape.length)), Jr(\"argMax\", [i[0]], l.shape.length);\n    var c = Hv(n, l, i[0], \"max\");\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n},\n    jv = {\n  kernelName: \"ArgMin\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a\n    } = s;\n    var i = y(a, r.shape);\n    var o = Zr(i, r.shape.length);\n    var l = r;\n    var u = [];\n    null != o && (l = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: o\n      }\n    }), u.push(l), i = ea(i.length, l.shape.length)), Jr(\"argMin\", [i[0]], l.shape.length);\n    var c = Hv(n, l, i[0], \"min\");\n    return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n},\n    Kv = {\n  kernelName: \"Asin\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return asin(x);\\n\"\n  })\n},\n    Xv = {\n  kernelName: \"Asinh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;return log(x + sqrt(x * x + 1.0));\"\n  })\n},\n    Yv = {\n  kernelName: \"Atan\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return atan(x);\\n\"\n  })\n},\n    Jv = {\n  kernelName: \"Atan2\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return atan(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = atan(a, b);\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    Zv = {\n  kernelName: \"Atanh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  if ((x < -1.0) || (x > 1.0)) return NAN;\\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;\"\n  })\n};\n\nclass Qv {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (this.variableNames = [\"x\"], \"avg\" === t && n) throw new Error(\"Cannot compute positions for average pool.\");\n    var a = e.filterWidth,\n        i = e.strideHeight,\n        o = e.strideWidth,\n        l = e.dilationHeight,\n        u = e.dilationWidth,\n        c = e.effectiveFilterHeight,\n        h = e.effectiveFilterWidth,\n        d = e.padInfo.top,\n        p = e.padInfo.left;\n    this.outputShape = e.outShape;\n    var f = \"avg\" === t;\n    var g = \"0.0\";\n    if (f || (g = \"-1.0 / 1e-20\"), n) return void (this.userCode = \"\\n        const ivec2 strides = ivec2(\".concat(i, \", \").concat(o, \");\\n        const ivec2 pads = ivec2(\").concat(d, \", \").concat(p, \");\\n\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int batch = coords[0];\\n          int d = coords[3];\\n\\n          ivec2 xRCCorner = coords.yz * strides - pads;\\n          int xRCorner = xRCCorner.x;\\n          int xCCorner = xRCCorner.y;\\n\\n          // max/min x(?, ?, d) to get y(yR, yC, d).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n          float avgValue = 0.0;\\n\\n          for (int wR = 0; wR < \").concat(c, \";\\n              wR += \").concat(l, \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(h, \";\\n                wC += \").concat(u, \") {\\n              int xC = xCCorner + wC;\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              float value = getX(batch, xR, xC, d);\\n\\n              // If a min / max value has already been found, use it. If not,\\n              // use the current value.\\n              float currMinMaxValue = mix(\\n                  value, minMaxValue, minMaxValueFound);\\n              if (value >= currMinMaxValue) {\\n                minMaxValue = value;\\n                minMaxValueFound = 1.0;\\n                minMaxPosition = \").concat(s ? r ? \"((batch  * \".concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + d\") : \"(xR * \".concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + d\") : \"wR * \".concat(h, \" + wC\"), \";\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \"));\n    var m = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"avg\" === t && (m = \"avgValue / count\");\n    var b = 4 * Math.floor(a / 4),\n        x = a % 4,\n        y = \"\\n      if (\".concat(f, \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \");\n    this.userCode = \"\\n      const ivec2 strides = ivec2(\".concat(i, \", \").concat(o, \");\\n      const ivec2 pads = ivec2(\").concat(d, \", \").concat(p, \");\\n      const float initializationValue = \").concat(g, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xR, int xC, int d) {\\n        if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xR, xC, d);\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // max/min x(?, ?, d) to get y(yR, yC, d).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\").concat(g, \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wR = 0; wR < \").concat(c, \";\\n            wR += \").concat(l, \") {\\n          int xR = xRCorner + wR;\\n\\n          if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(b, \"; wC += 4) {\\n            int xC = xCCorner + wC * \").concat(u, \";\\n\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              getValue(batch, xR, xC + 2 * \").concat(u, \", d),\\n              getValue(batch, xR, xC + 3 * \").concat(u, \", d)\\n            );\\n\\n            \").concat(y, \"\\n          }\\n\\n          int xC = xCCorner + \").concat(b, \";\\n          if (\").concat(1 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              initializationValue,\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          } else if (\").concat(2 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          } else if (\").concat(3 === x, \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \").concat(u, \", d),\\n              getValue(batch, xR, xC + 2 * \").concat(u, \", d),\\n              initializationValue\\n            );\\n\\n            \").concat(y, \"\\n          }\\n        }\\n        setOutput(\").concat(m, \");\\n      }\\n    \");\n  }\n\n}\n\nclass eI {\n  constructor(e, t, n) {\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    if (this.variableNames = [\"x\"], \"avg\" === t && n) throw new Error(\"Cannot compute positions for average pool.\");\n    var a = e.filterWidth,\n        i = e.strideDepth,\n        o = e.strideHeight,\n        l = e.strideWidth,\n        u = e.dilationDepth,\n        c = e.dilationHeight,\n        h = e.dilationWidth,\n        d = e.effectiveFilterDepth,\n        p = e.effectiveFilterHeight,\n        f = e.effectiveFilterWidth,\n        g = e.padInfo.front,\n        m = e.padInfo.top,\n        b = e.padInfo.left;\n    this.outputShape = e.outShape;\n    var x = \"avg\" === t;\n    var y = \"0.0\";\n    if (x || (y = \"-1.0 / 1e-20\"), n) return void (this.userCode = \"\\n        const ivec3 strides =\\n            ivec3(\".concat(i, \", \").concat(o, \", \").concat(l, \");\\n        const ivec3 pads = ivec3(\").concat(g, \", \").concat(m, \", \").concat(b, \");\\n\\n        void main() {\\n          ivec5 coords = getOutputCoords();\\n          int batch = coords.x;\\n          int ch = coords.u;\\n\\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n          int xDCorner = xCorner.x;\\n          int xRCorner = xCorner.y;\\n          int xCCorner = xCorner.z;\\n\\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n\\n          for (int wD = 0; wD < \").concat(d, \";\\n              wD += \").concat(u, \") {\\n            int xD = xDCorner + wD;\\n\\n            if (xD < 0 || xD >= \").concat(e.inDepth, \") {\\n              continue;\\n            }\\n\\n            for (int wR = 0; wR < \").concat(p, \";\\n                wR += \").concat(c, \") {\\n              int xR = xRCorner + wR;\\n\\n              if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n                continue;\\n              }\\n\\n              for (int wC = 0; wC < \").concat(f, \";\\n                  wC += \").concat(h, \") {\\n                int xC = xCCorner + wC;\\n\\n                if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                  continue;\\n                }\\n\\n                float value = getX(batch, xD, xR, xC, ch);\\n\\n                // If a min / max value has already been found, use it. If not,\\n                // use the current value.\\n                float currMinMaxValue = mix(\\n                    value, minMaxValue, minMaxValueFound);\\n                if (value >= currMinMaxValue) {\\n                  minMaxValue = value;\\n                  minMaxValueFound = 1.0;\\n                  minMaxPosition = \").concat(s ? r ? \"(((batch * \".concat(e.inDepth, \" + xD) * \").concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + ch\") : \"((xD * \".concat(e.inHeight, \" + xR) * \").concat(e.inWidth, \" + xC) * \").concat(e.inChannels, \" + ch\") : \"wD * \".concat(p, \" * \").concat(f, \" +\\n                      wR * \").concat(f, \" + wC\"), \";\\n                }\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \"));\n    var k = \"\".concat(t, \"(\").concat(t, \"(\").concat(t, \"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\");\n    \"avg\" === t && (k = \"avgValue / count\");\n    var w = 4 * Math.floor(a / 4),\n        v = a % 4,\n        I = \"\\n      if (\".concat(x, \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \");\n    this.userCode = \"\\n      const ivec3 strides =\\n        ivec3(\".concat(i, \", \").concat(o, \", \").concat(l, \");\\n      const ivec3 pads = ivec3(\").concat(g, \", \").concat(m, \", \").concat(b, \");\\n      const float initializationValue = \").concat(y, \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\\n        if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xD, xR, xC, ch);\\n      }\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xDCorner = xCorner.x;\\n        int xRCorner = xCorner.y;\\n        int xCCorner = xCorner.z;\\n\\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\").concat(y, \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(d, \";\\n            wD += \").concat(u, \") {\\n          int xD = xDCorner + wD;\\n\\n          if (xD < 0 || xD >= \").concat(e.inDepth, \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \").concat(p, \";\\n            wR += \").concat(c, \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(w, \"; wC += 4) {\\n              int xC = xCCorner + wC * \").concat(h, \";\\n\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 3 * \").concat(h, \", ch)\\n              );\\n\\n              \").concat(I, \"\\n            }\\n\\n            int xC = xCCorner + \").concat(w, \";\\n            if (\").concat(1 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                initializationValue,\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            } else if (\").concat(2 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            } else if (\").concat(3 === v, \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \").concat(h, \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \").concat(h, \", ch),\\n                initializationValue\\n              );\\n\\n              \").concat(I, \"\\n            }\\n          }\\n          setOutput(\").concat(k, \");\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar tI = {\n  kernelName: \"AvgPool\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    ck(r, \"avgPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ts(i, 1), () => \"Error in avgPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = xs(r.shape, a, i, 1, o, u);\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) return Zw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var h = new Qv(c, \"avg\", !1);\n    return n.runWebGLProgram(h, [r], \"float32\");\n  }\n},\n    nI = {\n  kernelName: \"AvgPool3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: l,\n      dataFormat: u\n    } = s,\n        c = ys(r.shape, a, i, [1, 1, 1], o, l, u),\n        h = new eI(c, \"avg\", !1);\n    return n.runWebGLProgram(h, [r], \"float32\");\n  }\n};\n\nclass sI {\n  constructor(e) {\n    this.variableNames = [\"dy\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterHeight,\n        n = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n      const float avgMultiplier = float(\").concat(1 / (e.filterHeight * e.filterWidth), \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \";\\n            wR += \").concat(e.dilationHeight, \") {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \").concat(n, \";\\n            wC+= \").concat(e.dilationWidth, \") {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n\\n            dotProd += dyValue * avgMultiplier;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass rI {\n  constructor(e) {\n    this.variableNames = [\"dy\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterDepth,\n        n = e.effectiveFilterHeight,\n        s = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n      const float avgMultiplier = float(\").concat(1 / (e.filterDepth * e.filterHeight * e.filterWidth), \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(t, \";\\n            wD += \").concat(e.dilationDepth, \") {\\n          float dyD = float(dyDCorner + wD) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyD < 0.0 || dyD >= \").concat(e.outDepth, \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \").concat(n, \";\\n              wR += \").concat(e.dilationHeight, \") {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \").concat(s, \";\\n                wC += \").concat(e.dilationWidth, \") {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n\\n              dotProd += dyValue * avgMultiplier;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar aI = {\n  kernelName: \"AvgPool3DGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a,\n        {\n      filterSize: o,\n      strides: l,\n      pad: u,\n      dimRoundingMode: c\n    } = s,\n        h = ys(i.shape, o, l, [1, 1, 1], u, c),\n        d = new rI(h);\n    return n.runWebGLProgram(d, [r], i.dtype);\n  }\n},\n    iI = {\n  kernelName: \"AvgPoolGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a;\n    ck([r, a], \"avgPoolGrad\");\n    var {\n      filterSize: o,\n      strides: l,\n      pad: u\n    } = s,\n        c = xs(i.shape, o, l, 1, u),\n        h = new sI(c);\n    return n.runWebGLProgram(h, [r], i.dtype);\n  }\n},\n    oI = {\n  kernelName: \"BatchMatMul\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      a: r,\n      b: a\n    } = t,\n        {\n      transposeA: i,\n      transposeB: o\n    } = s;\n    return Tv({\n      a: r,\n      b: a,\n      transposeA: i,\n      transposeB: o,\n      backend: n\n    });\n  }\n};\n\nclass lI {\n  constructor(e, t, n, s, r, a) {\n    this.outputShape = [], this.variableNames = [\"x\", \"mean\", \"variance\"], hr(e, t), hr(e, n);\n    var i = \"0.0\";\n    null != s && (hr(e, s), this.variableNames.push(\"offset\"), i = \"getOffsetAtOutCoords()\");\n    var o = \"1.0\";\n    null != r && (hr(e, r), this.variableNames.push(\"scale\"), o = \"getScaleAtOutCoords()\"), this.outputShape = e, this.userCode = \"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \".concat(i, \";\\n        float scale = \").concat(o, \";\\n        float inv = scale * inversesqrt(variance + float(\").concat(a, \"));\\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\\n      }\\n    \");\n  }\n\n}\n\nclass uI {\n  constructor(e, t, n, s, r, a) {\n    this.packedInputs = !0, this.packedOutput = !0, this.variableNames = [\"x\", \"mean\", \"variance\"], hr(e, t), hr(e, n);\n    var i = \"vec4(0.0)\";\n    null != s && (hr(e, s), this.variableNames.push(\"offset\"), i = \"getOffsetAtOutCoords()\");\n    var o = \"vec4(1.0)\";\n    null != r && (hr(e, r), this.variableNames.push(\"scale\"), o = \"getScaleAtOutCoords()\"), this.outputShape = e, this.userCode = \"\\n      void main() {\\n        vec4 offset = \".concat(i, \";\\n        vec4 scale = \").concat(o, \";\\n\\n        vec4 x = getXAtOutCoords();\\n        vec4 mean = getMeanAtOutCoords();\\n        vec4 variance = getVarianceAtOutCoords();\\n\\n        vec4 inv = scale * inversesqrt(variance + vec4(\").concat(a, \"));\\n\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \");\n  }\n\n}\n\nvar cI = {\n  kernelName: \"FusedBatchNorm\",\n  backendName: \"webgl\",\n  kernelFunc: _ref25 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref25;\n    var {\n      x: s,\n      mean: r,\n      variance: a,\n      offset: i,\n      scale: o\n    } = e;\n    l(r.shape.length === a.shape.length, () => \"Batch normalization gradient requires mean and variance to have equal ranks.\"), l(null == i || r.shape.length === i.shape.length, () => \"Batch normalization gradient requires mean and offset to have equal ranks.\"), l(null == o || r.shape.length === o.shape.length, () => \"Batch normalization gradient requires mean and scale to have equal ranks.\");\n    var {\n      varianceEpsilon: u\n    } = n;\n    null == u && (u = .001);\n    var c = [s, r, a];\n    var h = null;\n    null != i && (h = i.shape, c.push(i));\n    var d = null;\n    null != o && (d = o.shape, c.push(o));\n    var p = G().getBool(\"WEBGL_PACK_NORMALIZATION\") ? new uI(s.shape, r.shape, a.shape, h, d, u) : new lI(s.shape, r.shape, a.shape, h, d, u);\n    return t.runWebGLProgram(p, c, c[0].dtype);\n  }\n};\n\nclass hI {\n  constructor(e) {\n    this.variableNames = [\"source\"], this.outputShape = e, this.rank = e.length;\n    var t = Ck(this.rank);\n    this.customUniforms = [{\n      name: \"start\",\n      arrayIndex: this.rank,\n      type: \"int\"\n    }];\n\n    var n = function (e) {\n      if (1 === e) return \"sourceLoc\";\n      if (e <= 6) return dI.slice(0, e).map(e => \"sourceLoc.\" + e).join(\",\");\n      throw Error(\"Slicing for rank \".concat(e, \" is not yet supported\"));\n    }(this.rank);\n\n    var s;\n    s = \"\\n        \".concat(t, \" sourceLoc;\\n        \").concat(t, \" coords = getOutputCoords();\\n        \").concat(e.map((e, t) => \"sourceLoc.\".concat(dI[t], \" = start[\").concat(t, \"] + coords.\").concat(dI[t], \";\")).join(\"\\n\"), \"\\n      \"), this.userCode = \"\\n      void main() {\\n        \".concat(s, \"\\n        setOutput(getSource(\").concat(n, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar dI = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"];\n\nclass pI {\n  constructor(e) {\n    this.variableNames = [\"source\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.rank = e.length, this.customUniforms = [{\n      name: \"start\",\n      arrayIndex: this.rank,\n      type: \"int\"\n    }];\n    var t = Ck(this.rank),\n        n = Ow(\"coords\", this.rank),\n        s = Ow(\"sourceLoc\", this.rank),\n        r = 1 === this.rank ? \"sourceLoc\" : \"vec2(\".concat(s.slice(-2).join(), \")\"),\n        a = \"getChannel(getSource(\".concat(s.join(), \"), \").concat(r, \")\"),\n        i = \"\\n      result.x = \".concat(a, \";\\n      if (++\").concat(n[this.rank - 1], \" < \").concat(e[this.rank - 1], \") {\\n        ++\").concat(s[this.rank - 1], \";\\n        result.y = \").concat(a, \";\\n        --\").concat(s[this.rank - 1], \";\\n      }\\n    \"),\n        o = 1 === this.rank ? \"\" : \"\\n      --\".concat(n[this.rank - 1], \";\\n      if (++\").concat(n[this.rank - 2], \" < \").concat(e[this.rank - 2], \") {\\n        ++\").concat(s[this.rank - 2], \";\\n        result.z = \").concat(a, \";\\n        if (++\").concat(n[this.rank - 1], \" < \").concat(e[this.rank - 1], \") {\\n          ++\").concat(s[this.rank - 1], \";\\n          result.w = \").concat(a, \";\\n        }\\n      }\\n    \"),\n        l = this.rank <= 4 ? \"sourceLoc = coords +\\n            \".concat(t, \"(\").concat(e.map((e, t) => \"start[\".concat(t, \"]\")).join(), \");\") : e.map((e, t) => \"\".concat(s[t], \" = \").concat(n[t], \" + start[\").concat(t, \"];\")).join(\"\\n\");\n    this.userCode = \"\\n      void main() {\\n        \".concat(t, \" coords = getOutputCoords();\\n        \").concat(t, \" sourceLoc;\\n        \").concat(l, \"\\n        vec4 result = vec4(0.);\\n        \").concat(i, \"\\n        \").concat(o, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction fI(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    begin: a,\n    size: i\n  } = s,\n      [o, l] = Vn(r, a, i);\n  if (En(r, o, l), 0 === d(l)) return n.makeTensorInfo(l, r.dtype, []);\n\n  if (n.shouldExecuteOnCPU([r]) || \"string\" === r.dtype) {\n    var _e464 = n.texData.get(r.dataId),\n        _t391 = kw(_e464.values, o, l, r.shape, r.dtype);\n\n    return n.makeTensorInfo(l, r.dtype, _t391);\n  }\n\n  var {\n    isPacked: u\n  } = n.texData.get(r.dataId),\n      c = Wn(r.shape, o, l);\n\n  if (u || !c) {\n    var _e465 = G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new pI(l) : new hI(l);\n\n    return n.runWebGLProgram(_e465, [r], r.dtype, [o]);\n  }\n\n  return n.uploadToGPU(r.dataId), function (e, t, n, s) {\n    var r = s.texData.get(e.dataId),\n        a = s.makeTensorInfo(n, e.dtype),\n        i = s.texData.get(a.dataId);\n    Object.assign(i, r), i.refCount = 1, i.shape = n, i.dtype = e.dtype;\n    var o = Un(t, A(e.shape));\n    r.slice && (o += r.slice.flatOffset), i.slice = {\n      flatOffset: o,\n      origDataId: r.slice && r.slice.origDataId || e.dataId\n    };\n    var l = s.dataRefCount.get(i.slice.origDataId) || 1;\n    return s.dataRefCount.set(i.slice.origDataId, l + 1), a;\n  }(r, o, l, n);\n}\n\nvar gI = {\n  kernelName: \"Slice\",\n  backendName: \"webgl\",\n  kernelFunc: fI\n},\n    mI = {\n  kernelName: \"BatchToSpaceND\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      crops: i\n    } = s;\n    l(r.shape.length <= 4, () => \"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet\");\n\n    var o = a.reduce((e, t) => e * t),\n        u = Fo(r.shape, a, o),\n        c = Do(u.length, a.length),\n        h = _o(r.shape, a, o),\n        d = Oo(i, a.length),\n        p = Mo(h, i, a.length),\n        f = [],\n        g = mv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: u\n      }\n    }),\n        m = Nv({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }),\n        b = mv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: h\n      }\n    }),\n        x = fI({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        begin: d,\n        size: p\n      }\n    });\n\n    return f.push(g), f.push(m), f.push(b), f.forEach(e => n.disposeIntermediateTensorInfo(e)), x;\n  }\n},\n    bI = {\n  kernelName: \"Bincount\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i\n    } = s,\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        u = jk(o, l, a.dtype, a.shape, i);\n    return n.makeTensorInfo([i], a.dtype, u);\n  }\n},\n    xI = uv({\n  opSnippet: \"return float(a != b);\",\n  cpuKernelImpl: fw,\n  dtype: \"bool\"\n}),\n    yI = {\n  kernelName: \"NotEqual\",\n  backendName: \"webgl\",\n  kernelFunc: xI\n};\n\nfunction kI(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t;\n  return Zw({\n    inputs: {\n      x: n.texData.get(s.dataId).complexTensorInfos.real\n    },\n    backend: n\n  });\n}\n\nvar wI = {\n  kernelName: \"Real\",\n  backendName: \"webgl\",\n  kernelFunc: kI\n},\n    vI = {\n  kernelName: \"Cast\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s,\n      attrs: r\n    } = t,\n        {\n      x: a\n    } = n,\n        {\n      dtype: i\n    } = r;\n\n    if (\"complex64\" === i) {\n      if (\"complex64\" === a.dtype) return Zw({\n        inputs: {\n          x: a\n        },\n        backend: s\n      });\n\n      var _t392 = ca(a.shape),\n          _n283 = e({\n        inputs: {\n          x: a\n        },\n        backend: s,\n        attrs: {\n          dtype: \"float32\"\n        }\n      }),\n          _r164 = ev({\n        inputs: {\n          real: _n283,\n          imag: _t392\n        },\n        backend: s\n      });\n\n      return _t392.dispose(), s.disposeIntermediateTensorInfo(_n283), _r164;\n    }\n\n    if (\"complex64\" === a.dtype) {\n      var _t393 = kI({\n        inputs: {\n          input: a\n        },\n        backend: s\n      }),\n          _n284 = e({\n        inputs: {\n          x: _t393\n        },\n        backend: s,\n        attrs: {\n          dtype: i\n        }\n      });\n\n      return s.disposeIntermediateTensorInfo(_t393), _n284;\n    }\n\n    if (!I(a.dtype, i)) {\n      var _e466 = Zw({\n        inputs: {\n          x: a\n        },\n        backend: s\n      });\n\n      return {\n        dataId: _e466.dataId,\n        shape: _e466.shape,\n        dtype: i\n      };\n    }\n\n    if (\"int32\" === i) return function (e, t) {\n      var n = new Uw(e.shape, \"return float(int(x));\"),\n          s = t.runWebGLProgram(n, [e], \"int32\");\n      return {\n        dataId: s.dataId,\n        shape: s.shape,\n        dtype: s.dtype\n      };\n    }(a, s);\n\n    if (\"bool\" === i) {\n      var _e467 = s.makeTensorInfo([], \"bool\", w(\"bool\", 1)),\n          _t394 = xI({\n        inputs: {\n          a,\n          b: _e467\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_e467), _t394;\n    }\n\n    throw new Error(\"Error in Cast: failed to cast \".concat(a.dtype, \" to \").concat(i));\n  }\n},\n    II = \"return ceil(x);\",\n    $I = {\n  kernelName: \"Ceil\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: II,\n    packedOpSnippet: II,\n    cpuKernelImpl: Xk\n  })\n};\n\nclass SI {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.customUniforms = [{\n      name: \"minVal\",\n      type: \"float\"\n    }, {\n      name: \"maxVal\",\n      type: \"float\"\n    }], this.outputShape = e, this.userCode = \"\\n\\n      void main() {\\n        float value = getAAtOutCoords();\\n        if (isnan(value)) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, minVal, maxVal));\\n      }\\n    \";\n  }\n\n}\n\nclass NI {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"minVal\",\n      type: \"float\"\n    }, {\n      name: \"maxVal\",\n      type: \"float\"\n    }], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        vec4 value = getAAtOutCoords();\\n\\n        if (any(isnan(value))) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\\n      }\\n    \";\n  }\n\n}\n\nvar CI = {\n  kernelName: \"ClipByValue\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      clipValueMin: a,\n      clipValueMax: i\n    } = s;\n    var o;\n    return o = G().getBool(\"WEBGL_PACK_CLIP\") ? new NI(r.shape) : new SI(r.shape), n.runWebGLProgram(o, [r], r.dtype, [[a], [i]]);\n  }\n};\n\nclass TI {\n  constructor(e) {\n    this.variableNames = [\"real\", \"imag\"], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        float re = abs(getRealAtOutCoords());\\n        float im = abs(getImagAtOutCoords());\\n        float mx = max(re, im);\\n\\n        // sadly the length function in glsl is not underflow-safe\\n        // (at least not on Intel GPUs). So the safe solution is\\n        // to ensure underflow-safety in all cases.\\n        setOutput(\\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\\n        );\\n      }\\n    \";\n  }\n\n}\n\nfunction EI(e, t) {\n  return {\n    dataId: t.dataId,\n    dtype: t.dtype,\n    shape: e.shape\n  };\n}\n\nvar RI = {\n  kernelName: \"ComplexAbs\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = n.texData.get(s.dataId),\n        a = new TI(s.shape),\n        i = [EI(s, r.complexTensorInfos.real), EI(s, r.complexTensorInfos.imag)];\n    return n.runWebGLProgram(a, i, i[0].dtype);\n  }\n};\n\nclass AI {\n  constructor(e) {\n    this.outputShape = [], this.outputShape = Eo(e, 1), this.variableNames = e.map((e, t) => \"T\".concat(t));\n    var t = new Array(e.length - 1);\n    t[0] = e[0][1];\n\n    for (var _n285 = 1; _n285 < t.length; _n285++) {\n      t[_n285] = t[_n285 - 1] + e[_n285][1];\n    }\n\n    var n = [\"if (yC < \".concat(t[0], \") setOutput(getT0(yR, yC));\")];\n\n    for (var _e468 = 1; _e468 < t.length; _e468++) {\n      n.push(\"else if (yC < \".concat(t[_e468], \") setOutput(getT\").concat(_e468, \"(yR, yC-\").concat(t[_e468 - 1], \"));\"));\n    }\n\n    n.push(\"else setOutput(getT\".concat(t.length, \"(yR, yC-\").concat(t[t.length - 1], \"));\")), this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int yR = coords.x;\\n        int yC = coords.y;\\n\\n        \".concat(n.join(\"\\n        \"), \"\\n      }\\n    \");\n  }\n\n}\n\nclass FI {\n  constructor(e, t) {\n    this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [], this.outputShape = Eo(e, t);\n    var n = this.outputShape,\n        s = n.length,\n        r = Ck(s),\n        a = Ow(\"coords\", s),\n        i = [\"x\", \"y\", \"z\", \"w\", \"u\", \"v\"].slice(0, s);\n    this.variableNames = e.map((e, t) => \"T\".concat(t));\n    var o = new Array(e.length - 1);\n    o[0] = e[0][t];\n\n    for (var _n286 = 1; _n286 < o.length; _n286++) {\n      o[_n286] = o[_n286 - 1] + e[_n286][t];\n    }\n\n    var l = i[t],\n        u = i.slice(-2),\n        c = i.join();\n    var h = \"if (\".concat(l, \" < \").concat(o[0], \") {\\n        return getChannel(\\n            getT0(\").concat(c, \"), vec2(\").concat(u.join(), \"));\\n        }\");\n\n    for (var _e469 = 1; _e469 < o.length; _e469++) {\n      var _t395 = o[_e469 - 1];\n      h += \"\\n        if (\".concat(l, \" < \").concat(o[_e469], \"  && \").concat(l, \" >= \").concat(o[_e469 - 1], \") {\\n          return getChannel(\\n            getT\").concat(_e469, \"(\").concat(DI(i, l, _t395), \"),\\n            vec2(\").concat(DI(u, l, _t395), \"));\\n        }\");\n    }\n\n    var d = o[o.length - 1];\n    h += \"\\n        return getChannel(\\n          getT\".concat(o.length, \"(\").concat(DI(i, l, d), \"),\\n          vec2(\").concat(DI(u, l, d), \"));\"), this.userCode = \"\\n      float getValue(\".concat(i.map(e => \"int \" + e), \") {\\n        \").concat(h, \"\\n      }\\n\\n      void main() {\\n        \").concat(r, \" coords = getOutputCoords();\\n        vec4 result = vec4(getValue(\").concat(a, \"), 0., 0., 0.);\\n\\n        \").concat(a[s - 1], \" = \").concat(a[s - 1], \" + 1;\\n        if (\").concat(a[s - 1], \" < \").concat(n[s - 1], \") {\\n          result.g = getValue(\").concat(a, \");\\n        }\\n\\n        \").concat(a[s - 2], \" = \").concat(a[s - 2], \" + 1;\\n        if (\").concat(a[s - 2], \" < \").concat(n[s - 2], \") {\\n          result.a = getValue(\").concat(a, \");\\n        }\\n\\n        \").concat(a[s - 1], \" = \").concat(a[s - 1], \" - 1;\\n        if (\").concat(a[s - 2], \" < \").concat(n[s - 2], \" &&\\n            \").concat(a[s - 1], \" < \").concat(n[s - 1], \") {\\n          result.b = getValue(\").concat(a, \");\\n        }\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nfunction DI(e, t, n) {\n  var s = e.indexOf(t);\n  return e.map((e, t) => t === s ? \"\".concat(e, \" - \").concat(n) : e).join();\n}\n\nfunction _I(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    input: s\n  } = t;\n  return Zw({\n    inputs: {\n      x: n.texData.get(s.dataId).complexTensorInfos.imag\n    },\n    backend: n\n  });\n}\n\nvar OI = {\n  kernelName: \"Imag\",\n  backendName: \"webgl\",\n  kernelFunc: _I\n};\n\nfunction MI(e, t, n) {\n  var s = e[0].dtype;\n\n  if (\"complex64\" === s) {\n    var _s224 = e.map(e => kI({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _r165 = e.map(e => _I({\n      inputs: {\n        input: e\n      },\n      backend: n\n    })),\n        _a135 = MI(_s224, t, n),\n        _i95 = MI(_r165, t, n),\n        _o72 = ev({\n      inputs: {\n        real: _a135,\n        imag: _i95\n      },\n      backend: n\n    });\n\n    return _s224.forEach(e => n.disposeIntermediateTensorInfo(e)), _r165.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_a135), n.disposeIntermediateTensorInfo(_i95), _o72;\n  }\n\n  var r = n.shouldExecuteOnCPU(e);\n\n  if (\"string\" === s && (r = !0), r) {\n    var _r166 = e.map(e => {\n      var s = d(e.shape.slice(t));\n      return mv({\n        inputs: {\n          x: e\n        },\n        backend: n,\n        attrs: {\n          shape: [-1, s]\n        }\n      });\n    }),\n        _a136 = _r166.map(e => ({\n      vals: n.readSync(e.dataId),\n      shape: e.shape\n    })),\n        _i96 = Eo(_r166.map(e => e.shape), 1),\n        _o73 = Yk(_a136, _i96, s, 1 === _r166[0].shape[0]),\n        _l51 = Eo(e.map(e => e.shape), t),\n        _u40 = n.makeTensorInfo(_l51, s, _o73);\n\n    return _r166.forEach(e => n.disposeIntermediateTensorInfo(e)), _u40;\n  }\n\n  if (e.length > G().getNumber(\"WEBGL_MAX_TEXTURES_IN_SHADER\")) {\n    var _s225 = Math.floor(e.length / 2),\n        _r167 = MI(e.slice(0, _s225), t, n),\n        _a137 = MI(e.slice(_s225), t, n),\n        _i97 = MI([_r167, _a137], t, n);\n\n    return n.disposeIntermediateTensorInfo(_r167), n.disposeIntermediateTensorInfo(_a137), _i97;\n  }\n\n  if (G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") && e[0].shape.length > 1) {\n    var _r168 = new FI(e.map(e => e.shape), t);\n\n    return n.runWebGLProgram(_r168, e, s);\n  }\n\n  var {\n    tensors2D: a,\n    outShape: i\n  } = function (e, t, n) {\n    var s = Eo(e.map(e => e.shape), t);\n    return {\n      tensors2D: e.map(e => mv({\n        inputs: {\n          x: e\n        },\n        attrs: {\n          shape: [-1, d(e.shape.slice(t))]\n        },\n        backend: n\n      })),\n      outShape: s\n    };\n  }(e, t, n),\n      o = new AI(a.map(e => e.shape)),\n      l = n.runWebGLProgram(o, a, s);\n\n  a.forEach(e => n.disposeIntermediateTensorInfo(e));\n  var u = mv({\n    inputs: {\n      x: l\n    },\n    attrs: {\n      shape: i\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(l), u;\n}\n\nfunction LI(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    axis: r\n  } = s,\n      a = y(r, t[0].shape)[0],\n      i = Eo(t.map(e => e.shape), a);\n  if (0 === d(i)) return n.makeTensorInfo(i, t[0].dtype, []);\n  var o = t.filter(e => d(e.shape) > 0);\n  return 1 === o.length ? Zw({\n    inputs: {\n      x: o[0]\n    },\n    backend: n\n  }) : (To(o.map(e => e.shape), a), MI(o, a, n));\n}\n\nvar zI = {\n  kernelName: \"Concat\",\n  backendName: \"webgl\",\n  kernelFunc: LI\n};\n\nclass BI {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var a = e.padInfo.top,\n        i = e.padInfo.left,\n        o = e.strideHeight,\n        l = e.strideWidth,\n        u = e.dilationHeight,\n        c = e.dilationWidth,\n        h = e.filterHeight,\n        d = e.filterWidth,\n        p = 4 * Math.floor(e.inChannels / 4),\n        f = e.inChannels % 4,\n        g = \"channelsLast\" === e.dataFormat,\n        m = g ? 1 : 2,\n        b = g ? 2 : 3,\n        x = g ? 3 : 1;\n    var y = \"\",\n        k = \"\";\n    n && (y = s ? \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"float activation(float a) {\\n          float b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"\\n          float activation(float x) {\\n            \".concat(n, \"\\n          }\\n        \"), k = \"result = activation(result);\");\n    var w = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(y, \"\\n\\n      const ivec2 strides = ivec2(\").concat(o, \", \").concat(l, \");\\n      const ivec2 pads = ivec2(\").concat(a, \", \").concat(i, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d2 = coords[\").concat(x, \"];\\n\\n        ivec2 xRCCorner =\\n            ivec2(coords[\").concat(m, \"], coords[\").concat(b, \"]) * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(h, \"; wR++) {\\n          int xR = xRCorner + wR * \").concat(u, \";\\n\\n          if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(d, \"; wC++) {\\n            int xC = xCCorner + wC * \").concat(c, \";\\n\\n            if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n              continue;\\n            }\\n\\n            for (int d1 = 0; d1 < \").concat(p, \"; d1 += 4) {\\n              vec4 wValues = vec4(\\n                getW(wR, wC, d1, d2),\\n                getW(wR, wC, d1 + 1, d2),\\n                getW(wR, wC, d1 + 2, d2),\\n                getW(wR, wC, d1 + 3, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec4 xValues = vec4(\\n                  getX(batch, xR, xC, d1),\\n                  getX(batch, xR, xC, d1 + 1),\\n                  getX(batch, xR, xC, d1 + 2),\\n                  getX(batch, xR, xC, d1 + 3)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec4 xValues = vec4(\\n                  getX(batch, d1, xR, xC),\\n                  getX(batch, d1 + 1, xR, xC),\\n                  getX(batch, d1 + 2, xR, xC),\\n                  getX(batch, d1 + 3, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n\\n            if (\").concat(1 === f, \") {\\n\\n              if (\").concat(g, \") {\\n                dotProd +=\\n                    getX(batch, xR, xC, \").concat(p, \") *\\n                    getW(wR, wC, \").concat(p, \", d2);\\n              } else {\\n                dotProd +=\\n                    getX(batch, \").concat(p, \", xR, xC) *\\n                    getW(wR, wC, \").concat(p, \", d2);\\n              }\\n\\n            } else if (\").concat(2 === f, \") {\\n              vec2 wValues = vec2(\\n                getW(wR, wC, \").concat(p, \", d2),\\n                getW(wR, wC, \").concat(p, \" + 1, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xR, xC, \").concat(p, \"),\\n                  getX(batch, xR, xC, \").concat(p, \" + 1)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec2 xValues = vec2(\\n                  getX(batch, \").concat(p, \", xR, xC),\\n                  getX(batch, \").concat(p, \" + 1, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            } else if (\").concat(3 === f, \") {\\n              vec3 wValues = vec3(\\n                getW(wR, wC, \").concat(p, \", d2),\\n                getW(wR, wC, \").concat(p, \" + 1, d2),\\n                getW(wR, wC, \").concat(p, \" + 2, d2)\\n              );\\n\\n              if (\").concat(g, \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xR, xC, \").concat(p, \"),\\n                  getX(batch, xR, xC, \").concat(p, \" + 1),\\n                  getX(batch, xR, xC, \").concat(p, \" + 2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec3 xValues = vec3(\\n                  getX(batch, \").concat(p, \", xR, xC),\\n                  getX(batch, \").concat(p, \" + 1, xR, xC),\\n                  getX(batch, \").concat(p, \" + 2, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            }\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \").concat(w, \"\\n        \").concat(k, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass PI {\n  constructor(e) {\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var t = e.padInfo.front,\n        n = e.padInfo.top,\n        s = e.padInfo.left,\n        r = e.strideDepth,\n        a = e.strideHeight,\n        i = e.strideWidth,\n        o = e.dilationDepth,\n        l = e.dilationHeight,\n        u = e.dilationWidth,\n        c = e.filterDepth,\n        h = e.filterHeight,\n        d = e.filterWidth,\n        p = 4 * Math.floor(e.inChannels / 4),\n        f = e.inChannels % 4;\n    this.userCode = \"\\n      const ivec3 strides = ivec3(\".concat(r, \", \").concat(a, \", \").concat(i, \");\\n      const ivec3 pads = ivec3(\").concat(t, \", \").concat(n, \", \").concat(s, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d2 = coords.u;\\n\\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xFCorner = xFRCCorner.x;\\n        int xRCorner = xFRCCorner.y;\\n        int xCCorner = xFRCCorner.z;\\n\\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\\n        // values in that axis.\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \").concat(c, \"; wF++) {\\n          int xF = xFCorner + wF * \").concat(o, \";\\n\\n          if (xF < 0 || xF >= \").concat(e.inDepth, \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \").concat(h, \"; wR++) {\\n            int xR = xRCorner + wR * \").concat(l, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \").concat(d, \"; wC++) {\\n              int xC = xCCorner + wC * \").concat(u, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              for (int d1 = 0; d1 < \").concat(p, \"; d1 += 4) {\\n                vec4 xValues = vec4(\\n                  getX(batch, xF, xR, xC, d1),\\n                  getX(batch, xF, xR, xC, d1 + 1),\\n                  getX(batch, xF, xR, xC, d1 + 2),\\n                  getX(batch, xF, xR, xC, d1 + 3)\\n                );\\n                vec4 wValues = vec4(\\n                  getW(wF, wR, wC, d1, d2),\\n                  getW(wF, wR, wC, d1 + 1, d2),\\n                  getW(wF, wR, wC, d1 + 2, d2),\\n                  getW(wF, wR, wC, d1 + 3, d2)\\n                );\\n\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n              if (\").concat(1 === f, \") {\\n                dotProd +=\\n                  getX(batch, xF, xR, xC, \").concat(p, \") *\\n                  getW(wF, wR, wC, \").concat(p, \", d2);\\n              } else if (\").concat(2 === f, \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xF, xR, xC, \").concat(p, \"),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 1)\\n                );\\n                vec2 wValues = vec2(\\n                  getW(wF, wR, wC, \").concat(p, \", d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 1, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else if (\").concat(3 === f, \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xF, xR, xC, \").concat(p, \"),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 1),\\n                  getX(batch, xF, xR, xC, \").concat(p, \" + 2)\\n                );\\n                vec3 wValues = vec3(\\n                  getW(wF, wR, wC, \").concat(p, \", d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 1, d2),\\n                  getW(wF, wR, wC, \").concat(p, \" + 2, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass WI {\n  constructor(e, t) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"inputShape\",\n      type: \"ivec3\"\n    }, {\n      name: \"pad\",\n      type: \"ivec2\"\n    }, {\n      name: \"stride\",\n      type: \"ivec2\"\n    }, {\n      name: \"dilation\",\n      type: \"ivec2\"\n    }, {\n      name: \"inChannels\",\n      type: \"int\"\n    }, {\n      name: \"itemsPerBlockRow\",\n      type: \"int\"\n    }, {\n      name: \"outWidth\",\n      type: \"int\"\n    }], this.outputShape = e, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var {\n      dataFormat: n\n    } = t,\n        s = dk(),\n        r = \"channelsLast\" === n,\n        a = r ? 0 : 1,\n        i = r ? 1 : 2,\n        o = this.enableShapeUniforms ? \"if(blockIndex < outShape[1] && pos < outShape[0]) {\" : \"if(blockIndex < \".concat(e[1], \" && pos < \").concat(e[0], \") {\");\n    var l = \"\";\n\n    for (var _e470 = 0; _e470 <= 1; _e470++) {\n      for (var _t396 = 0; _t396 <= 1; _t396++) {\n        l += \"\\n          blockIndex = rc.y + \".concat(_t396, \";\\n          pos = rc.x + \").concat(_e470, \";\\n\\n          \").concat(o, \"\\n            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];\\n            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);\\n\\n            if(d0 < inputShape[\").concat(a, \"] && d0 >= 0) {\\n              // Use custom imod instead mod. On Intel GPU, mod may generate\\n              // unexpected value.\\n              // https://github.com/tensorflow/tfjs/issues/5447\\n              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];\\n              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /\\n                  inChannels);\\n\\n              if(d1 < inputShape[\").concat(i, \"] && d1 >= 0) {\\n\\n                ch = imod(pos, inChannels);\\n\\n                if (\").concat(r, \") {\\n                  innerDims = vec2(d1, ch);\\n                  result[\").concat(2 * _e470 + _t396, \"] = getChannel(\\n                    getA(d0, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                } else {\\n                  innerDims = vec2(d0, d1);\\n                  result[\").concat(2 * _e470 + _t396, \"] = getChannel(\\n                    getA(ch, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                }\\n              }\\n            }\\n          }\\n        \");\n      }\n    }\n\n    this.userCode = \"\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0);\\n\\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\\n        vec2 innerDims;\\n\\n        \".concat(l, \"\\n\\n        \").concat(s.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nfunction UI(_ref26) {\n  var {\n    x: e,\n    filter: t,\n    convInfo: n,\n    backend: s,\n    bias: r = null,\n    preluActivationWeights: a = null,\n    leakyreluAlpha: i = 0,\n    activation: o = null\n  } = _ref26;\n  var u = e.shape,\n      c = s.texData.get(e.dataId),\n      h = \"channelsLast\" === n.dataFormat;\n  var d;\n  var f = [];\n\n  if ((1 != u[0] * u[1] * u[2] && 1 !== n.outChannels || !(n.inChannels > 1e3)) && c.isPacked && h && null != c.texture && u[2] % 2 != 0 && p(c.shape.slice(-3), u.slice(-3))) {\n    var _h20 = {\n      dataId: e.dataId,\n      shape: [1, u[0] * u[1] * (u[2] + 1), n.inChannels],\n      dtype: e.dtype\n    },\n        _p17 = c.shape;\n    c.shape = c.shape.slice(), c.shape[c.shape.length - 2]++, l(rk(c.shape, _h20.shape), () => \"packed reshape \".concat(c.shape, \" to \").concat(_h20.shape, \" isn't free\"));\n\n    var _g21 = mv({\n      inputs: {\n        x: t\n      },\n      backend: s,\n      attrs: {\n        shape: [1, n.inChannels, n.outChannels]\n      }\n    });\n\n    f.push(_g21);\n\n    var _m14 = Tv({\n      a: _h20,\n      b: _g21,\n      backend: s,\n      transposeA: !1,\n      transposeB: !1,\n      bias: r,\n      activation: o,\n      preluActivationWeights: a,\n      leakyreluAlpha: i\n    }),\n        _b15 = s.texData.get(_m14.dataId);\n\n    l(_b15.isPacked, () => \"batchMatMul result is expected to be packed\"), c.shape = _p17, _b15.shape = n.outShape, d = Zw({\n      inputs: {\n        x: _m14\n      },\n      backend: s\n    }), d.shape = n.outShape, f.push(_m14);\n  } else {\n    var _l52 = mv({\n      inputs: {\n        x: e\n      },\n      backend: s,\n      attrs: {\n        shape: [1, h ? u[0] * u[1] * u[2] : u[0] * u[2] * u[3], n.inChannels]\n      }\n    }),\n        _c34 = mv({\n      inputs: {\n        x: t\n      },\n      backend: s,\n      attrs: {\n        shape: [1, n.inChannels, n.outChannels]\n      }\n    }),\n        _p18 = Tv({\n      a: _l52,\n      b: _c34,\n      transposeA: !1,\n      transposeB: !1,\n      backend: s,\n      bias: r,\n      activation: o,\n      preluActivationWeights: a,\n      leakyreluAlpha: i\n    });\n\n    d = mv({\n      inputs: {\n        x: _p18\n      },\n      backend: s,\n      attrs: {\n        shape: n.outShape\n      }\n    }), f.push(_l52), f.push(_c34), f.push(_p18);\n  }\n\n  for (var _e471 of f) {\n    s.disposeIntermediateTensorInfo(_e471);\n  }\n\n  return d;\n}\n\nfunction VI(_ref27) {\n  var {\n    x: e,\n    filter: t,\n    convInfo: n,\n    backend: s,\n    bias: r = null,\n    preluActivationWeights: a = null,\n    leakyreluAlpha: i = 0,\n    activation: o = null\n  } = _ref27;\n  var {\n    filterWidth: l,\n    filterHeight: u,\n    inChannels: c,\n    outWidth: h,\n    outHeight: p,\n    dataFormat: f\n  } = n,\n      g = \"channelsLast\" === f,\n      m = l * u * c,\n      b = p * h,\n      x = [m, b],\n      y = [],\n      k = mv({\n    inputs: {\n      x: e\n    },\n    backend: s,\n    attrs: {\n      shape: e.shape.slice(1)\n    }\n  }),\n      w = mv({\n    inputs: {\n      x: t\n    },\n    backend: s,\n    attrs: {\n      shape: [1, m, d(t.shape) / m]\n    }\n  });\n  y.push(k), y.push(w);\n  var v = new WI(x, n),\n      I = s.runWebGLProgram(v, [k], \"float32\", [k.shape, [n.padInfo.top, n.padInfo.left], [n.strideHeight, n.strideWidth], [n.dilationHeight, n.dilationWidth], [n.inChannels], [n.filterWidth * n.inChannels], [n.outWidth]]),\n      $ = mv({\n    inputs: {\n      x: I\n    },\n    backend: s,\n    attrs: {\n      shape: [1, x[0], x[1]]\n    }\n  });\n  y.push(I), y.push($);\n  var S = null != r,\n      N = null != a,\n      C = \"leakyrelu\" === o,\n      T = o ? cv(o, !0) : null,\n      E = new hv($.shape, w.shape, [1, b, n.outChannels], !0, !1, S, T, N, C),\n      R = [$, w];\n\n  if (r && R.push(r), N && R.push(a), C) {\n    var _e472 = s.makeTensorInfo([], \"float32\", Ue(i, \"float32\"));\n\n    R.push(_e472), y.push(_e472);\n  }\n\n  var A = s.runWebGLProgram(E, R, \"float32\"),\n      F = mv({\n    inputs: {\n      x: A\n    },\n    backend: s,\n    attrs: {\n      shape: g ? [1, p, h, n.outChannels] : [1, n.outChannels, p, h]\n    }\n  });\n  y.push(A);\n\n  for (var _e473 of y) {\n    s.disposeIntermediateTensorInfo(_e473);\n  }\n\n  return F;\n}\n\nvar GI = {\n  kernelName: \"Conv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dilations: u,\n      dimRoundingMode: c\n    } = s,\n        h = Es(l),\n        d = ks(r.shape, a.shape, i, u, o, c, !1, h);\n    var p;\n    if (1 !== d.filterHeight || 1 !== d.filterWidth || 1 !== d.dilationHeight || 1 !== d.dilationWidth || 1 !== d.strideHeight || 1 !== d.strideWidth || \"SAME\" !== d.padInfo.type && \"VALID\" !== d.padInfo.type) {\n      if (G().getBool(\"WEBGL_CONV_IM2COL\") && 1 === r.shape[0]) p = VI({\n        x: r,\n        filter: a,\n        convInfo: d,\n        backend: n\n      });else {\n        var _e474 = new BI(d);\n\n        p = n.runWebGLProgram(_e474, [r, a], \"float32\");\n      }\n    } else p = UI({\n      x: r,\n      filter: a,\n      convInfo: d,\n      backend: n\n    });\n    var f = mv({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        shape: d.outShape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), f;\n  }\n};\n\nclass HI {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int d2 = coords.w;\\n\\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \".concat(e.batchSize, \"; b++) {\\n          for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n            int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n              int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              if (\").concat(\"channelsLast\" === e.dataFormat, \") {\\n                float dyValue = getDy(b, yR, yC, d2);\\n                float xValue = getX(b, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              } else {\\n                float dyValue = getDy(b, d2, yR, yC);\\n                float xValue = getX(b, d1, xR, xC);\\n                dotProd += (xValue * dyValue);\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass qI {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterHeight,\n        n = e.filterWidth,\n        s = \"channelsLast\" === e.dataFormat;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[\").concat(s ? 3 : 1, \"];\\n\\n        ivec2 dyCorner = ivec2(coords[\").concat(s ? 1 : 2, \"], coords[\").concat(s ? 2 : 3, \"]) - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \").concat(t, \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \").concat(n, \" - 1 - wC;\\n\\n            for (int d2 = 0; d2 < \").concat(e.outChannels, \"; d2++) {\\n\\n              if (\").concat(s, \") {\\n                float xValue = getDy(batch, idyR, idyC, d2);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              } else {\\n                float xValue = getDy(batch, d2, idyR, idyC);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass jI {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int wF = coords.x;\\n        int wR = coords.y;\\n        int wC = coords.z;\\n        int d1 = coords.w;\\n        int d2 = coords.u;\\n\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \".concat(e.batchSize, \"; b++) {\\n          for (int yF = 0; yF < \").concat(e.outDepth, \"; yF++) {\\n            int xF = wF + yF * \").concat(e.strideDepth, \" - \").concat(e.padInfo.front, \";\\n\\n            if (xF < 0 || xF >= \").concat(e.inDepth, \") {\\n              continue;\\n            }\\n\\n            for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n              int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n              if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n                continue;\\n              }\\n\\n              for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n                int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n                if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                  continue;\\n                }\\n\\n                float dyValue = getDy(b, yF, yR, yC, d2);\\n                float xValue = getX(b, xF, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass KI {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterDepth,\n        n = e.filterHeight,\n        s = e.filterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.u;\\n\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyFCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \").concat(t, \"; wF++) {\\n          float dyF = float(dyFCorner + wF) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyF < 0.0 || dyF >= \").concat(e.outDepth, \".0 || fract(dyF) > 0.0) {\\n            continue;\\n          }\\n          int idyF = int(dyF);\\n\\n          int wFPerm = \").concat(t, \" - 1 - wF;\\n\\n          for (int wR = 0; wR < \").concat(n, \"; wR++) {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n              fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            int wRPerm = \").concat(n, \" - 1 - wR;\\n\\n            for (int wC = 0; wC < \").concat(s, \"; wC++) {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              int wCPerm = \").concat(s, \" - 1 - wC;\\n\\n              for (int d2 = 0; d2 < \").concat(e.outChannels, \"; d2++) {\\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar XI = {\n  kernelName: \"Conv2DBackpropFilter\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s,\n        h = Es(l),\n        d = ks(r.shape, c, i, 1, o, u, !1, h),\n        p = new HI(d);\n    return n.runWebGLProgram(p, [r, a], \"float32\");\n  }\n},\n    YI = {\n  kernelName: \"Conv2DBackpropInput\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      inputShape: i,\n      strides: o,\n      pad: l,\n      dataFormat: u,\n      dimRoundingMode: c\n    } = s,\n        h = Es(u),\n        d = ks(i, a.shape, o, 1, l, c, !1, h),\n        p = new qI(d);\n    return n.runWebGLProgram(p, [r, a], \"float32\");\n  }\n},\n    JI = {\n  kernelName: \"Conv3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s,\n        u = ws(r.shape, a.shape, i, l, o),\n        c = new PI(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    ZI = {\n  kernelName: \"Conv3DBackpropFilterV2\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      filterShape: l\n    } = s,\n        u = ws(r.shape, l, i, 1, o),\n        c = new jI(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    QI = {\n  kernelName: \"Conv3DBackpropInputV2\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      pad: i,\n      strides: o,\n      inputShape: l\n    } = s,\n        u = ws(l, a.shape, o, 1, i),\n        c = new KI(u);\n    return n.runWebGLProgram(c, [r, a], \"float32\");\n  }\n},\n    e$ = {\n  kernelName: \"Cos\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return cos(x);\\n\"\n  })\n},\n    t$ = {\n  kernelName: \"Cosh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  float e2x = exp(-x);\\n  return (e2x + 1.0 / e2x) / 2.0;\\n\"\n  })\n};\n\nclass n$ {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"Image\", \"Boxes\", \"BoxInd\"], this.outputShape = [];\n    var [a, i, o, l] = e,\n        [u] = t,\n        [c, h] = n;\n    this.outputShape = [u, c, h, l];\n    var d = \"bilinear\" === s ? 1 : 0,\n        [p, f] = [i - 1 + \".0\", o - 1 + \".0\"],\n        [g, m, b] = c > 1 ? [\"\" + (i - 1) / (c - 1), \"(y2-y1) * height_ratio\", \"y1*\".concat(p, \" + float(y)*(height_scale)\")] : [\"0.0\", \"0.0\", \"0.5 * (y1+y2) * \".concat(p)],\n        [x, y, k] = h > 1 ? [\"\" + (o - 1) / (h - 1), \"(x2-x1) * width_ratio\", \"x1*\".concat(f, \" + float(x)*(width_scale)\")] : [\"0.0\", \"0.0\", \"0.5 * (x1+x2) * \".concat(f)];\n    this.userCode = \"\\n      const float height_ratio = float(\".concat(g, \");\\n      const float width_ratio = float(\").concat(x, \");\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int y = coords[1];\\n        int x = coords[2];\\n        int d = coords[3];\\n\\n        // get box vals\\n        float y1 = getBoxes(b,0);\\n        float x1 = getBoxes(b,1);\\n        float y2 = getBoxes(b,2);\\n        float x2 = getBoxes(b,3);\\n\\n        // get image in batch index\\n        int bInd = round(getBoxInd(b));\\n        if(bInd < 0 || bInd >= \").concat(a, \") {\\n          return;\\n        }\\n\\n        float height_scale = \").concat(m, \";\\n        float width_scale = \").concat(y, \";\\n\\n        float in_y = \").concat(b, \";\\n        if( in_y < 0.0 || in_y > \").concat(p, \" ) {\\n          setOutput(float(\").concat(r, \"));\\n          return;\\n        }\\n        float in_x = \").concat(k, \";\\n        if( in_x < 0.0 || in_x > \").concat(f, \" ) {\\n          setOutput(float(\").concat(r, \"));\\n          return;\\n        }\\n\\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\\n        if(\").concat(d, \" == 1) {\\n          // Compute the four integer indices.\\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\\n\\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\\n\\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\\n\\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\\n          float newValue = top + (bottom - top) * fracCR.y;\\n          setOutput(newValue);\\n        } else {\\n          // Compute the coordinators of nearest neighbor point.\\n          ivec2 sourceNearestCR = ivec2(floor(\\n            sourceFracIndexCR + vec2(0.5,0.5)));\\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\\n          setOutput(newValue);\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar s$ = {\n  kernelName: \"CropAndResize\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      boxes: a,\n      boxInd: i\n    } = t,\n        {\n      cropSize: o,\n      method: l,\n      extrapolationValue: u\n    } = s,\n        c = new n$(r.shape, a.shape, o, l, u);\n    return n.runWebGLProgram(c, [r, a, i], \"float32\");\n  }\n};\n\nclass r$ {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.customUniforms = [{\n      name: \"index\",\n      type: \"float\"\n    }], this.outputShape = e;\n    var s = e.length,\n        r = t ? \"0.0\" : \"getX(\".concat(a$(s, \"coords\"), \")\"),\n        a = e[e.length - 1];\n    var i = \"\",\n        o = \"\";\n    t ? (i = n ? \"end != \" + (a - 1) : \"end != 0\", o = n ? \"end + 1\" : \"end - 1\") : (i = n ? \"end + pow2 < \".concat(a) : \"end >= pow2\", o = n ? \"end + pow2\" : \"end - pow2\"), this.userCode = \"\\n      void main() {\\n        \".concat(Ck(s), \" coords = getOutputCoords();\\n        int end = \").concat(i$(s, \"coords\"), \";\\n        float val = \").concat(r, \";\\n        int pow2 = int(pow(2.0, index));\\n        if (\").concat(i, \") {\\n          int idx = \").concat(o, \";\\n          \").concat(i$(s, \"coords\"), \" = idx;\\n          val += getX(\").concat(a$(s, \"coords\"), \");\\n        }\\n        setOutput(val);\\n      }\\n    \");\n  }\n\n}\n\nfunction a$(e, t) {\n  if (1 === e) return \"\".concat(t);\n  if (2 === e) return \"\".concat(t, \".x, \").concat(t, \".y\");\n  if (3 === e) return \"\".concat(t, \".x, \").concat(t, \".y, \").concat(t, \".z\");\n  if (4 === e) return \"\".concat(t, \".x, \").concat(t, \".y, \").concat(t, \".z, \").concat(t, \".w\");\n  throw Error(\"Cumulative sum for rank \".concat(e, \" is not yet supported\"));\n}\n\nfunction i$(e, t) {\n  if (1 === e) return \"\".concat(t);\n  if (2 === e) return \"\".concat(t, \".y\");\n  if (3 === e) return \"\".concat(t, \".z\");\n  if (4 === e) return \"\".concat(t, \".w\");\n  throw Error(\"Cumulative sum for rank \".concat(e, \" is not yet supported\"));\n}\n\nvar o$ = {\n  kernelName: \"Cumsum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      exclusive: i,\n      reverse: o\n    } = s,\n        l = r.shape.length,\n        u = Zr([a], l);\n    var c = r;\n    null != u && (c = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: u\n      }\n    }));\n    var h = ea(1, l)[0];\n    if (h !== l - 1) throw new Error(\"WebGL cumsum shader expects an inner-most axis=\".concat(r.shape.length - 1, \" but got axis=\").concat(a));\n    var d = c.shape[h];\n    var p = Zw({\n      inputs: {\n        x: c\n      },\n      backend: n\n    });\n\n    for (var _e475 = 0; _e475 <= Math.ceil(Math.log2(d)) - 1; _e475++) {\n      var _t397 = new r$(c.shape, !1, o),\n          _s226 = p;\n\n      p = n.runWebGLProgram(_t397, [p], p.dtype, [[_e475]]), n.disposeIntermediateTensorInfo(_s226);\n    }\n\n    if (i) {\n      var _e476 = new r$(c.shape, i, o),\n          _t398 = p;\n\n      p = n.runWebGLProgram(_e476, [p], p.dtype), n.disposeIntermediateTensorInfo(_t398);\n    }\n\n    if (null != u) {\n      var _e477 = Nv({\n        inputs: {\n          x: p\n        },\n        backend: n,\n        attrs: {\n          perm: Qr(u)\n        }\n      });\n\n      return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(c), _e477;\n    }\n\n    return p;\n  }\n},\n    l$ = {\n  kernelName: \"DenseBincount\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      weights: a\n    } = t,\n        {\n      size: i,\n      binaryOutput: o\n    } = s;\n\n    if (1 === r.shape.length) {\n      var _e478 = n.readSync(r.dataId),\n          _t399 = n.readSync(a.dataId),\n          _s227 = jk(_e478, _t399, a.dtype, a.shape, i);\n\n      return n.makeTensorInfo([i], a.dtype, _s227);\n    }\n\n    if (2 === r.shape.length) {\n      var _e479 = n.bufferSync(r),\n          _t400 = n.bufferSync(a),\n          _s228 = Kk(_e479, _t400, i, o);\n\n      return n.makeTensorInfo(_s228.shape, a.dtype, _s228.values);\n    }\n\n    throw new Error(\"Error in denseBincount: input must be at most rank 2, but got rank\".concat(r.shape.length, \".\"));\n  }\n};\n\nclass u$ {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = [], this.outputShape = e, this.blockSize = t, this.dataFormat = n, this.userCode = \"\\n    void main() {\\n      ivec4 coords = getOutputCoords();\\n      int b = coords[0];\\n      int h = \".concat(this.getHeightCoordString(), \";\\n      int w = \").concat(this.getWidthCoordString(), \";\\n      int d = \").concat(this.getDepthCoordString(), \";\\n\\n      int in_h = h / \").concat(t, \";\\n      int offset_h = imod(h, \").concat(t, \");\\n      int in_w = w / \").concat(t, \";\\n      int offset_w = imod(w, \").concat(t, \");\\n      int offset_d = (offset_h * \").concat(t, \" + offset_w) *\\n        \").concat(this.getOutputDepthSize(), \";\\n      int in_d = d + offset_d;\\n\\n      float result = \").concat(this.getInputSamplingString(), \";\\n      setOutput(result);\\n    }\\n  \");\n  }\n\n  getHeightCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[1]\" : \"coords[2]\";\n  }\n\n  getWidthCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[2]\" : \"coords[3]\";\n  }\n\n  getDepthCoordString() {\n    return \"NHWC\" === this.dataFormat ? \"coords[3]\" : \"coords[1]\";\n  }\n\n  getOutputDepthSize() {\n    return \"NHWC\" === this.dataFormat ? this.outputShape[3] : this.outputShape[1];\n  }\n\n  getInputSamplingString() {\n    return \"NHWC\" === this.dataFormat ? \"getX(b, in_h, in_w, in_d)\" : \"getX(b, in_d, in_h, in_w)\";\n  }\n\n}\n\nvar c$ = {\n  kernelName: \"DepthToSpace\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockSize: a,\n      dataFormat: i\n    } = s;\n    l(a > 1, () => \"blockSize should be > 1 for depthToSpace, but was: \".concat(a));\n    var o = r.shape[0],\n        u = (\"NHWC\" === i ? r.shape[1] : r.shape[2]) * a,\n        c = (\"NHWC\" === i ? r.shape[2] : r.shape[3]) * a,\n        h = (\"NHWC\" === i ? r.shape[3] : r.shape[1]) / (a * a),\n        d = new u$(\"NHWC\" === i ? [o, u, c, h] : [o, h, u, c], a, i);\n    return n.runWebGLProgram(d, [r], r.dtype);\n  }\n};\n\nclass h$ {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.customUniforms = [{\n      name: \"pads\",\n      type: \"ivec2\"\n    }, {\n      name: \"strides\",\n      type: \"ivec2\"\n    }, {\n      name: \"dilations\",\n      type: \"ivec2\"\n    }, {\n      name: \"inDims\",\n      type: \"ivec2\"\n    }], this.outputShape = e.outShape, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var a = e.filterHeight,\n        i = e.filterWidth,\n        o = e.outChannels / e.inChannels;\n    var l = \"\",\n        u = \"\";\n    n && (l = s ? \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"float activation(float a) {\\n          float b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"\\n          float activation(float x) {\\n            \".concat(n, \"\\n          }\\n        \"), u = \"result = activation(result);\");\n    var c = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(l, \"\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(o, \";\\n        int q = d2 - d1 * \").concat(o, \";\\n\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\\n        for (int wR = 0; wR < \").concat(a, \"; wR++) {\\n          int xR = xRCorner + wR * dilations[0];\\n\\n          if (xR < 0 || xR >= inDims[0]) {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \").concat(i, \"; wC++) {\\n            int xC = xCCorner + wC * dilations[1];\\n\\n            if (xC < 0 || xC >= inDims[1]) {\\n              continue;\\n            }\\n\\n            float xVal = getX(batch, xR, xC, d1);\\n            float wVal = getW(wR, wC, d1, q);\\n            dotProd += xVal * wVal;\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \").concat(c, \"\\n        \").concat(u, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nclass d$ {\n  constructor(e) {\n    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;\n    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    var s = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;\n    var r = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;\n    this.variableNames = [\"x\", \"W\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"pads\",\n      type: \"ivec2\"\n    }, {\n      name: \"strides\",\n      type: \"ivec2\"\n    }, {\n      name: \"dilations\",\n      type: \"ivec2\"\n    }, {\n      name: \"inDims\",\n      type: \"ivec2\"\n    }], this.outputShape = e.outShape, this.enableShapeUniforms = Fk(this.outputShape.length);\n    var a = e.outChannels / e.inChannels,\n        o = e.padInfo.left,\n        l = e.strideWidth,\n        u = e.dilationWidth,\n        c = e.filterHeight,\n        h = e.filterWidth,\n        d = h;\n    var p = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n    for (var _e480 = 0; _e480 < h; _e480++) {\n      p += \"\\n          vec4 xTexelC\".concat(2 * _e480, \";\\n          int xTexelC\").concat(2 * _e480, \"Ready;\\n          vec4 xTexelC\").concat(2 * _e480 + 1, \";\\n          int xTexelC\").concat(2 * _e480 + 1, \"Ready;\\n          vec4 xC\").concat(_e480, \";\");\n    }\n\n    for (var _e481 = 0; _e481 < c; _e481++) {\n      for (var _e482 = 0; _e482 < h; _e482++) {\n        p += \"\\n          xTexelC\".concat(2 * _e482, \" = vec4(0.0);\\n          xTexelC\").concat(2 * _e482, \"Ready = 0;\\n          xTexelC\").concat(2 * _e482 + 1, \" = vec4(0.0);\\n          xTexelC\").concat(2 * _e482 + 1, \"Ready = 0;\\n          xC\").concat(_e482, \" = vec4(0.0);\");\n      }\n\n      p += \"\\n        xR = xRCorner + \".concat(_e481, \" * dilations[0];\\n        if (xR >=0 && xR < inDims[0]) {\\n      \");\n\n      for (var _t401 = 0; _t401 < (d + 1) / 2; _t401++) {\n        var _n287 = 2 * _t401;\n\n        if (p += \"\\n          xC = xCCorner + \".concat(_n287 * u, \";\\n          \"), 1 === l) {\n          if (_n287 < h && (o % 2 == 1 ? (p += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(_n287, \"Ready == 0) {\\n                  xTexelC\").concat(_n287, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(_n287, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n287, \"Ready = 1;\\n                }\\n              \"), p += 1 === u && _n287 > 0 ? \"\\n                xC\".concat(_n287, \" = vec4(xTexelC\").concat(_n287 - 2, \".zw, xTexelC\").concat(_n287, \".xy);\\n                \") : \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\".concat(_n287, \" = vec4(previous.zw, xTexelC\").concat(_n287, \".xy);\\n                  } else {\\n                    xC\").concat(_n287, \" = vec4(0.0, 0.0, xTexelC\").concat(_n287, \".xy);\\n                  }\\n                  \")) : p += \"\\n                if (xC >= 0 && xC < inDims[1] && xTexelC\".concat(_n287, \"Ready == 0) {\\n                  xTexelC\").concat(_n287, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(_n287, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n287, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n287, \" = xTexelC\").concat(_n287, \";\\n                \"), _n287 + 1 < h)) {\n            var _e483 = o % 2 == 0 ? i(u) : u;\n\n            u % 2 == 0 && o % 2 == 1 || u % 2 != 0 && o % 2 != 1 ? (p += \"\\n                  xCOffset = xC + imod(pads[1], 2) + \".concat(_e483, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(_n287 + 1, \"Ready == 0) {\\n                    xTexelC\").concat(_n287 + 1, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      xTexelC\").concat(_n287 + 1, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(_n287 + 1, \"Ready = 1;\\n                  }\\n                  \"), u > 1 && (p += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(_n287, \"Ready == 0) {\\n                      xTexelC\").concat(_n287, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(_n287, \"Ready = 1;\\n                    }\\n                    \")), p += \"\\n                  xC\".concat(_n287 + 1, \" = vec4(xTexelC\").concat(_n287, \".zw, xTexelC\").concat(_n287 + 1, \".xy);\\n                  \")) : p += 1 === _e483 ? \"\\n                    xC\".concat(_n287 + 1, \" = xTexelC\").concat(_n287, \";\\n                    \") : \"\\n                    xCOffset = xC + \".concat(_e483, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(_n287 + 1, \"Ready == 0) {\\n                      xTexelC\").concat(_n287 + 1, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= inDims[1]) {\\n                        xTexelC\").concat(_n287 + 1, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(_n287 + 1, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(_n287 + 1, \" = xTexelC\").concat(_n287 + 1, \";\\n                    \");\n          }\n        } else _n287 < h && (o % 2 == 1 ? (p += \"\\n                xCOffset = xC + 1 - strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(_n287, \"Ready == 0) {\\n                  xTexelC\").concat(_n287, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(_n287, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n287, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC\").concat(_n287 + 1, \"Ready == 0) {\\n                  xTexelC\").concat(_n287 + 1, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= inDims[1]) {\\n                    xTexelC\").concat(_n287 + 1, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n287 + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n287, \" = vec4(xTexelC\").concat(_n287, \".zw, xTexelC\").concat(_n287 + 1, \".zw);\\n              \"), _n287 + 1 < h && (p += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + strides[1];\\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\".concat(_n287 + 1, \" = vec4(xTexelC\").concat(_n287 + 1, \".xy, final.xy);\\n                \"))) : (p += \"\\n                if(xC >= 0 && xC < inDims[1] && xTexelC\".concat(_n287, \"Ready == 0) {\\n                  xTexelC\").concat(_n287, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(_n287, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_n287, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(_n287 + 1, \"Ready == 0) {\\n                  xTexelC\").concat(_n287 + 1, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(_n287 + 1, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(_n287 + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(_n287, \" = vec4(\\n                  xTexelC\").concat(_n287, \".xy, xTexelC\").concat(_n287 + 1, \".xy);\\n              \"), _n287 + 1 < h && (p += \"\\n                  xC\".concat(_n287 + 1, \" = vec4(xTexelC\").concat(_n287, \".zw, xTexelC\").concat(_n287 + 1, \".zw);\\n                \"))));\n\n        _n287 < h && (p += \"\\n            wTexel = getW(\".concat(_e481, \", \").concat(_n287, \", d1, q);\\n            dotProd += xC\").concat(_n287, \" * vec4(wTexel.xz, wTexel.xz);\\n          \"), _n287 + 1 < h && (p += \"\\n              wTexel = getW(\".concat(_e481, \", \").concat(_n287 + 1, \", d1, q);\\n              dotProd += xC\").concat(_n287 + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \")));\n      }\n\n      p += \"\\n        }\\n      \";\n    }\n\n    var f = \"\",\n        g = \"\";\n    n && (f = s ? \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(n, \"\\n        }\") : r ? \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(n, \"\\n        }\") : \"vec4 activation(vec4 x) {\\n          \".concat(n, \"\\n        }\"), g = \"result = activation(result);\");\n    var m = t ? \"result += getBiasAtOutCoords();\" : \"\";\n    t && this.variableNames.push(\"bias\"), s && this.variableNames.push(\"preluActivationWeights\"), r && this.variableNames.push(\"leakyreluAlpha\"), this.userCode = \"\\n      \".concat(f, \"\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(a, \";\\n        int q = d2 - d1 * \").concat(a, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(p, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(m, \"\\n        \").concat(g, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar p$ = {\n  kernelName: \"DepthwiseConv2dNative\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: u,\n      dimRoundingMode: c\n    } = s;\n    var h = u;\n    null == h && (h = [1, 1]), l(Ts(i, h), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '\").concat(h, \"'\"));\n    var d = ks(r.shape, a.shape, i, h, o, c, !0);\n    var p;\n    return p = G().getBool(\"WEBGL_PACK_DEPTHWISECONV\") && d.strideWidth <= 2 && d.outChannels / d.inChannels == 1 ? new d$(d) : new h$(d), n.runWebGLProgram(p, [r, a], \"float32\", [[d.padInfo.top, d.padInfo.left], [d.strideHeight, d.strideWidth], [d.dilationHeight, d.dilationWidth], [d.inHeight, d.inWidth]]);\n  }\n};\n\nclass f$ {\n  constructor(e) {\n    this.variableNames = [\"x\", \"dy\"], this.outputShape = e.filterShape, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int dm = coords.w;\\n        int d2 = d1 * \".concat(e.outChannels / e.inChannels, \" + dm;\\n\\n        float dotProd = 0.0;\\n\\n        // TO DO: Vec4 over the batch size\\n        for (int b = 0; b < \").concat(e.batchSize, \"; b++) {\\n          for (int yR = 0; yR < \").concat(e.outHeight, \"; yR++) {\\n            int xR = wR + yR * \").concat(e.strideHeight, \" - \").concat(e.padInfo.top, \";\\n\\n            if (xR < 0 || xR >= \").concat(e.inHeight, \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \").concat(e.outWidth, \"; yC++) {\\n              int xC = wC + yC * \").concat(e.strideWidth, \" - \").concat(e.padInfo.left, \";\\n\\n              if (xC < 0 || xC >= \").concat(e.inWidth, \") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass g$ {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"W\"], this.outputShape = e.inShape;\n    var t = e.filterHeight,\n        n = e.filterWidth,\n        s = e.outChannels / e.inChannels;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        float dotProd = 0.0;\\n\\n        for (int wR = 0; wR < \").concat(t, \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \").concat(t, \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \").concat(n, \" - 1 - wC;\\n\\n            // TO DO: Vec4 over the channelMul\\n            for (int dm = 0; dm < \").concat(s, \"; dm++) {\\n              int d2 = d1 * \").concat(s, \" + dm;\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar m$ = {\n  kernelName: \"DepthwiseConv2dNativeBackpropFilter\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      dy: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      filterShape: c\n    } = s,\n        h = ks(r.shape, c, i, o, l, u, !0),\n        d = new f$(h);\n    return n.runWebGLProgram(d, [r, a], \"float32\");\n  }\n},\n    b$ = {\n  kernelName: \"DepthwiseConv2dNativeBackpropInput\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      dilations: o,\n      pad: l,\n      dimRoundingMode: u,\n      inputShape: c\n    } = s,\n        h = ks(c, a.shape, i, o, l, u, !0),\n        d = new g$(h);\n    return n.runWebGLProgram(d, [r, a], \"float32\");\n  }\n};\n\nclass x$ {\n  constructor(e) {\n    this.variableNames = [\"X\"], this.outputShape = [e, e], this.userCode = \"\\n      void main() {\\n          ivec2 coords = getOutputCoords();\\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\\n          setOutput(val);\\n      }\\n    \";\n  }\n\n}\n\nvar y$ = {\n  kernelName: \"Diag\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t,\n        r = [...s.shape, ...s.shape],\n        a = d(s.shape),\n        i = mv({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [a]\n      }\n    }),\n        o = new x$(a),\n        l = n.runWebGLProgram(o, [i], i.dtype),\n        u = mv({\n      inputs: {\n        x: l\n      },\n      backend: n,\n      attrs: {\n        shape: r\n      }\n    });\n    return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(l), u;\n  }\n};\n\nclass k$ {\n  constructor(e) {\n    this.variableNames = [\"x\", \"W\"], this.outputShape = e.outShape;\n    var {\n      inHeight: t,\n      inWidth: n,\n      padInfo: s,\n      strideHeight: r,\n      strideWidth: a,\n      filterHeight: i,\n      filterWidth: o,\n      dilationHeight: l,\n      dilationWidth: u\n    } = e,\n        {\n      top: c,\n      left: h\n    } = s;\n    this.userCode = \"\\n      const ivec2 strides = ivec2(\".concat(r, \", \").concat(a, \");\\n      const ivec2 pads = ivec2(\").concat(c, \", \").concat(h, \");\\n      const float neg_infinity = -3.4e38;\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.w;\\n        ivec2 outTopLeftCorner =\\n            coords.yz * strides - pads;\\n        int hBeg = outTopLeftCorner.x;\\n        int wBeg = outTopLeftCorner.y;\\n\\n        float curVal = neg_infinity;\\n        for (int h = 0; h < \").concat(i, \"; h++) {\\n          int hIn = hBeg + h * \").concat(l, \";\\n\\n          if (hIn >= 0 && hIn < \").concat(t, \") {\\n            for (int w = 0; w < \").concat(o, \"; w++) {\\n              int wIn = wBeg + w * \").concat(u, \";\\n\\n              if (wIn >= 0 && wIn < \").concat(n, \") {\\n                float xVal = getX(batch, hIn, wIn, d1);\\n                float wVal = getW(h, w, d1);\\n\\n                float val = xVal + wVal;\\n                if (val > curVal) {\\n                  curVal = val;\\n                }\\n              }\\n            }\\n          }\\n        }\\n\\n        float result = curVal;\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar w$ = {\n  kernelName: \"Dilation2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a\n    } = t,\n        {\n      strides: i,\n      pad: o,\n      dilations: l\n    } = s,\n        u = bs(r.shape, a.shape, i, o, \"NHWC\", l);\n    var c;\n    var h = new k$(u);\n    c = n.runWebGLProgram(h, [r, a], \"float32\");\n    var d = mv({\n      inputs: {\n        x: c\n      },\n      backend: n,\n      attrs: {\n        shape: u.outShape\n      }\n    });\n    return n.disposeIntermediateTensorInfo(c), d;\n  }\n},\n    v$ = {\n  kernelName: \"Einsum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      equation: r\n    } = s,\n        a = t,\n        {\n      allDims: i,\n      summedDims: o,\n      idDims: l\n    } = qo(r, a.length);\n    Ko(i.length, l, a);\n    var {\n      path: u,\n      steps: c\n    } = Xo(o, l),\n        h = c.length;\n    var d = null,\n        f = i.length;\n    var g = [];\n\n    for (var _e484 = 0; _e484 < h; ++_e484) {\n      for (var _t402 of c[_e484]) {\n        var {\n          permutationIndices: _e485,\n          expandDims: _s229\n        } = jo(f, l[_t402]);\n\n        var _r169 = void 0;\n\n        Yo(_e485) ? _r169 = a[_t402] : (_r169 = Nv({\n          inputs: {\n            x: a[_t402]\n          },\n          backend: n,\n          attrs: {\n            perm: _e485\n          }\n        }), g.push(_r169));\n\n        var _i98 = _r169.shape.slice();\n\n        for (var _e486 = 0; _e486 < _s229.length; ++_e486) {\n          _i98.splice(_s229[_e486], 0, 1);\n        }\n\n        p(_r169.shape, _i98) || (_r169 = mv({\n          inputs: {\n            x: _r169\n          },\n          backend: n,\n          attrs: {\n            shape: _i98\n          }\n        }), g.push(_r169)), null === d ? d = _r169 : (d = fv({\n          inputs: {\n            a: _r169,\n            b: d\n          },\n          backend: n\n        }), g.push(d));\n      }\n\n      _e484 < h - 1 && (u[_e484] >= 0 && (d = $v({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          axis: u[_e484] - (i.length - f),\n          keepDims: !1\n        }\n      }), g.push(d)), f--);\n    }\n\n    for (var _e487 of g) {\n      _e487 !== d && n.disposeIntermediateTensorInfo(_e487);\n    }\n\n    return d;\n  }\n},\n    I$ = {\n  kernelName: \"Elu\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return (x >= 0.0) ? x : (exp(x) - 1.0);\",\n    packedOpSnippet: \"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\"\n  })\n},\n    $$ = {\n  kernelName: \"EluGrad\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      dy: s,\n      y: r\n    } = t,\n        a = G().getBool(\"WEBGL_PACK_BINARY_OPERATIONS\") ? new Jw(\"\\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\\n\", s.shape, r.shape) : new Yw(\"return (b >= 1.0) ? a : a * (b + 1.0);\", s.shape, r.shape);\n    return n.runWebGLProgram(a, [s, r], s.dtype);\n  }\n},\n    S$ = {\n  kernelName: \"Equal\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a == b);\",\n    packedOpSnippet: \"\\n  return vec4(equal(a, b));\\n\",\n    dtype: \"bool\",\n    cpuKernelImpl: Jk\n  })\n},\n    N$ = {\n  kernelName: \"Erf\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: '\\n  // Error function is calculated approximately with elementary function.\\n  // See \"Handbook of Mathematical Functions with Formulas,\\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\\n  float p = 0.3275911;\\n  float a1 = 0.254829592;\\n  float a2 = -0.284496736;\\n  float a3 = 1.421413741;\\n  float a4 = -1.453152027;\\n  float a5 = 1.061405429;\\n\\n  float sign = sign(x);\\n  x = abs(x);\\n  float t = 1.0 / (1.0 + p * x);\\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\\n'\n  })\n},\n    C$ = \"return exp(x);\",\n    T$ = lv({\n  opSnippet: C$,\n  packedOpSnippet: C$,\n  cpuKernelImpl: Zk\n}),\n    E$ = {\n  kernelName: \"Exp\",\n  backendName: \"webgl\",\n  kernelFunc: T$\n};\n\nfunction R$(e) {\n  var {\n    inputs: t,\n    attrs: n,\n    backend: s\n  } = e,\n      {\n    dim: r\n  } = n,\n      {\n    input: a\n  } = t,\n      i = a.shape.length,\n      o = a.shape.slice();\n  var u = r;\n  return r < 0 && (l(-(i + 1) <= r, () => \"Axis must be in the interval [\".concat(-(i + 1), \", \").concat(i, \"]\")), u = i + r + 1), o.splice(u, 0, 1), mv({\n    inputs: {\n      x: a\n    },\n    backend: s,\n    attrs: {\n      shape: o\n    }\n  });\n}\n\nvar A$ = {\n  kernelName: \"ExpandDims\",\n  backendName: \"webgl\",\n  kernelFunc: R$\n},\n    F$ = \"return exp(x) - 1.0;\",\n    D$ = {\n  kernelName: \"Expm1\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: F$,\n    packedOpSnippet: F$,\n    cpuKernelImpl: Qk\n  })\n};\n\nclass _$ {\n  constructor(e, t, n) {\n    this.variableNames = [\"real\", \"imag\"];\n    var s = t[1];\n    this.outputShape = t;\n    var r = n ? \"2.0 * \".concat(Math.PI) : \"-2.0 * \".concat(Math.PI),\n        a = n ? \"\".concat(s, \".0\") : \"1.0\";\n    var i;\n    if (\"real\" === e) i = \"return real * expR - imag * expI;\";else {\n      if (\"imag\" !== e) throw new Error(\"FFT component must be either \\\"real\\\" or \\\"imag\\\", got \".concat(e, \".\"));\n      i = \"return real * expI + imag * expR;\";\n    }\n    this.userCode = \"\\n      const float exponentMultiplier = \".concat(r, \";\\n\\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\\n        \").concat(i, \"\\n      }\\n\\n      float mulMatDFT(int batch, int index) {\\n        float indexRatio = float(index) / float(\").concat(s, \");\\n        float exponentMultiplierTimesIndexRatio =\\n            exponentMultiplier * indexRatio;\\n\\n        float result = 0.0;\\n\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          // x = (-2|2 * PI / N) * index * i;\\n          float x = exponentMultiplierTimesIndexRatio * float(i);\\n          float expR = cos(x);\\n          float expI = sin(x);\\n          float real = getReal(batch, i);\\n          float imag = getImag(batch, i);\\n\\n          result +=\\n              unaryOpComplex(real, expR, imag, expI) / \").concat(a, \";\\n        }\\n\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        setOutput(mulMatDFT(coords[0], coords[1]));\\n      }\\n    \");\n  }\n\n}\n\nfunction O$(e, t, n) {\n  var s = n.texData.get(e.dataId),\n      r = d(e.shape),\n      a = e.shape[e.shape.length - 1],\n      i = mv({\n    inputs: {\n      x: e\n    },\n    backend: n,\n    attrs: {\n      shape: [r / a, a]\n    }\n  }),\n      o = i.shape,\n      l = new _$(\"real\", o, t),\n      u = new _$(\"imag\", o, t),\n      c = [{\n    dataId: s.complexTensorInfos.real.dataId,\n    dtype: s.complexTensorInfos.real.dtype,\n    shape: o\n  }, {\n    dataId: s.complexTensorInfos.imag.dataId,\n    dtype: s.complexTensorInfos.imag.dtype,\n    shape: o\n  }],\n      h = n.runWebGLProgram(l, c, \"float32\"),\n      p = n.runWebGLProgram(u, c, \"float32\"),\n      f = ev({\n    inputs: {\n      real: h,\n      imag: p\n    },\n    backend: n\n  });\n  n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(p);\n  var g = mv({\n    inputs: {\n      x: f\n    },\n    backend: n,\n    attrs: {\n      shape: e.shape\n    }\n  });\n  return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(f), g;\n}\n\nvar M$ = {\n  kernelName: \"FFT\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t;\n    return O$(s, !1, n);\n  }\n};\n\nclass L$ {\n  constructor(e, t) {\n    this.outputShape = [], this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.variableNames = [\"x\"], this.outputShape = e, this.userCode = \"\\n      void main() {\\n        // Input can be obtained from uniform value.\\n        setOutput(value);\\n      }\\n    \";\n  }\n\n}\n\nfunction z$(e) {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    shape: s,\n    value: r\n  } = n;\n  var {\n    dtype: a\n  } = n;\n\n  if (a = a || T(r), \"string\" === a) {\n    var _e488 = v(a, d(s));\n\n    return _e488.fill(r), t.makeTensorInfo(s, a, _e488);\n  }\n\n  {\n    var _e489 = new L$(s, r);\n\n    return t.runWebGLProgram(_e489, [], a, [[r]]);\n  }\n}\n\nvar B$ = {\n  kernelName: \"Fill\",\n  backendName: \"webgl\",\n  kernelFunc: z$\n};\n\nclass P$ {\n  constructor(e) {\n    this.variableNames = [\"Image\"], this.outputShape = [];\n    var t = e[2];\n    this.outputShape = e, this.userCode = \"\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int x = coords[2];\\n\\n          int coordX = \".concat(t, \" - x - 1;\\n          float outputValue;\\n          if(coordX >= 0 && coordX < \").concat(t, \") {\\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\\n          } else {\\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\\n          }\\n          setOutput(outputValue);\\n        }\\n    \");\n  }\n\n}\n\nvar W$ = {\n  kernelName: \"FlipLeftRight\",\n  backendName: \"webgl\",\n  kernelFunc: _ref28 => {\n    var {\n      inputs: e,\n      backend: t\n    } = _ref28;\n    var {\n      image: n\n    } = e,\n        s = t,\n        r = new P$(n.shape);\n    return s.runWebGLProgram(r, [n], n.dtype);\n  }\n},\n    U$ = \"return floor(x);\",\n    V$ = {\n  kernelName: \"Floor\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: U$,\n    packedOpSnippet: U$,\n    cpuKernelImpl: ew\n  })\n},\n    G$ = {\n  kernelName: \"FloorDiv\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\",\n    packedOpSnippet: \"\\n  ivec4 ia = round(a);\\n  ivec4 ib = round(b);\\n  bvec4 cond = notEqual(ib, ivec4(0));\\n  ivec4 result = ivec4(0);\\n  vec4 s = sign(a) * sign(b);\\n\\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n  if (cond[0]) {\\n    result[0] = idiv(ia[0], ib[0], s[0]);\\n  }\\n  if (cond[1]) {\\n    result[1] = idiv(ia[1], ib[1], s[1]);\\n  }\\n  if (cond[2]) {\\n    result[2] = idiv(ia[2], ib[2], s[2]);\\n  }\\n  if (cond[3]) {\\n    result[3] = idiv(ia[3], ib[3], s[3]);\\n  }\\n  return vec4(result);\\n\",\n    dtype: \"int32\"\n  })\n};\n\nclass H$ {\n  constructor(e) {\n    this.variableNames = [\"A\"];\n    var t = dk(),\n        [n, s] = e;\n    this.outputShape = e, this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\".concat(s, \".0, \").concat(n, \".0);\\n\\n        vec4 values = \").concat(t.texture2D, \"(A, uv);\\n        float value;\\n        if (depth == 0) {\\n          value = values.r;\\n        } else if (depth == 1) {\\n          value = values.g;\\n        } else if (depth == 2) {\\n          value = values.b;\\n        } else if (depth == 3) {\\n          value = values.a;\\n        }\\n\\n        setOutput(floor(value * 255.0 + 0.5));\\n      }\\n    \");\n  }\n\n}\n\nclass q$ {\n  constructor(e) {\n    this.variableNames = [\"A\"], this.packedInputs = !1, this.packedOutput = !0;\n    var t = dk(),\n        [n, s] = e;\n    this.outputShape = e, this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n\\n        vec4 result = vec4(0.);\\n\\n        for(int row=0; row<=1; row++) {\\n          for(int col=0; col<=1; col++) {\\n            texC = coords[1] + row;\\n            depth = coords[2] + col;\\n\\n            vec2 uv = (vec2(texC, texR) + halfCR) /\\n                       vec2(\".concat(s, \".0, \").concat(n, \".0);\\n            vec4 values = \").concat(t.texture2D, \"(A, uv);\\n            float value;\\n            if (depth == 0) {\\n              value = values.r;\\n            } else if (depth == 1) {\\n              value = values.g;\\n            } else if (depth == 2) {\\n              value = values.b;\\n            } else if (depth == 3) {\\n              value = values.a;\\n            }\\n\\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\\n          }\\n        }\\n\\n        \").concat(t.output, \" = result;\\n      }\\n    \");\n  }\n\n}\n\nvar j$ = {\n  kernelName: \"FromPixels\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e;\n    var {\n      pixels: r\n    } = t;\n    var {\n      numChannels: a\n    } = s,\n        i = \"undefined\" != typeof HTMLVideoElement && r instanceof HTMLVideoElement,\n        o = \"undefined\" != typeof HTMLImageElement && r instanceof HTMLImageElement,\n        [l, u] = i ? [r.videoWidth, r.videoHeight] : [r.width, r.height],\n        c = [u, l],\n        h = [u, l, a];\n    (o || i) && (null == K$ && (K$ = document.createElement(\"canvas\").getContext(\"2d\")), K$.canvas.width = l, K$.canvas.height = u, K$.drawImage(r, 0, 0, l, u), r = K$.canvas);\n    var d = n.makeTensorInfo(c, \"int32\");\n    n.texData.get(d.dataId).usage = zy.PIXELS, n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId), r);\n    var p = G().getBool(\"WEBGL_PACK\") ? new q$(h) : new H$(h),\n        f = n.runWebGLProgram(p, [d], \"int32\");\n    return n.disposeData(d.dataId), f;\n  }\n};\nvar K$;\nvar X$ = {\n  kernelName: \"FusedConv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: l,\n      pad: u,\n      dataFormat: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s,\n        g = Es(c),\n        m = ks(r.shape, a.shape, l, h, u, d, !1, g);\n    var b;\n    var x = [];\n    if (1 !== m.filterHeight || 1 !== m.filterWidth || 1 !== m.dilationHeight || 1 !== m.dilationWidth || 1 !== m.strideHeight || 1 !== m.strideWidth || \"SAME\" !== m.padInfo.type && \"VALID\" !== m.padInfo.type) {\n      if (G().getBool(\"WEBGL_CONV_IM2COL\") && 1 === r.shape[0]) b = VI({\n        x: r,\n        filter: a,\n        convInfo: m,\n        backend: n,\n        bias: i,\n        activation: p,\n        preluActivationWeights: o,\n        leakyreluAlpha: f\n      });else {\n        var _e490 = null != i,\n            _t403 = null != o,\n            _s230 = \"leakyrelu\" === p,\n            _l53 = p ? cv(p, !1) : null,\n            _u41 = new BI(m, _e490, _l53, _t403, _s230),\n            _c35 = [r, a];\n\n        if (i && _c35.push(i), o && _c35.push(o), _s230) {\n          var _e491 = n.makeTensorInfo([], \"float32\", Ue(f, \"float32\"));\n\n          _c35.push(_e491), x.push(_e491);\n        }\n\n        b = n.runWebGLProgram(_u41, _c35, \"float32\");\n      }\n    } else b = UI({\n      x: r,\n      filter: a,\n      convInfo: m,\n      backend: n,\n      bias: i,\n      activation: p,\n      preluActivationWeights: o,\n      leakyreluAlpha: f\n    });\n    var y = mv({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        shape: m.outShape\n      }\n    });\n    return x.push(b), x.forEach(e => n.disposeIntermediateTensorInfo(e)), y;\n  }\n},\n    Y$ = {\n  kernelName: \"FusedDepthwiseConv2D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      filter: a,\n      bias: i,\n      preluActivationWeights: o\n    } = t,\n        {\n      strides: u,\n      pad: c,\n      dilations: h,\n      dimRoundingMode: d,\n      activation: p,\n      leakyreluAlpha: f\n    } = s,\n        g = [];\n    var m = h;\n    null == m && (m = [1, 1]), l(Ts(u, m), () => \"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \".concat(u, \" and dilations '\").concat(m, \"'\"));\n    var b = ks(r.shape, a.shape, u, m, c, d, !0),\n        x = G().getBool(\"WEBGL_PACK_DEPTHWISECONV\") && b.strideWidth <= 2 && b.outChannels / b.inChannels == 1,\n        y = p ? cv(p, x) : null,\n        k = [r, a],\n        w = null != i,\n        v = null != o,\n        I = \"leakyrelu\" === p;\n\n    if (w && k.push(i), v && k.push(o), I) {\n      var _e492 = n.makeTensorInfo([], \"float32\", Ue(f, \"float32\"));\n\n      k.push(_e492), g.push(_e492);\n    }\n\n    var $;\n    $ = x ? new d$(b, w, y, v, I) : new h$(b, w, y, v, I);\n    var S = n.runWebGLProgram($, k, \"float32\", [[b.padInfo.top, b.padInfo.left], [b.strideHeight, b.strideWidth], [b.dilationHeight, b.dilationWidth], [b.inHeight, b.inWidth]]);\n    return g.forEach(e => n.disposeIntermediateTensorInfo(e)), S;\n  }\n};\n\nclass J$ {\n  constructor(e, t, n) {\n    this.sliceDim = e, this.strides = t, this.variableNames = [\"x\", \"indices\"], this.outputShape = n;\n    var s = Ck(t.length),\n        r = Ck(n.length);\n    this.userCode = \"\\n        \".concat(s, \" strides = \").concat(s, \"(\").concat(this.strides, \");\\n         void main() {\\n          \").concat(r, \" coords = getOutputCoords();\\n          int flattenIndex = 0;\\n          for (int j = 0; j < \").concat(this.sliceDim, \"; j++) {\\n            int index = round(getIndices(coords[0], j));\\n            flattenIndex += index * \").concat(this.sliceDim > 1 ? \"strides[j]\" : \"strides\", \";\\n          }\\n          setOutput(getX(flattenIndex, coords[1]));\\n        }\\n      \");\n  }\n\n}\n\nvar Z$ = {\n  kernelName: \"GatherNd\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      params: s,\n      indices: r\n    } = t,\n        a = r.shape,\n        i = a[a.length - 1],\n        o = d(s.shape),\n        [l, u, c, h] = Nn(s, r),\n        p = mv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [u, i]\n      }\n    }),\n        f = mv({\n      inputs: {\n        x: s\n      },\n      backend: n,\n      attrs: {\n        shape: [d(s.shape) / c, c]\n      }\n    });\n\n    if (n.shouldExecuteOnCPU([s, r]) || \"string\" === s.dtype) {\n      var _e493 = n.readSync(r.dataId),\n          _t404 = n.bufferSync(s),\n          _a138 = tw(_e493, _t404, s.dtype, u, i, c, h, s.shape, o);\n\n      return n.makeTensorInfo(l, s.dtype, _a138.values);\n    }\n\n    var g = new J$(i, h, [u, c]),\n        m = n.runWebGLProgram(g, [f, p], f.dtype),\n        b = mv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: l\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(m), b;\n  }\n};\n\nclass Q$ {\n  constructor(e, t) {\n    this.variableNames = [\"A\", \"indices\"], this.outputShape = t, this.rank = t.length;\n\n    var n = Ck(this.rank),\n        s = function (e, t) {\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\"],\n          s = [];\n\n      for (var _t405 = 0; _t405 < e.length; _t405++) {\n        s.push(2 === _t405 ? \"int(getIndices(resRC.x, resRC.z))\" : \"\".concat(n[_t405]));\n      }\n\n      return s.join();\n    }(e);\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(n, \" resRC = getOutputCoords();\\n        setOutput(getA(\").concat(s, \"));\\n      }\\n    \");\n  }\n\n}\n\nfunction eS(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r,\n    indices: a\n  } = t,\n      {\n    axis: i,\n    batchDims: o\n  } = s,\n      l = tl(r, a, y(i, r.shape)[0], o),\n      u = d(a.shape),\n      c = [],\n      h = mv({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      shape: [l.batchSize, l.outerSize, l.dimSize, l.sliceSize]\n    }\n  }),\n      p = mv({\n    inputs: {\n      x: a\n    },\n    backend: n,\n    attrs: {\n      shape: [l.batchSize, u / l.batchSize]\n    }\n  });\n  c.push(h), c.push(p);\n  var f = [l.batchSize, l.outerSize, u / l.batchSize, l.sliceSize];\n\n  if (n.shouldExecuteOnCPU([r, a]) || \"string\" === r.dtype) {\n    var _e494 = n.bufferSync(p),\n        _t406 = n.bufferSync(h),\n        _s231 = nw(_t406, _e494, f);\n\n    return c.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(l.outputShape, _s231.dtype, _s231.values);\n  }\n\n  var g = new Q$(h.shape, f),\n      m = n.runWebGLProgram(g, [h, p], h.dtype);\n  c.push(m);\n  var b = mv({\n    inputs: {\n      x: m\n    },\n    backend: n,\n    attrs: {\n      shape: l.outputShape\n    }\n  });\n  return c.forEach(e => n.disposeIntermediateTensorInfo(e)), b;\n}\n\nvar tS = {\n  kernelName: \"GatherV2\",\n  backendName: \"webgl\",\n  kernelFunc: eS\n},\n    nS = {\n  kernelName: \"Greater\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a > b);\",\n    packedOpSnippet: \"\\n  return vec4(greaterThan(a, b));\\n\",\n    cpuKernelImpl: sw,\n    dtype: \"bool\"\n  })\n},\n    sS = {\n  kernelName: \"GreaterEqual\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a >= b);\",\n    packedOpSnippet: \"\\n  return vec4(greaterThanEqual(a, b));\\n\",\n    dtype: \"bool\",\n    cpuKernelImpl: rw\n  })\n},\n    rS = {\n  kernelName: \"IFFT\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      input: s\n    } = t;\n    return O$(s, !0, n);\n  }\n},\n    aS = {\n  kernelName: \"IsFinite\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return float(!isnan(x) && !isinf(x));\",\n    dtype: \"bool\"\n  })\n},\n    iS = {\n  kernelName: \"IsInf\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return float(isinf(x));\",\n    dtype: \"bool\"\n  })\n},\n    oS = {\n  kernelName: \"IsNan\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return float(isnan(x));\",\n    dtype: \"bool\"\n  })\n},\n    lS = {\n  kernelName: \"Less\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a < b);\",\n    packedOpSnippet: \"\\n  return vec4(lessThan(a, b));\\n\",\n    cpuKernelImpl: aw,\n    dtype: \"bool\"\n  })\n},\n    uS = {\n  kernelName: \"LessEqual\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a <= b);\",\n    packedOpSnippet: \"\\n  return vec4(lessThanEqual(a, b));\\n\",\n    cpuKernelImpl: iw,\n    dtype: \"bool\"\n  })\n},\n    cS = {\n  kernelName: \"LinSpace\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      backend: t,\n      attrs: n\n    } = e,\n        {\n      start: s,\n      stop: r,\n      num: a\n    } = n,\n        i = ow(s, r, a);\n    return t.makeTensorInfo([i.length], \"float32\", i);\n  }\n},\n    hS = {\n  kernelName: \"Log\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (x < 0.0) return NAN;\\n  return log(x);\",\n    packedOpSnippet: \"\\n  vec4 result = log(x);\\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: lw\n  })\n},\n    dS = {\n  kernelName: \"Log1p\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return log(1.0 + x);\"\n  })\n},\n    pS = {\n  kernelName: \"LogicalAnd\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a >= 1.0 && b >= 1.0);\",\n    packedOpSnippet: \"\\n  return vec4(\\n    vec4(greaterThanEqual(a, vec4(1.0))) *\\n    vec4(greaterThanEqual(b, vec4(1.0))));\\n\",\n    dtype: \"bool\"\n  })\n},\n    fS = {\n  kernelName: \"LogicalNot\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return float(!(x >= 1.0));\"\n  })\n},\n    gS = {\n  kernelName: \"LogicalOr\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return float(a >= 1.0 || b >= 1.0);\",\n    packedOpSnippet: \"\\n  return min(\\n    vec4(greaterThanEqual(a, vec4(1.0))) +\\n    vec4(greaterThanEqual(b, vec4(1.0))),\\n    vec4(1.0));\\n\",\n    dtype: \"bool\"\n  })\n};\n\nclass mS {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"x\"], this.outputShape = [];\n    var a = t,\n        i = e[3] - 1;\n    var o;\n    this.outputShape = e;\n    var l = \"float(\".concat(n, \") + float(\").concat(s, \") * sum\");\n    o = .5 === r ? \"inversesqrt(\".concat(l, \")\") : 1 === r ? \"1.0/(\".concat(l, \")\") : \"exp(log(\".concat(l, \") * float(-\").concat(r, \"));\"), this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n        int d = coords[3];\\n        float x = getX(b, r, c, d);\\n        float sum = 0.0;\\n        for (int j = -\".concat(a, \"; j <= \").concat(a, \"; j++) {\\n          int idx = d + j;\\n          if (idx >= 0 && idx <=  \").concat(i, \") {\\n            float z = getX(b, r, c, idx);\\n            sum += z * z;\\n          }\\n        }\\n        float val = x * \").concat(o, \";\\n        setOutput(val);\\n      }\\n    \");\n  }\n\n}\n\nclass bS {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"x\"], this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0;\n    var a = t,\n        i = e[3] - 1;\n    var o;\n    this.outputShape = e;\n    var l = \"float(\".concat(n, \") + float(\").concat(s, \") * sum\");\n    o = .5 === r ? \"inversesqrt(\".concat(l, \")\") : 1 === r ? \"1.0/(\".concat(l, \")\") : \"exp(log(\".concat(l, \") * float(-\").concat(r, \"));\"), this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords.x;\\n        int r = coords.y;\\n        int c = coords.z;\\n        int d = coords.w;\\n\\n        bool hasNextCol = d < \".concat(this.outputShape[3], \";\\n        bool hasNextRow = c < \").concat(this.outputShape[2], \";\\n\\n        vec4 sum = vec4(0.);\\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\\n\\n        vec4 xAtOutputCoords = vec4(\\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\\n          hasNextCol ?\\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\\n          hasNextRow ?\\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\\n        );\\n\\n        int firstChannel = d - \").concat(a, \";\\n        vec2 cache = vec2(0.);\\n        if(firstChannel >= 0){\\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\\n            if(hasNextRow){\\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\\n            }\\n        }\\n\\n        ivec2 depth = ivec2(d, d + 1);\\n        for (int j = - \").concat(a, \"; j <= \").concat(a, \"; j++) {\\n          ivec2 idx = depth + j;\\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(\").concat(i, \"));\\n\\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\\n\\n          if(depthInRange || depthPlusOneInRange){\\n            vec4 z = vec4(0.);\\n            vec4 xFragAtCurrentDepth;\\n            z.xz = cache.xy;\\n            if(depthPlusOneInRange && hasNextCol){\\n              xFragAtCurrentDepth = idx.y != d ?\\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\\n              if(hasNextRow){\\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\\n              }\\n            }\\n            cache.xy = z.yw;\\n            sum += z * z;\\n          }\\n        }\\n        vec4 result = xAtOutputCoords * \").concat(o, \";\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar xS = {\n  kernelName: \"LRN\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      depthRadius: a,\n      bias: i,\n      alpha: o,\n      beta: l\n    } = s,\n        u = G().getBool(\"WEBGL_PACK_NORMALIZATION\") ? new bS(r.shape, a, i, o, l) : new mS(r.shape, a, i, o, l);\n    return n.runWebGLProgram(u, [r], r.dtype);\n  }\n};\n\nclass yS {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"inputImage\", \"outputImage\", \"dy\"], this.outputShape = [], this.outputShape = e, this.depth = e[3], this.depthRadius = t, this.bias = n, this.alpha = s, this.beta = r, this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float result = 0.0;\\n        for (int d = 0; d < \".concat(this.depth, \"; ++d) {\\n          int depthBegin = int(max(0.0, float(d - \").concat(t, \")));\\n          int depthEnd = int(min(float(\").concat(this.depth, \"),\\n              float(d + \").concat(t, \" + 1)));\\n\\n          const int MIN_DEPTH_BEGIN = 0;\\n          const int MAX_DEPTH_END = \").concat(this.depth, \";\\n\\n          float norm = 0.0;\\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd) {\\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n\\n          norm = float(\").concat(s, \") * norm + float(\").concat(n, \");\\n\\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd){\\n              float dyi = -2.0 * float(\").concat(s, \")\\n                * float(\").concat(r, \")\\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\\n                / norm;\\n              if (k == d) {\\n                dyi += pow(norm, -1.0 * \").concat(r, \");\\n              }\\n              if (k == coords[3]) {\\n                dyi *= getDy(b, r, c, d);\\n                result += dyi;\\n              }\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n      }\\n      setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar kS = {\n  kernelName: \"LRNGrad\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      y: a,\n      dy: i\n    } = t,\n        {\n      depthRadius: o,\n      bias: l,\n      alpha: u,\n      beta: c\n    } = s,\n        h = new yS(r.shape, o, l, u, c);\n    return n.runWebGLProgram(h, [r, a, i], r.dtype);\n  }\n};\n\nfunction wS(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reductionIndices: a,\n    keepDims: i\n  } = s,\n      o = r.shape.length,\n      l = y(a, r.shape);\n  var u = l;\n  var c = Zr(u, o),\n      h = null != c,\n      p = n.shouldExecuteOnCPU([r]);\n  var f = r;\n\n  if (h) {\n    if (p) {\n      var _e495 = n.texData.get(f.dataId).values,\n          _t407 = new Array(o);\n\n      for (var _e496 = 0; _e496 < _t407.length; _e496++) {\n        _t407[_e496] = r.shape[c[_e496]];\n      }\n\n      var _s232 = Fw(_e495, r.shape, r.dtype, c, _t407);\n\n      f = n.makeTensorInfo(_t407, r.dtype), n.texData.get(f.dataId).values = _s232;\n    } else f = Iv(r, c, n);\n\n    u = ea(u.length, o);\n  }\n\n  Jr(\"max\", u, o);\n  var [g, m] = Xr(f.shape, u);\n  var b,\n      x = g;\n\n  if (i && (x = Yr(g, l)), p) {\n    var _e497 = n.texData.get(f.dataId),\n        _t408 = uw(_e497.values, d(m), x, r.dtype);\n\n    b = n.makeTensorInfo(x, r.dtype), n.texData.get(b.dataId).values = _t408;\n  } else b = function (e, t, n, s) {\n    var r = d(t),\n        a = mv({\n      inputs: {\n        x: e\n      },\n      attrs: {\n        shape: [d(e.shape) / r, r]\n      },\n      backend: s\n    }),\n        i = kv(a, e.dtype, \"max\", s),\n        o = mv({\n      inputs: {\n        x: i\n      },\n      attrs: {\n        shape: n\n      },\n      backend: s\n    });\n    return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(i), o;\n  }(f, m, x, n);\n\n  return h && n.disposeIntermediateTensorInfo(f), b;\n}\n\nvar vS = {\n  kernelName: \"Max\",\n  backendName: \"webgl\",\n  kernelFunc: wS\n},\n    IS = {\n  kernelName: \"Maximum\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return max(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = vec4(max(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: cw\n  })\n},\n    $S = {\n  kernelName: \"MaxPool\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t;\n    ck(r, \"maxPool\");\n    var {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dimRoundingMode: u\n    } = s;\n    l(Ts(i, 1), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(i, \" and dilations '1'\"));\n    var c = xs(r.shape, a, i, 1, o, u);\n    if (1 === c.filterWidth && 1 === c.filterHeight && p(c.inShape, c.outShape)) return Zw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var h = new Qv(c, \"max\", !1);\n    return n.runWebGLProgram(h, [r], r.dtype);\n  }\n},\n    SS = {\n  kernelName: \"MaxPool3D\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      filterSize: a,\n      strides: i,\n      pad: o,\n      dataFormat: l,\n      dimRoundingMode: u\n    } = s,\n        c = ys(r.shape, a, i, [1, 1, 1], o, u, l),\n        h = new eI(c, \"max\", !1);\n    return n.runWebGLProgram(h, [r], r.dtype);\n  }\n};\n\nclass NS {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"maxPos\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterHeight,\n        n = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec2 pads = ivec2(\".concat(t - 1 - e.padInfo.top, \", \").concat(n - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \").concat(t, \";\\n          wR += \").concat(e.dilationHeight, \") {\\n          float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n          if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \").concat(n, \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n            if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n            int maxPosValue = \").concat(t * n - 1, \" - int(getMaxPos(b, idyR, idyC, d));\\n\\n            // Get the current value, check it against the value from the\\n            // position matrix.\\n            int curPosValue = wR * \").concat(n, \" + wC;\\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n            dotProd += dyValue * mask;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nclass CS {\n  constructor(e) {\n    this.variableNames = [\"dy\", \"maxPos\"], this.outputShape = e.inShape;\n    var t = e.effectiveFilterDepth,\n        n = e.effectiveFilterHeight,\n        s = e.effectiveFilterWidth;\n    this.userCode = \"\\n      const ivec3 pads = ivec3(\".concat(t - 1 - e.padInfo.front, \", \").concat(n - 1 - e.padInfo.top, \", \").concat(s - 1 - e.padInfo.left, \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \").concat(t, \";\\n           wD += \").concat(e.dilationDepth, \") {\\n          float dyD = float(dyDCorner + wD) / \").concat(e.strideDepth, \".0;\\n\\n          if (dyD < 0.0 || dyD >= \").concat(e.outDepth, \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \").concat(n, \";\\n              wR += \").concat(e.dilationHeight, \") {\\n            float dyR = float(dyRCorner + wR) / \").concat(e.strideHeight, \".0;\\n\\n            if (dyR < 0.0 || dyR >= \").concat(e.outHeight, \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \").concat(s, \";\\n                wC += \").concat(e.dilationWidth, \") {\\n              float dyC = float(dyCCorner + wC) / \").concat(e.strideWidth, \".0;\\n\\n              if (dyC < 0.0 || dyC >= \").concat(e.outWidth, \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n              int maxPosValue = \").concat(t * n * s - 1, \" -\\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\\n\\n              // Get the current value, check it against the value from the\\n              // position matrix.\\n              int curPosValue =\\n                  wD * \").concat(n, \" * \").concat(s, \" +\\n                  wR * \").concat(s, \" + wC;\\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n              dotProd += dyValue * mask;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \");\n  }\n\n}\n\nvar TS = {\n  kernelName: \"MaxPool3DGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a\n    } = t,\n        i = a,\n        {\n      filterSize: o,\n      strides: l,\n      pad: u,\n      dimRoundingMode: c\n    } = s,\n        h = ys(i.shape, o, l, [1, 1, 1], u, c),\n        d = new eI(h, \"max\", !0),\n        p = n.runWebGLProgram(d, [i], i.dtype),\n        f = new CS(h),\n        g = n.runWebGLProgram(f, [r, p], i.dtype);\n    return n.disposeIntermediateTensorInfo(p), g;\n  }\n},\n    ES = {\n  kernelName: \"MaxPoolGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      dy: r,\n      input: a,\n      output: i\n    } = t,\n        o = a;\n    ck([a, i], \"maxPoolGrad\");\n    var {\n      filterSize: l,\n      strides: u,\n      pad: c,\n      dimRoundingMode: h\n    } = s,\n        d = xs(o.shape, l, u, 1, c, h),\n        p = new Qv(d, \"max\", !0),\n        f = n.runWebGLProgram(p, [o], o.dtype),\n        g = new NS(d),\n        m = n.runWebGLProgram(g, [r, f], o.dtype);\n    return n.disposeIntermediateTensorInfo(f), m;\n  }\n},\n    RS = {\n  kernelName: \"MaxPoolWithArgmax\",\n  backendName: \"webgl\",\n  kernelFunc: _ref29 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref29;\n    var {\n      x: s\n    } = e,\n        {\n      filterSize: r,\n      strides: a,\n      pad: i,\n      includeBatchInIndex: o\n    } = t,\n        u = n;\n    l(4 === s.shape.length, () => \"Error in maxPool: input must be rank 4 but got rank \".concat(s.shape.length, \".\"));\n    var c = [1, 1];\n    l(Ts(a, c), () => \"Error in maxPool: Either strides or dilations must be 1. Got strides \".concat(a, \" and dilations '\").concat(c, \"'\"));\n\n    var h = xs(s.shape, r, a, c, i),\n        [d, p] = function (e, t, n, s) {\n      var r = new Qv(n, \"max\", !1);\n      var a = s.runWebGLProgram(r, [e], \"float32\");\n      return r = new Qv(n, \"max\", !0, !0, t), [a, s.runWebGLProgram(r, [e], \"float32\")];\n    }(s, o, h, u);\n\n    return [d, p];\n  }\n},\n    AS = {\n  kernelName: \"Mean\",\n  backendName: \"webgl\",\n  kernelFunc: _ref30 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref30;\n    var {\n      x: s\n    } = e,\n        {\n      keepDims: r,\n      axis: a\n    } = t,\n        i = n,\n        o = s.shape.length,\n        l = y(a, s.shape);\n    var u = l;\n    var c = Zr(u, o),\n        h = null != c,\n        p = i.shouldExecuteOnCPU([s]),\n        f = [];\n    var g = s;\n\n    if (h) {\n      if (p) {\n        var _e498 = i.texData.get(g.dataId).values,\n            _t409 = new Array(o);\n\n        for (var _e499 = 0; _e499 < _t409.length; _e499++) {\n          _t409[_e499] = s.shape[c[_e499]];\n        }\n\n        var _n288 = Fw(_e498, s.shape, s.dtype, c, _t409);\n\n        g = i.makeTensorInfo(_t409, s.dtype), i.texData.get(g.dataId).values = _n288;\n      } else g = Iv(s, c, i);\n\n      f.push(g), u = ea(u.length, o);\n    }\n\n    Jr(\"sum\", u, o);\n    var [m, b] = Xr(g.shape, u);\n    var x = m;\n    r && (x = Yr(m, l));\n\n    var k = function (e, t, n, s) {\n      var r = d(t),\n          a = mv({\n        inputs: {\n          x: e\n        },\n        attrs: {\n          shape: [d(e.shape) / r, r]\n        },\n        backend: s\n      }),\n          i = kv(a, \"float32\", \"mean\", s),\n          o = mv({\n        inputs: {\n          x: i\n        },\n        attrs: {\n          shape: n\n        },\n        backend: s\n      });\n      return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(i), o;\n    }(g, b, x, i);\n\n    for (var _e500 of f) {\n      i.disposeIntermediateTensorInfo(_e500);\n    }\n\n    return k;\n  }\n},\n    FS = {\n  kernelName: \"Min\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = y(a, r.shape);\n    var u = l;\n    var c = Zr(u, o);\n    var h = r;\n    null != c && (h = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), u = ea(u.length, r.shape.length)), Jr(\"min\", u, o);\n    var [p, f] = Xr(h.shape, u),\n        g = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, d(f)]\n      }\n    }),\n        m = kv(g, g.dtype, \"min\", n);\n    var b;\n    return b = mv(i ? {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: Yr(p, l)\n      }\n    } : {\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    }), n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(m), null != c && n.disposeIntermediateTensorInfo(h), b;\n  }\n},\n    DS = {\n  kernelName: \"Minimum\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return min(a, b);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = vec4(min(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",\n    cpuKernelImpl: hw\n  })\n};\n\nclass _S {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Ck(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = [\"coords[0]\", \"coords[1]\", \"coords[2]\", \"coords[3]\"].slice(0, s),\n        l = \"reflect\" === n ? 0 : 1;\n    this.userCode = 1 !== s ? \"\\n      \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outC = getOutputCoords();\\n        for (int i = 0; i < \").concat(s, \"; i++) {\\n          if (outC[i] < start[i]) {\\n            outC[i] = start[i] * 2 - outC[i] - \").concat(l, \";\\n          } else if(outC[i] >= end[i]) {\\n            outC[i] = (end[i] - 1) * 2 - outC[i] + \").concat(l, \";\\n          }\\n        }\\n        \").concat(r, \" coords = outC - start;\\n        setOutput(getX(\").concat(o, \"));\\n      }\\n    \") : \"\\n        int start = \".concat(a, \";\\n        int end = \").concat(i, \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start) {\\n            outC = start * 2 - outC - \").concat(l, \";\\n          } else if(outC >= end) {\\n            outC = (end - 1) * 2 - outC + \").concat(l, \";\\n          }\\n          setOutput(getX(outC - start));\\n        }\\n      \");\n  }\n\n}\n\nclass OS {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Ck(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = Ow(\"rc\", s),\n        l = Ow(\"source\", s),\n        u = \"\".concat(o[s - 1], \" < \").concat(this.outputShape[s - 1]),\n        c = 1 === s ? \"source\" : \"vec2(\".concat(l.slice(-2).join(), \")\"),\n        h = \"reflect\" === n ? 0 : 1;\n    var d = \"\";\n\n    if (1 === s) {\n      var _e501 = \"\\n        \".concat(r, \" source = rc;\\n        if (source < start) {\\n          source = start * 2 - source - \").concat(h, \";\\n        } else if (source >= end) {\\n          source = (end - 1) * 2 - source + \").concat(h, \";\\n        }\\n        source -= start;\\n      \");\n\n      d = \"\\n        \".concat(r, \" rc = outputLoc;\\n        \").concat(_e501, \"\\n        result[0] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        \").concat(o[s - 1], \" += 1;\\n        if(\").concat(u, \") {\\n          \").concat(_e501, \"\\n          result[1] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n      \");\n    } else {\n      var _e502 = \"\\n        \".concat(r, \" source = rc;\\n        \").concat(r, \" lt = \").concat(r, \"(lessThan(source, start));\\n        \").concat(r, \" gte = \").concat(r, \"(greaterThanEqual(source, end));\\n        \").concat(r, \" orig = 1 - (lt + gte);\\n        source = orig * source +\\n                lt * (start * 2 - source - \").concat(h, \") +\\n                gte * ((end - 1) * 2 - source + \").concat(h, \");\\n        source -= start;\\n      \");\n\n      d = \"\\n        \".concat(r, \" rc = outputLoc;\\n        \").concat(_e502, \"\\n        result[0] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        \").concat(o[s - 1], \" += 1;\\n        if(\").concat(u, \") {\\n          \").concat(_e502, \"\\n          result[1] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n        rc = outputLoc;\\n        \").concat(o[s - 2], \" += 1;\\n        if(\").concat(o[s - 2], \" < \").concat(this.outputShape[s - 2], \") {\\n          \").concat(_e502, \"\\n          result[2] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n          \").concat(o[s - 1], \" += 1;\\n          if(\").concat(u, \") {\\n            \").concat(_e502, \"\\n            result[3] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n          }\\n        }\\n      \");\n    }\n\n    this.userCode = \"\\n      const \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      const \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \").concat(d, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar MS = {\n  kernelName: \"MirrorPad\",\n  backendName: \"webgl\",\n  kernelFunc: _ref31 => {\n    var {\n      inputs: e,\n      backend: t,\n      attrs: n\n    } = _ref31;\n    var {\n      x: s\n    } = e,\n        {\n      paddings: r,\n      mode: a\n    } = n,\n        i = G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new OS(s.shape, r, a) : new _S(s.shape, r, a);\n    return t.runWebGLProgram(i, [s], s.dtype);\n  }\n},\n    LS = {\n  kernelName: \"Mod\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"if (b == 0.0) return NAN;\\n  return mod(a, b);\",\n    packedOpSnippet: \"\\n  vec4 result = mod(a, b);\\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n};\n\nclass zS {\n  constructor(e, t, n) {\n    this.variableNames = [\"probs\"], this.customUniforms = [{\n      name: \"seed\",\n      type: \"float\"\n    }], this.outputShape = [e, n], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n\\n        float r = random(seed);\\n        float cdf = 0.0;\\n\\n        for (int i = 0; i < \".concat(t - 1, \"; i++) {\\n          cdf += getProbs(batch, i);\\n\\n          if (r < cdf) {\\n            setOutput(float(i));\\n            return;\\n          }\\n        }\\n\\n        // If no other event happened, last event happened.\\n        setOutput(float(\").concat(t - 1, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar BS = uv({\n  opSnippet: \"\\nif (a == b) {\\n  return 1.0;\\n};\\nreturn a / b;\",\n  packedOpSnippet: \"\\n  // vec4 one = vec4(equal(a, b));\\n  // return one + (vec4(1.0) - one) * a / b;\\n  vec4 result = a / b;\\n  if(a.x == b.x) {\\n    result.x = 1.;\\n  }\\n  if(a.y == b.y) {\\n    result.y = 1.;\\n  }\\n  if(a.z == b.z) {\\n    result.z = 1.;\\n  }\\n  if(a.w == b.w) {\\n    result.w = 1.;\\n  }\\n\\n  return result;\\n\",\n  checkOutOfBounds: !0\n}),\n    PS = {\n  kernelName: \"RealDiv\",\n  backendName: \"webgl\",\n  kernelFunc: BS\n},\n    WS = \"return a - b;\",\n    US = uv({\n  opSnippet: WS,\n  packedOpSnippet: WS,\n  supportsComplex: !0,\n  cpuKernelImpl: Ew\n}),\n    VS = {\n  kernelName: \"Sub\",\n  backendName: \"webgl\",\n  kernelFunc: US\n};\n\nfunction GS(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    logits: r\n  } = t,\n      {\n    dim: a\n  } = s,\n      i = y([a], r.shape),\n      o = wS({\n    inputs: {\n      x: r\n    },\n    backend: n,\n    attrs: {\n      reductionIndices: i,\n      keepDims: !1\n    }\n  }),\n      l = Yr(o.shape, i),\n      u = mv({\n    inputs: {\n      x: o\n    },\n    backend: n,\n    attrs: {\n      shape: l\n    }\n  }),\n      c = US({\n    inputs: {\n      a: r,\n      b: u\n    },\n    backend: n\n  }),\n      h = T$({\n    inputs: {\n      x: c\n    },\n    backend: n\n  }),\n      d = $v({\n    inputs: {\n      x: h\n    },\n    backend: n,\n    attrs: {\n      axis: i,\n      keepDims: !1\n    }\n  }),\n      p = mv({\n    inputs: {\n      x: d\n    },\n    backend: n,\n    attrs: {\n      shape: l\n    }\n  }),\n      f = BS({\n    inputs: {\n      a: h,\n      b: p\n    },\n    backend: n\n  });\n  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(c), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(p), f;\n}\n\nvar HS = {\n  kernelName: \"Softmax\",\n  backendName: \"webgl\",\n  kernelFunc: GS\n},\n    qS = {\n  kernelName: \"Multinomial\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      logits: r\n    } = t,\n        {\n      numSamples: a,\n      seed: i,\n      normalized: o\n    } = s,\n        l = o ? r : GS({\n      inputs: {\n        logits: r\n      },\n      backend: n,\n      attrs: {\n        dim: r.shape.length - 1\n      }\n    }),\n        u = new zS(l.shape[0], l.shape[1], a),\n        c = n.runWebGLProgram(u, [l], \"int32\", [[i]]);\n    return o || n.disposeIntermediateTensorInfo(l), c;\n  }\n},\n    jS = \"return -x;\",\n    KS = {\n  kernelName: \"Neg\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      x: s\n    } = t;\n\n    if (n.shouldExecuteOnCPU([s])) {\n      var _e503 = n.texData.get(s.dataId),\n          [_t410, _r170] = pw(_e503.values, s.shape, s.dtype);\n\n      return n.makeTensorInfo(_r170, s.dtype, _t410);\n    }\n\n    var r;\n    return r = G().getBool(\"WEBGL_PACK_UNARY_OPERATIONS\") ? new Gw(s.shape, jS) : new Uw(s.shape, jS), n.runWebGLProgram(r, [s], s.dtype);\n  }\n},\n    XS = Ki,\n    YS = {\n  kernelName: \"NonMaxSuppressionV3\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    W(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l\n    } = s,\n        u = n.readSync(r.dataId),\n        c = n.readSync(a.dataId),\n        {\n      selectedIndices: h\n    } = XS(u, c, i, o, l);\n    return n.makeTensorInfo([h.length], \"int32\", new Int32Array(h));\n  }\n},\n    JS = Xi,\n    ZS = {\n  kernelName: \"NonMaxSuppressionV4\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    W(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      padToMaxOutputSize: u\n    } = s,\n        c = n.readSync(r.dataId),\n        h = n.readSync(a.dataId),\n        {\n      selectedIndices: d,\n      validOutputs: p\n    } = JS(c, h, i, o, l, u);\n    return [n.makeTensorInfo([d.length], \"int32\", new Int32Array(d)), n.makeTensorInfo([], \"int32\", new Int32Array([p]))];\n  }\n},\n    QS = Yi,\n    eN = {\n  kernelName: \"NonMaxSuppressionV5\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    W(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\");\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      boxes: r,\n      scores: a\n    } = t,\n        {\n      maxOutputSize: i,\n      iouThreshold: o,\n      scoreThreshold: l,\n      softNmsSigma: u\n    } = s,\n        c = n.readSync(r.dataId),\n        h = n.readSync(a.dataId),\n        d = i,\n        p = o,\n        f = l,\n        g = u,\n        {\n      selectedIndices: m,\n      selectedScores: b\n    } = QS(c, h, d, p, f, g);\n    return [n.makeTensorInfo([m.length], \"int32\", new Int32Array(m)), n.makeTensorInfo([b.length], \"float32\", new Float32Array(b))];\n  }\n};\n\nclass tN {\n  constructor(e, t, n, s) {\n    this.variableNames = [\"indices\"], this.outputShape = [e, t], this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int index = round(getIndices(coords.x));\\n        setOutput(mix(float(\".concat(s, \"), float(\").concat(n, \"),\\n                      float(index == coords.y)));\\n      }\\n    \");\n  }\n\n}\n\nvar nN = {\n  kernelName: \"OneHot\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r\n    } = t,\n        {\n      depth: a,\n      onValue: i,\n      offValue: o\n    } = s,\n        l = d(r.shape),\n        u = new tN(l, a, i, o),\n        c = mv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [l]\n      }\n    }),\n        h = n.runWebGLProgram(u, [c], r.dtype);\n    n.disposeIntermediateTensorInfo(c);\n    var p = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [...r.shape, a]\n      }\n    });\n    return n.disposeIntermediateTensorInfo(h), p;\n  }\n};\n\nfunction sN(e) {\n  var {\n    inputs: t,\n    backend: n\n  } = e,\n      {\n    x: s\n  } = t;\n\n  if (\"complex64\" === s.dtype) {\n    var _e504 = kI({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _t411 = sN({\n      inputs: {\n        x: _e504\n      },\n      backend: n\n    }),\n        _r171 = _I({\n      inputs: {\n        input: s\n      },\n      backend: n\n    }),\n        _a139 = sN({\n      inputs: {\n        x: _r171\n      },\n      backend: n\n    }),\n        _i99 = ev({\n      inputs: {\n        real: _t411,\n        imag: _a139\n      },\n      backend: n\n    });\n\n    return n.disposeIntermediateTensorInfo(_e504), n.disposeIntermediateTensorInfo(_t411), n.disposeIntermediateTensorInfo(_r171), n.disposeIntermediateTensorInfo(_a139), _i99;\n  }\n\n  return z$({\n    attrs: {\n      shape: s.shape,\n      dtype: s.dtype,\n      value: \"string\" === s.dtype ? \"\" : 0\n    },\n    backend: n\n  });\n}\n\nvar rN = {\n  kernelName: \"ZerosLike\",\n  backendName: \"webgl\",\n  kernelFunc: sN\n},\n    aN = {\n  kernelName: \"OnesLike\",\n  backendName: \"webgl\",\n  kernelFunc: function e(t) {\n    var {\n      inputs: n,\n      backend: s\n    } = t,\n        {\n      x: r\n    } = n;\n    if (\"string\" === r.dtype) throw new Error(\"onesLike is not supported under string dtype\");\n\n    if (\"complex64\" === r.dtype) {\n      var _t412 = kI({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _n289 = e({\n        inputs: {\n          x: _t412\n        },\n        backend: s\n      }),\n          _a140 = _I({\n        inputs: {\n          input: r\n        },\n        backend: s\n      }),\n          _i100 = sN({\n        inputs: {\n          x: _a140\n        },\n        backend: s\n      }),\n          _o74 = ev({\n        inputs: {\n          real: _n289,\n          imag: _i100\n        },\n        backend: s\n      });\n\n      return s.disposeIntermediateTensorInfo(_t412), s.disposeIntermediateTensorInfo(_n289), s.disposeIntermediateTensorInfo(_a140), s.disposeIntermediateTensorInfo(_i100), _o74;\n    }\n\n    return z$({\n      attrs: {\n        shape: r.shape,\n        dtype: r.dtype,\n        value: 1\n      },\n      backend: s\n    });\n  }\n},\n    iN = {\n  kernelName: \"Pack\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      axis: r\n    } = s;\n    if (1 === t.length) return R$({\n      inputs: {\n        input: t[0]\n      },\n      backend: n,\n      attrs: {\n        dim: r\n      }\n    });\n    var a = t[0].shape,\n        i = t[0].dtype;\n    t.forEach(e => {\n      u(a, e.shape, \"All tensors passed to stack must have matching shapes\"), l(i === e.dtype, () => \"All tensors passed to stack must have matching dtypes\");\n    });\n    var o = [],\n        c = LI({\n      inputs: t.map(e => {\n        var t = R$({\n          inputs: {\n            input: e\n          },\n          backend: n,\n          attrs: {\n            dim: r\n          }\n        });\n        return o.push(t), t;\n      }),\n      backend: n,\n      attrs: {\n        axis: r\n      }\n    });\n    return o.forEach(e => n.disposeIntermediateTensorInfo(e)), c;\n  }\n};\n\nclass oN {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Ck(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = [\"coords[0]\", \"coords[1]\", \"coords[2]\", \"coords[3]\"].slice(0, s);\n    this.userCode = 1 !== s ? \"\\n      \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outC = getOutputCoords();\\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\\n          setOutput(value);\\n        } else {\\n          \").concat(r, \" coords = outC - start;\\n          setOutput(getX(\").concat(o, \"));\\n        }\\n      }\\n    \") : \"\\n        int start = \".concat(a, \";\\n        int end = \").concat(i, \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start || outC >= end) {\\n            setOutput(value);\\n          } else {\\n            setOutput(getX(outC - start));\\n          }\\n        }\\n      \");\n  }\n\n}\n\nclass lN {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{\n      name: \"value\",\n      type: \"float\"\n    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);\n    var s = e.length,\n        r = Ck(s),\n        a = t.map(e => e[0]).join(\",\"),\n        i = t.map((t, n) => t[0] + e[n]).join(\",\"),\n        o = Ow(\"rc\", s),\n        l = Ow(\"source\", s),\n        u = \"\".concat(o[s - 1], \" < \").concat(this.outputShape[s - 1]),\n        c = 1 === s ? \"source\" : \"vec2(\".concat(l.slice(-2).join(), \")\"),\n        h = [\"\".concat(r, \" rc = outputLoc;\"), \"\".concat(o[s - 1], \" += 1;\\n       if(\").concat(u, \") {\\n      \"), 1 === s ? \"\" : \"}\\n       rc = outputLoc;\\n       \".concat(o[s - 2], \" += 1;\\n       if(\").concat(o[s - 2], \" < \").concat(this.outputShape[s - 2], \") {\"), 1 === s ? \"\" : \"  \".concat(o[s - 1], \" += 1;\\n         if(\").concat(u, \") {\")],\n        d = 1 === s ? \"rc < start || rc >= end\" : \"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))\";\n    var p = \"\";\n\n    for (var _e505 = 0, _t413 = 1 === s ? 2 : 4; _e505 < _t413; _e505++) {\n      p += \"\\n        \".concat(h[_e505], \"\\n        if (\").concat(d, \") {\\n          result[\").concat(_e505, \"] = float(value);\\n        } else {\\n          \").concat(r, \" source = rc - start;\\n          result[\").concat(_e505, \"] = getChannel(getX(\").concat(l.join(), \"), \").concat(c, \");\\n        }\\n      \");\n    }\n\n    p += 1 === s ? \"} \" : \"}}\", this.userCode = \"\\n      const \".concat(r, \" start = \").concat(r, \"(\").concat(a, \");\\n      const \").concat(r, \" end = \").concat(r, \"(\").concat(i, \");\\n\\n      void main() {\\n        \").concat(r, \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \").concat(p, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}\n\nvar uN = e => {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    paddings: a,\n    constantValue: i\n  } = s;\n  if (0 === d(r.shape)) return z$({\n    backend: n,\n    attrs: {\n      shape: a.map((e, t) => e[0] + r.shape[t] + e[1]),\n      value: i,\n      dtype: r.dtype\n    }\n  });\n  var o = G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new lN(r.shape, a, i) : new oN(r.shape, a, i);\n  return n.runWebGLProgram(o, [r], r.dtype, [[i]]);\n},\n    cN = {\n  kernelName: \"PadV2\",\n  backendName: \"webgl\",\n  kernelFunc: uN\n},\n    hN = {\n  kernelName: \"Pow\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"\\n  if(a < 0.0 && floor(b) < b){\\n    return NAN;\\n  }\\n  if (b == 0.0) {\\n    return 1.0;\\n  }\\n  return (round(mod(b, 2.0)) != 1) ?\\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\",\n    packedOpSnippet: \"\\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\\n  vec4 result = multiplier * pow(abs(a), b);\\n\\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\\n  bvec4 isExpZero = equal(b, vec4(0.0));\\n  result.r = isExpZero.r ? 1.0 : result.r;\\n  result.g = isExpZero.g ? 1.0 : result.g;\\n  result.b = isExpZero.b ? 1.0 : result.b;\\n  result.a = isExpZero.a ? 1.0 : result.a;\\n\\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    dN = {\n  kernelName: \"Prod\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      axis: a,\n      keepDims: i\n    } = s,\n        o = r.shape.length,\n        l = [],\n        u = y(a, r.shape);\n    var c = u;\n    var h = Zr(c, o);\n    var p,\n        f = r;\n\n    if (null != h && (f = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: h\n      }\n    }), c = ea(c.length, o), l.push(f)), Jr(\"prod\", c, o), n.shouldExecuteOnCPU([f])) {\n      var _e506 = n.texData.get(f.dataId).values,\n          {\n        outVals: _t414,\n        outShape: _s233,\n        outDtype: _r172\n      } = gw(f.shape, f.dtype, _e506, c);\n      p = n.makeTensorInfo(_s233, _r172, _t414);\n    } else {\n      var [_e507, _t415] = Xr(f.shape, c),\n          _s234 = d(_t415),\n          _a141 = mv({\n        inputs: {\n          x: f\n        },\n        backend: n,\n        attrs: {\n          shape: [-1, _s234]\n        }\n      }),\n          _i101 = kv(_a141, ft(r.dtype), \"prod\", n);\n\n      p = mv({\n        inputs: {\n          x: _i101\n        },\n        backend: n,\n        attrs: {\n          shape: _e507\n        }\n      }), l.push(_a141), l.push(_i101);\n    }\n\n    if (i) {\n      l.push(p);\n\n      var _e508 = Yr(p.shape, u);\n\n      p = mv({\n        inputs: {\n          x: p\n        },\n        backend: n,\n        attrs: {\n          shape: _e508\n        }\n      });\n    }\n\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;\n  }\n},\n    pN = e => {\n  var {\n    backend: t,\n    attrs: n\n  } = e,\n      {\n    start: s,\n    stop: r,\n    step: a,\n    dtype: i\n  } = n,\n      o = mw(s, r, a, i);\n  return t.makeTensorInfo([o.length], i, o);\n},\n    fN = {\n  kernelName: \"Range\",\n  backendName: \"webgl\",\n  kernelFunc: pN\n},\n    gN = {\n  kernelName: \"Reciprocal\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return 1.0 / x;\"\n  })\n},\n    mN = {\n  kernelName: \"Relu\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : x;\\n\",\n    packedOpSnippet: \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\"\n  })\n},\n    bN = {\n  kernelName: \"Relu6\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return (x < 0.0) ? 0.0 : min(6.0, x);\\n\",\n    packedOpSnippet: \"\\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\"\n  })\n};\n\nclass xN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)\" : \"vec2(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec2 inputShapeRC = vec2(\").concat(i, \".0, \").concat(o, \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the four integer indices.\\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\\n        ivec2 sourceCeilRC = ivec2(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\\n\\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\\n\\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\\n        float newValue = top + (bottom - top) * fracRC.x;\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nclass yN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)\" : \"vec3(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec3 inputShapeRC = vec3(\").concat(i, \".0, \").concat(o, \".0,\\n                                     \").concat(o, \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the four integer indices.\\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\\n        ivec3 sourceCeilRC = ivec3(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \").concat(l - 1, \";\\n        bool hasNextRow = coords.z < \").concat(n - 1, \";\\n\\n        // In parallel, construct four corners for all four components in\\n        // packed 2x2 cell.\\n        vec4 topLeft = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomLeft = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 topRight = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomRight = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\\n\\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\\n        vec4 newValue = mix(top, bottom, fracRC.x);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nvar kN = {\n  kernelName: \"ResizeBilinear\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s,\n        [l, u] = o,\n        c = G().getBool(\"WEBGL_PACK_IMAGE_OPERATIONS\") ? new yN(r.shape, l, u, a, i) : new xN(r.shape, l, u, a, i);\n    return n.runWebGLProgram(c, [r], \"float32\");\n  }\n};\n\nclass wN {\n  constructor(e, t, n) {\n    this.variableNames = [\"dy\"], this.outputShape = [], this.outputShape = t;\n    var [, s, r] = t,\n        [, a, i] = e,\n        o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r],\n        l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i],\n        u = o[0] / l[0],\n        c = o[1] / l[1],\n        h = 1 / u,\n        d = 1 / c,\n        p = 2 * Math.ceil(h) + 2,\n        f = 2 * Math.ceil(d) + 2;\n    this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\".concat(u, \");\\n        const float widthScale = float(\").concat(c, \");\\n\\n        const float invHeightScale = float(\").concat(h, \");\\n        const float invWidthScale = float(\").concat(d, \");\\n\\n        const int winHeight = int(\").concat(p, \");\\n        const int winWidth = int(\").concat(f, \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(startRLerp - float(winHeight / 2));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(startCLerp - float(winWidth / 2));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \").concat(a, \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \").concat(i, \") {\\n              continue;\\n            }\\n\\n            float dxR = float(dyR) * heightScale;\\n            int topDxRIndex = int(floor(dxR));\\n            int bottomDxRIndex = int(min(ceil(dxR), \").concat(s - 1, \".0));\\n            float dxRLerp = dxR - float(topDxRIndex);\\n            float inverseDxRLerp = 1.0 - dxRLerp;\\n\\n            float dxC = float(dyC) * widthScale;\\n            int leftDxCIndex = int(floor(dxC));\\n            int rightDxCIndex = int(min(ceil(dxC), \").concat(r - 1, \".0));\\n            float dxCLerp = dxC - float(leftDxCIndex);\\n            float inverseDxCLerp = 1.0 - dxCLerp;\\n\\n            if (r == topDxRIndex && c == leftDxCIndex) {\\n              // topLeft\\n              accumulator +=\\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == topDxRIndex && c == rightDxCIndex) {\\n              // topRight\\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\\n              // bottomLeft\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\\n              // bottomRight\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \");\n  }\n\n}\n\nvar vN = {\n  kernelName: \"ResizeBilinearGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s,\n        o = new wN(a.shape, r.shape, i);\n    return n.runWebGLProgram(o, [a], a.dtype);\n  }\n};\n\nclass IN {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))\" : \"vec2(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec2 inputShapeRC = vec2(\").concat(i, \".0, \").concat(o, \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec2 sourceNearestRC = ivec2(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \").concat(s ? \"0.5\" : \"0.0\", \")));\\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nclass $N {\n  constructor(e, t, n, s, r) {\n    this.variableNames = [\"A\"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];\n    var [a, i, o, l] = e;\n    this.outputShape = [a, t, n, l];\n    var u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o],\n        c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];\n    var h;\n    h = r ? \"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))\" : \"vec3(yRC) * effectiveInputOverOutputRatioRC\", this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \".concat(u[0] / c[0], \",\\n          \").concat(u[1] / c[1], \",\\n          \").concat(u[1] / c[1], \");\\n      const vec3 inputShapeRC = vec3(\").concat(i, \".0, \").concat(o, \".0,\\n                                     \").concat(o, \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = \").concat(h, \";\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec3 sourceNearestRC = ivec3(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \").concat(s ? \"0.5\" : \"0.0\", \")));\\n\\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \").concat(l - 1, \";\\n        bool hasNextRow = coords.z < \").concat(n - 1, \";\\n\\n        vec4 newValue = vec4(\\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\\n\\n        setOutput(newValue);\\n      }\\n    \");\n  }\n\n}\n\nvar SN = {\n  kernelName: \"ResizeNearestNeighbor\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r\n    } = t,\n        {\n      alignCorners: a,\n      halfPixelCenters: i,\n      size: o\n    } = s,\n        [l, u] = o,\n        c = G().getBool(\"WEBGL_PACK_IMAGE_OPERATIONS\") ? new $N(r.shape, l, u, a, i) : new IN(r.shape, l, u, a, i);\n    return n.runWebGLProgram(c, [r], r.dtype);\n  }\n};\n\nclass NN {\n  constructor(e, t, n) {\n    this.variableNames = [\"dy\"], this.outputShape = [], this.outputShape = t;\n    var [, s, r] = t,\n        [, a, i] = e,\n        o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r],\n        l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i],\n        u = o[0] / l[0],\n        c = o[1] / l[1],\n        h = 1 / u,\n        d = 1 / c,\n        p = 2 * Math.ceil(h) + 2,\n        f = 2 * Math.ceil(d) + 2;\n    this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\".concat(u, \");\\n        const float widthScale = float(\").concat(c, \");\\n\\n        const float invHeightScale = float(\").concat(h, \");\\n        const float invWidthScale = float(\").concat(d, \");\\n\\n        const int winHeight = int(\").concat(p, \");\\n        const int winWidth = int(\").concat(f, \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \").concat(a, \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \").concat(i, \") {\\n              continue;\\n            }\\n\\n            float sourceFracRow =\\n              float(\").concat(o[0], \") *\\n                (float(dyR) / float(\").concat(l[0], \"));\\n\\n            float sourceFracCol =\\n                float(\").concat(o[1], \") *\\n                  (float(dyC) / float(\").concat(l[1], \"));\\n\\n            int sourceNearestRow = int(min(\\n                float(int(\").concat(s, \") - 1),\\n                \").concat(n, \" ? float(round(sourceFracRow)) :\\n                                  float(floor(sourceFracRow))));\\n\\n            int sourceNearestCol = int(min(\\n                float(int(\").concat(r, \") - 1),\\n                \").concat(n, \" ? float(round(sourceFracCol)) :\\n                                  float(floor(sourceFracCol))));\\n\\n            if (r == sourceNearestRow && c == sourceNearestCol) {\\n              accumulator += getDy(b, dyR, dyC, d);\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \");\n  }\n\n}\n\nvar CN = {\n  kernelName: \"ResizeNearestNeighborGrad\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      images: r,\n      dy: a\n    } = t,\n        {\n      alignCorners: i\n    } = s,\n        o = new NN(a.shape, r.shape, i);\n    return n.runWebGLProgram(o, [a], a.dtype);\n  }\n};\n\nclass TN {\n  constructor(e, t) {\n    this.variableNames = [\"x\"];\n    var n = e.length;\n    if (n > 4) throw new Error(\"WebGL backend: Reverse of rank-\".concat(n, \" tensor is not yet supported\"));\n    if (this.outputShape = e, 1 === n) return void (this.userCode = \"\\n        void main() {\\n          int coord = getOutputCoords();\\n          setOutput(getX(\".concat(e[0], \" - coord - 1));\\n        }\\n      \"));\n    var s = e.map((n, s) => (n => -1 !== t.indexOf(n) && 1 !== e[n] ? \"\".concat(e[n], \" - coords[\").concat(n, \"] - 1\") : \"coords[\".concat(n, \"]\"))(s)).join(\",\"),\n        r = Ck(n);\n    this.userCode = \"\\n      void main() {\\n        \".concat(r, \" coords = getOutputCoords();\\n        setOutput(getX(\").concat(s, \"));\\n      }\\n    \");\n  }\n\n}\n\nclass EN {\n  constructor(e, t) {\n    this.variableNames = [\"x\"], this.packedInputs = !0, this.packedOutput = !0;\n    var n = e.length;\n    if (n > 4) throw new Error(\"WebGL backend: Reverse of rank-\".concat(n, \" tensor is not yet supported\"));\n    this.outputShape = e;\n    var s = Ow(\"rc\", n),\n        r = \"\".concat(s[n - 1], \" + 1 < \").concat(this.outputShape[n - 1]),\n        a = \"\".concat(s[n - 2], \" + 1 < \").concat(this.outputShape[n - 2]),\n        i = Ck(n);\n\n    function o(n) {\n      var s = e.map((s, r) => function (n, s) {\n        return -1 !== t.indexOf(n) && 1 !== e[n] ? \"\".concat(e[n], \" - \").concat(s[n], \" - 1\") : \"\".concat(s[n]);\n      }(r, n));\n      return \"getChannel(getX(\".concat(s.join(\",\"), \"), vec2(\").concat(s.slice(-2).join(\",\"), \"))\");\n    }\n\n    this.userCode = 1 === n ? \"\\n        void main(){\\n          int rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = getChannel(getX(\".concat(e[0], \" - rc - 1),\\n            \").concat(e[0], \" - rc - 1);\\n          if(\").concat(r, \"){\\n              result.g = getChannel(getX(\").concat(e[0], \" - (rc  + 1) - 1),\\n                \").concat(e[0], \" - (rc  + 1) - 1);\\n          }\\n          setOutput(result);\\n        }\\n      \") : \"\\n        void main() {\\n          \".concat(i, \" rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = \").concat(function (e) {\n      return o(e);\n    }(s.slice()), \";\\n          if(\").concat(r, \"){\\n            result.g = \").concat(function (e) {\n      return e[n - 1] = \"(\" + e[n - 1] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n          }\\n          if(\").concat(a, \") {\\n            result.b = \").concat(function (e) {\n      return e[n - 2] = \"(\" + e[n - 2] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n            if(\").concat(r, \") {\\n              result.a = \").concat(function (e) {\n      return e[n - 1] = \"(\" + e[n - 1] + \" + 1)\", e[n - 2] = \"(\" + e[n - 2] + \" + 1)\", o(e);\n    }(s.slice()), \";\\n            }\\n          }\\n          setOutput(result);\\n        }\\n    \");\n  }\n\n}\n\nvar RN = {\n  kernelName: \"Reverse\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      dims: a\n    } = s,\n        i = r.shape.length,\n        o = y(a, r.shape);\n    if (0 === i) return Zw({\n      inputs: {\n        x: r\n      },\n      backend: n\n    });\n    var l = G().getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\") ? new EN(r.shape, o) : new TN(r.shape, o);\n    return n.runWebGLProgram(l, [r], r.dtype);\n  }\n};\n\nclass AN {\n  constructor(e, t) {\n    this.variableNames = [\"Image\"], this.outputShape = [], this.customUniforms = [{\n      name: \"params\",\n      type: \"vec4\"\n    }];\n    var n = e[1],\n        s = e[2];\n    this.outputShape = e;\n    var r = \"\";\n    r = \"number\" == typeof t ? \"float outputValue = \".concat(t.toFixed(2), \";\") : \"\\n        vec3 fill = vec3(\".concat(t.join(\",\"), \");\\n        float outputValue = fill[coords[3]];\"), this.userCode = \"\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int x = coords[2];\\n          int y = coords[1];\\n          float coordXFloat = (float(x) - params[0]) * params[3] -\\n            (float(y) - params[1]) * params[2];\\n          float coordYFloat = (float(x) - params[0]) * params[2] +\\n            (float(y) - params[1]) * params[3];\\n          int coordX = int(round(coordXFloat + params[0]));\\n          int coordY = int(round(coordYFloat + params[1]));\\n          \".concat(r, \"\\n          if(coordX >= 0 && coordX < \").concat(s, \" && coordY >= 0 && coordY < \").concat(n, \") {\\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\\n          }\\n          setOutput(outputValue);\\n        }\\n    \");\n  }\n\n}\n\nvar FN = {\n  kernelName: \"RotateWithOffset\",\n  backendName: \"webgl\",\n  kernelFunc: _ref32 => {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref32;\n    var {\n      image: s\n    } = e,\n        {\n      radians: r,\n      fillValue: a,\n      center: i\n    } = t,\n        o = n,\n        l = new AN(s.shape, a),\n        [u, c] = Ao(i, s.shape[1], s.shape[2]),\n        h = [[u, c, Math.sin(r), Math.cos(r)]];\n    return o.runWebGLProgram(l, [s], s.dtype, h);\n  }\n},\n    DN = {\n  kernelName: \"Round\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  // OpenGL ES does not support round function.\\n  // The algorithm is based on banker's rounding.\\n  float base = floor(x);\\n  if ((x - base) < 0.5) {\\n    return floor(x);\\n  } else if ((x - base) > 0.5) {\\n    return ceil(x);\\n  } else {\\n    if (mod(base, 2.0) == 0.0) {\\n      return base;\\n    } else {\\n      return base + 1.0;\\n    }\\n  }\\n\"\n  })\n},\n    _N = {\n  kernelName: \"Rsqrt\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return inversesqrt(x);\",\n    cpuKernelImpl: bw\n  })\n};\n\nclass ON {\n  constructor(e, t, n, s, r, a) {\n    var i = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !0;\n    this.variableNames = [\"updates\", \"indices\", \"defaultValue\"], this.outputShape = a;\n    var o = Ck(r.length),\n        l = Ck(a.length);\n    var u = \"\";\n    1 === n ? u = \"i\" : 2 === n && (u = \"i, j\");\n    var c = \"\";\n    1 === s ? c = \"i\" : 2 === s && (c = \"i, coords[1]\"), this.userCode = \"\\n        \".concat(o, \" strides = \").concat(o, \"(\").concat(r, \");\\n\\n        void main() {\\n          \").concat(l, \" coords = getOutputCoords();\\n          float sum = 0.0;\\n          bool found = false;\\n          for (int i = 0; i < \").concat(e, \"; i++) {\\n            int flattenedIndex = 0;\\n            for (int j = 0; j < \").concat(t, \"; j++) {\\n              int index = round(getIndices(\").concat(u, \"));\\n              flattenedIndex += index * \").concat(t > 1 ? \"strides[j]\" : \"strides\", \";\\n            }\\n            if (flattenedIndex == coords[0]) {\\n              sum += getUpdates(\").concat(c, \");\\n              found = true;\\n            }\\n          }\\n          setOutput(mix(getDefaultValue(), sum, float(found)));\\n        }\\n      \");\n  }\n\n}\n\nvar MN = {\n  kernelName: \"ScatterNd\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      indices: r,\n      updates: a\n    } = t,\n        {\n      shape: i\n    } = s,\n        {\n      sliceRank: o,\n      numUpdates: l,\n      sliceSize: u,\n      strides: c,\n      outputSize: h\n    } = Tn(0, r, i),\n        d = [h / u, u];\n    if (0 === h) return n.makeTensorInfo(i, r.dtype);\n    var p = mv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: [l, o]\n      }\n    }),\n        f = mv({\n      inputs: {\n        x: a\n      },\n      backend: n,\n      attrs: {\n        shape: [l, u]\n      }\n    }),\n        g = n.makeTensorInfo([], \"float32\", new Float32Array([0])),\n        m = new ON(l, o, p.shape.length, f.shape.length, c, d),\n        b = n.runWebGLProgram(m, [f, p, g], f.dtype),\n        x = mv({\n      inputs: {\n        x: b\n      },\n      backend: n,\n      attrs: {\n        shape: i\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(f), n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(g), x;\n  }\n};\n\nclass LN {\n  constructor(e, t, n) {\n    var s, r;\n    if (this.variableNames = [\"c\", \"a\", \"b\"], this.outputShape = t, n > 4) throw Error(\"Where for rank \".concat(n, \" is not yet supported\"));\n    if (1 === n) r = \"resRC\", s = \"resRC\";else {\n      var _n290 = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\"],\n          _a142 = [],\n          _i102 = [];\n\n      for (var _s235 = 0; _s235 < t.length; _s235++) {\n        _i102.push(\"\".concat(_n290[_s235])), _s235 < e && _a142.push(\"\".concat(_n290[_s235]));\n      }\n\n      s = _a142.join(), r = _i102.join();\n    }\n    var a = Ck(n);\n    this.userCode = \"\\n      void main() {\\n        \".concat(a, \" resRC = getOutputCoords();\\n        float cVal = getC(\").concat(s, \");\\n        if (cVal >= 1.0) {\\n          setOutput(getA(\").concat(r, \"));\\n        } else {\\n          setOutput(getB(\").concat(r, \"));\\n        }\\n      }\\n    \");\n  }\n\n}\n\nvar zN = {\n  kernelName: \"Select\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      condition: s,\n      t: r,\n      e: a\n    } = t,\n        i = new LN(s.shape.length, r.shape, r.shape.length);\n    return n.runWebGLProgram(i, [s, r, a], pt(r.dtype, a.dtype));\n  }\n},\n    BN = {\n  kernelName: \"Selu\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\\n  // see: https://arxiv.org/abs/1706.02515\\n  float scaleAlpha = 1.7580993408473768;\\n  float scale = 1.0507009873554805;\\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\\n\"\n  })\n},\n    PN = \"return 1.0 / (1.0 + exp(-1.0 * x));\",\n    WN = {\n  kernelName: \"Sigmoid\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: PN,\n    packedOpSnippet: PN,\n    cpuKernelImpl: xw\n  })\n},\n    UN = {\n  kernelName: \"Sign\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  if (isnan(x)) { return 0.0; }\\n  return sign(x);\\n\"\n  })\n},\n    VN = {\n  kernelName: \"Sin\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"if (isnan(x)) return x;\\n  return sin(x);\\n\"\n  })\n},\n    GN = {\n  kernelName: \"Sinh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  float e2x = exp(x);\\n  return (e2x - 1.0 / e2x) / 2.0;\\n\"\n  })\n},\n    HN = {\n  kernelName: \"Softplus\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  float epsilon = 1.1920928955078125e-7;\\n  float threshold = log(epsilon) + 2.0;\\n\\n  bool too_large = x > -threshold;\\n  bool too_small = x < threshold;\\n\\n  float result;\\n  float exp_x = exp(x);\\n\\n  if (too_large){\\n    result = x;\\n  }\\n  else if (too_small){\\n    result = exp_x;\\n  }\\n  else{\\n    result = log(exp_x + 1.0);\\n  }\\n  return result;\\n\"\n  })\n},\n    qN = {\n  kernelName: \"SpaceToBatchND\",\n  backendName: \"webgl\",\n  kernelFunc: e => {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      blockShape: a,\n      paddings: i\n    } = s;\n    l(r.shape.length <= 4, () => \"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet\");\n    var o = a.reduce((e, t) => e * t),\n        u = [[0, 0]];\n    u.push(...i);\n\n    for (var _e509 = 1 + a.length; _e509 < r.shape.length; ++_e509) {\n      u.push([0, 0]);\n    }\n\n    var c = [],\n        h = uN({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        paddings: u,\n        constantValue: 0\n      }\n    }),\n        d = Fo(h.shape, a, o, !1),\n        p = Do(d.length, a.length, !1),\n        f = _o(h.shape, a, o, !1),\n        g = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: d\n      }\n    }),\n        m = Nv({\n      inputs: {\n        x: g\n      },\n      backend: n,\n      attrs: {\n        perm: p\n      }\n    }),\n        b = mv({\n      inputs: {\n        x: m\n      },\n      backend: n,\n      attrs: {\n        shape: f\n      }\n    });\n\n    return c.push(h), c.push(g), c.push(m), c.forEach(e => n.disposeIntermediateTensorInfo(e)), b;\n  }\n},\n    jN = {\n  kernelName: \"SparseFillEmptyRows\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      indices: s,\n      values: r,\n      denseShape: a,\n      defaultValue: i\n    } = t;\n    if (1 !== a.shape.length) throw new Error(\"Dense shape must be a vector, saw:\\n         \".concat(a.shape));\n    if (2 !== s.shape.length) throw new Error(\"Indices must be a matrix, saw:\\n         \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Values must be a vector, saw:\\n         \".concat(r.shape));\n    if (0 !== i.shape.length) throw new Error(\"Default value must be a scalar, saw:\\n        \".concat(i.shape));\n    var o = n.readSync(s.dataId),\n        l = n.readSync(r.dataId),\n        u = n.readSync(a.dataId),\n        c = n.readSync(i.dataId)[0],\n        [h, d, p, f, g] = ww(o, s.shape, s.dtype, l, r.dtype, u, c);\n    return [n.makeTensorInfo(d, s.dtype, h), n.makeTensorInfo([d[0]], r.dtype, p), n.makeTensorInfo([f.length], \"bool\", new Uint8Array(f.map(e => Number(e)))), n.makeTensorInfo([g.length], s.dtype, new Int32Array(g))];\n  }\n},\n    KN = {\n  kernelName: \"SparseReshape\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      inputIndices: s,\n      inputShape: r,\n      newShape: a\n    } = t;\n    if (2 !== s.shape.length) throw new Error(\"Input indices should be a matrix but received shape \".concat(s.shape));\n    if (1 !== r.shape.length) throw new Error(\"Input shape should be a vector but received shape \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Target shape should be a vector but received shape \".concat(a.shape));\n    var i = Array.from(n.readSync(r.dataId)),\n        o = n.readSync(s.dataId),\n        l = Array.from(n.readSync(a.dataId)),\n        [u, c, h] = vw(o, s.shape, s.dtype, i, l);\n    return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))];\n  }\n},\n    XN = {\n  kernelName: \"SparseSegmentMean\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n              \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n              \".concat(a.shape));\n    var i = n.readSync(s.dataId),\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        [u, c] = Iw(i, s.shape, s.dtype, o, l, !0);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    YN = {\n  kernelName: \"SparseSegmentSum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n\n    } = e,\n        {\n      data: s,\n      indices: r,\n      segmentIds: a\n    } = t;\n    if (s.shape.length < 1) throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    if (1 !== r.shape.length) throw new Error(\"Indices should be a vector but received shape\\n             \".concat(r.shape));\n    if (1 !== a.shape.length) throw new Error(\"Segment ids should be a vector but received shape\\n             \".concat(a.shape));\n    var i = n.readSync(s.dataId),\n        o = n.readSync(r.dataId),\n        l = n.readSync(a.dataId),\n        [u, c] = Iw(i, s.shape, s.dtype, o, l);\n    return n.makeTensorInfo(c, s.dtype, u);\n  }\n},\n    JN = {\n  kernelName: \"SparseToDense\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      sparseIndices: r,\n      sparseValues: a,\n      defaultValue: i\n    } = t,\n        {\n      outputShape: o\n    } = s,\n        {\n      sliceRank: l,\n      numUpdates: u,\n      strides: c,\n      outputSize: h\n    } = Tn(0, r, o),\n        d = new ON(u, l, r.shape.length, a.shape.length, c, [h, 1], !1),\n        p = n.runWebGLProgram(d, [a, r, i], a.dtype),\n        f = mv({\n      inputs: {\n        x: p\n      },\n      backend: n,\n      attrs: {\n        shape: o\n      }\n    });\n    return n.disposeIntermediateTensorInfo(p), f;\n  }\n},\n    ZN = {\n  kernelName: \"SplitV\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      numOrSizeSplits: a,\n      axis: i\n    } = s,\n        o = y(i, r.shape)[0],\n        l = Zo(r, a, o),\n        u = new Array(r.shape.length).fill(0),\n        c = r.shape.slice();\n    return l.map(e => {\n      var t = [...c];\n      t[o] = e;\n      var s = fI({\n        inputs: {\n          x: r\n        },\n        backend: n,\n        attrs: {\n          begin: u,\n          size: t\n        }\n      });\n      return u[o] += e, s;\n    });\n  }\n},\n    QN = \"return sqrt(x);\",\n    eC = {\n  kernelName: \"Sqrt\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: QN,\n    packedOpSnippet: QN,\n    cpuKernelImpl: $w\n  })\n},\n    tC = {\n  kernelName: \"Square\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return x * x;\"\n  })\n},\n    nC = {\n  kernelName: \"SquaredDifference\",\n  backendName: \"webgl\",\n  kernelFunc: uv({\n    opSnippet: \"return (a - b) * (a - b);\",\n    packedOpSnippet: \"return (a - b) * (a - b);\"\n  })\n},\n    sC = {\n  kernelName: \"Step\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(_ref33) {\n    var {\n      inputs: e,\n      attrs: t,\n      backend: n\n    } = _ref33;\n    var {\n      x: s\n    } = e,\n        r = new Uw(s.shape, \"if (isnan(x)) return x;\\n    return x > 0.0 ? 1.0 : float(\".concat(t.alpha, \");\\n  \"));\n    return n.runWebGLProgram(r, [s], s.dtype);\n  }\n};\n\nclass rC {\n  constructor(e, t, n) {\n    this.variableNames = [\"x\"], this.outputShape = n;\n    var s = n.length,\n        r = Ck(n.length),\n        a = Ck(n.length);\n    var i = \"\";\n    if (1 === s) i = \"coords * strides + begin\";else {\n      var _e510 = 0;\n      i = n.map((t, s) => (_e510++, 1 === n.length ? \"coords * strides[\".concat(s, \"] + begin[\").concat(s, \"]\") : \"coords[\".concat(_e510 - 1, \"] * strides[\").concat(s, \"] + begin[\").concat(s, \"]\"))).join(\",\");\n    }\n    this.userCode = \"\\n      \".concat(r, \" begin = \").concat(r, \"(\").concat(e, \");\\n      \").concat(r, \" strides = \").concat(r, \"(\").concat(t, \");\\n\\n      void main() {\\n        \").concat(a, \" coords = getOutputCoords();\\n        setOutput(getX(\").concat(i, \"));\\n      }\\n    \");\n  }\n\n}\n\nvar aC = {\n  kernelName: \"StridedSlice\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      begin: a,\n      end: i,\n      strides: o,\n      beginMask: l,\n      endMask: u,\n      ellipsisMask: c,\n      newAxisMask: h,\n      shrinkAxisMask: d\n    } = s,\n        {\n      nonStrided: p,\n      $begin: f,\n      $strides: g,\n      size: m,\n      newShape: b,\n      outShape: x\n    } = Gn(r.shape, a, i, o, l, u, c, h, d),\n        y = mv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        shape: b\n      }\n    });\n    var k;\n\n    if (p) {\n      var _e511 = fI({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          begin: f,\n          size: m\n        }\n      });\n\n      k = mv({\n        inputs: {\n          x: _e511\n        },\n        backend: n,\n        attrs: {\n          shape: x\n        }\n      }), n.disposeIntermediateTensorInfo(_e511);\n    } else if (x.some(e => 0 === e)) k = n.makeTensorInfo(x, r.dtype, []);else if (n.shouldExecuteOnCPU([y])) {\n      var _e512 = n.texData.get(y.dataId),\n          _t416 = pn(y.shape, y.dtype, _e512.values),\n          _s236 = Sw(x, _t416, g, f);\n\n      k = n.makeTensorInfo(x, y.dtype, _s236.values);\n    } else {\n      var _e513 = new rC(f, g, x);\n\n      k = n.runWebGLProgram(_e513, [y], y.dtype);\n    }\n\n    var w = mv({\n      inputs: {\n        x: k\n      },\n      backend: n,\n      attrs: {\n        shape: x\n      }\n    });\n    return n.disposeIntermediateTensorInfo(y), n.disposeIntermediateTensorInfo(k), w;\n  }\n},\n    iC = {\n  kernelName: \"StringNGrams\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      separator: r,\n      nGramWidths: a,\n      leftPad: i,\n      rightPad: o,\n      padWidth: l,\n      preserveShortSequences: u\n    } = s,\n        {\n      data: c,\n      dataSplits: h\n    } = t,\n        d = n.readSync(c.dataId),\n        p = n.readSync(h.dataId),\n        [f, g] = Nw(d, p, r, a, i, o, l, u);\n    return [n.makeTensorInfo([f.length], \"string\", f), n.makeTensorInfo(h.shape, \"int32\", g)];\n  }\n},\n    oC = {\n  kernelName: \"StringSplit\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      skipEmpty: r\n    } = s,\n        {\n      input: a,\n      delimiter: i\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (1 !== a.shape.length) throw new Error(\"Input must be a vector, got shape: \".concat(a.shape));\n    if (0 !== i.shape.length) throw new Error(\"Delimiter must be a scalar, got shape: \".concat(i.shape));\n    var o = n.readSync(a.dataId),\n        l = n.readSync(i.dataId)[0],\n        [u, c, h] = Cw(o, l, r),\n        d = c.length;\n    return [n.makeTensorInfo([d, 2], \"int32\", u), n.makeTensorInfo([d], \"string\", c), n.makeTensorInfo([2], \"int32\", new Int32Array(h))];\n  }\n},\n    lC = {\n  kernelName: \"StringToHashBucketFast\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      numBuckets: r\n    } = s,\n        {\n      input: a\n    } = t;\n    if (\"string\" !== a.dtype) throw new Error(\"Input must be of datatype string\");\n    if (r <= 0) throw new Error(\"Number of buckets must be at least 1\");\n    var i = n.readSync(a.dataId),\n        o = Tw(i, r);\n    return n.makeTensorInfo(a.shape, \"int32\", o);\n  }\n},\n    uC = {\n  kernelName: \"Tan\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"return tan(x);\"\n  })\n},\n    cC = {\n  kernelName: \"Tanh\",\n  backendName: \"webgl\",\n  kernelFunc: lv({\n    opSnippet: \"\\n  float e2x = exp(-2.0 * abs(x));\\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\\n\"\n  })\n};\n\nclass hC {\n  constructor(e, t) {\n    this.variableNames = [\"A\"];\n    var n = new Array(e.length);\n\n    for (var _s237 = 0; _s237 < n.length; _s237++) {\n      n[_s237] = e[_s237] * t[_s237];\n    }\n\n    this.outputShape = n, this.rank = n.length;\n\n    var s = Ck(this.rank),\n        r = function (e) {\n      var t = e.length;\n      if (t > 5) throw Error(\"Tile for rank \".concat(t, \" is not yet supported\"));\n      if (1 === t) return \"imod(resRC, \".concat(e[0], \")\");\n      var n = [\"resRC.x\", \"resRC.y\", \"resRC.z\", \"resRC.w\", \"resRC.u\"],\n          s = [];\n\n      for (var _t417 = 0; _t417 < e.length; _t417++) {\n        s.push(\"imod(\".concat(n[_t417], \", \").concat(e[_t417], \")\"));\n      }\n\n      return s.join();\n    }(e);\n\n    this.userCode = \"\\n      void main() {\\n        \".concat(s, \" resRC = getOutputCoords();\\n        setOutput(getA(\").concat(r, \"));\\n      }\\n    \");\n  }\n\n}\n\nfunction dC(e) {\n  var {\n    inputs: t,\n    backend: n,\n    attrs: s\n  } = e,\n      {\n    x: r\n  } = t,\n      {\n    reps: a\n  } = s;\n\n  if (\"string\" === r.dtype || r.shape.length > 5) {\n    var _e514 = n.readSync(r.dataId),\n        _t418 = \"string\" === r.dtype ? _e514.map(e => qe(e)) : _e514,\n        _s238 = pn(r.shape, r.dtype, _t418),\n        _i103 = Rw(_s238, a);\n\n    return n.makeTensorInfo(_i103.shape, _i103.dtype, _i103.values);\n  }\n\n  var i = new hC(r.shape, a);\n  return n.runWebGLProgram(i, [r], r.dtype);\n}\n\nvar pC = {\n  kernelName: \"Tile\",\n  backendName: \"webgl\",\n  kernelFunc: dC\n};\n\nclass fC {\n  constructor(e) {\n    this.variableNames = [\"x\", \"indices\"], this.customUniforms = [{\n      name: \"n\",\n      type: \"int\"\n    }, {\n      name: \"firstPass\",\n      type: \"int\"\n    }, {\n      name: \"negativeInf\",\n      type: \"float\"\n    }, {\n      name: \"dir\",\n      type: \"int\"\n    }, {\n      name: \"inc\",\n      type: \"int\"\n    }], this.outputShape = e, this.userCode = \"\\n       void main() {\\n         ivec2 coords = getOutputCoords();\\n         int batch = coords[0];\\n         int elemIdx = coords[1];\\n\\n         // We compare elements pair-wise within a group of size 2 * inc.\\n         // The comparing rule for each group alternates between ascending\\n         // and descending. Within each group, we compare each pair at\\n         // positions i and i+inc. To decide whether an element at position i\\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\\n         // inc, it is in the first half of the group, we denote it as x0,\\n         // otherwise we denote it as x1.\\n         // For example, as shown in the Bitonic top K paper referenced above,\\n         // Figure5(a) shows that element[1] is in the\\n         // second half of the group when group size is 2, but it is in the\\n         // first half of the group when group size is 4.\\n\\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\\n\\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\\n\\n         // Denotes which direction indices are in (ascending or descending).\\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\\n         if (reverse == isGreater) { // Elements in opposite order of direction\\n           int iTemp = i0;\\n           i0 = i1;\\n           i1 = iTemp;\\n         }\\n         if (isFirstInPair) {\\n            setOutput(float(i0));\\n         } else {\\n            setOutput(float(i1));\\n         }\\n       }\\n     \";\n  }\n\n}\n\nclass gC {\n  constructor(e) {\n    this.variableNames = [\"x\", \"indices\"], this.customUniforms = [{\n      name: \"n\",\n      type: \"int\"\n    }, {\n      name: \"firstPass\",\n      type: \"int\"\n    }, {\n      name: \"k\",\n      type: \"int\"\n    }], this.outputShape = e, this.userCode = \"\\n    void main() {\\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\\n         ivec2 coords = getOutputCoords();\\n         int batch = coords[0];\\n         int elemIdx = coords[1];\\n\\n         // The output size is half of the previous size.\\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\\n         // we only need to output the indices at positions |, the indices at\\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\\n         // (Merge phase) in the Bitonic Top K paper referenced above.\\n         // For example, the paper shows we only need to output the orange bars.\\n         // The output sequence should look like this | | | | | | | |.\\n         // Because the sequence is halved, to map the output index back\\n         // to the previous sequence to find the corresponding value,\\n         // we need to double the index. When we double the index,\\n         // we basically interpolate a position, so 2i looks like\\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\\n         // of each 2k positions by - elemIdx % k. E.g. for output at\\n         // index 4,5,6,7, we want to get the corresponding element at\\n         // original index 8,9,10,11, for output at index 8,9,10,11,\\n         // we want to get the corresponding element at original index\\n         // 16,17,18,19, so on and so forth.\\n\\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\\n\\n         float x0 = getX(batch, i0);\\n         float x1 = i1 < n ? getX(batch, i1) : x0;\\n\\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\\n       }\\n     \";\n  }\n\n}\n\nfunction mC(e, t) {\n  null !== t && e.disposeIntermediateTensorInfo(t);\n}\n\nfunction bC(e) {\n  var t = 1;\n\n  for (; t < e;) {\n    t *= 2;\n  }\n\n  return t;\n}\n\nvar xC = {\n  kernelName: \"TopK\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r\n    } = t,\n        {\n      k: a,\n      sorted: i\n    } = s,\n        o = G().getNumber(\"TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD\"),\n        l = G().getNumber(\"TOPK_K_CPU_HANDOFF_THRESHOLD\"),\n        u = r.shape,\n        c = u[u.length - 1];\n\n    if (n.shouldExecuteOnCPU([r]) || c < o || a > l) {\n      var _e515 = n.readSync(r.dataId),\n          [_t419, _s239] = Aw(_e515, u, r.dtype, a, i);\n\n      return [n.makeTensorInfo(_t419.shape, _t419.dtype, _t419.values), n.makeTensorInfo(_s239.shape, _s239.dtype, _s239.values)];\n    }\n\n    if (0 === a) return u[u.length - 1] = 0, [n.makeTensorInfo(u, r.dtype, []), n.makeTensorInfo(u, \"int32\", [])];\n    if (1 === c) return [r, z$({\n      attrs: {\n        shape: u,\n        dtype: \"int32\",\n        value: 0\n      },\n      backend: n\n    })];\n    var h = n.texData.get(r.dataId),\n        p = null !== h && h.isPacked,\n        f = p ? n.unpackTensor(r) : r,\n        g = d(u) / c,\n        m = mv({\n      inputs: {\n        x: f\n      },\n      attrs: {\n        shape: [g, c]\n      },\n      backend: n\n    });\n    p && mC(n, f);\n    var b = bC(a),\n        x = bC(c);\n    var y = null;\n\n    var k = () => null === y ? [m, m] : [m, y],\n        w = (e, t, s) => {\n      var r = k(),\n          a = new fC(s),\n          i = y;\n      y = n.runWebGLProgram(a, r, \"int32\", [[c], [null === y ? 1 : 0], [Number.NEGATIVE_INFINITY], [e], [t]]), mC(n, i);\n    };\n\n    for (var _e516 = 1; _e516 < b; _e516 *= 2) {\n      var _t420 = 2 * _e516;\n\n      for (var _n291 = _e516; _n291 >= 1; _n291 /= 2) {\n        w(_t420, _n291, [g, x]);\n      }\n    }\n\n    for (var _e517 = x; _e517 > b; _e517 /= 2) {\n      var _t421 = k(),\n          _s240 = new gC([g, _e517 / 2]),\n          _r173 = y;\n\n      y = n.runWebGLProgram(_s240, _t421, \"int32\", [[c], [null === y ? 1 : 0], [b]]), mC(n, _r173);\n\n      var _a143 = b / 2,\n          _i104 = 2 * _a143;\n\n      for (var _e518 = _a143; _e518 >= 1; _e518 /= 2) {\n        w(_i104, _e518, y.shape);\n      }\n    }\n\n    var v = y;\n    y = fI({\n      inputs: {\n        x: y\n      },\n      backend: n,\n      attrs: {\n        begin: 0,\n        size: [g, a]\n      }\n    }), mC(n, v);\n    var I = eS({\n      inputs: {\n        x: m,\n        indices: y\n      },\n      backend: n,\n      attrs: {\n        axis: 1,\n        batchDims: 1\n      }\n    });\n    mC(n, m);\n    var $ = u.slice(0, -1);\n    $.push(a), v = y, y = mv({\n      inputs: {\n        x: y\n      },\n      attrs: {\n        shape: $\n      },\n      backend: n\n    }), mC(n, v);\n    var S = I;\n    return I = mv({\n      inputs: {\n        x: I\n      },\n      attrs: {\n        shape: $\n      },\n      backend: n\n    }), mC(n, S), [I, y];\n  }\n};\n\nclass yC {\n  constructor(e, t, n, s, r, a) {\n    this.variableNames = [\"Image\", \"Transforms\"], this.outputShape = a;\n    var i = \"nearest\" === n ? 1 : 2;\n    var o;\n\n    switch (s) {\n      case \"constant\":\n        o = 1;\n        break;\n\n      case \"reflect\":\n        o = 2;\n        break;\n\n      case \"wrap\":\n        o = 3;\n        break;\n\n      case \"nearest\":\n        o = 4;\n        break;\n\n      default:\n        o = 1;\n    }\n\n    this.userCode = \"\\n            float mapCoord(float outCoord, float len) {\\n              float inCoord = outCoord;\\n              if(\".concat(o, \" == 2) {\\n                if (inCoord < 0.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz2 = 2.0 * len;\\n                    if (inCoord < sz2) {\\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\\n                      inCoord;\\n                    }\\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\\n                  }\\n                } else if (inCoord > len - 1.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz2 = 2.0 * len;\\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\\n                    if (inCoord >= len) {\\n                      inCoord = sz2 - inCoord - 1.0;\\n                    }\\n                  }\\n                }\\n                return clamp(inCoord, 0.0, len - 1.0);\\n              } else if (\").concat(o, \" == 3) {\\n                if (inCoord < 0.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz = len - 1.0;\\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\\n                  }\\n                } else if (inCoord > len - 1.0) {\\n                  if (len <= 1.0) {\\n                    inCoord = 0.0;\\n                  } else {\\n                    float sz = len - 1.0;\\n                    inCoord -= len * float(int(float(inCoord / sz)));\\n                  }\\n                }\\n                return clamp(inCoord, 0.0, len - 1.0);\\n              } else if (\").concat(o, \" == 4) {\\n                return clamp(outCoord, 0.0, len - 1.0);\\n              } else {\\n                return outCoord;\\n              }\\n            }\\n\\n            float readWithFillValue(int batch, int coordY, int coordX,\\n              int channel) {\\n              float outputValue;\\n              if (0 <= coordY && coordY < \").concat(e, \" && 0 <= coordX && coordX < \").concat(t, \") {\\n                  outputValue = getImage(batch, coordY, coordX, channel);\\n              } else {\\n                outputValue = float(\").concat(r, \");\\n              }\\n              return outputValue;\\n            }\\n\\n            void main() {\\n              ivec4 coords = getOutputCoords();\\n              float outputValue;\\n              int batch = coords[0];\\n              int x = coords[2];\\n              int y = coords[1];\\n              int channel = coords[3];\\n              float xf = float(x);\\n              float yf = float(y);\\n              float a1 = getTransforms(batch, 0);\\n              float a2 = getTransforms(batch, 1);\\n              float a3 = getTransforms(batch, 2);\\n              float b1 = getTransforms(batch, 3);\\n              float b2 = getTransforms(batch, 4);\\n              float b3 = getTransforms(batch, 5);\\n              float c1 = getTransforms(batch, 6);\\n              float c2 = getTransforms(batch, 7);\\n              float projection = c1 * xf + c2 * yf + 1.0;\\n              if (projection == 0.0) {\\n                outputValue = float(\").concat(r, \");\\n              } else {\\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\\n                float mapX = mapCoord(inX, float(\").concat(t, \"));\\n                float mapY = mapCoord(inY, float(\").concat(e, \"));\\n\\n                if (\").concat(i, \" == 1) {\\n                  int coordY = int(round(mapY));\\n                  int coordX = int(round(mapX));\\n                  outputValue = readWithFillValue(batch, coordY, coordX,\\n                    channel);\\n                } else {\\n                  float yFloor = floor(mapY);\\n                  float xFloor = floor(mapX);\\n                  float yCeil = yFloor + 1.0;\\n                  float xCeil = xFloor + 1.0;\\n                  float valueYFloor = (xCeil - mapX) *\\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\\n                  (mapX - xFloor) *\\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\\n                  float valueYCeil = (xCeil - mapX) *\\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\\n                  (mapX - xFloor) *\\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\\n                  outputValue = (yCeil - mapY) * valueYFloor +\\n                  (mapY - yFloor) * valueYCeil;\\n                }\\n              }\\n              setOutput(outputValue);\\n            }\\n        \");\n  }\n\n}\n\nvar kC = {\n  kernelName: \"Transform\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      image: r,\n      transforms: a\n    } = t,\n        {\n      interpolation: i,\n      fillMode: o,\n      fillValue: l,\n      outputShape: u\n    } = s,\n        [c, h, d, p] = r.shape,\n        [f, g] = null != u ? u : [h, d],\n        m = new yC(h, d, i, o, l, [c, f, g, p]);\n    return n.runWebGLProgram(m, [r, a], \"float32\");\n  }\n},\n    wC = {\n  kernelName: \"Unique\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      attrs: n,\n      backend: s\n    } = e,\n        {\n      axis: r\n    } = n,\n        {\n      x: a\n    } = t;\n    ck(a, \"unique\"), console.warn(\"WARNING: \", \"UI might be locked temporarily as data is being downloaded\");\n    var i = s.readSync(a.dataId),\n        {\n      outputValues: o,\n      outputShape: l,\n      indices: u\n    } = Dw(i, r, a.shape, a.dtype);\n    return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], \"int32\", u)];\n  }\n},\n    vC = {\n  kernelName: \"Unpack\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      value: r\n    } = t;\n    var {\n      axis: a\n    } = s;\n    a < 0 && (a += r.shape.length);\n    var i = r,\n        o = i.shape.length,\n        l = r.shape[a],\n        u = new Array(o - 1);\n    var c = 0;\n\n    for (var _e519 = 0; _e519 < o; _e519++) {\n      _e519 !== a && (u[c++] = i.shape[_e519]);\n    }\n\n    var h = [],\n        d = new Array(o).fill(0),\n        p = i.shape.slice();\n    p[a] = 1;\n    var f = new Array(l);\n\n    for (var _e520 = 0; _e520 < f.length; _e520++) {\n      d[a] = _e520;\n\n      var _t422 = fI({\n        inputs: {\n          x: i\n        },\n        backend: n,\n        attrs: {\n          begin: d,\n          size: p\n        }\n      }),\n          _s241 = mv({\n        inputs: {\n          x: _t422\n        },\n        backend: n,\n        attrs: {\n          shape: u\n        }\n      });\n\n      f[_e520] = _s241, h.push(_t422);\n    }\n\n    return h.forEach(e => n.disposeIntermediateTensorInfo(e)), f;\n  }\n};\n\nclass IC {\n  constructor(e, t) {\n    this.variableNames = [\"x\", \"segmentIds\"];\n    var n = e.windowSize,\n        s = e.batchSize,\n        r = e.inSize,\n        a = e.numSegments,\n        i = a * Math.ceil(r / n);\n    this.outputShape = [s, i];\n    var o = 4 * Math.floor(n / 4),\n        l = n % 4,\n        u = \"\\n        sumValue += dot(values, segFilter);\\n    \";\n    var c = \"\";\n    r % n > 0 && (c = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return initializationValue;\\n        }\\n      \"));\n    var h = \"\";\n    r % n > 0 && (h = \"\\n        if (inIdx < 0 || inIdx >= \".concat(r, \") {\\n          return -1.0;\\n        }\\n      \")), this.userCode = \"\\n      const float initializationValue = 0.0;\\n\\n      float getValue(int batch, int inIdx) {\\n        \".concat(c, \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      float getSegmentIdAtIndex(int inIdx) {\\n        \").concat(h, \"\\n        return getSegmentIds(inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = int(floor(float(outIdx) / float(\\n          \").concat(a, \")) * float(\").concat(n, \"));\\n        int currentSeg = int(mod(float(outIdx), float(\").concat(a, \")));\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \").concat(o, \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\\n          );\\n\\n          \").concat(u, \"\\n        }\\n\\n        int inIdx = inOffset + \").concat(o, \";\\n        if (\").concat(1 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            0,\\n            0,\\n            0\\n          );\\n\\n          \").concat(u, \"\\n        } else if (\").concat(2 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n              0,\\n              0\\n          );\\n\\n          \").concat(u, \"\\n        } else if (\").concat(3 === l, \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            0\\n          );\\n\\n          \").concat(u, \"\\n        }\\n        setOutput(sumValue);\\n      }\\n    \");\n  }\n\n}\n\nvar $C = [xS, kS, Ev, Av, Fv, Dv, Ov, zv, Bv, Pv, qv, jv, Kv, Xv, Jv, Yv, Zv, nI, tI, aI, iI, oI, cI, mI, bI, vI, $I, CI, RI, tv, zI, XI, YI, GI, ZI, QI, JI, e$, t$, s$, o$, l$, c$, m$, b$, p$, y$, w$, v$, I$, $$, S$, N$, E$, A$, D$, M$, B$, W$, V$, G$, j$, X$, Y$, Z$, tS, nS, sS, Qw, rS, OI, aS, iS, oS, rv, lS, uS, cS, dS, hS, pS, fS, gS, vS, SS, $S, TS, ES, RS, IS, AS, FS, DS, MS, LS, qS, gv, KS, YS, ZS, eN, yI, nN, aN, iN, cN, hN, ov, dN, fN, wI, PS, gN, bN, mN, bv, kN, vN, SN, CN, RN, FN, DN, _N, MN, zN, BN, WN, UN, VN, GN, gI, HS, HN, qN, jN, KN, XN, YN, JN, ZN, eC, tC, nC, sC, aC, iC, oC, lC, VS, Sv, uC, cC, pC, xC, kC, Cv, wC, vC, {\n  kernelName: \"UnsortedSegmentSum\",\n  backendName: \"webgl\",\n  kernelFunc: function kernelFunc(e) {\n    var {\n      inputs: t,\n      backend: n,\n      attrs: s\n    } = e,\n        {\n      x: r,\n      segmentIds: a\n    } = t,\n        {\n      numSegments: i\n    } = s,\n        o = r.shape.length,\n        l = [];\n    var u = 0;\n    var c = Zr([u], o);\n    var h = r;\n    null != c && (h = Nv({\n      inputs: {\n        x: r\n      },\n      backend: n,\n      attrs: {\n        perm: c\n      }\n    }), l.push(h), u = ea(1, o)[0]);\n    var p = el(h.shape, u, i),\n        f = d([h.shape[u]]),\n        g = mv({\n      inputs: {\n        x: h\n      },\n      backend: n,\n      attrs: {\n        shape: [-1, f]\n      }\n    });\n    l.push(g);\n\n    var m = ft(r.dtype),\n        b = (e, t, s, r, a) => {\n      var i = e.shape[0],\n          o = e.shape[1],\n          u = Qo(o, a),\n          c = new IC({\n        windowSize: u,\n        inSize: o,\n        batchSize: i,\n        numSegments: a\n      }, t),\n          h = n.compileAndRun(c, [e, s], r);\n      if (l.push(h), h.shape[1] === a) return h;\n      var d = pN({\n        backend: n,\n        attrs: {\n          start: 0,\n          stop: a,\n          step: 1,\n          dtype: \"float32\"\n        }\n      }),\n          p = dC({\n        inputs: {\n          x: d\n        },\n        backend: n,\n        attrs: {\n          reps: [o / u]\n        }\n      });\n      return l.push(d), l.push(p), b(h, t, p, r, a);\n    },\n        x = mv({\n      inputs: {\n        x: b(g, \"unsortedSegmentSum\", a, m, i)\n      },\n      backend: n,\n      attrs: {\n        shape: p\n      }\n    });\n\n    var y = x;\n\n    if (null != c) {\n      l.push(x);\n\n      var _e521 = Qr(c);\n\n      y = Nv({\n        inputs: {\n          x: y\n        },\n        backend: n,\n        attrs: {\n          perm: _e521\n        }\n      });\n    }\n\n    return l.forEach(e => n.disposeIntermediateTensorInfo(e)), y;\n  }\n}, rN];\n\nfor (var _e522 of $C) {\n  ee(_e522);\n}\n\nvar SC = [\"worker\"],\n    NC = {\n  train: function () {\n    var _train = _asyncToGenerator(function* (e) {\n      var {\n        data: t\n      } = e;\n      var n = [];\n\n      var s = function (e, t, n) {\n        if (c(e), null != t && 3 !== t.length) throw new Error(\"tensor3d() requires shape to have three numbers\");\n        var s = Ct(e, n);\n        if (3 !== s.length && 1 !== s.length) throw new Error(\"tensor3d() requires values to be number[][][] or flat/TypedArray\");\n        if (1 === s.length && null == t) throw new Error(\"tensor3d() requires shape to be provided when `values` are a flat array\");\n        return _t(e, t, s, n);\n      }(t.xData, [t.xData.length, t.model.inputShape[0], t.model.inputShape[1]]),\n          r = $n(bi(t.yData, \"int32\"), t.model.labels.length),\n          {\n        epochs: a,\n        model: i\n      } = function (e, t) {\n        var n = new Rd(void 0);\n        return \"\" == t && (n.add(Mf({\n          inputShape: e.inputShape,\n          kernelSize: [4],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(zf({\n          poolSize: [2]\n        })), n.add(Lf({\n          rate: .1\n        })), n.add(Mf({\n          kernelSize: [2],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(zf({\n          poolSize: [2]\n        })), n.add(Lf({\n          rate: .1\n        })), n.add(Mf({\n          kernelSize: [2],\n          strides: 1,\n          filters: 16,\n          activation: \"relu\"\n        })), n.add(Lf({\n          rate: .1\n        })), n.add(new qp(void 0)), n.add(new Hp({\n          units: e.outputShape,\n          activation: \"softmax\"\n        })), n.compile({\n          loss: \"categoricalCrossentropy\",\n          optimizer: \"adam\",\n          metrics: [\"accuracy\"]\n        })), {\n          model: n,\n          epochs: 250\n        };\n      }(t.model, t.modelBlockJSON);\n\n      var o;\n      yield i.fit(s, r, {\n        epochs: a,\n        callbacks: {\n          onEpochEnd: CC\n        }\n      }).then(e => {\n        n = e.history.acc;\n      }), yield i.save({\n        save: e => {\n          o = e;\n          var t = {\n            modelArtifactsInfo: {\n              dateSaved: new Date(),\n              modelTopologyType: \"JSON\"\n            }\n          };\n          return Promise.resolve(t);\n        }\n      });\n      var l = o.weightData;\n      return o.weightData = null, {\n        modelJSON: JSON.stringify(o),\n        modelWeights: l,\n        trainingInfo: n\n      };\n    });\n\n    function train(_x56) {\n      return _train.apply(this, arguments);\n    }\n\n    return train;\n  }(),\n  predict: function () {\n    var _predict = _asyncToGenerator(function* (e) {\n      var {\n        data: t\n      } = e,\n          n = Ot(t.zData),\n          s = JSON.parse(t.model.modelJSON);\n      s.weightData = new Uint32Array(t.model.weights).buffer;\n      var r = yield (a = {\n        load: () => Promise.resolve(s)\n      }, null == i && (i = {}), function () {\n        var _ref34 = _asyncToGenerator(function* (e, t) {\n          if (null == t && (t = {}), \"string\" == typeof e) {\n            var _n292 = Ht.getLoadHandlers(e, t);\n\n            if (0 === _n292.length) _n292.push(vn(e, t));else if (_n292.length > 1) throw new xu(\"Found more than one (\".concat(_n292.length, \") load handlers for URL '\").concat(e, \"'\"));\n            e = _n292[0];\n          }\n\n          return function () {\n            var _ref35 = _asyncToGenerator(function* (e, t, n) {\n              if (null == n && (n = {}), null == e.load) throw new xu(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n              var s = yield e.load();\n              var r = s.modelTopology;\n              null != r.model_config && (r = r.model_config);\n              var a = null == n.strict || n.strict,\n                  i = null != s.weightData && null != s.weightSpecs && a,\n                  o = Rh(nd(r), void 0, i),\n                  l = s.trainingConfig;\n\n              if (null != l && o.loadTrainingConfig(l), null != s.userDefinedMetadata && o.setUserDefinedMetadata(s.userDefinedMetadata), null != s.weightData) {\n                if (null == s.weightSpecs) throw new xu(\"LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.\");\n\n                var {\n                  modelWeights: _e523,\n                  optimizerWeights: _t423\n                } = function (e, t) {\n                  var n = function (e, t) {\n                    var n = {};\n                    var s,\n                        r = 0;\n\n                    for (var _a144 of t) {\n                      var _t424 = _a144.name,\n                          _i105 = _a144.dtype,\n                          _o75 = _a144.shape,\n                          _l54 = d(_o75);\n\n                      var _u42 = void 0;\n\n                      if (\"quantization\" in _a144) {\n                        var _n293 = _a144.quantization;\n\n                        if (\"uint8\" === _n293.dtype || \"uint16\" === _n293.dtype) {\n                          if (!(\"min\" in _n293) || !(\"scale\" in _n293)) throw new Error(\"Weight \".concat(_a144.name, \" with quantization \").concat(_n293.dtype, \" doesn't have corresponding metadata min and scale.\"));\n                        } else {\n                          if (\"float16\" !== _n293.dtype) throw new Error(\"Weight \".concat(_a144.name, \" has unknown quantization dtype \").concat(_n293.dtype, \". Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.\"));\n                          if (\"float32\" !== _i105) throw new Error(\"Weight \".concat(_a144.name, \" is quantized with \").concat(_n293.dtype, \" which only supports weights of type float32 not \").concat(_i105, \".\"));\n                        }\n\n                        var _o76 = Mt[_n293.dtype],\n                            _c36 = e.slice(r, r + _l54 * _o76),\n                            _h21 = \"uint8\" === _n293.dtype ? new Uint8Array(_c36) : new Uint16Array(_c36);\n\n                        if (\"float32\" === _i105) {\n                          if (\"uint8\" === _n293.dtype || \"uint16\" === _n293.dtype) {\n                            _u42 = new Float32Array(_h21.length);\n\n                            for (var _e524 = 0; _e524 < _h21.length; _e524++) {\n                              _u42[_e524] = _h21[_e524] * _n293.scale + _n293.min;\n                            }\n                          } else {\n                            if (\"float16\" !== _n293.dtype) throw new Error(\"Unsupported quantization type \".concat(_n293.dtype, \" for weight type float32.\"));\n                            void 0 === s && (s = Gt()), _u42 = s(_h21);\n                          }\n                        } else {\n                          if (\"int32\" !== _i105) throw new Error(\"Unsupported dtype in weight '\".concat(_t424, \"': \").concat(_i105));\n                          if (\"uint8\" !== _n293.dtype && \"uint16\" !== _n293.dtype) throw new Error(\"Unsupported quantization type \".concat(_n293.dtype, \" for weight type int32.\"));\n                          _u42 = new Int32Array(_h21.length);\n\n                          for (var _e525 = 0; _e525 < _h21.length; _e525++) {\n                            _u42[_e525] = Math.round(_h21[_e525] * _n293.scale + _n293.min);\n                          }\n                        }\n                        r += _l54 * _o76;\n                      } else if (\"string\" === _i105) {\n                        var _t425 = d(_a144.shape);\n\n                        _u42 = [];\n\n                        for (var _n294 = 0; _n294 < _t425; _n294++) {\n                          var _t426 = new Uint32Array(e.slice(r, r + 4))[0];\n                          r += 4;\n\n                          var _n295 = new Uint8Array(e.slice(r, r + _t426));\n\n                          _u42.push(_n295), r += _t426;\n                        }\n                      } else {\n                        var _s242 = Mt[_i105],\n                            _a145 = e.slice(r, r + _l54 * _s242);\n\n                        if (\"float32\" === _i105) _u42 = new Float32Array(_a145);else if (\"int32\" === _i105) _u42 = new Int32Array(_a145);else if (\"bool\" === _i105) _u42 = new Uint8Array(_a145);else {\n                          if (\"complex64\" !== _i105) throw new Error(\"Unsupported dtype in weight '\".concat(_t424, \"': \").concat(_i105));\n                          {\n                            _u42 = new Float32Array(_a145);\n\n                            var _e526 = new Float32Array(_u42.length / 2),\n                                _s243 = new Float32Array(_u42.length / 2);\n\n                            for (var _t427 = 0; _t427 < _e526.length; _t427++) {\n                              _e526[_t427] = _u42[2 * _t427], _s243[_t427] = _u42[2 * _t427 + 1];\n                            }\n\n                            var _r174 = Ot(_e526, _o75, \"float32\"),\n                                _i106 = Ot(_s243, _o75, \"float32\");\n\n                            n[_t424] = Dt(_r174, _i106), _r174.dispose(), _i106.dispose();\n                          }\n                        }\n                        r += _l54 * _s242;\n                      }\n\n                      \"complex64\" !== _i105 && (n[_t424] = Ot(_u42, _o75, _i105));\n                    }\n\n                    return n;\n                  }(e, t),\n                      s = {},\n                      r = [];\n\n                  return t.forEach(e => {\n                    \"optimizer\" === e.group ? r.push({\n                      name: e.name,\n                      tensor: n[e.name]\n                    }) : s[e.name] = n[e.name];\n                  }), {\n                    modelWeights: s,\n                    optimizerWeights: r\n                  };\n                }(s.weightData, s.weightSpecs);\n\n                o.loadWeights(_e523, a), null != o.optimizer && _t423.length > 0 && (yield o.optimizer.setWeights(_t423)), Zn(_e523), Zn(_t423.map(e => e.tensor));\n              }\n\n              return o;\n            });\n\n            return function (_x60, _x61, _x62) {\n              return _ref35.apply(this, arguments);\n            };\n          }()(e, 0, t);\n        });\n\n        return function (_x58, _x59) {\n          return _ref34.apply(this, arguments);\n        };\n      }()(a, i));\n      var a, i;\n      var o = yield r.predict(n);\n      return {\n        prediction: yield o.dataSync()\n      };\n    });\n\n    function predict(_x57) {\n      return _predict.apply(this, arguments);\n    }\n\n    return predict;\n  }()\n};\n\nfunction CC(e, t) {\n  self.postMessage({\n    type: \"progress\",\n    data: t\n  });\n}\n\nself.addEventListener(\"message\", /*#__PURE__*/function () {\n  var _ref36 = _asyncToGenerator(function* (t) {\n    var n = t.data,\n        {\n      worker: s\n    } = n,\n        r = function (e, t) {\n      if (null == e) return {};\n      var n,\n          s,\n          r = {},\n          a = Object.keys(e);\n\n      for (s = 0; s < a.length; s++) {\n        t.indexOf(n = a[s]) >= 0 || (r[n] = e[n]);\n      }\n\n      return r;\n    }(n, SC);\n\n    if (\"tf\" !== s) return;\n    var a = e({\n      worker: s\n    }, r, {\n      data: yield function () {\n        var _ref37 = _asyncToGenerator(function* (e) {\n          try {\n            var _t428 = NC[e.type];\n            return yield null == _t428 ? void 0 : _t428(e);\n          } catch (e) {\n            return void console.error(e);\n          }\n        });\n\n        return function (_x64) {\n          return _ref37.apply(this, arguments);\n        };\n      }()(n)\n    });\n    self.postMessage(a);\n  });\n\n  return function (_x63) {\n    return _ref36.apply(this, arguments);\n  };\n}()), console.debug(\"jacdac tf: worker registered\");"],"names":[],"sourceRoot":""}